\chapter{Estado del Arte}
En este capítulo se describirán las investigaciones anteriores con relación al Aprendizaje Automático, además de sus aplicaciones. También se verán algunas investigaciones referente al reconocimiento de voz y los algoritmos usados para estas tareas.

Este trabajo también presentará investigaciones referentes a Aprendizaje Profundo, exclusivamente nos enfocaremos a la Redes Neuronales Recurrentes (RNN), ya que son usadas en este seminario.

%---Escribir un texto de un o dos párrafo(s) máximo de 10 líneas con una introducción al capítulo 

%---El capítulo estado del arte es tanto o más importante que la tesis en sí. En el se debe especificar que desarrollo relacionado a tu tesis existe ya a nivel global y en que se diferencia tu trabajo de ellos. Por lo tanto un análisis exhaustivo de la especialidad y de los trabajos previos es tanto o más importante que el trabajo en sí, ya que indica un alto conocimiento de la materia si está bien estudiado.

%---En este capítulo van a ir muchas citas \cite{Wan09} de trabajos pero sobre todo de artículos científico, haga un buen estudio del arte \cite{Shuo10,Feldmann03}

\section{Aprendizaje Automático}
El uso del Aprendizaje Automático representa una gran ventaja para empresas que manejan gran cantidad de datos debido a que permiten descubrir patrones y analizar estos.

\subsection{GPGPU Performance and Power Estimation Using Machine Learning}
Un equipo conformado por investigadores\cite{GPU} de AMD y The University of Texas at Austin, fueron quienes propusieron el uso de redes neuronales para predecir el rendimiento de una GPU.
En la actualidad existen empresas dedicadas a la creación de GPUs, en el proceso una parte fundamental es la verificación del rendimiento de las GPUs. Actualmente existen simuladores conocidos como GPGPU-SIM que permiten realizar estimaciones precisas pero estos presentan algunas dificultades como el tiempo empleado en configurarlos en base al hardware real, no obstante, este proceso se encuentra propenso a errores. 
\subsection{Handshape recognition for Argentinian Sign	Language using ProbSom}
Investigadores de la Universidad de La Plata, en Argentina  conformado por Franco Ronchetti, Facundo Quiroga, César Estrebou, y Laura Lanzarini\cite{HAND}, desarrollaron un sistema que permite el reconocimiento de lenguaje de señas argentino. Esta investigación fue realizada usando una técnica llamada ProbSom, esta puede ser comparada con otros métodos como las Máquinas de Soporte Vectorial, Bosques Aleatorios y Redes Neuronales.
\section{Aprendizaje Profundo}
Dentro del área de Aprendizaje Automático encontramos Deep Learning o Aprendizaje Profundo el cual consiste en un conjunto de algoritmos que modela abstracciones de alto nivel.\\
En esta sección hablaremos de un paper que nos sirvió de introducción al campo del aprendizaje profundo.

\subsection{Deep Machine Learning - A New Frontier in Artificial Intelligence}
Este trabajo de investigación fue realizado por investigadores Thomas	Karnowski, Derek Rose - Oak Ridge National Laboratory y Itamar	Arel - University of Tennessee \cite{DML}, el objetivo principal de este trabajo fue presentarnos el aprendizaje profundo como un camino para la imitación del cerebro humano y sus principales cualidades como el reconocimientos de objetos, rostros, etc.\\
En este paper presenta una introducción a los temas de \textit{Convolutional Neural Network (CNN)} y \textit{Deep Belief Network}, nos describe a las CNN como una familia de redes neuronales multicapas que fueron diseñadas para tratar datos de dimensionalidad 2 como lo son las imágenes y los videos.\\
Por otro lado, también nos muestra las aplicaciones del aprendizaje profundo como: análisis de documentos, detección de voz, rostro, procesamiento natural del lenguaje, etc.

La aplicación de la inteligencia artificial no solo se realizó para investigaciones, sino también en algunas empresas privadas que apoyan el campo del Aprendizaje Profundo con el objetivo de buscar sus aplicaciones comerciales, entre estas empresas tenemos a: Numenta y Binatix.

\subsection{On Optimization Methods for Deep Learning}
Un equipo de la Universidad de Standford realizó unas pruebas con el objetivo de encontrar métodos adecuados para un entrenamiento en aprendizaje profundo. El equipo se percato de lo común que resulta el uso de gradiente de descenso estocástica (SGD por sus siglas en inglés) en aprendizaje profundo. Se realizaron pruebas con otros métodos de optimización como la gradiente conjugada y Limited memmory BFGS(L-BFGS) los cuales permitieron acelerar el proceso de entrenamiento de algoritmos de Aprendizaje Profundo mostrando en su mayoría mejores resultados que el SGD. \textquotedblleft Usando L-BFGS el modelo CNN alcanza el 0.69\%  en el estándar del MNIST dataset. \textquotedblright \cite{Optimization}


\section{Reconocimiento de Voz}
\subsection{Review of Algorithms and Applications in Speech Recognition System}
Este trabajo fue realizado por CR Rashmi del \textit{ Cork Institute of Tecnology (CIT) } en la investigación se describe el reconocimiento del habla como un método para poder realizar distintas aplicaciones como: reconocimiento del hablante (Identificación Biométrica), emociones, acento, etc. Además se presentan distintos algoritmos que usan transformada de fourier y modelos probabilísticos que son aplicados a tareas de reconocimiento de voz.\\ Esta investigación se centra en los algoritmos para la extracción de características y coincidencia de patrones.\\ Entre principales algoritmos para la extracción de características que muestran tenemos: RCC, MFCC, LPC, etc. Siendo el MFCC uno de los mejores para realizar tareas de reconocimiento del hablante. Por otro lado, en coincidencia de patrones tenemos algoritmos como VQ, HMM, SVM, MLP, GMM, etc. Para tareas de reconocimiento de emociones y géneros destaca el GMM.
\subsection{SPEECH RECOGNITION WITH DEEP RECURRENT NEURAL NETWORKS}
Esta investigación realizada por los investigadores Alex Graves, Abdel-rahman Mohamed y Geoffrey Hinton de la Universidad de Toronto. El principal objetivo de esta investigación fue utilizar las redes neuronales recurrentes para el reconocimiento de fonemas utilizando el conjunto de datos TIMIT, el uso de las redes neuronales resulta adecuado debía a la naturaleza dinámica del habla.\\ El tipo de entrenamiento utilizado fue \textit{ end-to-end training} además se utilizan distribuciones diferenciales para todas las posibles salidas fonéticas. Entre los métodos estudiados para estas distribuciones de salida tenemos \textit{Connectionist Temporal Classification (CTC)} este método decide si emitir una etiqueta de acuerdo al fonema identificado o no emitirla.\\  \textquotedblleft Las redes neuronales entrenadas con CTC son generalmente bidireccionales para asegurar que la distribución de salida dependa únicamente de la secuencia de entrada \textquotedblright. Otro método estudiado en esta investigación de RNN transducer el cual predice un fonema dado uno previo. En la experimentación fueron usados 2 reguladores \textit{parada temprana} y \textit{pesos de ruidos}. \textquotedblleft CLC se obtiene un porcentaje de error de 23.9 \% a 18.4 \% a medida que se aumentan los niveles ocultos de la red \textquotedblright.

\subsection{EFFICIENT CEPSTRAL NORMALIZATION FOR ROBUST SPEECH RECOGNITION}
Esta investigación estuvo a cargo de Fu-Hua Liu, Richard M. Stern, Xuedong Huang y Alejandro Acero del departamento de ingeniería eléctrica e informática de la Universidad de Carnegie Mellon. El objetivo de esta investigación fue comparar los procedimientos basados en cepstrum usados en el reconocimiento de voz sobre variedad de entornos acústicos.\\ Para los autores \textquotedblleft Los estudios muestran que los sistemas de reconocimiento de voz que son diseñados para ser independientes del hablante funcionan de manera incorrecta cuando se prueban distintos micrófonos o entornos con los cuales fueron entrenados \textquotedblright. Una solución a este problema es la aplicación de técnicas de normalización cepstral como \textit{ SNR - Dependet Cepstral Normalization (SDCN)}, \textit{Fixed Codeword-Dependet Cepstral Normalization (FCDCN)} y \textit{ Multiple fixed codeword-dependent cepstral normalization (MFCDCN)}.\\ Entre el FCDCN y MFCDCN este último resulta ser mejor debido a que no requiere del entrenamiento del especifico como lo hace el FCDCN.

\subsection{DELTA-SPECTRAL CEPSTRAL COEFFICIENTS FOR ROBUST SPEECH RECOGNITION}

El presente paper fue realizado por Kshitiz Kumar, Chanwoo Kim y Richard M. Stern del departamento de ingeniería eléctrica e informática de la Universidad de Carnegie Mellon. En esta investigación se busca diseñar un sistema de reconocimiento de voz más robusto mediante el uso de las características delta-espectrales. En palabra de los autores \textquotedblleft \textit{A pesar que las características delta cepstrales capturan la información dinámica y mejoran la precisión del reconocimiento de voz no son robustos contra el ruido y reverberación.}\textquotedblright

\subsection{Voice Recognition Algorithms using Mel Frequency Cepstral Coefficient (MFCC) and Dynamic Time Warping (DTW) Techniques
}
Esta investigación fue realizada por Lindasalwa Muda, Mumtaj Begam y I. Elamvazuthi, en esta se describen los principios involucrados en el reconocimiento de voz como la extracción de características y patrones. Al igual que otras investigaciones los autores afirman \textquotedblleft \textit{La voz es una señal de infinita información. Un análisis directo y sintetizado es requerido para la gran cantidad de señal contenida en la señal.} \textquotedblright \\ El reconocimiento de voz puede ser divido en 2 fases una fase de entrenamiento en que el hablante provee información o muestras de su voz y una fase de testeo donde se verifica que la voz de entrada coincida con la del hablante del proceso de entrenamiento.	Los investigadores utilizan MFCC para la extracción de características y DTW para reconocimiento de los patrones. En las pruebas de identificación se logro encontrar una distorsión optima en DTW que permitió reconocer al hablante.
\subsection{Convolutional Neural Networks for Speech Recognition}
Entre los distintos modelos existentes en redes neuronales profundas ha surgido la necesidad de realizar modelos híbridos como \textit{Deep Neural Network- Hidden Markov Model (DNN-HMM)} y \textit{Gaussian Mixture Model - Hidden Markov Model (GMM-HMM)}. La presente investigación encontró que la primera es más robusta debido a la capacidad que poseen las redes neuronales al momento de modelar correlaciones complejas de las características de la voz.\\ Los resultados mostraron que usando CNN se obtuvo una mejora de 6-10 \% en tareas de phone recognition y búsqueda de voz en un gran vocabulario.
\subsection{TIME-FREQUENCY CONVOLUTIONAL NETWORKS FOR ROBUST SPEECH RECOGNITION}
Este estudio usa a las redes neuronales convolucionales profundas (DCNN) para generar una arquitectura más robusta contra el ruido y otras variaciones del entorno. DCNN usa los filtros de convolución para así poder remover las distorciones cross-spectral una cualidad de este tipo de red es que no utiliza la convolución sobre el tiempo. Por lo cual esta convolución es trata en esta investigación definiendo un esquema llamado time-frequency convolutional network (TFCNN), esta red aplica 2 capas de convolución paralelas una para la frecuencia y otra para el tiempo.\\ En las pruebas realizadas se nota una mejora al probar con ruidos, canales y datos dañados con reverberación a comparación del uso de DCNN.
\section{Conclusiones}
%Hemos visto la necesidad....
En el campo del reconocimiento de voz se encontraron métodos como el MFCC y delta - MFCC los cuales permiten extraer las características necesarias para el análisis. Además las redes neuronales recurrentes surgen como una alternativa para el tratado del reconocimiento de voz.
%Poner unas conclusiones del capítulo y lo más importante, donde se enfoca tu trabajo y lo que se diferenncia del resto

