{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importanción de librerías "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import librosa\n",
    "from python_speech_features import mfcc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de ficheros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función se encarga de generar un archivo txt de manera que este contenga 2 elementos por fila ('name_file','etiqueta') de esta manera permitirá poder entrenar la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "def generate_file_data(dir,name):\n",
    "    directory=dir\n",
    "    #el nombre de los archivos posee el primer dígito en el nombre de esta forma permitirá etiquetarlos.\n",
    "    a={'0':'cero','1':'uno','2':'dos','3':'tres','4':'cuatro','5':'cinco','6':'seis','7':'siete','8':'ocho','9':'nueve'}\n",
    "    da=os.listdir(directory)\n",
    "    # ordena los archivos\n",
    "    da.sort()\n",
    "    file = open(dir+name+'.txt',\"w\")\n",
    "    for filename in da:\n",
    "        if '.wav' in filename:\n",
    "            file.write(filename+','+a[filename[0]]+'\\n')\n",
    "    file.close() \n",
    "    # genera el fichero\n",
    "    with open(directory+'/'+name+'.txt') as f:\n",
    "        read_data = f.read()\n",
    "        f.closed\n",
    "    read_data=read_data.split('\\n')\n",
    "    read_data=read_data[0:len(read_data)-1]\n",
    "    return read_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding words with One Hot Encoding\n",
    "En esta sección se usará one hot encoding para representar las palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "vocabulary_words=np.array(['cero','uno','dos','tres','cuatro','cinco','seis','siete','ocho','nueve'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore',categories='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories='auto',\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "       n_values=None, sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder.fit(X=vocabulary_words.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['cero', 'cinco', 'cuatro', 'dos', 'nueve', 'ocho', 'seis', 'siete',\n",
       "        'tres', 'uno'], dtype='<U6')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=onehot_encoder.transform(vocabulary_words.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['cero'],\n",
       "       ['uno'],\n",
       "       ['dos'],\n",
       "       ['tres'],\n",
       "       ['cuatro'],\n",
       "       ['cinco'],\n",
       "       ['seis'],\n",
       "       ['siete'],\n",
       "       ['ocho'],\n",
       "       ['nueve']], dtype='<U6')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder.inverse_transform(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se muestran las funciones para codificar y decodificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x):# tomará un array de string y lo transformada a encode\n",
    "    return onehot_encoder.transform(x.reshape(-1,1)).toarray()\n",
    "def decode(x):\n",
    "    return onehot_encoder.inverse_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=encode(np.array(['uno','dos']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['uno'],\n",
       "       ['dos']], dtype='<U6')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_features(DIR,list_dir):\n",
    "    mfcc_audios=[]\n",
    "    for dir in list_dir:\n",
    "        wave, sr = librosa.load(DIR+dir, mono=True)\n",
    "        features= librosa.feature.mfcc(wave, sr,n_mfcc=20)\n",
    "        features=librosa.feature.delta(features)\n",
    "        \n",
    "        #features = sklearn.preprocessing.minmax_scale\n",
    "        #features=sklearn.preprocessing.normalize(features,axis=1)\n",
    "        try:\n",
    "            features=np.pad(features,((0,0),(0,160-len(features[0]))),mode='constant', constant_values=0)\n",
    "        except OSError as err:\n",
    "            print(dir)\n",
    "        scaler = sklearn.preprocessing.StandardScaler()\n",
    "        features=scaler.fit_transform(features)\n",
    "        mfcc_audios.append(features)\n",
    "    mfcc_audios=np.array(mfcc_audios)\n",
    "    return mfcc_audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(dir,name):\n",
    "    file = open(dir+name)\n",
    "    f=file.read()\n",
    "    file.close()\n",
    "    f=f.split('\\n')\n",
    "    f=f[0:len(f)-1]\n",
    "    labels=[]\n",
    "    names_audios=[]\n",
    "    for i in f:\n",
    "        j=i.split(',')\n",
    "        names_audios.append(j[0])\n",
    "        labels.append(j[1])\n",
    "    labels=np.array(labels)\n",
    "    onehot= encode(labels)\n",
    "    mfcc=mfcc_features(dir,names_audios)\n",
    "    print(name+' OK')\n",
    "    return mfcc,onehot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    def __init__(self,data):\n",
    "        self.i=0#para el shuffle\n",
    "        self.data_dir=data\n",
    "        self.shuffle=None\n",
    "        self.dir_training=data+'/training/'\n",
    "        self.dir_test=data+'/test/'\n",
    "        self.training_set=None\n",
    "        self.test_set=None\n",
    "    def split_dataset(self):\n",
    "        if os.path.exists(self.dir_training+'training.txt')==False:\n",
    "            generate_file_data(self.dir_training,name='training')\n",
    "        if os.path.exists(self.dir_training+'test.txt')==False:\n",
    "            generate_file_data(self.dir_test,name='test')\n",
    "        print('loadfiles')\n",
    "    def prepare(self):\n",
    "        self.training_set=prepare_data(self.dir_training,'training.txt')\n",
    "        self.test_set=prepare_data(self.dir_test,'test.txt')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loadfiles\n"
     ]
    }
   ],
   "source": [
    "d=dataset('data')\n",
    "d.split_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training.txt OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.txt OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    }
   ],
   "source": [
    "d.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = sklearn.preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minscale(data):\n",
    "    for i in data:\n",
    "        scale.fit(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red neuronal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se definen los distintos modelos a aplicar en este seminario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se dividen los conjuntos\n",
    "trainX, trainY = d.training_set[0],d.training_set[1]\n",
    "testX, testY = d.test_set[0],d.test_set[1]\n",
    "trainX=np.matrix.transpose(trainX,[0,2,1])\n",
    "testX=np.matrix.transpose(testX,[0,2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A continuación mostramos un elemento del training y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.64700507,  1.9945672 ,  1.98824514, ..., -0.53819457,\n",
       "         0.12530242, -0.33085568],\n",
       "       [ 1.64700507,  1.9945672 ,  1.98824514, ..., -0.53819457,\n",
       "         0.12530242, -0.33085568],\n",
       "       [ 1.64700507,  1.9945672 ,  1.98824514, ..., -0.53819457,\n",
       "         0.12530242, -0.33085568],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.64700507,  1.9945672 ,  1.98824514, ..., -0.53819457,\n",
       "         0.12530242, -0.33085568],\n",
       "       [ 1.64700507,  1.9945672 ,  1.98824514, ..., -0.53819457,\n",
       "         0.12530242, -0.33085568],\n",
       "       [ 1.64700507,  1.9945672 ,  1.98824514, ..., -0.53819457,\n",
       "         0.12530242, -0.33085568],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX=np.array([scale.transform(i) for i in testX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.29477372,  0.        ,  0.51545782, ...,  0.4650055 ,\n",
       "          0.52288985,  0.61232301],\n",
       "        [ 0.29906835,  0.02024784,  0.56387608, ...,  0.33298813,\n",
       "          0.38843232,  0.49291624],\n",
       "        [ 0.31282293,  0.08258129,  0.6970484 , ...,  0.28165512,\n",
       "          0.34687953,  0.48497778],\n",
       "        ...,\n",
       "        [ 1.        ,  0.        ,  0.51545782, ...,  0.4650055 ,\n",
       "          0.52288985,  0.61232301],\n",
       "        [ 1.        ,  0.        ,  0.51545782, ...,  0.4650055 ,\n",
       "          0.52288985,  0.61232301],\n",
       "        [ 1.        ,  0.        ,  0.51545782, ...,  0.4650055 ,\n",
       "          0.52288985,  0.61232301]],\n",
       "\n",
       "       [[ 0.13746074,  0.51679168,  1.06093256, ...,  0.6218253 ,\n",
       "          0.51352008,  0.81244541],\n",
       "        [ 0.17236937,  0.47360122,  0.79626235, ...,  0.64032587,\n",
       "          0.50851148,  0.85233189],\n",
       "        [ 0.17854422,  0.38254017,  0.56358559, ...,  0.67150158,\n",
       "          0.71558776,  0.91095523],\n",
       "        ...,\n",
       "        [ 1.        ,  0.        ,  0.51545782, ...,  0.4650055 ,\n",
       "          0.52288985,  0.61232301],\n",
       "        [ 1.        ,  0.        ,  0.51545782, ...,  0.4650055 ,\n",
       "          0.52288985,  0.61232301],\n",
       "        [ 1.        ,  0.        ,  0.51545782, ...,  0.4650055 ,\n",
       "          0.52288985,  0.61232301]],\n",
       "\n",
       "       [[-0.04512004,  0.        ,  0.51545782, ...,  0.4650055 ,\n",
       "          0.52288985,  0.61232301],\n",
       "        [-0.04512004,  0.        ,  0.51545782, ...,  0.4650055 ,\n",
       "          0.52288985,  0.61232301],\n",
       "        [-0.04512004,  0.        ,  0.51545782, ...,  0.4650055 ,\n",
       "          0.52288985,  0.61232301],\n",
       "        ...,\n",
       "        [ 1.        ,  0.        ,  0.51545782, ...,  0.4650055 ,\n",
       "          0.52288985,  0.61232301],\n",
       "        [ 1.        ,  0.        ,  0.51545782, ...,  0.4650055 ,\n",
       "          0.52288985,  0.61232301],\n",
       "        [ 1.        ,  0.        ,  0.51545782, ...,  0.4650055 ,\n",
       "          0.52288985,  0.61232301]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.36707247,  0.5425902 ,  0.68844175, ...,  0.93556625,\n",
       "          0.58547845,  0.64509692],\n",
       "        [ 0.4574321 ,  0.6157258 ,  0.42875375, ...,  0.59016276,\n",
       "          0.47275544,  0.5490286 ],\n",
       "        [ 0.51526181,  0.63010354,  0.29799194, ...,  0.42298178,\n",
       "          0.49742636,  0.47619402],\n",
       "        ...,\n",
       "        [ 1.        ,  0.        ,  0.51545782, ...,  0.4650055 ,\n",
       "          0.52288985,  0.61232301],\n",
       "        [ 1.        ,  0.        ,  0.51545782, ...,  0.4650055 ,\n",
       "          0.52288985,  0.61232301],\n",
       "        [ 1.        ,  0.        ,  0.51545782, ...,  0.4650055 ,\n",
       "          0.52288985,  0.61232301]],\n",
       "\n",
       "       [[-0.00442536,  0.27931067,  0.87886538, ...,  0.68517631,\n",
       "          0.64667046,  0.64343396],\n",
       "        [ 0.13818764,  0.60039978,  0.88445631, ...,  0.30744995,\n",
       "          0.21226395,  0.36305376],\n",
       "        [ 0.18718903,  0.6848483 ,  0.78732377, ..., -0.06996322,\n",
       "          0.0600627 ,  0.42428188],\n",
       "        ...,\n",
       "        [ 1.        ,  0.        ,  0.51545782, ...,  0.4650055 ,\n",
       "          0.52288985,  0.61232301],\n",
       "        [ 1.        ,  0.        ,  0.51545782, ...,  0.4650055 ,\n",
       "          0.52288985,  0.61232301],\n",
       "        [ 1.        ,  0.        ,  0.51545782, ...,  0.4650055 ,\n",
       "          0.52288985,  0.61232301]],\n",
       "\n",
       "       [[ 0.28017468,  0.27085567,  0.86971312, ...,  0.27360758,\n",
       "          0.43135808,  0.64094934],\n",
       "        [ 0.39247055,  0.41598083,  0.71330766, ...,  0.42015362,\n",
       "          0.63845928,  0.72291934],\n",
       "        [ 0.43601237,  0.38487243,  0.62576544, ...,  0.4991791 ,\n",
       "          0.68614139,  0.80391019],\n",
       "        ...,\n",
       "        [ 1.        ,  0.        ,  0.51545782, ...,  0.4650055 ,\n",
       "          0.52288985,  0.61232301],\n",
       "        [ 1.        ,  0.        ,  0.51545782, ...,  0.4650055 ,\n",
       "          0.52288985,  0.61232301],\n",
       "        [ 1.        ,  0.        ,  0.51545782, ...,  0.4650055 ,\n",
       "          0.52288985,  0.61232301]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de prueba\n",
    "A continuación presentamos 4 modelos que serán entrenados para el reconocimiento de voz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_simple(name,n_units=128,time_steps=160,n_inputs=20,batch_size=10,n_epochs=500):\n",
    "    n_class=10\n",
    "    dir='Models/Model_'\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.SimpleRNN(128, input_shape=(time_steps,n_inputs)))\n",
    "    model.add(tf.layers.Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    timei=time.time()\n",
    "    history=model.fit(trainX,trainY,batch_size=batch_size,epochs=n_epochs,validation_data=[testX,testY])\n",
    "    timef=time.time()\n",
    "    if os.path.exists(dir+name) == False:\n",
    "        os.mkdir(dir+name)\n",
    "    model.save(dir+name+'/'+name)\n",
    "    t=timef-timei\n",
    "    file = open(dir+name+'/'+name+'_time.txt',\"w\")\n",
    "    file.write(str(t))\n",
    "    file.close()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_simple(name,n_units=128,time_steps=160,n_inputs=20,batch_size=10,n_epochs=500):\n",
    "    n_class=10\n",
    "    dir='Models/Model_'\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(n_units, input_shape=(time_steps,n_inputs)))\n",
    "    model.add(tf.layers.Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    timei=time.time()\n",
    "    history=model.fit(trainX,trainY,batch_size=batch_size,epochs=n_epochs,validation_data=[testX,testY])\n",
    "    timef=time.time()\n",
    "    if os.path.exists(dir+name) == False:\n",
    "        os.mkdir(dir+name)\n",
    "    model.save(dir+name+'/'+name)\n",
    "    t=timef-timei\n",
    "    file = open(dir+name+'/'+name+'_time.txt',\"w\")\n",
    "    file.write(str(t))\n",
    "    file.close()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_with_Dropout(name,n_units=128,time_steps=160,n_inputs=20,batch_size=10,n_epochs=500,dropout=0.5):\n",
    "    n_class=10\n",
    "    dir='Models/Model_'\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(n_units, input_shape=(time_steps,n_inputs)))\n",
    "    model.add(tf.layers.Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    timei=time.time()\n",
    "    history=model.fit(trainX,trainY,batch_size=batch_size,epochs=n_epochs,validation_data=[testX,testY])\n",
    "    timef=time.time()\n",
    "    if os.path.exists(dir+name) == False:\n",
    "        os.mkdir(dir+name)\n",
    "    model.save(dir+name+'/'+name)\n",
    "    t=timef-timei\n",
    "    file = open(dir+name+'/'+name+'_time.txt',\"w\")\n",
    "    file.write(str(t))\n",
    "    file.close()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_with_3layers(name,n_units=128,time_steps=160,n_inputs=20,batch_size=10,n_epochs=500):\n",
    "    n_class=10\n",
    "    dir='Models/Model_'\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(n_units, input_shape=(time_steps,n_inputs),return_sequences=True))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.LSTM(n_units, input_shape=(time_steps,n_inputs),return_sequences=True))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.LSTM(n_units, input_shape=(time_steps,n_inputs)))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.layers.Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    timei=time.time()\n",
    "    history=model.fit(trainX,trainY,batch_size=batch_size,epochs=n_epochs,validation_data=[testX,testY])\n",
    "    timef=time.time()\n",
    "    if os.path.exists(dir+name) == False:\n",
    "        os.mkdir(dir+name)\n",
    "    model.save(dir+name+'/'+name)\n",
    "    t=timef-timei\n",
    "    file = open(dir+name+'/'+name+'_time.txt',\"w\")\n",
    "    file.write(str(t))\n",
    "    file.close()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_with_2layers_1D(name,dropout,n_units=20,time_steps=160,n_inputs=20,batch_size=10,n_epochs=500):\n",
    "    n_class=10\n",
    "    dir='Models/Model_'\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(n_units, input_shape=(time_steps,n_inputs),return_sequences=True))\n",
    "    #model.add(tf.keras.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
    "    model.add(tf.keras.layers.LSTM(n_units, input_shape=(time_steps,n_inputs)))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.layers.Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    timei=time.time()\n",
    "    history=model.fit(trainX,trainY,batch_size=batch_size,epochs=n_epochs,validation_data=[testX,testY])\n",
    "    timef=time.time()\n",
    "    if os.path.exists(dir+name) == False:\n",
    "        os.mkdir(dir+name)\n",
    "    model.save(dir+name+'/'+name)\n",
    "    t=timef-timei\n",
    "    file = open(dir+name+'/'+name+'_time.txt',\"w\")\n",
    "    file.write(str(t))\n",
    "    file.close()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting and saving modelo\n",
    "Se presentará una función que graficará los resultados y guardará el modelo y sus datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_saving(history,name):\n",
    "    dir='Models/Model_'\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Precision del Modelo')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Test'], loc='upper left')\n",
    "    plt.savefig(dir+name+'/prec')\n",
    "    plt.show()\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Perdida del modelo')\n",
    "    plt.ylabel('Perdida')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Test'], loc='upper left')\n",
    "    plt.savefig(dir+name+'/cost')\n",
    "    plt.show()\n",
    "    json.dump(history.history, open('Models/Model_'+name+'/'+name+'_history', 'w'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento \n",
    "Entrenaremos distintas con los modelos definidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/500\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 2.3309 - acc: 0.0917 - val_loss: 2.3922 - val_acc: 0.0818\n",
      "Epoch 2/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3627 - acc: 0.1167 - val_loss: 2.3060 - val_acc: 0.1455\n",
      "Epoch 3/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3560 - acc: 0.1167 - val_loss: 2.3139 - val_acc: 0.1455\n",
      "Epoch 4/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3453 - acc: 0.0708 - val_loss: 2.3476 - val_acc: 0.0727\n",
      "Epoch 5/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3626 - acc: 0.1083 - val_loss: 2.3476 - val_acc: 0.1091\n",
      "Epoch 6/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.3184 - acc: 0.1458 - val_loss: 2.3623 - val_acc: 0.1091\n",
      "Epoch 7/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.3359 - acc: 0.1208 - val_loss: 2.4152 - val_acc: 0.0909\n",
      "Epoch 8/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3644 - acc: 0.1417 - val_loss: 2.3792 - val_acc: 0.0727\n",
      "Epoch 9/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.3217 - acc: 0.1125 - val_loss: 2.3597 - val_acc: 0.0909\n",
      "Epoch 10/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.3775 - acc: 0.0708 - val_loss: 2.4000 - val_acc: 0.0636\n",
      "Epoch 11/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3658 - acc: 0.0875 - val_loss: 2.3863 - val_acc: 0.0818\n",
      "Epoch 12/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3684 - acc: 0.1167 - val_loss: 2.3574 - val_acc: 0.1182\n",
      "Epoch 13/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3606 - acc: 0.0750 - val_loss: 2.3863 - val_acc: 0.0455\n",
      "Epoch 14/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3302 - acc: 0.0833 - val_loss: 2.3813 - val_acc: 0.0909\n",
      "Epoch 15/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3260 - acc: 0.1333 - val_loss: 2.4096 - val_acc: 0.0545\n",
      "Epoch 16/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3229 - acc: 0.1000 - val_loss: 2.4133 - val_acc: 0.0273\n",
      "Epoch 17/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3339 - acc: 0.1292 - val_loss: 2.3970 - val_acc: 0.0545\n",
      "Epoch 18/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3164 - acc: 0.1083 - val_loss: 2.3597 - val_acc: 0.0545\n",
      "Epoch 19/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.3280 - acc: 0.1167 - val_loss: 2.3987 - val_acc: 0.0636\n",
      "Epoch 20/500\n",
      "240/240 [==============================] - 3s 12ms/step - loss: 2.3226 - acc: 0.1167 - val_loss: 2.4023 - val_acc: 0.0455\n",
      "Epoch 21/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3225 - acc: 0.0917 - val_loss: 2.4057 - val_acc: 0.0727\n",
      "Epoch 22/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3253 - acc: 0.0958 - val_loss: 2.3954 - val_acc: 0.0545\n",
      "Epoch 23/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3402 - acc: 0.1250 - val_loss: 2.3902 - val_acc: 0.0818\n",
      "Epoch 24/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3065 - acc: 0.1083 - val_loss: 2.3921 - val_acc: 0.0636\n",
      "Epoch 25/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3044 - acc: 0.1042 - val_loss: 2.3903 - val_acc: 0.0545\n",
      "Epoch 26/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3082 - acc: 0.1167 - val_loss: 2.4572 - val_acc: 0.0364\n",
      "Epoch 27/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3004 - acc: 0.1167 - val_loss: 2.4037 - val_acc: 0.0727\n",
      "Epoch 28/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3147 - acc: 0.1083 - val_loss: 2.4319 - val_acc: 0.0545\n",
      "Epoch 29/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3238 - acc: 0.1167 - val_loss: 2.4453 - val_acc: 0.0727\n",
      "Epoch 30/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2945 - acc: 0.1042 - val_loss: 2.4481 - val_acc: 0.0727\n",
      "Epoch 31/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3086 - acc: 0.1167 - val_loss: 2.4598 - val_acc: 0.0455\n",
      "Epoch 32/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2966 - acc: 0.1417 - val_loss: 2.4498 - val_acc: 0.0455\n",
      "Epoch 33/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3177 - acc: 0.1167 - val_loss: 2.4162 - val_acc: 0.0545\n",
      "Epoch 34/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3085 - acc: 0.1208 - val_loss: 2.4451 - val_acc: 0.0545\n",
      "Epoch 35/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3091 - acc: 0.1167 - val_loss: 2.3527 - val_acc: 0.0727\n",
      "Epoch 36/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3015 - acc: 0.1000 - val_loss: 2.3692 - val_acc: 0.0818\n",
      "Epoch 37/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3307 - acc: 0.1083 - val_loss: 2.3597 - val_acc: 0.0818\n",
      "Epoch 38/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3369 - acc: 0.1000 - val_loss: 2.3732 - val_acc: 0.0909\n",
      "Epoch 39/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3395 - acc: 0.1083 - val_loss: 2.4002 - val_acc: 0.0818\n",
      "Epoch 40/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3556 - acc: 0.0792 - val_loss: 2.3616 - val_acc: 0.1091\n",
      "Epoch 41/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3062 - acc: 0.1292 - val_loss: 2.4265 - val_acc: 0.0909\n",
      "Epoch 42/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3600 - acc: 0.0750 - val_loss: 2.3282 - val_acc: 0.1091\n",
      "Epoch 43/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3176 - acc: 0.1417 - val_loss: 2.4247 - val_acc: 0.0636\n",
      "Epoch 44/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3293 - acc: 0.1333 - val_loss: 2.3946 - val_acc: 0.0455\n",
      "Epoch 45/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3234 - acc: 0.1000 - val_loss: 2.3772 - val_acc: 0.0636\n",
      "Epoch 46/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2964 - acc: 0.1042 - val_loss: 2.4157 - val_acc: 0.0545\n",
      "Epoch 47/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2973 - acc: 0.1375 - val_loss: 2.4159 - val_acc: 0.0636\n",
      "Epoch 48/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3085 - acc: 0.1250 - val_loss: 2.4306 - val_acc: 0.0636\n",
      "Epoch 49/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2954 - acc: 0.1250 - val_loss: 2.4267 - val_acc: 0.0636\n",
      "Epoch 50/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3403 - acc: 0.1042 - val_loss: 2.4067 - val_acc: 0.1000\n",
      "Epoch 51/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3281 - acc: 0.1167 - val_loss: 2.4401 - val_acc: 0.1000\n",
      "Epoch 52/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3272 - acc: 0.1208 - val_loss: 2.4059 - val_acc: 0.0727\n",
      "Epoch 53/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3088 - acc: 0.1208 - val_loss: 2.4096 - val_acc: 0.0636\n",
      "Epoch 54/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3060 - acc: 0.1208 - val_loss: 2.4232 - val_acc: 0.0364\n",
      "Epoch 55/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2954 - acc: 0.1375 - val_loss: 2.4375 - val_acc: 0.0909\n",
      "Epoch 56/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3103 - acc: 0.1542 - val_loss: 2.4127 - val_acc: 0.0727\n",
      "Epoch 57/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.3441 - acc: 0.0958 - val_loss: 2.3869 - val_acc: 0.0364\n",
      "Epoch 58/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3300 - acc: 0.1167 - val_loss: 2.3675 - val_acc: 0.1000\n",
      "Epoch 59/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.3213 - acc: 0.1083 - val_loss: 2.4147 - val_acc: 0.0636\n",
      "Epoch 60/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.3106 - acc: 0.1000 - val_loss: 2.4201 - val_acc: 0.0727\n",
      "Epoch 61/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3604 - acc: 0.0958 - val_loss: 2.3720 - val_acc: 0.1182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.3912 - acc: 0.0917 - val_loss: 2.3418 - val_acc: 0.1273\n",
      "Epoch 63/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3677 - acc: 0.1042 - val_loss: 2.3362 - val_acc: 0.1273\n",
      "Epoch 64/500\n",
      "240/240 [==============================] - 3s 14ms/step - loss: 2.3496 - acc: 0.1167 - val_loss: 2.3347 - val_acc: 0.1091\n",
      "Epoch 65/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3660 - acc: 0.0917 - val_loss: 2.3255 - val_acc: 0.0727\n",
      "Epoch 66/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3638 - acc: 0.0833 - val_loss: 2.3151 - val_acc: 0.1091\n",
      "Epoch 67/500\n",
      "240/240 [==============================] - 3s 10ms/step - loss: 2.3306 - acc: 0.0750 - val_loss: 2.3368 - val_acc: 0.1636\n",
      "Epoch 68/500\n",
      "240/240 [==============================] - 4s 15ms/step - loss: 2.3342 - acc: 0.1167 - val_loss: 2.3305 - val_acc: 0.0727\n",
      "Epoch 69/500\n",
      "240/240 [==============================] - 3s 12ms/step - loss: 2.3381 - acc: 0.1667 - val_loss: 2.4046 - val_acc: 0.1091\n",
      "Epoch 70/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.3531 - acc: 0.1292 - val_loss: 2.2942 - val_acc: 0.1000\n",
      "Epoch 71/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.3563 - acc: 0.0958 - val_loss: 2.3374 - val_acc: 0.1182\n",
      "Epoch 72/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.3722 - acc: 0.0500 - val_loss: 2.3049 - val_acc: 0.1182\n",
      "Epoch 73/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3536 - acc: 0.1042 - val_loss: 2.3707 - val_acc: 0.0818\n",
      "Epoch 74/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.3820 - acc: 0.0625 - val_loss: 2.3209 - val_acc: 0.1364\n",
      "Epoch 75/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3326 - acc: 0.1083 - val_loss: 2.2965 - val_acc: 0.1455\n",
      "Epoch 76/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.3218 - acc: 0.1292 - val_loss: 2.3363 - val_acc: 0.1273\n",
      "Epoch 77/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.3593 - acc: 0.1000 - val_loss: 2.3235 - val_acc: 0.1091\n",
      "Epoch 78/500\n",
      "240/240 [==============================] - 3s 12ms/step - loss: 2.3676 - acc: 0.1000 - val_loss: 2.3597 - val_acc: 0.0909\n",
      "Epoch 79/500\n",
      "240/240 [==============================] - 3s 12ms/step - loss: 2.3493 - acc: 0.0917 - val_loss: 2.3357 - val_acc: 0.1091\n",
      "Epoch 80/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3508 - acc: 0.1042 - val_loss: 2.3333 - val_acc: 0.1273\n",
      "Epoch 81/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.3587 - acc: 0.0917 - val_loss: 2.3350 - val_acc: 0.0909\n",
      "Epoch 82/500\n",
      "240/240 [==============================] - 3s 13ms/step - loss: 2.3480 - acc: 0.1208 - val_loss: 2.3400 - val_acc: 0.1000\n",
      "Epoch 83/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.3473 - acc: 0.1125 - val_loss: 2.3644 - val_acc: 0.1000\n",
      "Epoch 84/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.3586 - acc: 0.0458 - val_loss: 2.3901 - val_acc: 0.0818\n",
      "Epoch 85/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.3283 - acc: 0.1000 - val_loss: 2.3700 - val_acc: 0.0818\n",
      "Epoch 86/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.3263 - acc: 0.1042 - val_loss: 2.4284 - val_acc: 0.0818\n",
      "Epoch 87/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2824 - acc: 0.1375 - val_loss: 2.3809 - val_acc: 0.1000\n",
      "Epoch 88/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.2670 - acc: 0.1417 - val_loss: 2.4115 - val_acc: 0.0909\n",
      "Epoch 89/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2638 - acc: 0.1458 - val_loss: 2.3953 - val_acc: 0.0909\n",
      "Epoch 90/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2580 - acc: 0.1417 - val_loss: 2.4292 - val_acc: 0.0818\n",
      "Epoch 91/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2593 - acc: 0.1625 - val_loss: 2.4148 - val_acc: 0.1182\n",
      "Epoch 92/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2467 - acc: 0.1625 - val_loss: 2.4312 - val_acc: 0.0909\n",
      "Epoch 93/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2481 - acc: 0.1750 - val_loss: 2.4160 - val_acc: 0.0727\n",
      "Epoch 94/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2375 - acc: 0.1875 - val_loss: 2.4201 - val_acc: 0.0909\n",
      "Epoch 95/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2447 - acc: 0.1708 - val_loss: 2.4495 - val_acc: 0.0818\n",
      "Epoch 96/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2451 - acc: 0.1542 - val_loss: 2.4359 - val_acc: 0.0909\n",
      "Epoch 97/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2354 - acc: 0.1708 - val_loss: 2.4352 - val_acc: 0.0909\n",
      "Epoch 98/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2437 - acc: 0.1667 - val_loss: 2.4370 - val_acc: 0.1000\n",
      "Epoch 99/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2329 - acc: 0.1792 - val_loss: 2.4642 - val_acc: 0.1000\n",
      "Epoch 100/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2307 - acc: 0.1917 - val_loss: 2.4317 - val_acc: 0.1000\n",
      "Epoch 101/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2307 - acc: 0.1875 - val_loss: 2.4493 - val_acc: 0.0818\n",
      "Epoch 102/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2294 - acc: 0.1625 - val_loss: 2.4451 - val_acc: 0.1000\n",
      "Epoch 103/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2351 - acc: 0.1917 - val_loss: 2.4358 - val_acc: 0.0909\n",
      "Epoch 104/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2328 - acc: 0.1542 - val_loss: 2.4650 - val_acc: 0.0909\n",
      "Epoch 105/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2263 - acc: 0.2000 - val_loss: 2.4447 - val_acc: 0.0909\n",
      "Epoch 106/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2203 - acc: 0.1708 - val_loss: 2.4487 - val_acc: 0.0909\n",
      "Epoch 107/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2293 - acc: 0.1792 - val_loss: 2.4724 - val_acc: 0.0909\n",
      "Epoch 108/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2271 - acc: 0.1792 - val_loss: 2.4554 - val_acc: 0.0727\n",
      "Epoch 109/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2278 - acc: 0.1833 - val_loss: 2.4617 - val_acc: 0.0727\n",
      "Epoch 110/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2237 - acc: 0.1750 - val_loss: 2.4572 - val_acc: 0.0909\n",
      "Epoch 111/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2299 - acc: 0.1792 - val_loss: 2.4813 - val_acc: 0.0818\n",
      "Epoch 112/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2232 - acc: 0.1708 - val_loss: 2.4501 - val_acc: 0.1091\n",
      "Epoch 113/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2136 - acc: 0.2000 - val_loss: 2.4734 - val_acc: 0.0818\n",
      "Epoch 114/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2285 - acc: 0.1792 - val_loss: 2.4722 - val_acc: 0.0818\n",
      "Epoch 115/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2182 - acc: 0.1792 - val_loss: 2.4789 - val_acc: 0.1000\n",
      "Epoch 116/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2257 - acc: 0.1792 - val_loss: 2.4800 - val_acc: 0.0818\n",
      "Epoch 117/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2240 - acc: 0.1917 - val_loss: 2.4710 - val_acc: 0.0909\n",
      "Epoch 118/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2177 - acc: 0.1875 - val_loss: 2.4879 - val_acc: 0.0818\n",
      "Epoch 119/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2134 - acc: 0.1875 - val_loss: 2.4913 - val_acc: 0.0909\n",
      "Epoch 120/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2195 - acc: 0.1875 - val_loss: 2.4613 - val_acc: 0.0909\n",
      "Epoch 121/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2283 - acc: 0.1875 - val_loss: 2.4738 - val_acc: 0.0818\n",
      "Epoch 122/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2147 - acc: 0.1833 - val_loss: 2.4706 - val_acc: 0.1182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2149 - acc: 0.1833 - val_loss: 2.4714 - val_acc: 0.0727\n",
      "Epoch 124/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2156 - acc: 0.2000 - val_loss: 2.4743 - val_acc: 0.0818\n",
      "Epoch 125/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.2218 - acc: 0.1750 - val_loss: 2.4809 - val_acc: 0.0909\n",
      "Epoch 126/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2081 - acc: 0.1792 - val_loss: 2.4545 - val_acc: 0.1000\n",
      "Epoch 127/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2161 - acc: 0.1750 - val_loss: 2.4710 - val_acc: 0.0909\n",
      "Epoch 128/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.2069 - acc: 0.1792 - val_loss: 2.4896 - val_acc: 0.0909\n",
      "Epoch 129/500\n",
      "240/240 [==============================] - 3s 13ms/step - loss: 2.2179 - acc: 0.1875 - val_loss: 2.4684 - val_acc: 0.0636\n",
      "Epoch 130/500\n",
      "240/240 [==============================] - 3s 13ms/step - loss: 2.2094 - acc: 0.1958 - val_loss: 2.4844 - val_acc: 0.0727\n",
      "Epoch 131/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.2165 - acc: 0.1667 - val_loss: 2.4773 - val_acc: 0.1000\n",
      "Epoch 132/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.2122 - acc: 0.1917 - val_loss: 2.4868 - val_acc: 0.0909\n",
      "Epoch 133/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.2107 - acc: 0.1833 - val_loss: 2.4718 - val_acc: 0.0909\n",
      "Epoch 134/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.2054 - acc: 0.1917 - val_loss: 2.4829 - val_acc: 0.0636\n",
      "Epoch 135/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2047 - acc: 0.2125 - val_loss: 2.4809 - val_acc: 0.1364\n",
      "Epoch 136/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2042 - acc: 0.1833 - val_loss: 2.4631 - val_acc: 0.1000\n",
      "Epoch 137/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2099 - acc: 0.1750 - val_loss: 2.4813 - val_acc: 0.1273\n",
      "Epoch 138/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1945 - acc: 0.1917 - val_loss: 2.4918 - val_acc: 0.0636\n",
      "Epoch 139/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1960 - acc: 0.1792 - val_loss: 2.4894 - val_acc: 0.0727\n",
      "Epoch 140/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1918 - acc: 0.1708 - val_loss: 2.4877 - val_acc: 0.0909\n",
      "Epoch 141/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1952 - acc: 0.1833 - val_loss: 2.4765 - val_acc: 0.1000\n",
      "Epoch 142/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2004 - acc: 0.1750 - val_loss: 2.4664 - val_acc: 0.0909\n",
      "Epoch 143/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1961 - acc: 0.1875 - val_loss: 2.4821 - val_acc: 0.0909\n",
      "Epoch 144/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1887 - acc: 0.1792 - val_loss: 2.4844 - val_acc: 0.0909\n",
      "Epoch 145/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1984 - acc: 0.1792 - val_loss: 2.4679 - val_acc: 0.1091\n",
      "Epoch 146/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1884 - acc: 0.1625 - val_loss: 2.4980 - val_acc: 0.0909\n",
      "Epoch 147/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1964 - acc: 0.1750 - val_loss: 2.4994 - val_acc: 0.0818\n",
      "Epoch 148/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.1956 - acc: 0.2083 - val_loss: 2.4790 - val_acc: 0.1000\n",
      "Epoch 149/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.1892 - acc: 0.1625 - val_loss: 2.4908 - val_acc: 0.0636\n",
      "Epoch 150/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1875 - acc: 0.2042 - val_loss: 2.4879 - val_acc: 0.0909\n",
      "Epoch 151/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1759 - acc: 0.1792 - val_loss: 2.4987 - val_acc: 0.1091\n",
      "Epoch 152/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1862 - acc: 0.1958 - val_loss: 2.4852 - val_acc: 0.0727\n",
      "Epoch 153/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1926 - acc: 0.1875 - val_loss: 2.5061 - val_acc: 0.1091\n",
      "Epoch 154/500\n",
      "240/240 [==============================] - 3s 12ms/step - loss: 2.1694 - acc: 0.1875 - val_loss: 2.4936 - val_acc: 0.0818\n",
      "Epoch 155/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1758 - acc: 0.2042 - val_loss: 2.4864 - val_acc: 0.1091\n",
      "Epoch 156/500\n",
      "240/240 [==============================] - 3s 12ms/step - loss: 2.1861 - acc: 0.1708 - val_loss: 2.4985 - val_acc: 0.0818\n",
      "Epoch 157/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1803 - acc: 0.2000 - val_loss: 2.5004 - val_acc: 0.1091\n",
      "Epoch 158/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.1761 - acc: 0.1750 - val_loss: 2.5068 - val_acc: 0.0909\n",
      "Epoch 159/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1725 - acc: 0.1833 - val_loss: 2.5076 - val_acc: 0.0818\n",
      "Epoch 160/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1674 - acc: 0.1750 - val_loss: 2.5250 - val_acc: 0.0727\n",
      "Epoch 161/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1726 - acc: 0.2042 - val_loss: 2.4909 - val_acc: 0.1091\n",
      "Epoch 162/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.1754 - acc: 0.1750 - val_loss: 2.5123 - val_acc: 0.1273\n",
      "Epoch 163/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.1603 - acc: 0.1917 - val_loss: 2.5356 - val_acc: 0.0909\n",
      "Epoch 164/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.1662 - acc: 0.1833 - val_loss: 2.5203 - val_acc: 0.0909\n",
      "Epoch 165/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1494 - acc: 0.1458 - val_loss: 2.5262 - val_acc: 0.0818\n",
      "Epoch 166/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1658 - acc: 0.1667 - val_loss: 2.5405 - val_acc: 0.1000\n",
      "Epoch 167/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1587 - acc: 0.1792 - val_loss: 2.5400 - val_acc: 0.0636\n",
      "Epoch 168/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1488 - acc: 0.2083 - val_loss: 2.5300 - val_acc: 0.1182\n",
      "Epoch 169/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1476 - acc: 0.1833 - val_loss: 2.5395 - val_acc: 0.1000\n",
      "Epoch 170/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1566 - acc: 0.1917 - val_loss: 2.5360 - val_acc: 0.1364\n",
      "Epoch 171/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1507 - acc: 0.1958 - val_loss: 2.5484 - val_acc: 0.1091\n",
      "Epoch 172/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1553 - acc: 0.1917 - val_loss: 2.5449 - val_acc: 0.1273\n",
      "Epoch 173/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1665 - acc: 0.1792 - val_loss: 2.5511 - val_acc: 0.1273\n",
      "Epoch 174/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1484 - acc: 0.1792 - val_loss: 2.5801 - val_acc: 0.0818\n",
      "Epoch 175/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1338 - acc: 0.2083 - val_loss: 2.5459 - val_acc: 0.1455\n",
      "Epoch 176/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1475 - acc: 0.1958 - val_loss: 2.5491 - val_acc: 0.1182\n",
      "Epoch 177/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1559 - acc: 0.1792 - val_loss: 2.5550 - val_acc: 0.1273\n",
      "Epoch 178/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1571 - acc: 0.2000 - val_loss: 2.5720 - val_acc: 0.1091\n",
      "Epoch 179/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1380 - acc: 0.1875 - val_loss: 2.5713 - val_acc: 0.1000\n",
      "Epoch 180/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1384 - acc: 0.2042 - val_loss: 2.5731 - val_acc: 0.1273\n",
      "Epoch 181/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1266 - acc: 0.2083 - val_loss: 2.5903 - val_acc: 0.1182\n",
      "Epoch 182/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1528 - acc: 0.1500 - val_loss: 2.5748 - val_acc: 0.1364\n",
      "Epoch 183/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.1376 - acc: 0.1708 - val_loss: 2.5963 - val_acc: 0.1273\n",
      "Epoch 184/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.1249 - acc: 0.2000 - val_loss: 2.6004 - val_acc: 0.1273\n",
      "Epoch 185/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1239 - acc: 0.2083 - val_loss: 2.5740 - val_acc: 0.1364\n",
      "Epoch 186/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1235 - acc: 0.1875 - val_loss: 2.5955 - val_acc: 0.1455\n",
      "Epoch 187/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1364 - acc: 0.1958 - val_loss: 2.6049 - val_acc: 0.1091\n",
      "Epoch 188/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1432 - acc: 0.1708 - val_loss: 2.5928 - val_acc: 0.1273\n",
      "Epoch 189/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1278 - acc: 0.2125 - val_loss: 2.5973 - val_acc: 0.1091\n",
      "Epoch 190/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1387 - acc: 0.1708 - val_loss: 2.5934 - val_acc: 0.1091\n",
      "Epoch 191/500\n",
      "240/240 [==============================] - 3s 12ms/step - loss: 2.1294 - acc: 0.2000 - val_loss: 2.6117 - val_acc: 0.1182\n",
      "Epoch 192/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1316 - acc: 0.1750 - val_loss: 2.6313 - val_acc: 0.1182\n",
      "Epoch 193/500\n",
      "240/240 [==============================] - 3s 13ms/step - loss: 2.1203 - acc: 0.2042 - val_loss: 2.5748 - val_acc: 0.1091\n",
      "Epoch 194/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1284 - acc: 0.1792 - val_loss: 2.6352 - val_acc: 0.1091\n",
      "Epoch 195/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1142 - acc: 0.1833 - val_loss: 2.6035 - val_acc: 0.1455\n",
      "Epoch 196/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1187 - acc: 0.2083 - val_loss: 2.6242 - val_acc: 0.1273\n",
      "Epoch 197/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1188 - acc: 0.1958 - val_loss: 2.6467 - val_acc: 0.0909\n",
      "Epoch 198/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1115 - acc: 0.1917 - val_loss: 2.6337 - val_acc: 0.1091\n",
      "Epoch 199/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1212 - acc: 0.2000 - val_loss: 2.6277 - val_acc: 0.1273\n",
      "Epoch 200/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1132 - acc: 0.2000 - val_loss: 2.6281 - val_acc: 0.1091\n",
      "Epoch 201/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1307 - acc: 0.1833 - val_loss: 2.6484 - val_acc: 0.1273\n",
      "Epoch 202/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1208 - acc: 0.1958 - val_loss: 2.6593 - val_acc: 0.1091\n",
      "Epoch 203/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1236 - acc: 0.2000 - val_loss: 2.6328 - val_acc: 0.1273\n",
      "Epoch 204/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1216 - acc: 0.1917 - val_loss: 2.6500 - val_acc: 0.1182\n",
      "Epoch 205/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1155 - acc: 0.2083 - val_loss: 2.6448 - val_acc: 0.1273\n",
      "Epoch 206/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.1124 - acc: 0.1917 - val_loss: 2.6426 - val_acc: 0.0909\n",
      "Epoch 207/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1185 - acc: 0.1958 - val_loss: 2.6582 - val_acc: 0.1273\n",
      "Epoch 208/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1208 - acc: 0.1958 - val_loss: 2.6752 - val_acc: 0.1091\n",
      "Epoch 209/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1160 - acc: 0.1917 - val_loss: 2.6686 - val_acc: 0.1091\n",
      "Epoch 210/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1133 - acc: 0.2208 - val_loss: 2.6492 - val_acc: 0.1091\n",
      "Epoch 211/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1153 - acc: 0.1958 - val_loss: 2.6694 - val_acc: 0.1182\n",
      "Epoch 212/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1132 - acc: 0.2208 - val_loss: 2.6839 - val_acc: 0.1091\n",
      "Epoch 213/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.1076 - acc: 0.1958 - val_loss: 2.6658 - val_acc: 0.1273\n",
      "Epoch 214/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1061 - acc: 0.2000 - val_loss: 2.6977 - val_acc: 0.1000\n",
      "Epoch 215/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.1107 - acc: 0.2083 - val_loss: 2.6572 - val_acc: 0.1182\n",
      "Epoch 216/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.1097 - acc: 0.2083 - val_loss: 2.6710 - val_acc: 0.1273\n",
      "Epoch 217/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1115 - acc: 0.1833 - val_loss: 2.7021 - val_acc: 0.1091\n",
      "Epoch 218/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1104 - acc: 0.2083 - val_loss: 2.6842 - val_acc: 0.1273\n",
      "Epoch 219/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1059 - acc: 0.1875 - val_loss: 2.6817 - val_acc: 0.1000\n",
      "Epoch 220/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1052 - acc: 0.2042 - val_loss: 2.6951 - val_acc: 0.1273\n",
      "Epoch 221/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1063 - acc: 0.1958 - val_loss: 2.6747 - val_acc: 0.1364\n",
      "Epoch 222/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.1090 - acc: 0.2000 - val_loss: 2.6739 - val_acc: 0.1273\n",
      "Epoch 223/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1016 - acc: 0.2250 - val_loss: 2.6774 - val_acc: 0.1091\n",
      "Epoch 224/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1227 - acc: 0.2042 - val_loss: 2.6900 - val_acc: 0.1273\n",
      "Epoch 225/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.1111 - acc: 0.2125 - val_loss: 2.6873 - val_acc: 0.1364\n",
      "Epoch 226/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1164 - acc: 0.1917 - val_loss: 2.7282 - val_acc: 0.0818\n",
      "Epoch 227/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.1180 - acc: 0.1833 - val_loss: 2.7015 - val_acc: 0.1182\n",
      "Epoch 228/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.1161 - acc: 0.1917 - val_loss: 2.6945 - val_acc: 0.1091\n",
      "Epoch 229/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.1225 - acc: 0.1917 - val_loss: 2.7119 - val_acc: 0.0909\n",
      "Epoch 230/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.1140 - acc: 0.2125 - val_loss: 2.6930 - val_acc: 0.1091\n",
      "Epoch 231/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1200 - acc: 0.1875 - val_loss: 2.7086 - val_acc: 0.1182\n",
      "Epoch 232/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1012 - acc: 0.2208 - val_loss: 2.7287 - val_acc: 0.1091\n",
      "Epoch 233/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1045 - acc: 0.2083 - val_loss: 2.6972 - val_acc: 0.0909\n",
      "Epoch 234/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.1039 - acc: 0.2125 - val_loss: 2.7117 - val_acc: 0.1091\n",
      "Epoch 235/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1077 - acc: 0.1833 - val_loss: 2.7349 - val_acc: 0.0727\n",
      "Epoch 236/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.1034 - acc: 0.1875 - val_loss: 2.7018 - val_acc: 0.1091\n",
      "Epoch 237/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1077 - acc: 0.1917 - val_loss: 2.7144 - val_acc: 0.1000\n",
      "Epoch 238/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1027 - acc: 0.1917 - val_loss: 2.7293 - val_acc: 0.1273\n",
      "Epoch 239/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1149 - acc: 0.1875 - val_loss: 2.7269 - val_acc: 0.1182\n",
      "Epoch 240/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1082 - acc: 0.2083 - val_loss: 2.7178 - val_acc: 0.1091\n",
      "Epoch 241/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1017 - acc: 0.2083 - val_loss: 2.7283 - val_acc: 0.1273\n",
      "Epoch 242/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1204 - acc: 0.2000 - val_loss: 2.6969 - val_acc: 0.1091\n",
      "Epoch 243/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1210 - acc: 0.1708 - val_loss: 2.7573 - val_acc: 0.1273\n",
      "Epoch 244/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1046 - acc: 0.2125 - val_loss: 2.7242 - val_acc: 0.1182\n",
      "Epoch 245/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0954 - acc: 0.2208 - val_loss: 2.7329 - val_acc: 0.1000\n",
      "Epoch 246/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1082 - acc: 0.2042 - val_loss: 2.7284 - val_acc: 0.1273\n",
      "Epoch 247/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1085 - acc: 0.1750 - val_loss: 2.7346 - val_acc: 0.1091\n",
      "Epoch 248/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.0982 - acc: 0.1917 - val_loss: 2.7316 - val_acc: 0.1273\n",
      "Epoch 249/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0996 - acc: 0.2167 - val_loss: 2.7327 - val_acc: 0.1000\n",
      "Epoch 250/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1041 - acc: 0.2042 - val_loss: 2.7602 - val_acc: 0.1091\n",
      "Epoch 251/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1191 - acc: 0.1958 - val_loss: 2.7286 - val_acc: 0.1182\n",
      "Epoch 252/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1045 - acc: 0.2000 - val_loss: 2.7488 - val_acc: 0.1273\n",
      "Epoch 253/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0980 - acc: 0.1917 - val_loss: 2.7518 - val_acc: 0.1182\n",
      "Epoch 254/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1027 - acc: 0.2167 - val_loss: 2.7638 - val_acc: 0.1273\n",
      "Epoch 255/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.1076 - acc: 0.2000 - val_loss: 2.7258 - val_acc: 0.1091\n",
      "Epoch 256/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.1033 - acc: 0.2125 - val_loss: 2.7664 - val_acc: 0.1273\n",
      "Epoch 257/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.1076 - acc: 0.2083 - val_loss: 2.7591 - val_acc: 0.1000\n",
      "Epoch 258/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1135 - acc: 0.2000 - val_loss: 2.7322 - val_acc: 0.1273\n",
      "Epoch 259/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1066 - acc: 0.2083 - val_loss: 2.7951 - val_acc: 0.0909\n",
      "Epoch 260/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.1026 - acc: 0.1875 - val_loss: 2.7492 - val_acc: 0.1182\n",
      "Epoch 261/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1067 - acc: 0.2125 - val_loss: 2.7486 - val_acc: 0.1182\n",
      "Epoch 262/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0975 - acc: 0.2042 - val_loss: 2.7642 - val_acc: 0.1000\n",
      "Epoch 263/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0920 - acc: 0.2042 - val_loss: 2.7498 - val_acc: 0.1364\n",
      "Epoch 264/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.1012 - acc: 0.1750 - val_loss: 2.7709 - val_acc: 0.1273\n",
      "Epoch 265/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0980 - acc: 0.2083 - val_loss: 2.7701 - val_acc: 0.1182\n",
      "Epoch 266/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0928 - acc: 0.2208 - val_loss: 2.7462 - val_acc: 0.1273\n",
      "Epoch 267/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0958 - acc: 0.2000 - val_loss: 2.7598 - val_acc: 0.1273\n",
      "Epoch 268/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1063 - acc: 0.2125 - val_loss: 2.7532 - val_acc: 0.1182\n",
      "Epoch 269/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0971 - acc: 0.2042 - val_loss: 2.7996 - val_acc: 0.1091\n",
      "Epoch 270/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0920 - acc: 0.2083 - val_loss: 2.7597 - val_acc: 0.1273\n",
      "Epoch 271/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0957 - acc: 0.2083 - val_loss: 2.7595 - val_acc: 0.1091\n",
      "Epoch 272/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.0955 - acc: 0.2167 - val_loss: 2.7804 - val_acc: 0.1091\n",
      "Epoch 273/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1008 - acc: 0.1875 - val_loss: 2.7777 - val_acc: 0.1091\n",
      "Epoch 274/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0906 - acc: 0.2125 - val_loss: 2.7759 - val_acc: 0.1182\n",
      "Epoch 275/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.1003 - acc: 0.2167 - val_loss: 2.7742 - val_acc: 0.1091\n",
      "Epoch 276/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1051 - acc: 0.2042 - val_loss: 2.7438 - val_acc: 0.1182\n",
      "Epoch 277/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0952 - acc: 0.1958 - val_loss: 2.8057 - val_acc: 0.1091\n",
      "Epoch 278/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1010 - acc: 0.2000 - val_loss: 2.7837 - val_acc: 0.1091\n",
      "Epoch 279/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0987 - acc: 0.2167 - val_loss: 2.7653 - val_acc: 0.1273\n",
      "Epoch 280/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1013 - acc: 0.1708 - val_loss: 2.7852 - val_acc: 0.1091\n",
      "Epoch 281/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0917 - acc: 0.1917 - val_loss: 2.7911 - val_acc: 0.1273\n",
      "Epoch 282/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1037 - acc: 0.2125 - val_loss: 2.7807 - val_acc: 0.1091\n",
      "Epoch 283/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1055 - acc: 0.2042 - val_loss: 2.7675 - val_acc: 0.1273\n",
      "Epoch 284/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0913 - acc: 0.2042 - val_loss: 2.8089 - val_acc: 0.1182\n",
      "Epoch 285/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0964 - acc: 0.1917 - val_loss: 2.7831 - val_acc: 0.1273\n",
      "Epoch 286/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0879 - acc: 0.2125 - val_loss: 2.8040 - val_acc: 0.1000\n",
      "Epoch 287/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1024 - acc: 0.2083 - val_loss: 2.7876 - val_acc: 0.1182\n",
      "Epoch 288/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0980 - acc: 0.2042 - val_loss: 2.7926 - val_acc: 0.1091\n",
      "Epoch 289/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0942 - acc: 0.2083 - val_loss: 2.7832 - val_acc: 0.1364\n",
      "Epoch 290/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0900 - acc: 0.1875 - val_loss: 2.7966 - val_acc: 0.1182\n",
      "Epoch 291/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1026 - acc: 0.2000 - val_loss: 2.7888 - val_acc: 0.1182\n",
      "Epoch 292/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.1053 - acc: 0.1875 - val_loss: 2.8042 - val_acc: 0.1091\n",
      "Epoch 293/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.0985 - acc: 0.1958 - val_loss: 2.7952 - val_acc: 0.1273\n",
      "Epoch 294/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.0887 - acc: 0.2042 - val_loss: 2.7955 - val_acc: 0.1000\n",
      "Epoch 295/500\n",
      "240/240 [==============================] - 3s 13ms/step - loss: 2.0951 - acc: 0.2083 - val_loss: 2.8018 - val_acc: 0.1091\n",
      "Epoch 296/500\n",
      "240/240 [==============================] - 3s 14ms/step - loss: 2.0997 - acc: 0.2083 - val_loss: 2.8194 - val_acc: 0.1182\n",
      "Epoch 297/500\n",
      "240/240 [==============================] - 3s 10ms/step - loss: 2.0960 - acc: 0.2125 - val_loss: 2.8065 - val_acc: 0.1091\n",
      "Epoch 298/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.0989 - acc: 0.2083 - val_loss: 2.7959 - val_acc: 0.1273\n",
      "Epoch 299/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0986 - acc: 0.1958 - val_loss: 2.8294 - val_acc: 0.1182\n",
      "Epoch 300/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.0889 - acc: 0.2167 - val_loss: 2.7809 - val_acc: 0.1000\n",
      "Epoch 301/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.0927 - acc: 0.2208 - val_loss: 2.7920 - val_acc: 0.1364\n",
      "Epoch 302/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0980 - acc: 0.2000 - val_loss: 2.8297 - val_acc: 0.0818\n",
      "Epoch 303/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.0972 - acc: 0.2167 - val_loss: 2.8124 - val_acc: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1031 - acc: 0.2083 - val_loss: 2.7923 - val_acc: 0.1091\n",
      "Epoch 305/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.0978 - acc: 0.2250 - val_loss: 2.7915 - val_acc: 0.1091\n",
      "Epoch 306/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.0997 - acc: 0.2000 - val_loss: 2.8135 - val_acc: 0.1182\n",
      "Epoch 307/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0951 - acc: 0.1833 - val_loss: 2.8378 - val_acc: 0.0727\n",
      "Epoch 308/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.0946 - acc: 0.2042 - val_loss: 2.8240 - val_acc: 0.1364\n",
      "Epoch 309/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.0984 - acc: 0.2042 - val_loss: 2.8098 - val_acc: 0.1091\n",
      "Epoch 310/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1051 - acc: 0.2083 - val_loss: 2.8305 - val_acc: 0.0455\n",
      "Epoch 311/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.0892 - acc: 0.2167 - val_loss: 2.8043 - val_acc: 0.1182\n",
      "Epoch 312/500\n",
      "240/240 [==============================] - 3s 12ms/step - loss: 2.0958 - acc: 0.2125 - val_loss: 2.8173 - val_acc: 0.1364\n",
      "Epoch 313/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0852 - acc: 0.2167 - val_loss: 2.8202 - val_acc: 0.1091\n",
      "Epoch 314/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.0917 - acc: 0.2167 - val_loss: 2.8146 - val_acc: 0.1273\n",
      "Epoch 315/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0919 - acc: 0.1958 - val_loss: 2.8175 - val_acc: 0.1182\n",
      "Epoch 316/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1014 - acc: 0.1833 - val_loss: 2.8344 - val_acc: 0.1000\n",
      "Epoch 317/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.0978 - acc: 0.2125 - val_loss: 2.8258 - val_acc: 0.1000\n",
      "Epoch 318/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0884 - acc: 0.2125 - val_loss: 2.8229 - val_acc: 0.1364\n",
      "Epoch 319/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0934 - acc: 0.1917 - val_loss: 2.8208 - val_acc: 0.1091\n",
      "Epoch 320/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0871 - acc: 0.2083 - val_loss: 2.8048 - val_acc: 0.1273\n",
      "Epoch 321/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0969 - acc: 0.1875 - val_loss: 2.8345 - val_acc: 0.1273\n",
      "Epoch 322/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.0961 - acc: 0.2042 - val_loss: 2.8538 - val_acc: 0.1000\n",
      "Epoch 323/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0881 - acc: 0.2125 - val_loss: 2.8231 - val_acc: 0.1182\n",
      "Epoch 324/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0928 - acc: 0.2042 - val_loss: 2.8104 - val_acc: 0.1273\n",
      "Epoch 325/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1004 - acc: 0.2042 - val_loss: 2.8290 - val_acc: 0.1364\n",
      "Epoch 326/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1011 - acc: 0.2083 - val_loss: 2.8328 - val_acc: 0.1182\n",
      "Epoch 327/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0883 - acc: 0.2208 - val_loss: 2.8225 - val_acc: 0.1364\n",
      "Epoch 328/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0995 - acc: 0.2083 - val_loss: 2.8301 - val_acc: 0.1273\n",
      "Epoch 329/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0977 - acc: 0.1875 - val_loss: 2.8500 - val_acc: 0.1000\n",
      "Epoch 330/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0943 - acc: 0.2000 - val_loss: 2.8240 - val_acc: 0.1182\n",
      "Epoch 331/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0853 - acc: 0.2125 - val_loss: 2.8433 - val_acc: 0.1000\n",
      "Epoch 332/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0944 - acc: 0.1917 - val_loss: 2.8500 - val_acc: 0.0818\n",
      "Epoch 333/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0930 - acc: 0.2083 - val_loss: 2.8378 - val_acc: 0.1091\n",
      "Epoch 334/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.0895 - acc: 0.2000 - val_loss: 2.8241 - val_acc: 0.1182\n",
      "Epoch 335/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.0937 - acc: 0.2000 - val_loss: 2.8589 - val_acc: 0.1091\n",
      "Epoch 336/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.0936 - acc: 0.2083 - val_loss: 2.8469 - val_acc: 0.1091\n",
      "Epoch 337/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.0872 - acc: 0.2000 - val_loss: 2.8367 - val_acc: 0.1273\n",
      "Epoch 338/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0870 - acc: 0.2125 - val_loss: 2.8273 - val_acc: 0.1091\n",
      "Epoch 339/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0928 - acc: 0.2125 - val_loss: 2.8324 - val_acc: 0.1091\n",
      "Epoch 340/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0955 - acc: 0.1875 - val_loss: 2.8515 - val_acc: 0.0909\n",
      "Epoch 341/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.0996 - acc: 0.2000 - val_loss: 2.8480 - val_acc: 0.1182\n",
      "Epoch 342/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0942 - acc: 0.1958 - val_loss: 2.8597 - val_acc: 0.1091\n",
      "Epoch 343/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0933 - acc: 0.2083 - val_loss: 2.8393 - val_acc: 0.1182\n",
      "Epoch 344/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0889 - acc: 0.2125 - val_loss: 2.8461 - val_acc: 0.1273\n",
      "Epoch 345/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0948 - acc: 0.2208 - val_loss: 2.8237 - val_acc: 0.1182\n",
      "Epoch 346/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0980 - acc: 0.1958 - val_loss: 2.8714 - val_acc: 0.1182\n",
      "Epoch 347/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1045 - acc: 0.2000 - val_loss: 2.8391 - val_acc: 0.1273\n",
      "Epoch 348/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0902 - acc: 0.2042 - val_loss: 2.8571 - val_acc: 0.1000\n",
      "Epoch 349/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0890 - acc: 0.1917 - val_loss: 2.8616 - val_acc: 0.1091\n",
      "Epoch 350/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0928 - acc: 0.1917 - val_loss: 2.8695 - val_acc: 0.1000\n",
      "Epoch 351/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0999 - acc: 0.1750 - val_loss: 2.8413 - val_acc: 0.1273\n",
      "Epoch 352/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0954 - acc: 0.2208 - val_loss: 2.8448 - val_acc: 0.1091\n",
      "Epoch 353/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.0843 - acc: 0.2083 - val_loss: 2.8462 - val_acc: 0.1364\n",
      "Epoch 354/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0857 - acc: 0.2125 - val_loss: 2.8679 - val_acc: 0.1091\n",
      "Epoch 355/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0952 - acc: 0.2083 - val_loss: 2.8477 - val_acc: 0.1091\n",
      "Epoch 356/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0898 - acc: 0.2083 - val_loss: 2.8375 - val_acc: 0.1273\n",
      "Epoch 357/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0855 - acc: 0.2083 - val_loss: 2.8686 - val_acc: 0.1091\n",
      "Epoch 358/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0850 - acc: 0.2125 - val_loss: 2.8381 - val_acc: 0.1364\n",
      "Epoch 359/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0846 - acc: 0.2000 - val_loss: 2.8717 - val_acc: 0.1182\n",
      "Epoch 360/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0864 - acc: 0.2083 - val_loss: 2.8525 - val_acc: 0.1182\n",
      "Epoch 361/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.0903 - acc: 0.1958 - val_loss: 2.8672 - val_acc: 0.1182\n",
      "Epoch 362/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.0930 - acc: 0.2125 - val_loss: 2.8515 - val_acc: 0.1000\n",
      "Epoch 363/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0888 - acc: 0.2042 - val_loss: 2.8554 - val_acc: 0.1364\n",
      "Epoch 364/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0854 - acc: 0.2083 - val_loss: 2.8623 - val_acc: 0.1182\n",
      "Epoch 365/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0870 - acc: 0.2125 - val_loss: 2.8697 - val_acc: 0.1273\n",
      "Epoch 366/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0876 - acc: 0.1958 - val_loss: 2.8585 - val_acc: 0.1182\n",
      "Epoch 367/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0964 - acc: 0.1958 - val_loss: 2.8505 - val_acc: 0.1091\n",
      "Epoch 368/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.0902 - acc: 0.2000 - val_loss: 2.8719 - val_acc: 0.1273\n",
      "Epoch 369/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0964 - acc: 0.2208 - val_loss: 2.8588 - val_acc: 0.1091\n",
      "Epoch 370/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0944 - acc: 0.1875 - val_loss: 2.8643 - val_acc: 0.1091\n",
      "Epoch 371/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0971 - acc: 0.2167 - val_loss: 2.8720 - val_acc: 0.1182\n",
      "Epoch 372/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0794 - acc: 0.2167 - val_loss: 2.8556 - val_acc: 0.1273\n",
      "Epoch 373/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0914 - acc: 0.1875 - val_loss: 2.8858 - val_acc: 0.1091\n",
      "Epoch 374/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0929 - acc: 0.1917 - val_loss: 2.8375 - val_acc: 0.1364\n",
      "Epoch 375/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0896 - acc: 0.1833 - val_loss: 2.8635 - val_acc: 0.1091\n",
      "Epoch 376/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0820 - acc: 0.2083 - val_loss: 2.8677 - val_acc: 0.1273\n",
      "Epoch 377/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0945 - acc: 0.2000 - val_loss: 2.8612 - val_acc: 0.1182\n",
      "Epoch 378/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0856 - acc: 0.1875 - val_loss: 2.8689 - val_acc: 0.1273\n",
      "Epoch 379/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0978 - acc: 0.1875 - val_loss: 2.8659 - val_acc: 0.1000\n",
      "Epoch 380/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0883 - acc: 0.1750 - val_loss: 2.8918 - val_acc: 0.1182\n",
      "Epoch 381/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0863 - acc: 0.2125 - val_loss: 2.8521 - val_acc: 0.1182\n",
      "Epoch 382/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0816 - acc: 0.1917 - val_loss: 2.8815 - val_acc: 0.1091\n",
      "Epoch 383/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0916 - acc: 0.2083 - val_loss: 2.8859 - val_acc: 0.1091\n",
      "Epoch 384/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0883 - acc: 0.1958 - val_loss: 2.8547 - val_acc: 0.1182\n",
      "Epoch 385/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0953 - acc: 0.2208 - val_loss: 2.8691 - val_acc: 0.1273\n",
      "Epoch 386/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0895 - acc: 0.2208 - val_loss: 2.8878 - val_acc: 0.1000\n",
      "Epoch 387/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0912 - acc: 0.2042 - val_loss: 2.8680 - val_acc: 0.1273\n",
      "Epoch 388/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0870 - acc: 0.1917 - val_loss: 2.8753 - val_acc: 0.1182\n",
      "Epoch 389/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0872 - acc: 0.2125 - val_loss: 2.8748 - val_acc: 0.1273\n",
      "Epoch 390/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0914 - acc: 0.2000 - val_loss: 2.8777 - val_acc: 0.1091\n",
      "Epoch 391/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0881 - acc: 0.2083 - val_loss: 2.8762 - val_acc: 0.1000\n",
      "Epoch 392/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0920 - acc: 0.2000 - val_loss: 2.8787 - val_acc: 0.1273\n",
      "Epoch 393/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0915 - acc: 0.2125 - val_loss: 2.8645 - val_acc: 0.1182\n",
      "Epoch 394/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0837 - acc: 0.2125 - val_loss: 2.8833 - val_acc: 0.1182\n",
      "Epoch 395/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0995 - acc: 0.1833 - val_loss: 2.8679 - val_acc: 0.1273\n",
      "Epoch 396/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0852 - acc: 0.2042 - val_loss: 2.8649 - val_acc: 0.1091\n",
      "Epoch 397/500\n",
      "240/240 [==============================] - 3s 10ms/step - loss: 2.0938 - acc: 0.2125 - val_loss: 2.8560 - val_acc: 0.1273\n",
      "Epoch 398/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0928 - acc: 0.2083 - val_loss: 2.8930 - val_acc: 0.1182\n",
      "Epoch 399/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0941 - acc: 0.2208 - val_loss: 2.8559 - val_acc: 0.1364\n",
      "Epoch 400/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0973 - acc: 0.2167 - val_loss: 2.8763 - val_acc: 0.1273\n",
      "Epoch 401/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0923 - acc: 0.1625 - val_loss: 2.8571 - val_acc: 0.1182\n",
      "Epoch 402/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1069 - acc: 0.2167 - val_loss: 2.8666 - val_acc: 0.1273\n",
      "Epoch 403/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0853 - acc: 0.2167 - val_loss: 2.8728 - val_acc: 0.1364\n",
      "Epoch 404/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0873 - acc: 0.2125 - val_loss: 2.8814 - val_acc: 0.1182\n",
      "Epoch 405/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1051 - acc: 0.2083 - val_loss: 2.8562 - val_acc: 0.1182\n",
      "Epoch 406/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0893 - acc: 0.2167 - val_loss: 2.8561 - val_acc: 0.1364\n",
      "Epoch 407/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0907 - acc: 0.2042 - val_loss: 2.8731 - val_acc: 0.1273\n",
      "Epoch 408/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0920 - acc: 0.2042 - val_loss: 2.8529 - val_acc: 0.1182\n",
      "Epoch 409/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0975 - acc: 0.1917 - val_loss: 2.8913 - val_acc: 0.1182\n",
      "Epoch 410/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0918 - acc: 0.2208 - val_loss: 2.8577 - val_acc: 0.1182\n",
      "Epoch 411/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1008 - acc: 0.2125 - val_loss: 2.8662 - val_acc: 0.1182\n",
      "Epoch 412/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0914 - acc: 0.2083 - val_loss: 2.8667 - val_acc: 0.1273\n",
      "Epoch 413/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0891 - acc: 0.2083 - val_loss: 2.8819 - val_acc: 0.1091\n",
      "Epoch 414/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1002 - acc: 0.1958 - val_loss: 2.8806 - val_acc: 0.1273\n",
      "Epoch 415/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.1061 - acc: 0.1750 - val_loss: 2.8627 - val_acc: 0.1364\n",
      "Epoch 416/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1060 - acc: 0.2000 - val_loss: 2.8627 - val_acc: 0.1000\n",
      "Epoch 417/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1071 - acc: 0.2000 - val_loss: 2.8503 - val_acc: 0.1182\n",
      "Epoch 418/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0891 - acc: 0.2167 - val_loss: 2.8873 - val_acc: 0.1091\n",
      "Epoch 419/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0924 - acc: 0.2042 - val_loss: 2.8560 - val_acc: 0.1364\n",
      "Epoch 420/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.0972 - acc: 0.2125 - val_loss: 2.8751 - val_acc: 0.1091\n",
      "Epoch 421/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1098 - acc: 0.2042 - val_loss: 2.8611 - val_acc: 0.1182\n",
      "Epoch 422/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1076 - acc: 0.1958 - val_loss: 2.8602 - val_acc: 0.1091\n",
      "Epoch 423/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1032 - acc: 0.1958 - val_loss: 2.8592 - val_acc: 0.1000\n",
      "Epoch 424/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0871 - acc: 0.2167 - val_loss: 2.8541 - val_acc: 0.1273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1080 - acc: 0.2167 - val_loss: 2.8616 - val_acc: 0.1182\n",
      "Epoch 426/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1083 - acc: 0.1958 - val_loss: 2.8513 - val_acc: 0.1091\n",
      "Epoch 427/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0823 - acc: 0.2125 - val_loss: 2.8648 - val_acc: 0.1000\n",
      "Epoch 428/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1107 - acc: 0.1917 - val_loss: 2.8649 - val_acc: 0.1091\n",
      "Epoch 429/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1011 - acc: 0.2125 - val_loss: 2.8493 - val_acc: 0.1182\n",
      "Epoch 430/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1054 - acc: 0.1958 - val_loss: 2.8650 - val_acc: 0.1182\n",
      "Epoch 431/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0988 - acc: 0.2083 - val_loss: 2.8565 - val_acc: 0.1182\n",
      "Epoch 432/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.0990 - acc: 0.2042 - val_loss: 2.8549 - val_acc: 0.1000\n",
      "Epoch 433/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1029 - acc: 0.2000 - val_loss: 2.8458 - val_acc: 0.1182\n",
      "Epoch 434/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1033 - acc: 0.2042 - val_loss: 2.8443 - val_acc: 0.1273\n",
      "Epoch 435/500\n",
      "240/240 [==============================] - 3s 10ms/step - loss: 2.0913 - acc: 0.2083 - val_loss: 2.8624 - val_acc: 0.0909\n",
      "Epoch 436/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1020 - acc: 0.1875 - val_loss: 2.8555 - val_acc: 0.1091\n",
      "Epoch 437/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1109 - acc: 0.2000 - val_loss: 2.8493 - val_acc: 0.1182\n",
      "Epoch 438/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1064 - acc: 0.2042 - val_loss: 2.8466 - val_acc: 0.1182\n",
      "Epoch 439/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.0935 - acc: 0.2042 - val_loss: 2.8536 - val_acc: 0.1091\n",
      "Epoch 440/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1015 - acc: 0.1958 - val_loss: 2.8505 - val_acc: 0.1182\n",
      "Epoch 441/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1039 - acc: 0.1958 - val_loss: 2.8527 - val_acc: 0.1000\n",
      "Epoch 442/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.1017 - acc: 0.1958 - val_loss: 2.8147 - val_acc: 0.1182\n",
      "Epoch 443/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1034 - acc: 0.2042 - val_loss: 2.8517 - val_acc: 0.1091\n",
      "Epoch 444/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0998 - acc: 0.2083 - val_loss: 2.8475 - val_acc: 0.1182\n",
      "Epoch 445/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0954 - acc: 0.1875 - val_loss: 2.8698 - val_acc: 0.0818\n",
      "Epoch 446/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1021 - acc: 0.2208 - val_loss: 2.8342 - val_acc: 0.1091\n",
      "Epoch 447/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0928 - acc: 0.2042 - val_loss: 2.8469 - val_acc: 0.1364\n",
      "Epoch 448/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0987 - acc: 0.2042 - val_loss: 2.8275 - val_acc: 0.1273\n",
      "Epoch 449/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1069 - acc: 0.2042 - val_loss: 2.8424 - val_acc: 0.1091\n",
      "Epoch 450/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.0930 - acc: 0.1958 - val_loss: 2.8509 - val_acc: 0.1000\n",
      "Epoch 451/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.0982 - acc: 0.1750 - val_loss: 2.8298 - val_acc: 0.1091\n",
      "Epoch 452/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1177 - acc: 0.2083 - val_loss: 2.8374 - val_acc: 0.1000\n",
      "Epoch 453/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1106 - acc: 0.2000 - val_loss: 2.8504 - val_acc: 0.1182\n",
      "Epoch 454/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1047 - acc: 0.2083 - val_loss: 2.8359 - val_acc: 0.0909\n",
      "Epoch 455/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0955 - acc: 0.2042 - val_loss: 2.8377 - val_acc: 0.1091\n",
      "Epoch 456/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1141 - acc: 0.1792 - val_loss: 2.8407 - val_acc: 0.1091\n",
      "Epoch 457/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1104 - acc: 0.1833 - val_loss: 2.8491 - val_acc: 0.1091\n",
      "Epoch 458/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.1021 - acc: 0.2125 - val_loss: 2.8384 - val_acc: 0.1091\n",
      "Epoch 459/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1050 - acc: 0.2208 - val_loss: 2.8299 - val_acc: 0.1091\n",
      "Epoch 460/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1036 - acc: 0.1792 - val_loss: 2.8516 - val_acc: 0.0818\n",
      "Epoch 461/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1076 - acc: 0.2000 - val_loss: 2.8349 - val_acc: 0.1182\n",
      "Epoch 462/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1063 - acc: 0.1667 - val_loss: 2.8491 - val_acc: 0.0818\n",
      "Epoch 463/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1063 - acc: 0.2042 - val_loss: 2.8492 - val_acc: 0.1091\n",
      "Epoch 464/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1121 - acc: 0.1958 - val_loss: 2.8196 - val_acc: 0.1091\n",
      "Epoch 465/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1045 - acc: 0.1917 - val_loss: 2.8366 - val_acc: 0.1091\n",
      "Epoch 466/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1046 - acc: 0.1958 - val_loss: 2.8488 - val_acc: 0.1273\n",
      "Epoch 467/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1068 - acc: 0.2000 - val_loss: 2.8179 - val_acc: 0.1091\n",
      "Epoch 468/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.0976 - acc: 0.1875 - val_loss: 2.8363 - val_acc: 0.0818\n",
      "Epoch 469/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0969 - acc: 0.2042 - val_loss: 2.8493 - val_acc: 0.0818\n",
      "Epoch 470/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1043 - acc: 0.2125 - val_loss: 2.8308 - val_acc: 0.1000\n",
      "Epoch 471/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1087 - acc: 0.2083 - val_loss: 2.8440 - val_acc: 0.0909\n",
      "Epoch 472/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1099 - acc: 0.1917 - val_loss: 2.8287 - val_acc: 0.1182\n",
      "Epoch 473/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.0955 - acc: 0.2000 - val_loss: 2.8213 - val_acc: 0.1091\n",
      "Epoch 474/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1047 - acc: 0.1958 - val_loss: 2.8530 - val_acc: 0.0818\n",
      "Epoch 475/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1084 - acc: 0.2125 - val_loss: 2.8315 - val_acc: 0.1000\n",
      "Epoch 476/500\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1000 - acc: 0.2000 - val_loss: 2.8375 - val_acc: 0.1182\n",
      "Epoch 477/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1100 - acc: 0.2125 - val_loss: 2.8265 - val_acc: 0.1091\n",
      "Epoch 478/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1145 - acc: 0.1958 - val_loss: 2.8516 - val_acc: 0.1091\n",
      "Epoch 479/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1010 - acc: 0.1917 - val_loss: 2.8183 - val_acc: 0.1182\n",
      "Epoch 480/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1054 - acc: 0.2083 - val_loss: 2.8277 - val_acc: 0.1000\n",
      "Epoch 481/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1001 - acc: 0.1917 - val_loss: 2.8462 - val_acc: 0.0909\n",
      "Epoch 482/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1102 - acc: 0.1917 - val_loss: 2.8248 - val_acc: 0.1182\n",
      "Epoch 483/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1101 - acc: 0.1958 - val_loss: 2.8433 - val_acc: 0.1091\n",
      "Epoch 484/500\n",
      "240/240 [==============================] - 3s 12ms/step - loss: 2.1031 - acc: 0.1958 - val_loss: 2.8214 - val_acc: 0.1182\n",
      "Epoch 485/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.1185 - acc: 0.1625 - val_loss: 2.8410 - val_acc: 0.0727\n",
      "Epoch 486/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.1057 - acc: 0.2167 - val_loss: 2.8281 - val_acc: 0.1273\n",
      "Epoch 487/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.1199 - acc: 0.1667 - val_loss: 2.8174 - val_acc: 0.1182\n",
      "Epoch 488/500\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.1069 - acc: 0.1750 - val_loss: 2.8573 - val_acc: 0.1000\n",
      "Epoch 489/500\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1033 - acc: 0.2000 - val_loss: 2.8212 - val_acc: 0.1182\n",
      "Epoch 490/500\n",
      "240/240 [==============================] - 3s 14ms/step - loss: 2.0995 - acc: 0.2083 - val_loss: 2.8245 - val_acc: 0.0909\n",
      "Epoch 491/500\n",
      "240/240 [==============================] - 4s 16ms/step - loss: 2.1102 - acc: 0.2125 - val_loss: 2.8474 - val_acc: 0.0909\n",
      "Epoch 492/500\n",
      "240/240 [==============================] - 4s 15ms/step - loss: 2.1034 - acc: 0.1667 - val_loss: 2.8251 - val_acc: 0.1091\n",
      "Epoch 493/500\n",
      "240/240 [==============================] - 4s 15ms/step - loss: 2.1052 - acc: 0.1958 - val_loss: 2.8308 - val_acc: 0.1091\n",
      "Epoch 494/500\n",
      "240/240 [==============================] - 4s 15ms/step - loss: 2.1092 - acc: 0.1917 - val_loss: 2.8312 - val_acc: 0.0818\n",
      "Epoch 495/500\n",
      "240/240 [==============================] - 4s 15ms/step - loss: 2.1065 - acc: 0.1875 - val_loss: 2.8119 - val_acc: 0.1091\n",
      "Epoch 496/500\n",
      "240/240 [==============================] - 4s 15ms/step - loss: 2.1033 - acc: 0.1958 - val_loss: 2.8330 - val_acc: 0.1091\n",
      "Epoch 497/500\n",
      "240/240 [==============================] - 3s 13ms/step - loss: 2.0977 - acc: 0.2000 - val_loss: 2.8238 - val_acc: 0.1182\n",
      "Epoch 498/500\n",
      "240/240 [==============================] - 3s 12ms/step - loss: 2.1109 - acc: 0.2042 - val_loss: 2.8273 - val_acc: 0.0909\n",
      "Epoch 499/500\n",
      "240/240 [==============================] - 3s 12ms/step - loss: 2.1057 - acc: 0.2000 - val_loss: 2.8232 - val_acc: 0.1182\n",
      "Epoch 500/500\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.1000 - acc: 0.1917 - val_loss: 2.8362 - val_acc: 0.1000\n"
     ]
    }
   ],
   "source": [
    "RNN=RNN_simple('RNNsimple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnXeYFdX5xz/nlq2wLB0EZLEiWFARW6xBxRhr7DGWxJj4M5pmEpIYNaCJSaxRbEnUYI0lloiKFRQRBQVBelvpZReWZett5/fHzJl7Zu7MLbt7t8B8n+c+d8qZM2fa+563CyklPnz48OHDR0sR6OgB+PDhw4ePrg2fkfjw4cOHj1bBZyQ+fPjw4aNV8BmJDx8+fPhoFXxG4sOHDx8+WgWfkfjw4cOHj1bBZyQ+dksIIRYKIU7M0GZPIUSdECLYDuOZJoS4Osu2UgixT77H1JJzCiFOFEKsa48x+eg88BmJj04FIUSlEKLRJOCbhRBPCCG6tfV5pJQjpZTTMrRZI6XsJqWMt/X58wWTIUkhxCGO7S+b20/soKH52IXhMxIfnRFnSim7AYcBo4GbnA2EAf/9dccy4HK1IoToDRwNbO2wEfnYpeF/iD46LaSU64E3gQPBmm3fLoT4GGgA9hJC9BBC/EsIsVEIsV4IcZuuihJC/FAIsVgIsVMIsUgIcZi5vVIIMdZcHiOEmCOEqDWloLvN7RXmLD5kru8hhHhNCLFNCLFCCPFD7Ty3CiGeF0JMNs+1UAgx2uvahBCnCCGWCCF2CCEeAIRj//fNcW8XQkwVQgzN4dY9DVyk3YdLgJeBiNZ/oRDiXiHEBvN3rxCiUNv/K/OebhBCfN8xtkIhxJ1CiDXm/XpYCFHscZ0HmM+txrwnZ+VwHT66CHxG4qPTQggxBPgWMFfb/D3gGqA78DXwBBAD9gEOBU4FrjaPvwC4FWN2XgacBVS7nOo+4D4pZRmwN/C8x5CeA9YBewDnA38SQpys7T/LbFMOvAY84HFdfYD/YkhafYCVwLHa/rOB3wHnAX2Bj4BnPcbkhg3AIox7Acb1T3a0+T1wFDAKOAQYY44HIcQ44EbgFGBfYKzj2DuA/cxj9wEGATe7XGcY+B/wNtAPuB54Wgixfw7X4qMrQErp//xfp/kBlUAdUIPBKB4Eis1904AJWtv+QLPab267BPjAXJ4K/DTNecaayx8CfwT6ONpUABIIAUOAONBd2/9n4Alz+VbgXW3fCKDR49yXA7O0dYHBoK42198EfqDtD2BIYEPNdQns49H3NAxGehkG8xkOLDP3rQNONJdXAt/SjjsNqDSXHwPu0Pbtp85pjrUe2FvbfzSw2lw+EVhnLh8HbAICWttngVs7+j3zf237C3kxGB8+OhDnSCnf9di3VlseCoSBjUJYmqGA1mYIBsHMhB8AE4AlQojVwB+llK872uwBbJNS7tS2fY1hw1HYpC03AEVCiJCUMubSl3UdUkophHBe131CiLu0bQJj5v91FtcDhsRzF4YE9qTL/j0cfX1tblP7PnfsU+gLlACfa/dcAG6ebXsAa6WUCUdfg7K7BB9dBT4j8dHVoKerXoshkfRxIdZq/94ZO5RyOXCJabw/D3jRNFDr2AD0EkJ015jJnsD6XC8A2IjB5ADDcUBfN8d9u5Ty6Rb0DYCUskEI8SZwLe73YAMGw1poru9pbksZn7lPoQpoBEZKw4aVDhuAIUKIgMZM9sRwBvCxC8G3kfjospBSbsTQv98lhCgTQgSEEHsLIU4wm/wTuFEIcbjp5bWPm9FaCHGZEKKvSexqzM36LBop5VpgJvBnIUSREOJgDEnmqRYMfQowUghxnmnIvwEYoO1/GPitEGKkOb4epr0nV/wOOEFKWemy71ngJiFEX9NmczPJa3keuFIIMUIIUQLcog4y79E/gHuEEP3M8Q0SQpzmco5PMSSzXwshwqbr8ZkYdiQfuxB8RuKjq+NyoADDuLwdeBEYCCClfAG4HXgG2Am8AvRy6WMcsFAIUYdheL9YStno0u4SDLvJBgwvqFvSqOA8IaWsAi7AMFpXYxi0P9b2vwz8BXhOCFELfAWc3oLzbJBSzvDYfRswB5gPLAC+MLchpXwTuBd4H1hh/uv4jbl9ljm+d4EUA7qUMoLBOE7HkGQeBC6XUi7J9Vp8dG4IKf3CVj58+PDho+XwJRIfPnz48NEq+IzEhw8fPny0Cj4j8eHDhw8frYLPSHz48OHDR6uwW8SR9OnTR1ZUVHT0MHz48OGjS+Hzzz+vklL2zdRut2AkFRUVzJkzp6OH4cOHDx9dCkKIrDIp+KotHz58+PDRKviMxIcPHz58tAo+I/Hhw4cPH63CbmEjcUM0GmXdunU0NTV19FC6BIqKihg8eDDhcLijh+LDh49Oht2Wkaxbt47u3btTUVGBlg7bhwuklFRXV7Nu3TqGDRvW0cPx4cNHJ0NeVVtCiHFCiKVmWdLxLvt/YZY/nS+EeE9lZhVCjBJCfGKW5pwvhLhIO+YJIcRqIcQ88zeqJWNramqid+/ePhPJAkIIevfu7UtvPnz4cEXeGIlZL3oSRubPERj1HkY4ms0FRkspD8bI2vpXc3sDRpbQkRiZWe8VQpRrx/1KSjnK/M1rxRhbeuhuB/9e+fDhwwv5lEjGACuklKvMdNLPAWfrDaSUH0gpG8zVWcBgc/sys9gQUsoNwBaMymw+fHQKRGIJnp+zlq6ePTsaN64jkeja1+GjY5FPRjIIe1nUdaQvsfkDjFrVNgghxmDUm9BLpt5uqrzuEUIUunUmhLhGCDFHCDFn69atuY8+z6iurmbUqFGMGjWKAQMGMGjQIGs9Eolk1cdVV13F0qVL07aZNGkSTz/d4kJ7PjzwwAcr+PWL85myYGNHD6VVeHjaSn794nxe/bIlhR59+DDQKYztQojLMGpfn+DYPhCj3vQVWqnO32LUxi4AHsUosjPB2aeU8lFzP6NHj+50063evXszb56hlbv11lvp1q0bN954o62NlBIpJYGAO79//PHHM57nuuuua/1gfaSgqq4ZgJqGaAePpHXYvNOwe+1scqtU7MNHdsinRLIee93nwbjUtxZCjAV+D5wlpWzWtpdhlCT9vZRyltoupdwoDTQDj2Oo0HYZrFixghEjRvDd736XkSNHsnHjRq655hpGjx7NyJEjmTAhyTO/8Y1vMG/ePGKxGOXl5YwfP55DDjmEo48+mi1btgBw0003ce+991rtx48fz5gxY9h///2ZOXMmAPX19XznO99hxIgRnH/++YwePdpicj7coSxGnW6GkiPi5vQs4NvAfLQC+ZRIZgP7CiGGYTCQi4FL9QZCiEOBR4BxUsot2vYCjFKmk6WULzqOGSil3CgM6+85GGVIW4U//m8hizbUtrYbG0bsUcYtZ45s0bFLlixh8uTJjB49GoA77riDXr16EYvFOOmkkzj//PMZMcLut7Bjxw5OOOEE7rjjDn7xi1/w2GOPMX58iqMcUko+++wzXnvtNSZMmMBbb73F/fffz4ABA3jppZf48ssvOeyww1o07l0Nc9dsp6QgxOCexZQW2j8Vi+46bCRrtzVQGA7Qr3uRa5+rq+rpURymV2lB1uP4av0O9unXjaJwMKfxp8OmHU3EpbRsI8FAbozk6+p6uhWG6N3NVbNsg/Oat9VH2NEYZVif0rTHSSmZu7aGQ4eUp3X22NkUZcbyKkZX9KJvd/fxLN+8k35lRfQotsdBZXuOXCGlZN7aGg7ds6fr/nhCsmD9DkYNKXfd39WQN4lEShkDfgJMBRYDz0spFwohJgghzjKb/Q3oBrxguvK+Zm6/EDgeuNLFzfdpIcQCjDrTfTDrTO9K2HvvvS0mAvDss89y2GGHcdhhh7F48WIWLVqUckxxcTGnn26U9T788MOprKx07fu8885LaTNjxgwuvvhiAA455BBGjmwZA9yVMHXhJs59cCan3fshP3ry85T9agbvtFEf99cPGHP7e579nnTnNE69Z3rW49iys4lv3z+D37/c6vmSDUf9+T2OveN94rJljOSEv03j+L9+kFXbk+6cxun3fWitn3L3dE66c1rG4177cgPnPTiT177ckLbd05+u4dqnv+Dud5Z5tjnlng/5zkMzU7ZPXbiZ8x6cyQufr8s4nlzw3Oy1nPvgTN5ZtNl1/11vL+WcSR+zeGPbTmA7Cnm1kUgp3wDecGy7WVse63HcU8BTHvtObssxAi2WHPKF0tLkTG358uXcd999fPbZZ5SXl3PZZZe5xnMUFCRnuMFgkFjMXeddWFiYsY0PqKyqt5Y/WVWdsj8pkOSu3Kqqy86ZApI2mHlrt+d8nmxgSSQtmI3XR+IZ26j7s7nW0lpTXZ/d9a/YUgdAZVVD2nY7m4x7VNvkbq9S16j607FxRyNgSH0Xjh6Ssr+lWLW1Tvvvn7J/lvlO1TXvGt+gn2urk6O2tpbu3btTVlbGxo0bmTp1apuf49hjj+X5558HYMGCBa4Sz+6GTDYDpQbJhY00ZkF4nYjEDCNGONh2n2q9RryURJLIkxtzY9T7mjMxYTWmTMJSNG60a/K4v/URb2LdzVRZtjVBD5oOMjEPt2rl3FBS0Hbqyo5Ep/Da8uGNww47jBEjRjB8+HCGDh3Kscce2+bnuP7667n88ssZMWKE9evRo0ebn6crQecj6ehYLuEX2xuSM/FEQlIXiVFWFEZKSW1TLEV/D9AcM4hjKGgyLrNtSUGQ5liCboUhdjRGKSsKZa3jr6xOSls7Go1ZvCJ4kViCSDzBph1NDO5Z7GqXiSoLfRbYnsarrTmWSGv3UafZ3hBlS20T/crc7U6K2TbF3BlJg8Zg1m5roLggSPeiEIkElu2rTvNacz6Ppmic9TWN7NWnNOt7HDafVyyenpG0hn83RGKEAgEKQh0vD/iMpBPg1ltvtZb32Wcfm8eUEIInn3zS9bgZM2ZYyzU1NdbyxRdfbNk8brvtNtf2AwYMYMWKFYCRkPGZZ56hqKiI5cuXc+qppzJkSNuJ+bsilMSSi2pLdxW+8+2lPDhtJfNvPZVnP13Dn99cwqzffpMBPezEsr7ZZCTmDPe+95Zz77vLGTGwjEUba/ngxhM56c5pTDznQL531NCsxrF2W6O1PG2pEWOlmMMVj31mqfLOOHggky5NdbxoaM5estqeRo1V3xxLy0iURPLYx6t57OPVLPzjaSlOD/rYm6LuDE6XNo4z7TqDexazbnsjD37XuD5danlq1tf84dWFTLvxRCr6lPKL5+fxxoJN3HfxKM4elS4ULomQJZG4j0mp4+KtCAQdcfNURg0p55Xr2n5ymSt8RuKDuro6vvnNbxKLxZBS8sgjjxAK+a+GgtunriamzbHsZ+c1mkTy+nwjkHFbXYS3Fm4CYN32BhdGYhA4NcN9YY5hFF5kGmmXb94JwPSlW7JmJA0uqh41q9ftQds8bDl1aVRFTijmqcavo745Tu9u3sc6iWxdc8yVkaixe6kO3Rjfuu0GM1VMSJdI3l1sOJCuqqqjok+p1TYX25aSIL1UW8q+5LU/W8xbW5O5UTvApxY+KC8v5/PPUz2Tdmdkq8KIeDASKWVKH7qaRxHWaDxhGbrdaIoiOGqG69TlKxtELjYUtzFHXNRVXrPphhzsCTWNBvEtKUglNelsF5DKSLxUapZE4qHaSmf/UKonvU3INMqo0ymh0+tZu0H1EcugBsyXbaq90fHKNR8+OiGEx7KCIhBeEombmkUR1WBAWIS/MRonYBGuVKKiJBI1w3USRWXjyIWRuI05Gks9d3MsgdRiTRT0Mbip9hIJaW1XzLNUMyorV+P6DAzJSWSjHvYGtb3Zcc/VuN0ksOSxCXMsSSbk9TyaPRiVG0Lm8/Aas4KXDaWrwWckPvKOivFT+Pt7yzvs/JFYgorxU5j8SWXWx2QSSCImAXh4+kpembueaNw4h8KoCW+nHKPUPEWhAIWmgbS+OW7NXi/5xyw+Wr6VmoYIFeOn8OaCjdas/aPlVfzy+S9TiJvq88t1NVSMn8Ka6gbG3j2d37w4P+X8G3c0UjF+CtOXpeaeUwS1QGNIkViCsXdPZ+QtU9nREGVO5TYqxk9h8cadVpv3Fm/hm3dNs4js9voII255i9Pu/dBaByjRVFJF5rWf//An7GiIsv9NbzLpgxU8NG0lFeOn8Je3lvCL5+elMBLn7H7kzW9x+5RFljS1ozFKxfgpPDXrax6evpK9fvcGD09fyQ/+PSflehWaTIlOdx1WEuKPn/qcD5Zsse7Nve8up2L8FE74W+b4GfX6ZLKBuO3/wytfcbIZZzPx9UVUjJ9CxfgpVNc1p7RVOPnOaa7PvL3gMxIfeYWamaYLFss31Az6rrfbbgy6muPRD1el6OHdZv1qW0ImJYj65pgtGPChaSuprDbiJh6cttI2a3/pi9SgOcVIvjaPmb58Kyu21PGfOWtT2n62ehsA7y/ZkrIvGk+QSEhiiQT79+/OUXv1ojmWYOXWehqjcTbvbOJ5s893Fm1K9lm5jZVb69lhjmN9TSNN0QTLNhtxFGu3pcaA6Ab2T1ZV0RxL8LepS/nLW0sAmPrVJr5cW4NTK+Sc3ddH4vzjo9VJO4f1nJdamSpenZc+mHFHo3FMQyRuMSr9eTz28eoUlZa61+mgGISXelDBbf+Ts75mVVU98YTkXzNWW9vVPXVCSsmqqnrXZ95e8BmJj7zCTffe3lBkIZeYO32m6Dan1PX1JQXBjAQDkqqWplg8yUgiMVvMypadzRSFk0ymPoOHlG7AB2hMo8apTmMsbo4l2NkcIyHhgtGDGVReYs3Wwc449TFtqW2yjldjVpBSstoM7NTvl85IPlxeBUDPkrBlN1pVVU9TNJGiUvOykTgJfSwuLXVWxEUdVai5yyp1IxhMEJKqLYVcHCqssZrvg5tqS1cHprORbKhptK17ZR/YstNbUmkv+Iykg9AWaeQBHnvsMTZt2pS5YQehJR9hW6MlBs1M3jQ6USs2Yzqy7VMfTn1z3EYgttQ2WXrz+kgsox2hptEep6ETeeexevyIE9F4wmJK5SUFFIYDtuN1+4CuBlJEzGIkGiOLxqV1zqh2fwrDSbLzgSkd9eteZGMwTdG4FSyp4MWsnQwmmkhY0slWFyK7d9+kq9gOzQFCMT2ng1lL3mH1DN1UVzpzSWcjcT4vr4mQGndBGwat5gqfkXQQVBr5efPm8eMf/5if//zn1rqe7iQTOjsjyeTpEk9ILv3HLD5eUZV1nze/+pXN3vHqvPX87Lm51vov/jOPNxds5MNlW/n+E7NdmcLd7yzjfofdZn1NI2c/MIOqumYb4YsnJOdM+pizHpjBuQ9+TF1zLEUiSXedv3z+S86Z9LEtpkIRyQaHRFLbFOOcSR8b+5rjtmA6N6ggR9WFHkl+8l3TmFNpqLMWrNvB5E++9uwnGk9YhvGeJWEKggFbCpTvPPSJZRvRZ8qbTYnkzPtn8PbCTXz/iaQ9Ylt9xHKZ1SXTolCSYWzcYRy/dPNOWyr7pmg8RSKJxCTXPf0Fby+0v++zK+3pY5qiCWatMq671iU9/t79koxEZ8TXTP6cSCyBk7a7STU/enIO0XiCHz05h4+W221O7y/ZbKly1XW/MGctZz0wgysf/8yeWSDNhGV1lZ2RvDJ3Pdc9/UVKO5XOZ3CvYs++8g3f/bcT4t///jeTJk0iEolwzDHH8MADD5BIJLjqqquYN28eUkquueYa+vfvz7x587jooosoLi7ms88+y4kJtQcyzeaq65uZubKaZZvrmHOTa+q1FCiCePnRFQD89DkjgPPeiw+lORbnv3PX89+56wkGBPGEdJ3VK+P/9d/c19r2z49W8eW6HYbx3PGB6/76n6ystl1XaUHI9TrjCUkwICzbhnTsA0Ov75xIKsZXF4ll9BRSM+rCUICmaMJGjDfXNvOrF+fzwY0nMn2ZMfMf2KPIIt46onHJejNeYkCPIgrDgRQit2D9DsBOnLeZzLExGucaR3LLTSaTKSsK2Rit8kC79sS9WbutwYqp0dHoIZFMWbCRKQs2supP3/K8J2749sEDrfOcOqI/a7c1MG9tDTsaowQEDOtTysqt9WzZ2ZQSj+L2bKcu3Mycyu1MXbiZ6cu2smTi6dY+nZk2m4z9V5oh/DOTuRvXZL9GnXlur7dLm09/ugYw6pfrUHnM+nlkPm4P+IwE4M3xsGlB2/Y54CA4/Y6cD/vqq694+eWXmTlzJqFQiGuuuYbnnnuOvffem6qqKhYsMMZZU1NDeXk5999/Pw888ACjRo3K0HPHIKPvvfndtEUG70RCssY0hJYUBK3ZfKZZvRvS+f8npLRJJIXhgO06+3YvZOvOZiNGJJCcfVdpahbF3BoicU/dt5SphKZXaYFFvCEpkSii77SZ7FFuBDiuqqpnQFkR3z1yT+7UnA6GD+hONJ4gEkuwusow5lb0LqUwSzWJU7WmQ42tZ2kBW7SkjbG4ZOwB/fjNuOHm+udWUKZCQqYGGOrruQTy9S4t4KpjKyxGUl4S5rZzDuTb98+gpiFCKBjgF6fsz3XPfEFDJO5Q48U87XzvLzEy++5R7i0JuOUa0yU6p9pVVxt6xcXE4gnbO6PsPCJtMp/8wldtdTK8++67zJ49m9GjRzNq1CimT5/OypUr2WeffVi6dCk33HADU6dO7TK5sDLNqNVn1BafQEM0bqkD9uxVYm1PlzjQC+nySUlp13NH49J2ncpYHktI26y+uj5JTGtNAlzXHEtLAJw69L6O+h9KHaXG4zSo79HDIHKVVfVU9ClxqatixLRE4glWVzXQv6yQ0sIQhRlqn+xjqofSmZ90m4tOjBNS2ghhSaH7uXY4mJQ+IXBKS+nyTZWXhG3BoUEhrGSJOxqjFAQD1hjqmmM2J4Oqnc2e1/iBmV5mUBpG4hZPtFzLQux8vnoanSaP97YplrCNSR3TmnQrrYUvkUCLJId8QUrJ97//fSZOnJiyb/78+bz55ptMmjSJl156iUcffbQDRpgb1Ezda9atXv4tO5v5cNlWjt+vL6/P30BhKMgpI/qTSEjufHsplx9dkZI+xImG5phloBzSq4Qlmwydvq7amlO5zdqeDukCyf7y1hJbkFsklrBJJMUmEY7FE0Q0AqYTFaUeanDYW5yY4bAd9SsrZOlm7/HrahOAbkXGJ15Z3cBpIwdQ6ogwDwgjeG7RhlrW1zRy1F69gMyG2+EDurumZddRo9lc4gnJXW8v5bzDBhNL2BlJsQfTSsdInIb3sqKwVf7YiZ4lBbY0+UIIK+tvVV2E8pKwtd7QHLdNPJQNyA3q+nsUh/nNi/MZ1LOYq48bZmuzbPNOJr5uz6a9XHt+8YTkyU8qGbFHGYcP7WVL7OnFSBojcZvnmSWVatzl86+3M3fNdq4+bi/P8bclfImkk2Hs2LE8//zzVFUZBKS6upo1a9awdetWpJRccMEFTJgwgS++MIxu3bt3Z+fOzISxo6D0y16pwPVZ1OWPfQbAT56Zyw8nG3rmuWtreHDaSn75QubSv3XNMctLp3tRkmDqKpHzH/6Em15xLxKlSwbp3HlXV9Xb6ms0x+I2PXqxSawj8YSnak95FdU2pWckOspLwlx/8r6ZGwLH7N3bGEMsQVM0zrb6CIPKi1IkkoApkSjX128dNBCwe1bpCAYEBw4qY9yBAzKOIWm8N+x297+/gje/2kgiIW0OBs6Z9NgDjPodtSmMxNtIXeoh1YDBTHXGFQwIW4XKxkjcklAMicR4HsXhYFYqtLlravjPnLXc/c6yFPtTaUHIFgsC9tossYTkD68u5DsPfWKdX8ErCWVTNG67fnWf9bF+56GZ3DZlcU5pXVqDvDISIcQ4IcRSIcQKIURK3VchxC+EEIuEEPOFEO8JIYZq+64QQiw3f1do2w8XQiww+/y7aMv6mJ0ABx10ELfccgtjx47l4IMP5tRTT2Xz5s2sXbuW448/nlGjRnHVVVfxpz/9CYCrrrqKq6++Ome34faCepG9HlMmIqp0yM70F25oiMStj083WqazkdjjRTR1lUvKECe+ffBADhrUg0gsYWMkKnI75lB5uaGmIZJ1rM1/rjnasnkAdHcwhfKSZBr6i8fsyR49imiOJayZfXlJQYoaSQh7epXLjjQ+QS+J5OrjhvH69ccxZlivjONVqi09PX5Ds2FED2mEXSd2Zxw0kHMPNTLsppdI7M8nXYqYwlDAxriCAUMKu+O8g4zzxxNJiSRiqLbOO3QQvx63f8ZrhGT8CSSTQSr89lvDU9rbGKJDb6ZPerwkkuZY3GZb2WHeZ6eXG8Da7ZmDJ9sCeVNtCSGCGA4GpwDrgNlCiNeklLqcNxcYLaVsEEJcC/wVuEgI0Qu4BRiNoUb/3Dx2O/AQ8EPgU4zqi+OAN/N1He0BPY08wKWXXsqll16a0m7u3Lkp2y688EIuvPDCfA2t1VCE1EsiyTTjyyaYsMDU8dc1xyy1hK6ZakhjI2mIxOheZK8DEo1LK6AsHQqCRqqT5ljCxjCKC5RqS2bUW9c0RK2EjCn9h+xG/JKCoI1g9i0rZOfWJFHqVhiy1EmFoYB1vGX0LimwCKaCEIKwyfjCQWEF43lJJEoNVRjMXJBJjUVncHXNMWJxaQv60xlpPCGTAZmOCYAeo+L0pEqniisIBW0SiWIqKm2LlMmkkvWROE3ROEUFQUuSygWVDpfdcpc+9FifuGMS0WReV0lB0NO21xhJuEokbu/a6q31triZfCGfEskYYIWUcpWUMgI8B5ytN5BSfiClVCxzFjDYXD4NeEdKuc1kHu8A44QQA4EyKeUsaYSHTgbOyeM17LZISMm2+uaUKNxX5q53bb94Yy2zHfp5SM42vSoOpgvI+mDJFktGUMNwm3UpQ+vMldV8utpIg65nqFXLNS5Fll6Ys45/frSKjTsaeesrw3OoKRrPKplegUasnQQfDAKZyf15VVV9il1DodRRPa8oHLTN5J3unrrBuSAUoDAUZMaKKmatNO5Jz5JwSkW+gEgS4UItvqPAg1GooEEvRqND1VrXCXJDJEbCIZHoUmlcSk+biZ6GxpniPpzG2F4YCthcrBVT6aZJZ4rBLlhXQ1VdhKJQkB4lqYXGMsEZ+1HuUqxMZxDPz0mmvdmys4n/mq7iPUsKrFqLs765AAAgAElEQVQxTjTF4ujznFpHbRM9XildEGpbIp+MZBCgJ39ZZ27zwg9IShZexw4ylzP2KYS4RggxRwgxZ+tW9wfiwxtVdc2s295oM/5tb4jys//MY8mm2pT2p9/3ERc8/EnK9uZMjCTNzP+qJ2anbHOTFBQB/ft7y62iTbpaJJ1qa8Lri7htymKO/vP7ln67KRrPym5RWhiyJBJbwJ0ytie8bSRuON1hd3CmXu9RHLYRzL7d7c4HOiNQEsm2+gi3/s9QApS7SCTXnrA3BSHj2eiMqNCDMCu1XToJoE83+yxct8vUR+IpxvYrzHggMIihl8eY/hyr6u2G9QKXeidKEipwqLYsiUS7v0XhAAGRJOwHDOyeUSIZ0quYviYzVwzayUgy9aHqygBMnvm1xTzK0zCxxog9xkYtqm2rtDE4VW35QqcwtgshLsNQY/2trfqUUj4qpRwtpRzdt29frzZtdbpdDsmkcyqth7TE8FziMpotG4n7/kxptrNp70bUdEkgV/dfg5HYz+MW7FXRu8SSSHQbjppRR2NJG4kao5eb6riRA3jossP58pZTk/2YxOnsUXtQeccZFIQChDU1WE8HsXEyAiczKC8J24hn5R1ncOrIAUkpwyHRuEGNKRAQKcWqKu84g8o7zuCfVxxh2663q2+OpRjbj9mnD49dORqwq7ac0G0LTkO8rh786o+nUXnHGYwaUm5dl9PYDtiYqhDC8mgbUFbEBaOHpNxfHcXhIB/9+mRG7lEGwJCehrt5ikRSmuzj5OH9OOPggZ59rtya9ILTGdDt5x7I4J5JF2OnsV1BbdPVa864onwhn4xkPaDXax1sbrNBCDEW+D1wlpSyOcOx60mqvzz7zAZFRUVUV1f7zCQLSCmprq5mS0OSqWSL5gzuv87AP+d6NJZ+P7irWXSbRbp6FG5oiiZSJKWKPqUp7Yb16UZhKEhzLG6TSCxGokkkyquoSCPQOsFUx+vEXKm2dCIZCuoqIftzKLQxkmAKM3CzkRjjMM6TlUQS1tVf7m2cDEZ3tHAztkNSSkikUW3pNhMnI9EJqxq7um9OiUS9i041n3JECJsSWnmxtzSh+lD3YJBJ6Nc4sh13L0x6jIUCIq0kN3/dDmtZV6sJhD0PmVknxgl1D1ZX1RMMCA4YWGYrppZP5DOOZDawrxBiGAaxvxiwWZCFEIcCjwDjpJR6buupwJ+EED3N9VOB30optwkhaoUQR2EY2y8H7m/J4AYPHsy6devw1V7u2NEYZWdTjKbiENVFYYqKipiy0uDz2cQ9LdpQy9DeJRltJM6ZlV7rAlKlCZ14Ltywg4repa4eO7pEMmN59nm8AD5cvjUlsG+vPqVWGnaFij4eEolmbG+2jKchtjdEKS4IuuZ/UrEuOqFRxEMnuvqyc7bplCicjKG4IOhKgIpzkEhs6rNwMMUg7uwHYLPmElvXHCPuMLZDkjAbEok7I9EzGzvvoc7IQxrhVmMO2Iztxr+TqRoquGbrGegu5E6oPpQaTvem0yGEoLw4THV9hFAwVYrToXt/6fl0NtU22SYdK7bU2bIkqPFs3dnMyq11rK6uZ3BPQ+3WXhJJ3hiJlDImhPgJBlMIAo9JKRcKISYAc6SUr2GosroBL5izljVSyrNMhjERgxkBTJBSqq/4/4AngGIMm0qLPLbC4TDDhg3L3HA3xd+mLmHSB2v55Sn7WfmoGuOGMdrN4K2jKRrnnAc/5jfjhmf02nLmtDrzgRm2dacaTbddnPH3GXxzeD/X7L46Ya/Mon6EDrdcVKMrevHcbHu9hz16FGs2Ej2yPWiNVTFSRbR0InnI4HI+NZmT8kjSCZ5ikLoUos/uTx7ejze/SqYWKUwjUShViTr+jIOSKhZFpApCqUzMieKCbCSS5PayopCl/ulfVkhDJOYqkexlehadfuAAT/uA7u3klEjOOGiglQ/N6WpeGArYAhKdXlsKSkJR4w8EBOUlYWoaopwyoj/vLNpstb3kyD2B5D0oKwozqLyY9TWN7NWn1Gan6FFiMpJAIG0Evg59AnXokHJmraq21t2KxBWFjZRA37xrOocM7sGevUroWRLm63Yytuc1sl1K+QaGi66+7WZt2TNLn5TyMeAxl+1zgAPbcJg+XKA+NumyLZPL7vaGCJFYgtrGqGYbyU615YRTLeX0ppq+bKtrrqNcyqJ6oTgcZO7Np5CQkq/W2x0Mvrz5VAIBkd5GonltJVVbSUJ8+NCeXHvi3lz5+OyUwliQVBF5xUicf/hgTj9oIGfeP4PVVfUpXlv6vdKJ85KJ42x9qjHpxNYZAZ9sqzErD1uG3vfsm8ZSGAqy8I+ncduURbyzaAuxRKpEMqi8mEUTTqM4HEQIwec3jSUgBIdOfMe4nmDARlx1Z4pbzhzBlcdUcPsbi219qglGYSiA7mFtqbYczFJJW/p9/PDXJ9EUidOnWyG3TVnMYx+v5rqT9uaXp9hjTEoLQ7zx0+OoqmsmKAQnmhUO9X4NiSQ7RqJiSO69aBQnDe/nWtRMR3E4mVtuzbYGTtivLz2KwzYPrnzCT5HiwxVqVqerntTHmMkTSWUtjSUSlhrMqyZIJqakZqGKxrl5bbkxo7aog9IYjVszc6dKoqzY+HQKXLy2dNWWklRKLYkkSUjCwYBlRK13seOout9e9iWV6sNSs9i8toI26U1nJE5pQ41XfxRe+a9ylUjUmEoLQ5QWhAz334S0MS3rnBrz6u3IKVYYstdH0RlJaWHINeBVvXMFHhKJk5kpKc4uUYUpM+OMiguM7cXhpKpM2dJKC4L0KA7TozhsS6qp95vJRqJDMRI1SRqYIT2Q/ky3N0QpLymgR3GY2qYYsXjCepfyhU7hteWjc0BKyfb6CLF4wvpodZ26+gCbYwlqm6KuLrJSSksvu7Mpxk7Txz0aMwonOXX0meI11Cy0rjlOJJZIOackWT9dR1sX1HKqJBThKgwFicQTLNfKoCqJpKYxatl8lGpLd20tCAWsgDW3SogFLqotN1hG5WDAYioFoYCNSadzQ1Vj0pm9m1Ee7ATLSyLxUt+UFIaMkraJVNVWJoRDAVslQJ2ReNnf1OV7eW15jTuXAlHq/dVdnJ1qRdVvKBjIQSJJBiYCDOyRvtaI09OtZ0mB5XXmzBCQD/iMxIeF1+dv5NCJ73DmAx9b+YF0Ei0sRhLn4Fvf5v/MIjs6c4gnpJVafPInX/PULKOGws7mGKMmvMNTs+zFlTKVqFUMbfHGWi79x6wUxhNPSNdkfW2RCbW3lo/Ji7goovGJpsNWxPbGF77k0Q9XAUlCo3skhYPCClhzSzmiGEjYI/JdQY9GP2n/fta4YjaJxJuRKHWVfsu840gySyRe2/X76ZQGMsE5y9fTratMz87z6hJJIA0jUd5xlkTice379e8O2CssqomNLk05GanVr6kKzQaHDTVcl/uYktkhpiuzF4odHmg9S8P0NO93e3hu+aotHxa+WGNUmlusBUklbBKJ8a/EbmV81NU6kXjCFsToxNuLNvM9LQAtk0SiG9vnfL29TWvA33vRKA4e3IOT75oOwOTvj2Fwz2IKw4Z3k04cvGaSPVwil93iINQMX++nOBwkFAzw3i9PcFVdKILnNYNOtjP+C4IBHrj0MNbXNBIOBmwebukC3BQR0icEuqrorZ8dx7h7PzKurSBVbfXRr0+yudJ6eSZddMQQbnltIUDOEokTapY98ZwDLSY863fftNlRkhJJ0FW1BTDjNydZ9qACZSPxGP9Zh+zB3n27ceCgZAkHJfXpDMJ5bYqRBAPeEsn404dz+oEDOOFv0wD4w7dH8L2jkhmvDx/akyk3fAOBYHtDhO/+81Pb8TqDB+O9HDOsF49873D6l+W/4JXPSHxY6OsSdKfPUtUH6Ew1omcpjcakayqSZH+pVe/SwVndMJvUJdmiZ2mB5S0EMHxgd/p1d9dFe81SdZWR8uByy52ljO06HVEqJa9cSCobcTqXUaNPM8VJ2HDxVbVC9HubLrhOESEvO5buzFDkUM0VhgIM0Wq/GONxH29ROMiBg8r4an1tzhKJju5FIWobjffikMFJoq5n9IUkYywIequ2BvdMjt3NRqJDCGFjIpCUSLw864x+k3Y2r2c5oKyIob1LbcfsP6C7rc3IPbxrEKVIJCUFDOxRnFEl1lbwVVs+0sJNItmmSRzNsbgtY2kknkjrKeJUOWWKbHcmXMzk5ZULnB+1l6cSeKtrdAKtVDduhFSptHRa7eViq6DoUSZDqboMZ34su9dWGtVWONXYrkNXrRU50rC42VLSJeRWRNrN2J4tepYUWBJJOmlNV23pp/M6xLKRZKl+guQ9Tqd+TNpIvFVbmexgmeB8l1qScLI18BnJbo6zH5jBy3MN10I3F1Sd8CkCoTOK/W96i2P/8r61Ho0n0pZfTSQM/XbF+Cm8Om99RluGs9yqPadV615fpx3AK6IavBmJHoE8fKARL+FGXAtc7BDpzgdJh+lMaqCQJpHo0CUFZ/4rHcobyStjQTgorCqAOvMtLQylDdpzu75wBk+0bKA85gDPzMmAldgwGBB21ZbHuTNJJG5Q0pqbilPBcpoIBDzfo9aq+pyMpHea550P+Kqt3RiRWIIv1+1g0YZazj3UXlRHQQ8+tCQS0733iIqe9CotYOrCZKBWxPTO8kJcStabieQeeH8FFx0xJKWNHtDlVG3pEky/7kUpKSlOHt6P5licj1cYxu+J5xzIHzwKWTkJRjp1i0qbAfD69d+wlvWZ3z0XjeKTldVU9EkS8Gk3nsjX2xpYaVUTTI7fixG+ccNxJKRk8ieVQCqReeW6Y202CUVLnUTq7xcfyierqmmMxjhuX/d8c5BUvXhlvgkGBP/9v2NYsmmnTdq4/uR9UozgCk9ffaRrWpmCHBnJBzeeSHVdM8GA4NwHZwJw7Qn7cN0zhqNHupm8kkiEsJ/PSxoqaAEjmXD2SE4e3o+DBtvVTv+55ihLrRQMJiPtvfpW6skXfny0zSkhWxSb79KYil5cfszQtHXk8wGfkezGUMF+ykDpJNpgn0FbaapNRvHzsfuRkNgYSTSeSOslEktI6wOPJWRKHMmZh+zBIYN7cNuUxeYY7RLJTs1bp1/3whRGct5hg3ht3gZr/cT9vAloLgRDb6vryXVG0qM4zLgDB9gKElX0KaWiTylrzAjjRBaqrRFmJLiCU7U1yuHBE9S8tnT0KAlnVcmwyMX9V4cQgv5lRfQvs9uP9urbjb08bu+x+/Rx3R7SiGo2GNanlGEOhvSNfZN9p+tHXU5QCHvNdk+JxD1mKB1KC0OuiRiP3Ku3taxOFwoGPG1t6jqOqMhcMMwN6hmWFYf49sF7tKiP1sBnJLsxlASijOVuWX114qKkAaXaKikMpRjoI/H0EkkiIa3zRGKJFNWWc9bmDNTTXX37uXijOA2r6epm5MJIvAiW08jp1a/apt/PzKqtbL22co9/0KGurQ08pjNCTz/SUuh1WrKxkTjP5RV3olRbrVMypUJJQOGg8PQIa42qD/R3qa1Hnx18RrIbQxH0JivoL1UikVIy8fVF7N23m+UFpIzt3QqDDHTMUqPxVK+t7oUhdpp9r9paZ9UticRTAwwDQtjUFau22nMFbdHqXQ/pafcWAsMTSicUaY2gORDeXCo6uxEFJVXYje3pz5/tKS1jew5GYtvx5nid9dzzgYI2MLbrElo6G0mxlT3Zfi5vicR8Ri0emTt0RuZpbG8jG0kru2kxfEayGyMpkRiMxC3deiwh+fcnRnDiGFPsVoyipCBEICC4+dsjmPxJJZXVDYaNxGFs/8O3R/Drl+YD9lTg0XgixZ03FBBpP6qdZtbXc0btwU/H7ssjZsCfQlAI24ebToeuDJJPXHWEzYXZCxPPOZDRQ3umbL/7wkMsY7TCLWeO4Oi9k+oNpS7RJZJMXlsKmbL2W+6/oez6c2Jwz2J+ddr+nHWIXSXy2k+OZeGG1CJmrYG6Dy2RSF657liWOoqqpZvJ33XBITzz2ZoUVaDXIW5SY1tAMc2ElJ5ScGtTmCQZiS+R+GhnKC8tRUTrXLy2tmppKZx5rtQM9vvfGMbIPcq46NFZbKtvtqmrfvet4Qzu5W74i8YSKTaSQECknWU2mckYf/etA1IqCAJIJDrvSKe+UuM/0YwGz4TvHTXUdft5hw1O2XbVscNs62FXiSQ791+ZYY6sLtErGj0ThBBcd9I+KdsPHlzOwYPTR1TnCjUjb0kdoFFDylOYQrpJR7+yIn42dr+U7V7SpeqqrUsUJVPkJ9+D4rC9JntrVVtKus2QBCFv8N1/d2NkI5Es35LMIeVUQ+m6amVE3LLTWQI14OnTHoknUuJCAiK9FKHcgb0YRELaZ2W52EHyCUXwJLlIJNkRF8vY3kJG0p5QM2+3/Ggt668NZ+AuGa/bAoGALpEYy4N62idXrVVtqeM7SiLp/G+ej7whG68tvXSonkq9MBSwieNK933zqwttx4dD3owkGpd8sHSLbVsog0SixupFQBIymaLc6fbZkXCVSLIk/NmqtlpqI2lPqPfEWfmypUj3ruSKfEkkqt9EImk/dKpCW/ueqncgF1teW6Lzv3k+8oZ6h0TiloHWDQcMLOPcQwfZtqVmxzX+w8FA2jxPKx3G9GtP3CftR6UcBJQ94Odj9+PQPct5/KojOHH/vhy9V2/NS8b79Z78/TGe+/IBN/17Jr14UrWVHoqnttRG0p5QM/K2ypnWlhMF5SXX1uW31fsYl5Kj9urN2AP6MeHskdx0xgFWm9ZKVupV6qh5U14ZiRBinBBiqRBihRBivMv+44UQXwghYkKI87XtJwkh5mm/JiHEOea+J4QQq7V9o/J5Dbsy6iNJG0k8IWmMxl09mQ7XDMxnHbIHb/70OO74zsG2Nk6iXWHmDSoIBjxVOPv1t+eYevzKI6wkdV7Y0RilIJisNPfTsfvy8v8dy0n79+OJq8ZQFA5aeuKwx1d1xdFDOT5NfEk+oAhFLjTKGn2Gg7qSRBJuc4mkDRlJviQSpdpKSEoLQ/zziiMY2ruUq4/by2rTmusQQquxsqtJJEKIIDAJOB0YAVwihBjhaLYGuBJ4Rt8opfxASjlKSjkKOBloAN7WmvxK7ZdSzsvXNezq0CUSpeZykx6Gaqk2nDXUFVLyVhXay5a6wRlHkZxden/JtY1Rz6JLCupj8gr+aodwiRRYFSfzcPLWGtvbExYjaaOgldbEoziRfPvy5bXl3aY1Kjo94LKD+EheJZIxwAop5SopZQR4DjhbbyClrJRSzgfSTU/OB96UUuZWeNtHRtQ3J+NI1LKbPUMP6nOzo0Dqh6AIZrpZcqGDkWQzK9vRGE2bXBGSDMnr48wHMc8ES0+ew8mzVm2ZnXcFiUSN0a0oWkcjX8xeMbt4mo5bo6ILBISVymiXk0iAQcBabX2duS1XXAw869h2uxBivhDiHiGEa7J9IcQ1Qog5Qog5W7dubcFpd30optAYjVseXD1cJJIztfgCL0ZSXhK2iMQPj0u6vipJ5eTh/RigBS9+Y58+KSqvbD6m5ljCkna8YEkkHnrn8w9PddfNN3SmcMmYPTlwUFna9gAXHG7kITshgxquK3ltqZQt33ZJK5ILfnXa/mlT47cEx5qpVy4ek5r/rTVQ13xmmtQlrbGRFAQDySh+PyAxFUKIgcBBwFRt82+BTUAB8CjwG2CC81gp5aPmfkaPHt0R2oxOD5V+JCGThYLcPs6DB5fz3/87hvMenGlFqDtRFA6y7LbTrfVv3WcUQlI2l8euPILKqnpOvHMaAE9dfSQ/enKOrQ9FENXEbdzIATz8vcMBWFPdwPF/+wDIHIEdSGNsf+fnx7Nv/+4p2/MNoQWl/fm8g7I65pAh5VTecUbGdkp10hUkkr37dsvqmjLhupP2cY19aQ0GlRe3ydicyOaaW5UNuShkSa27okSyHtBZ+2BzWy64EHhZSmmFSkspN0oDzcDjGCo0Hy2ALl1Umzms3FRbpQVBa7uXROKEerF1O4Wzby+JRB2rfxNBPX15RtWW8e82y+sw98gs9OQtRWsj2310PFpjIykrDmuZjnc9RjIb2FcIMUwIUYChonotxz4uwaHWMqUUhHHHzgHcc4T7yAg9XcnbZtlctwJIQiRri2frIqxXp1Nw1q5wGtvTfUy6B1ZG1ZbZ1i3PVkcZI7P1wGoJ1C3OJWutj86F1kgk3YtC1gRll3P/lVLGgJ9gqKUWA89LKRcKISYIIc4CEEIcIYRYB1wAPCKEsKLZhBAVGBLNdEfXTwshFgALgD7Abfm6hl0deiT7i58bxa28Yj7KTEZywejc7Au6VKAI/OmmzthLIlElRk8d2T9lH2SWSJJeW8b/wVqtiD6l+a9f7QZVH+LMQ9o+xfce5cUM6VXcYbNRH61Ha9x/y4rCHW5sz6uNREr5BvCGY9vN2vJsDJWX27GVuBjnpZQnt+0od1/UN8cJBYQt35XTRrL0tnGAQciXTByXdcZcNfEWjjQfSyaOs2wXzhTvilns3bcbiyeMs6Vo16WVTDYSy2Zgnue/1x5DXEqkzD5RYlujb/dClkwclxeD+BVHV3DJmD3bvF8f7YfWGNsNicQ3tvvoINQ3x+hVWmDLj+VUbel691yIsPLFd2qX9D6840hS63zoNpKMcSSWF5OZRjwY6BQver6YWCAgKAr49pGujNbYSLoXhZMTt13QRuKjnbDdo9xpJtQ3x+jdza7qKU9TezoXeEkkOpxeVenEe31ft4yqLbP/LuDF5MMHtE6SKCsO2coKdwT8L62L45OV1Rw68R3eXbQ5c2MNiYSkIRqnTze7BNLauggKY4YZtUt6pGFMCWcK+TRfQTppJaWtspF0koSNPnx4QX0nrZEkDhpUzl59jZREBwzMHJ+UD3QGid9HKzBvbQ0Asyu3MXZE/wytk2iMxpESepUmGck/Lh/dZuO65cyRXHlMRdrcWekifZ3QJZJMKiKl2uosmX99+PDC41ceYav5kyteuvZoDh9qMKMpN3yDET4j8ZEzEgnCiUYg9/xRKhixt+bFNHxAd1tN9NagIBTIGPjnlEjSQZ+xZTJYpwtI9OGjM6G0MNSqEscj9+jhutze8L+0roz3buXqD4+lmKacU1/XmSVre2uqraJwsF2NdblIJDoyRXCnC0j04WNXQmeRun1G0pUxz0ia3I2mnOPcfvnCl4DhlqpQXBCkWwaPqLZEH4eh3+kO7IVMEdxKImnLokc+fHQmqBIMHRU34oSv2toFIBE5q7ZqzdxaYw9I2lWKQgH26dedB797GP/39BdtOEJ3XH50Bb1KCzhhv77MrtxO/7L0tUgUMqm21CzNj/T2oeOtnx1HrI1K/HY0nvnhUXy1fkenkUh8RtKVYYohLfk0IvEE5x46yObuqzy2vnVQ6zKzZotgQHD2KCPm9JQcHAWytZH4qi0fOoYP6BhDdD7Qp1shJ+7fr6OHYcGX/bsypFHTQSJyVm01RxMUhgJtWhiovZDJRhI3jfi+asuHj/aB/6V1aUhtKTdOEoknukTacTdkspHEEgaDbcsyrD58+PBG16QkPgyo/DrIFkskXRGZGGDU1IO3VXClDx8+0sP/0royVFqEtJWK3dGVJZJsVVu+sd2Hj/ZB16QkPkwoRkJOcSSxeIJ4QnbZQkiZJKlYXKm2/Nfbh4/2gP+ldXJE4wkmvr4obcR5gEROFpKISWh3VYkkqoztvkTiw0e7wHf/7eRYsaWOf81YzSFDyjnLWRSphTaS5qjBSNTM/vffOiCF6P7wuGEcOKjjUi6kQ/YSic9IfPhoD+R1SiqEGCeEWCqEWCGEGO+y/3ghxBdCiJgQ4nzHvrgQYp75e03bPkwI8anZ53/MMr67LBqjRmlb17xUpvtvruGITonkh8fvxVXHDrO1+f0ZI6wYj84G39juw0fnQt6+NCFEEJgEnA6MAC4RQoxwNFsDXAk849JFo5RylPk7S9v+F+AeKeU+wHbgB20++E6EJsVIXEUOVYNA5uT+m5RIuqaNJFOVRuX+6xvbffhoH+RzyjYGWCGlXCWljADPAWfrDaSUlVLK+ZCd25EwMgqeDLxobvo3cE7bDbnzQRH9uKtE0jLVViRuMKeuaiPJlFjSD0j04aN9kc8vbRCwVltfh0sN9jQoEkLMEULMEkIoZtEbqJFSxjL1KYS4xjx+ztatW3Mde6dBYxYSSYAEOWRkp8lhI9nVcNERRv3y4/fr08Ej8eFj90BnNrYPlVKuF0LsBbwvhFgA7Mj2YCnlo8CjAKNHj+6ymdqSqi2XnZaNBHLJuNXVvbYyYdSQcirvOKOjh+HDx26DfFKS9cAQbX2wuS0rSCnXm/+rgGnAoUA1UC6EUAwwpz67IprSqbZMBEi0ymvLhw8fPlqDfFKS2cC+ppdVAXAx8FqGYwAQQvQUQhSay32AY4FF0oi6+wBQHl5XAK+2+chdsKW2idVV9e1xKhvSqrasyPbcbCSff70N8BmJDx8+2gZZUxIhxCAhxDGmy+7xQojj07U37Rg/AaYCi4HnpZQLhRAThBBnmX0eIYRYB1wAPCKEWGgefgAwRwjxJQbjuENKucjc9xvgF0KIFRg2k39lf7k5ItIAf9sH/n4oY/70LifdOS1vp/JCU1buv1rSxvdvh7udznFJ1DZFufPtZUDX89oaPsCjdO97E+Fv+7rve+EqmPmAfdvSt+DWHtCwrW0H6MPHboqsbCRCiL8AFwGLgLi5WQIfpjtOSvkG8IZj283a8mwM9ZTzuJnAQR59rsLwCMs/GrdD/Vao30qQBHHan/A2m4zEvR5P0thuSSQf/jVtf5WaVNXVbCSvX/8Nd0vQR3d6H7R6OgQcz23m/cb/5q9gWNr5kA8fPrJAtsb2c4D9pZTeeTp2RcikV3IAaXHQ9kT6gMSk+29K/XMpwcVNVlfPdTXVVs4BhlJCYw0kYvbtQfO1d2734cNHi5Dtl7kKCGdstavBxkiM5e31kRZ1VZlS/6wAACAASURBVN8cs9RUTmyrj7gzCpLG9vTuvzLVGO9BJFd3YYkkZzTvBBlPvRcBk5HEfUbiw0dbIFtK0gDME0I8IoT4u/rlc2CdAjJJ+BUjOXTiO9Q2RXPuauQtUznmjvdTtm+rj3DYxHe4+51lrsc1WaqtdNZ0SczJSKKNri11RlLUxWwkGZFwxLU21Rj/ToYRMOdEvkTiw0ebIFtG8howEZgJfK79dm1oxDugaefrmlpGgLa5SDP1zUZf//1inesxaVVb2tjiTiNKrMm1bWVVPUft1Yu3f348PUt3sTRlCQeDbzQZSYpEEnTf7sOHjxYhKxuJlPLfpgvvfuampVLK3KflXQ0JXSJJEuoMGTpygsq6W+vBnJKqLe8+AiRSJRIXRiKlZFVVPeceOoj9+nt4QHVlxCMQKkyuN3kxEmUj2fVfYR8+2gPZem2diJHXqhLD23SIEOIKKWVar60uD81GolchjLm7ULUIyrZR1+zFSOK2dm4QQDyRgJjmCxFNZSTb6iPsbIpR0bu05QPuzIg7JZLtxr8nI+kI9wkfPnY9ZKvaugs4VUp5gpTyeOA04J78DauTQLpLJCmz/9acQuvqhmfncsTt79r2p8/+q8ZmSiRKlQOuEklldQMAFX1KWjHiTowURpJBIontXk6IPnzkC9kykrCUcqlakVIuY3fw4nK4/yqowkltAZ1BvPblBrbutBO3plg2EonptdWUnpE0RAyCWlbUzo/uHyfDPLdKAa3AjHvh2Uvs2+KmDWrrUrjnQKgyHRi83H897EgZseBFeGyc4dBw/+GwalrL+smE126AL59r2bHxGEw6Epa84b7/rd/Ba9cn15e+CQ8cAbEIPHQsLHzZ2L7+cyPAVTHlWAQmnw33HAQzWjiXlBIe/gZ89ZKx/q/T4IvJxvJT34FZD6UeU7cF7hoOWxa37Jwv/RAWvQrL3ob/XAafPgJv35R6jrtHwpYl8MavjF9rMP2v8OIuXeXCQraMZI4Q4p9CiBPN3z+AOfkcWKeAh40k0oaMJB2DAGiMpEnaaCKgvLZ0wuhCJJUkFWzvyoHrP4dXrm3bPt+9BZY6iKRiJLMehB1rYe5TxnqKRGIy0pYykpd+AGs+gY3zoXoFvP2HlvWTCUumwIp3M7dzQ1MNbF0Cr17nvn/WpCTxBvjfTw3Gu2OtEaj58o+N7dP+ArXrYe1nxnrteoNx7lgD797asrHFo7BpAbx0tbG+dlaSqa14F95KqYFnPOudG41n2xIsfBlWvg+rPoDF/4Nlb8EiR8amRa9C7Tr47BH47FHj1xp8cDt89WLmdrsAsg1IvBa4DrjBXP8IaOET7UJwiSOBtrWRuMcZSqvmRvo4EgOWRKLr/F1sJGrc4V21cqBSbYWKjH9P91/ztXe5Rzlhh1klobCsdf14IRG1qytzgXpfZJaTHmF6skUbzHXzHVGeJaqfphaOR4fu5JBLkrgWny+evJcxc7LRtCP1WiJ1xn9Bt/yPaRdDVhRFStkspbxbSnme+btnt4hy92IkZrzCjoYoY++eztJNO9N3k+ZjcdvXHEtoy5lVWwFhSiQ60YilxpFYtcx31cqBCQcjsbZ7uPm2VCJRqFlj/BfmyQMuEW854Vb3IltGolyiI2ackWIsqHfFfP9ayth0xDU3+GxdsFvDcNRzbqpJ3s/GGmiqtcceNZuMpK2f527g1JGWkQghnjf/Fwgh5jt/7TPEDoSHjSQSM5Y/WrGVFVvq+Pt7y9N2k8447xZoqHtwJVVbmSSShIORpPL5mFU5sB0ZSXvMOBWxUwQqXGzf7SRWar3TM5JYywm3uhfZEjElgShGoqpLqu1tKZHoThHxlmWKyAnqW2jcnryfTTWAhGatxFG+JJKmrMsodVlkUm391Pz/dr4H0imhMxIhrUmZkkiEScDSEXmAaBqbijMYG6ChOQ7mu9xkSifpAhIF0lBb2VRbLhKJebJ2LUHbHrOxQNAguopABR3OBM54EbXuEf2fNRQjKcqTaiseTbow53ysySxllvdfqfucEoml2lISSQvHYxtb1H05HVoTvKWec2NN8nyKoTRuh+KexrKSSJwTkdaicTuU9GrbPjsZ0lIUKeVGc7EKWCul/BooBA4BNuR5bB0PjQi6xZEEHN+YF6Ix7wZuTEhJJNF4wlJppUuRYuXa0omGi0QSNcfdrqqtbFUrLe5farmzzNmtkzg5mZlab637ryWR5IGRSPN5NtW0TKpT9yJX1VZzrX1dZFBtZcsI3MbmPN5tVtUW0FVbavzqW9GvJ2KqqNv6nW0LdWAnR7ZT0w8xaqgPAt4Gvgc8ka9BdRp4qbZMCUMZxN9auIm5a7xnarqXl24TqWmIcMtrC1PaKzfdRi3JY6bIdqexfUNVaq2NuKXaakeJJN+MJB5Nzp7jHpKGp2qrBRKJTtSVsV2Ppm8rqGeZiCWlhFyQs2pLMZKd9nUyGNtborbxUm1lKz3lCouR1EKj47vQr0dJJG0tRTe1gRTXyZEtRRFSygbgPOBBKeUFwMj8DauTwCsg0ZzZ69L2uQ/O9OxGZyS6veQvby3h869TXzIlkejZgjPl2oo5JJJnZ6babTrE2J5vRpKIJmfPikA5bR/OWbPFcFpgI9GZlDpPPtR3ujquJXaJRAtVW4qROCUS9Ryds+uWqLr0a0u0QM2VK6znLFPfDZtEohhJG49jN5BIsnX/FUKIo4HvAirCJmPqWCHEOOA+s+0/pZR3OPYfD9wLHAxcLKV80dw+CngIKMMopHW7lPI/5r4ngBMANRW6Uko5L8vryA0eXlvK5pEtOY7G7Mcq99uIh8qrwTSwq9rqoHltrZpuxFAcc4N2hHL/TbYvEhFY/ZHhG3/Gnea5TfffjpJIPpkER3vENaTDqmkw/3k4x8Xj/OHjkuqYZy+CS5+HTx+2t2moMqooftOM99Alkik3wvZKg3DGI4AwxnzyTTB4NGz6Cqb9GQ6+EOY+DTtdNLpexDraBC9fA0dcbQTviYBx/R//HZBw8h+gdgN8+axx7kTcINxH/hiGHpPs5/HTYeAhcMBZsGURjL1VO0ejUQUyETWYQSIGpf3g0MuSbRa+DOvmwGm3w/J3YdmbqWNV74SSMGrXw5zHksb2F640gvkUsVVwEsmZ90OwAI78kbH+9Uzj+oYcaVzrEVfDv88071sCJp+TPFaXHD+625DE+uwH/UcacS5gxL7UboB9T4MjrzG2rfkUZv7dYBIyAcdcbwQ1Hvlj4//rj1OvV0GpDl+5FtZ+mjoOMOKRGrbBsTfYty98GTbMhVMmuPcdKjbesWwmAvEYvHgVHH+j8ayzwbt/NO7NQednbptnZMtIfgb8FnjZLJe7F0YJXE8IIYLAJOAUYB0wWwjxmlYyF2ANcCVwo+PwBuByKeVyIcQewOdCiKlSSvVEfqWYTl6RcFdtKUYSyNIAqBvbozEJGZLuKonEVbW14h3j5V3+tm1ssUTCRtCKiMLyqTDnXxYjUcwo2FESydTftYyRTD7b+D/rgSTBU9i20r7+zIXJ5QPOMojL8reNKooWIzHvUzwKs//hfs6tS+GXi+GVHxvBc0te9x6fl0SyvdJg5IteTW7TAwy3LnNnTCvfh99UJtdr1hi/xf8z1sfemty3+iN3xjDi7OTyC1ca/6fdDk9/x32sTtUWwOs/h5HnJde/fCa1oqSKO1FQ0eKKkTx+uvGvgh9DRdBQnWy/fXVyWSfg7/0xuewk1CveNX6KkSx70/58VprlGrRvxBONpkvwl8+6jwMMhlGzJpWRqPvqyUgKDEaSjWqyahksfs14737yWeb2ADPuNv47ASPJNo5kupTyLCnlX8z1VVLKGzIcNgZYYbaNAM8BZ+sNpJSVUsr5QMKxfZmUcrm5vAHYAvTN6oraEp5xJKmqLYXmWJynZn1tU0Xpqq1souKf+LgScKi2pMPYqYnoSWN7su9CIoYxWSYshhi1vLa6qGorFx16SR+46EnoOzx1nyIU6WIYrDZZjN/rGjO5tjpLANvO30p1mZPAZ0LAhZFA6kve4FBl5aqOask1Z1INtcaTrHG7YTtJN454pGXqKSXN7QY53dJKJEKIe6WUPxNC/A9Sy2VLKc9Kc/ggYK22vg44MtcBCiHGYMzh9ann7UKIm4H3gPFuwZFCiGuAawD23HPPXE9rwMNGkk4ieWjaSu59dznF4SDfOdwoRx+J5cZIFm2sZXt9xIohAU21pT4aTb8vlI1E+wCKRDSpz0/EIFDQMZHtbclI4tFU114vqI834PKKW+6/aYhtLjYGr2vMpGsXaZ5Da91ic2YkykbiIKrOMdZvsa/nak8Q6RiJR1+ZGEVrbBBNNan963aURNxQOzVu9yxf7Qn1XmTlZm5+321Zo6IdkUm19aT5f2e+B+IGIcRAcwxXSGl9rb8FNmEwl0eB3wApsqWU8lFzP6NHj25ZVJyH11Y0TYqUHY3Gx7C9ITkb1dvr9hI3CGG8r02xuBVDAppEonTYmseRVdhKI3qGRKKMwTGgwDK2t2uqrbZkJLkUolL3x43xKIbbXJe6z3mubCQDrzaZmEHa2Xmaa9UJmpdrsKc6ReAyJ3RXbUEqI6lzMJJcAwpbcs2ZbAytCZJUqi0dOuGPR037VdRgzgU5lGDwcv5wg2rTLgG8bY+0jERKqaogzgEaFTE37R+ZfB7XA0O09cHmtqwghCgDpgC/l1LO0sakYluahRCPk2pfaTt4xpEYy25pS4LmB67vs9lIdFdglw+6tCBEXXOMSCyRQbWVFMKcEklEBg0biY2RGCq5cFBYbsvtgo5iJKqtLpEkEoaNRe1zGo7djs9KIvFiJBmIbNrZeQa1m2KQXud2uzYpjWA7N2nFMrY71TzOcTje2VxVW+nePa++Mqq2WiuROBmJdn/ikeRzbKzJkZGYx2XFSLq2+itbHcd7gF7EohjIlJZ0NrCvEGKYWV3xYoySvRlhtn8ZmOw0qptSCsKghucAX2V1BS2BRgSDLl5bbkGCypAd87CRzF+X3u++pMAgLuu2NzJjeRUA4aBIMiY1e4rqEknCZiNppNCQSEz11+ertlhjatcYEug4RqKgz4DVB60IVjojqGrjJW0EtXmUp0SSiZGkeRbprtXNBdmJiAuzSMRS85BZY/GQSJyMxYmcJZI0c1ev59HREol6Fnq7TJKDlMnjsnEzb02WhXwFcuaAbKlKkZTSmuKYy2mrI0kpY8BPgKnAYuB50+NrghDiLAAhxBFCiHXABcAjQggVnXchcDxwpRBinvkbZe57WgixAFgA9AFuy/IackcG1ZZbbIdyrdUlEt1G8ssXvkybxLG00PjQ/vTGYp6c9TUFwQB9uxUmvbZcJRIz/YlJ0OopolAkJZIfTf6M95dsJhpPtH/Cxg5nJJpqyyGhZSeReDwrPb+Wp0SSYbzZ2GjcoM9evWaybn3HI96MxBlHouC0maT0mWMm33TM0+t5tJWxvagcCrrb1zNJJImoXSJxbePyjuv3Jd8SSSR90tj2QLaMpF4IcZhaEUIcDmRkoVLKN6SU+0kp95ZS3m5uu1lK+Zq5PFtKOVhKWSql7C2lHGluf0pKGZZSjtJ+88x9J0spD5JSHiilvExncG0OW6ldyU1nHEAwIKycVa4SSSBVInHm2tpaZ740Lt+dkkgWbqjl8KE9+fR336RnaYHBtOKx5EsTs0skRhiJ6TYsCynSbCRB4qzYUkc8IdvXYws6ASPRZsA5BRCqNOwebXVG0lKJJN1s33mtIS3/kx6R7zWTdSPK8QiEvRiJkkgcErPuqusGr3QnUrrfl3SqMC+bVTqJI5HILDUpdOufzKsF0H2gwRycjMgmkWiqLX0cOlNxey/1+5IVI2mFRNIJAh5ziSN5QQixAWMCPAC4KG+j6ixwuP+WFIQIB4UhkXzwZ7qJ0SmHKEIdT7jbRQAqqxro1939g1YSCcB+/bvTs7SAYEAYTEtPR+GwkdwS+jeBV6cC0EChYSMxReoQceqaYkTjkpDy2PpiMpT0huFnZHMn0uOTSTDgYBh2XOq+fDCS2f/K/hidkXx8H+xYZwTbZYOV73u31RnJ3CeNuI1eexljO/U2w+aQiZGkm+0/faF9vbgn7NSSD864x5C2nCk/FPSiVda2J2HbqtTtS94wCj25oW6r9xjBKOpV8Q2o3wqVM5Lbd26Eqb9PbZ9OhfPfH7pv9yKUT19gBl5maaAuLjdiO9Rn1H0AbF1sVLzUocf6vH+7PdHj4teNQE392c3+p3Ht3QcY6XJUnjSFaKOx7YM/wYizYMBBxvZ4DKb+Fo79War6q3qlcZ5TJsKHf4O9ToQFL8DhVxjvmC7Zvf4zGPcX6LufsR5rhrd+a4xl5Hkw5Ijs7k8rkBUjkVLOFkIMB/Y3Ny2VUuYpn0EngqNCYiggCAcCRGMxmH4Hx4sQkPxgl2yqJWAykkgswcINOxhcXkJ1nZ2grK6qY8ww92ygpQVJnf4ws7a6EILtDVEiTXVGLGO4hES00RIni0SEq0JTreMaKKJMbLdmOSERp645TiyeIKwkElWR7tY2SHE99XfefbVl+hClKpryi8xtv2uWcdVtJM6I90x48lzvfc5U40+fD/0Pgs0L4PArjY86owRlEsDuAw3Cq0MFKh50IQw82ChVrLbNe9ogMrniHY9Kjs9d4r4dUiUUgDP/bkSLz/+P8Y5NPhvqNtvbvPVbWPSKsdytf3K/lzqv2wCo22Qs/397Zx4uR1Um/N/by12yrywJgQRIUDAQIIagICIDBBdwAQERcIaPRWTEZVD4nFE/xnGbh4FRGRUXRseFQUVFRQHZVEQlCLIoS8IeQcKSQLa79D3fH6dO16nTp6qrt3v7Juf3PP10d3V1dVV11XnPu0vBmYCkCIqHrsue7du/+6p/1FnywwOw7jH4232w/D16kB8Z1p0Rfdx9RazFbFmnu1auviG5zvUfzQ6DHh7Q+/mrz+pM+/8b/dZjv9FdGJ9bHU/oTDDC9/8BnroL9jkRbv6kfoA/gXb1jToR99yowMd9P9SJyKA7SrbjHq9DLtOWiExAh9meq5S6F5gvIlt9aflNg/HFURBFsSCUSwVGhv2O2BWX/Jrr7tM3w7d+9zhv+Nxv2OfC6/jEz5J9ph9/Pt02PsHSSHaeoSNEigJ/emId37lNzyaHihMY3Bw7JieQtK9uUr30MlTVWkpU2DgwTGVEjW5WO4yeacvOwF5wCCz8O/06K9zUZcpO+df1hRUb80S1CnFOR/TbPdqDYcmJehDsmxYvy/Lt7OFomPM9WmKr7PJqOObS+L3Pvm//V2/6Tz1jhvR9f6elFbzzquyItj1eH79+4dHkZ4tWxK/ffVv8+ohPwH6nwLLT9euTf6ivkdOuhdNvgO0ySgfaJed9ZrZ6uTTDm63wXmvMMPeGqtSG/xqNI03jdLG36/q5RoG8PpLLgUHgwOj9Gjrp5O4StgzEA4GgKBWFUkEYHNIXzoin2tbfXtQ3lV3exHDV2a9icl+JjQPps3RbI5k2QQ9Wxu/y1xe08Bgs9uuEw4h+kgPWRvqiqC09sBUZYcPAMEMjanTrbEF74+KzBEmxrGs8mdd5vuPSiNApZtS5qbb4zSlIJu+QsU/RxKLfEiRZjlm3ydaEmdm/3UzET7kvO/oKkueyfzoUnX4nLnYp/mI56cuoWdc6RlPK32AHE/S2q0GVFXrfjD9ieCD+z9KCDVzNyoQZ1/NRGeztNlMtukXyjiq7KaU+CwwBRJWAx2cKZgNUKvGAX2REayTFAoMD+qLwCZKNg/6BSwT2nTeN/nKx2j7Xx4Se+AadFGknpoHWhs1aMAwVko13+iQ5sGx2NJIyFV4aGGZ43EdtZcz8pBA7pO1BvhHTWr3B0cabYR+dW+O8zZtj0Z/R9MhEndkaSVaUkjt41uv210zp9lJ//QxsW6Pomxb/J76wZEgKh0IpKTiz1nWxm1JlCftmMK16+6bm/44U9YTO+IZ8mpZSsY/E3C/mf9v4bP7fMXSxIBkUkX4i0SwiuwEtxKuND2xBUmBE+0iKwsCgnmmOeE6fXdbEpqdYQEToKxer6/jm6hN74wvCRHCZKLGNW/TvDjiCxKeR6Kgto5Fo09bwiKI4rvNIMgY9KcZ9QZrVSPKWX0ld10kazSNICqXsJLeqRmLN0F98yr8uJPNboH6vlGZ8WHn6ryQ0EkuQDKUMcrYAKJSSgtMlS5CYfSuU219uxER4Td4x/3d6Jyc1krT7r2oWjdbribIrXN9TGvb5brQ8ThvIO6p8DPgFME9Evo1OUPxQx/aqSxipcbYXKBULDGYIkrT+7Oaa7isX2DKUPrjaUVtGIzE5KRs364vMFSQTJakWb6ZXtwaOBlHjIxmujFBut0ZSNzGrRUFibz9LKIjEoa32TLSRzOuGNBLPbNdNXMtj2uqblj3gmQHCnqG7jnmbkrNf9drGNmNPT8tFsbHNb33TYsGbNlu2z2ddjSSjI6VPK20XG5/Rg/Sk7fN/p29K5CPJ0EhE4vNlNJNyJEjc/7qQMtlJaCSdy4hIo+6dE2WQ349uarUcrb+fq5TKqXONX4aH44FL0I7qUkEYGk73kdSjv1xkS2Ta8iUmTrRMW8bxbhIgN26J/C+SvJEnSnKw3KSSM8YiIyhlMtvbLUjqCIpWBYk9GGcKkkI8wBVGwUfiu6E3RY7RRjSSrAET4gE4YdrKcMC6+1VPe8hrg0/skzNs+CKnbAFV7ov3K820ZZ/7dmgk7j62gxce088NaSRTdAi1ERC+a0yp2PRlBIqZALz0dHLdNPNuwkcy+hpJ3bOtlFIico1SajG69tU2Q1Ij0aatYkEYGTIaSeODcq9l2vIxwXK2TygnTVtbBgahBzbjCJJCcua7yfm8JPr3hisdKJFSb7BstX2qW64ijUIxFiQJ05bz+5Pn+HuAQIMaiWddk1tgfBh5KuNmDZj2PtUTONX9cgVJHe0hb1RQFvUECdQ3bdnU00iytA0zAGdFfTWL0TSzgiNceifr85OlkUAsQMx6ZgLkCpI0CmPrI8l75/xRRF6plLq9o3vTZdg+kk+UL2fDI9tTKuzFcKSRqCYESV+5WK0QvGzdz5lVfJLH1PZcP6KTG3vL8QVRcLLkJZrdb1TJweFwfpd4v8mpp1miwojSza9aKiH/h6/ArofCrN3jZfVm/Fkayd3fgxkLdCfC4UHdfKpnUjy76p0Mi460fivLR1KIB5GEs90ZzGcsiASJrwpuI/9nxroP36w7Bf76Ij2Qj1TShUpWdBL4fSRZNCpIfnNJvu02ypqVyfdmv576U/3v1ovayhIk5njb3eK5b2qcENyoRoLSeTWgr70fnqVf/zXK+3jkFpgatbownTKNJp5XkFQG4Zrz9H4+MPrz/byC5ADgnSLyKLCR6C5USu3dqR3rBmyNZEd5Hn77IYrbXVMVJD4fST36ywV+9eA6Dv7sjfx602cgur/mb/kOQJwwaGH6iJjCkRtVtrnCFTRFKlSUYqii6O9pUpBUhuGaf9IRRh9O6WrnI+uGvur/6OePr4c7vwm3fKZ2nffdk/1bM3bV2dpSjO3K9mC636lw71XaDj1xtk7wenENTJkbt2CdPl/v54pPwdcO18ukCLMWao1oXWTS2O2wOBnt1efC47/Tn693QlCfXx13ChzeovMXnrwDJs6ER36VXNfMvJefrZPHXIwg2XEJ7HKQnhUPvKgFrhlsTGRQzwTdFfKXH4+O/RTY+/hkIuLE2doEZzTFh+JE1gQ7LNYl442zd6+3wn1X+de1mbUHPPtA/P7Ac/SzK+Bm7AqIngDM3D35WaGoM7lX36Tt/Tsv18f40PU6OdNsqzwBps7Tmdt3fksvM4EL5twsf0++ir1vuAh+8eGkoDPXFuj2xVVB4tFIDr9QJya6mP937f3xsvt+pP8r26xoR+IND8Tad17T49r7k78xyuQVJEfWX2XrY6RSOwMuFoTKcK1p6x0H7My19z7NcxtjM9Nb953L+s1D3HB/3MOhL9I4nnh+M3gmiyWPxmDK1hsT1aaRbLV9i9PLt0wl8pGMNO8jqRauc0JP6wqSnHkkaeq4bc5yZ/VvvBief0T365ZCfNPag9a0efDePya/t9/JuqzLY7fqAeJczyz5fXfD1ChB8eNRuOfJV8WvZ+6mW6J++ZBaQeJy9Of183Or4fNRybol74S7vhWbtlZ8KluQTJoNf59jpmnXqzK/e/bv4L+W69fvv08LyyzNYO7+cPqN8IVlWpDs+WY46jP1BcnJP4LdDoWbPgW3fFoXSDzy3/RnthYhRXjvnenbKZR02ZXTb/B/bloXz34ZnHGTrrVlBIk5nyZyacUns/fZsMuBcOav4v/3rFthh1fApQfoAXrSdvDcQ/oznyDZ92RY80edzb/Lq+NJykRPY9c9VsBeb4ErT4mX7XcKTJkD130kWSjSaM1n/w6uOgOevltrOfWKaY4ymdNTEekTkfcB5wErgDVKqcfMY1T2cAyppAqSWo3kg4cvqgoJQ6Eg/PMb90ws6ytlCwHfQD8UmbZMu99NlWz57wqSIiPatFWJnO3NJKGZQdyNMGpFI8mzHdtH4q4zUokH2kIxNofkidgxzt/Uarg5Q4EbMaHYv2WEXT3fRyN+G/Afu1lW6tfOaHebbsiwMS3a4dR5QqOrvxN9zz439vfr+c3qnXvzO8YvYB9zXhNgPcx/ZQSTLRB8gsQOarBzd3yCpNRX+z/ZCbWV4Vp/YKnP7wPsEurZOb4BLEWXbD8KuKjje9RF+DSSUqFAJYrmsjWScqlATyl5Op95aSCRqQ7QX33vn6n7EgarGkkkSDbUEyQqeZGWqFAZUVFjq0JjkUyGNEd3s4LE1VTSSq7boYyuj2RkOB5MROJonjxCwHwvtRpu3gG8gcx9X7JcPWd7o4OGb31XaLnnZ+Ks5HsjSMz+Fkr5hLNZx3wvIUgaCMetd+7N8RjHtX3MeYMS6mGuC7O9SdvFn03yCZKUjHr7e/a6hXzB5gAAIABJREFU7n9gC+vKoF+Q+MLbu4R6d8ueUbQWIvI14A+d36XuQXkGyYLogRmSGkm5UKjmaBQLuhHVCxsHE7WzzGcQb8PFF1VlfCRGI9lYacy0VTSmLZPZ3pQgiVRtVwA0K0jcHIs0Z7RtqhkZrs0rqQ46AmXHPp6F+V6qRpIz6qfGX+8WHLRoSiNpMPrIl5PiZse7wmbCjGSV46pGYsKpi/mEc9E5p7bmkVfDM7+X+Xk5uZ69fj3BnBeTj1LVSCKB0DPJP/mw98Eu+T8xRZC4/0GxxxEkzjVc7ou328i5hMZ7zTdBPUFSvbuVUsOj2qK1CxjxmIB6CxW2VAVJfD5KRalGRO2901R2nTWJfzhoPhN7ipy4bB7H7q+7Dpv2uWX8A/DU/jIfXvEyZk+OVWUTtWWEz0vD2TfaAMkLrSxaI3lxyxBT+8vJQXukkm+wShuc6zVvSou0ckNG0wSS3bSnMpQcpEeGk+GUxqmaJ/yxriDJqZG4QqN/erqD1CtIckZttYKZwZrfcv/vCSkaSVWQlBo0bUXfs//TRjSrvMfsq1vVLo3EmKrMOZs0O/k+C/tYJ3lMW+V6pq0hj0bS76/c4MWJSBweSNe820Q909Y+IvJi9HgJ2Nu8FpG63h4RWSEiD4jIKhE53/P5a0TkjyIyLCLHOp+dKiIPRY9TreX7i8g90TY/Jx2UbiOeQbJfBimKHjzs8N9SIRYkvaUCF719H/aaMxUR4VNv3Zv9d9EXoMlqL6doJPNnTeDdr92NY/ePK9GaPBKjkdQTJD4fybMbBnhpyzALZk1MDu55M7/NuWiXj8Ttv5C2nRqNxNpeZdgqOaFiQZInV6Ea+ZNyg+Ud+Nzjy5oR29pmXtNWo7NPHzWmLWegTjVtWQmeeW6zqmnLE4LbiDmm3rk3mo5vAtQ2jcQxbRnNIs/27fPr1Uj6a89HwTJtjQzVauilXn94uw/3v8rTWKtFMgWJUqqolJoSPSYrpUrW64w6BSAiReBStG9lT+BEEdnTWe1x4F3Ad5zvzkCXZTkAWAZ8TETMVOCLwOnAwuixgg7h00j6GIpNWyr+w0Sk6iPJytUwWe1pGoldtNFgMttNGa56PpIBlbwRS1SqWs38WROTg3beCrXtNm3VaCQpmovrI7HXszUSpRrUSKLvtaqRuLatvDPiQl7TVjs0Ese05W7TrRDs00ga+R3fOW2nRmLuS59G0q6MdrMdc876p+trLc//a++/L/S41Fu7n8UeSyNxTFulPi0c8mbtu/foWAuSFlkGrFJKPayUGgSuAI6xV1BKPaqUuhtwR5sjgeuVUs8rpV4ArgdWiMiOwBSl1O+Uri/yTeDNnToA5RnceiUWJBXn9PUUcwiSwWxBAsCD1+kQSms2fnhhJYv7dBixa7qq+Q1HI/mn0pW8tnAXJYbZe82V/mzxZx+C6z+mk+ju+O/aMF87HPH2r8ZlGOyZ00tPw91X6tcbn4M7v10rSAY36cRGex/uvjK9E2FCIxnSTZ2q74eTg0k7TVtZvcVt3Js274zYV/rER6M+Eu9vGdNWmiCpZ9rKuQ+ZkXANGA7qnXujkXQie93FnLNSj072y1P51x7ofdpD2aOR2Katv94Ff7XCo40AabaOWFZXyjbRSUEyF3jCev9ktKyV786NXtfdpoicISIrRWTl2rV12oWmMOIRJP0M1jjb507Tf7Bxtmflavyfg3fV60hy20t3mc7pBy/Qb753qo7Df+y31c+/0vMfnD6kFTefILG1I/fz6bKBi8v/xTuKNzDzVx9J5isYQbDy63DrJXDDhfCTc+GqM50fsATfzz4YJ73Z5+jbx+l2qZvXwY/eDT8+uzZJ6sZP6MTGe61GRledHucGuNg+kucfSXZHXHxsrMYrBfOW60HowPf4t2VTL/zXNg8sPEInMoKO/3+Z1dOtxkfiCIbFxyXf77C3bq264z6w0yuT4aGHWQltc/bTA3wzlts5++pmWIZCERa8Rif2QZwkaHBrV5mBfM6+erA2rWFn7QGHWBbq5c55dn0kNv3TdF4JwAHv9u/3UZ/V56PeMc/dXz+/+r3xsh0W6yRR0Imby86s/V4eDv0IzNgtfj9nP52vMm0+LDw8bhQ2/2CdNGmzPDquBYfEy4rl2uZipV6/IDEC/ifvddaPBIipCGybO33N2Nzz10jh0ibpQGWz7kApdRlwGcDSpUub6q6kfM52BqsZ5gph1qQebj3/dUCsiZRL6fL5wN1m8uin38Atv70VrouXX3HG8jgZ0SRTVfyV+gdVrSBZMfhpruv9MAC7z5kFTgmlfgaYaCr/r7dksdE0NjlfcDvPuSawjZFwtgWMyQDfsj6u4WQcz4uOggd/Hlcz3ZhTuNsaiV2/6chPwXYvh1UmaU3pzPGPZfTqsDE3bR4n5Enfi18f99/Oh65py3HGvu2ryfdn/Tp+vduhyc8O/iA8cz/ccyUccBbsc3z9ffNxxs21y079Sfx6lwPhhO/GLXZdjcMIkqV/rx+Gc5ygzRWf1P/B1U72uu+clnrjFrNpHHCmftRj4qza9rFnWf3i8yRupnHIh/TDMHsRvOf3+vVbL4uXv+unuqnWJYvjZTsv1/v1t/viZYWiXhfgf96qKyOU+lOitlI0DXM+jfZqWwHecBH85Sc6udXH+/8MU/PO35unkxrJGmCe9X6naFkr310TvW5mmw3jM231yWDVLFWhQMGS/lUfSY7scde0VfDNwlL8F4Me+W+bswqFIsNSrvl8i9FUbL+Dma24LUSHHXU4NWrLM9vZsi42M5nB36j7ZgbvOtvTsPfV3ic7fwQa78RY9ZHUKbNej0ac7Y1sr9MRkolquymCJA+JSDQr8XFbIM2Xk7bcmOTsasgG27Tl4jr+7eq+hWKtz8S+F0YpebGTguR2YKGILBCRHuAE4Oqc370WOEJEpkdO9iOAa5VSTwEvisjyKFrrFCDFJtI6PtNWD0MJjaRoCQ3jI/GVOXFxo7YKPuGTopIOUHvB2Q72YkGoFHrYbCUmjiDx9+xZfrX0ybpkRq470DeSkGhvywgSc+OYgdLX+9qH7e+w96k62Jnz1qggMT6SHE2asnAFSVaJ83wbjJ47LEhsYeEOfI0IkrJPkLR4TscLjQoSM554M9t70gd9N8vevidEsn0m412QKKWGgXPQQuEvwJVKqftE5EIRORpARF4pIk8CxwFfFpH7ou8+D/wrWhjdDlwYLQM4G/gqsApYDfy8Y8fgc7arwap/QyEJTcKYtvrL9Z2APZISpWQTDd5v2Tepmvp8JLZGUiwIlWIfm61lvQxRjZRO00jshj1upIcrSMy2fNFWW9bFBRRNobuiI0iymjPZ2OYsr0YSXcKNaiRVM0yrGonzu+3aXqc1EltYuE7rRhz8tkZSrRYQNBIv5tr3JSTa4b8uVY0kMpva4e1SrBUk9rUzSlnwHfWRKKWuAa5xln3Uen07SVOVvd7Xga97lq8EXtHePfWjRkYYVMXEoN9raSQVCgmNZEPUr32XmRPqbruUFbVliLSFi47bBy6MF7vhvVArSFSxly3WLL2XIfpMA6wBjyDZ/ALMXKgr14JHkKSYtrwayQuxY9D4SMzNZYRY3vLYttAbdG4gsG6aMdJI3N9tNVxXZYS2thO3kZRNI0KsWv+pJ/5e0Ej8y81/66tdlmXacsu12PdBoZitdYySIBnlBt7jDFWhQnJ21kvsIxlBEhFaa17QM+YFs+qXrS7jzPB9hRSjQd61evk0kiFrTlAsCKrUl6i5VZIRJpuWvIlsccu0NXn72uXOvtTgK22yeV1sJzdOfHNzGcGStxd1wtluvXYH2jHzkTjvW9YkRksjaZOPxJckF3wk/uVGe/fVLss0bTnlWuxJntQpX9OOPKQcBEGSwcjICMOOIOlRA1WNZARJ+DbWrNOCZH4uQeKYhHwVUc0g7ZiPvOG/1l9ZEC1I3PWmSTSTcXMzhjbrCLGshj1ptbASyY2Wmcws3+wKkpxRVYbBlKit6uDXrEZSJ7M9L66PpFGBVrO9UfKRtM3Z7inbsa1oJGkDf9pyc09IsfacZzrbTbkWTyBHwTZtea6ZUSprFQRJFiMVhh3r37wN97C76ECxRbKG+SNxSOMr52sb5rzp9U1b0x9xQhRtYWFu5MogPH0vPPPnxKo9Pdk3aqkglHr6a5zyUyUalG2hteoGuCcKb3XLY9/6Objtv2Djs/E6hkdv1YmTt10aLzNhyysvj9Vv17TVaGtXW+jZLXJd01bDGkmdhMTctCg4ajY3SqYtsQSx6yNpSJB4CgluKzX50hIi03xMWRF5xXK6ZmG0vl5PMRGxTFstX8vNEwRJBq+YM5m+vuSgvfjZn3Fy6ZcATJABvrrh7OpnFx23hF+dd2hNOfkanlzJtAedgTnha4gutMoQfOnV8OVkQtNV73ESnByKBaF/3j4s2GsZqlCq1gSbiifj+9ZL4OooeW3HfZKfXf8vcO0F8J3jYfWNyc82PA3fOQ6e9HRf3rIOHvtNcpm52Ic21a6fxaAT9WWouVkbHNAn76DrIM3aI7l84RH++khpmMFh5kLonaoT/1ph33fq5zn7tradelR7eZTbpJF4ZtPLzmhu38YLpnbaa85zlqeYk0yOzPT5tZ/5TFumc6Q5x0YA2QmdhULUbRKYs0Q/KzXq5z4Ikgxm9Bcpl/M7q/p7iuycw9Fulx/51vBh+oXREpSKX6c4uOfPzi7TUCwIvPFiph7/JeSjz3HdHv8KwBQ2pg+Se7w+OQh+8EE4P+r8Zycw1sNcwFucmp72zfXqc+GCNXD6TfW3Zwbqd1yRXG4Gu2Y1kgkz4LyHYKf9k8tP+p5enhezf8d/Cy54XLfnPfmHje2LzR5H6aS2afPqr9sK5rwVe1oM/zU+EmcQ/Ph6eP2/N79/44WPr4fX/XNyWZogWfIOvf6EGbWfFRzT1mvO0xUQIOlz+vh6OOrT8XspwJ5Hw0ee1pUBDK//99qkzQ6y1Wa2twU1krwoCuV0X0EjWGasarSVWZaobpvyW56eJTZFxztfiWY0k9mY7hOwQ39BX+x22Ya8mO0MbdLfNZpWwober5v/uFVn82zX0KqPpF0YAWYfXzsq9nYauylUjWmrifDfLmy2NGY08/+7PhK7jEqWH0+skGtXcxlFgkaShStI2mWD3BLPFDYT/flGkNjCwydIcgzsbpb8SEH/xlQ2pEfUuKU9Ej6EBgZpM+BXBpOVTxPnMTrmRrLA3ZalrfpI2kb0u1nhtN2I3aa2HZntXdj+dcyoM9Hz4v4PdhmVrHHH/s4Y/gdBkGThNn1qV3MYK6u7GqJrZu71SrynzBbtMGS3aORIUe/3FDakH4MbEVLNCehLOrzrYbcWLacIkqrzsIEscLfUeY1GMkYYAZbQXMeBIJEsQdLAOS2WyN34KpBO0en5Uu7LJ0gSYdxBkHQnasSR+G1S3zfHgqQaomv8IvUEScogZYchu+VWjCCZwED6RZmmHZT68jWKMtjmqh7LX+TT7PIOWFKoHahaTUhsF8YUad/E7eqJ0UmqbWpLrflIwN+oKdAY7vVtl1HJqhTQifGpCYIgyUKNIImbqk2zX1sjwdVInMZNLimhhbbsqNVIbNtrTo3E0KgWZpugbNNWwkfS4DZ9wtOttRVMW41RzbLuaS38F/xl0QON4Z4/u4xKVl6O/V8F01aX4mok7WKzT5AYjcT2kfhMW/6/TCwhJ47AU7ZfpNwf94Ww8cWoQ2NZyj2Tk+snTFvWRd6ocPINzAUnamusne1ZRRC7EeN/8wVUNCpIyv3j45i7GVeQlPvjeybrHvT5SMZgUhUESRYjFUcjyfOdkURDqhqGtsCff1R9O6ic8upNmrZsK5FyBlVVtGY0pV4dMVWz3RSB2UiWcv/05KwooZG0ELTg1UgcH8mYKSSekibjYVBNCBLnGm908hQ0ktZxrxn7nGZqJMG01f24Gkkem/7tX4XLj4IHUooS3//TRFJetZaX19me37QlwJAq8sTI7JrPhnqmxiXlp8yFV55WuwGT1DR9PtiCp14lV7v7W//U5MVsax5p0W9z9kvftulEaL67vVWr05wHk7i36Ijs/ewU+5+qn8sp/qBuxTQ72ufE1k1b0xd0Pu9lPLLra7M/twNIzNgya5F+nrwjTNlRX0vTd0nfRkITjiZxy05vdE9bZhxc8WPIMZeiKkNwyV76fR6V8blV+tntMGjYoPuu84H7WfTJ33NoIerNXA3/bVYjEV4+cDkK4W3OZyM9E1k+8AXmTxzix0ecGLWj/Uf4tyhU9/QbYWpUhPmcO0hM781sqGcyfPgRXWxx4mxAdIBAsRf+cBn84sPaYW8LEvt1miA57Xr46mHw1F3xsvMf19t9/DYteM13z7gF/jW6+czgt8Mr4CN/a19EXaMcfqFOSLNnjeNBkEzeQZ+3Ui8885fkZ40KkhO/2/mSLuONf3m2/jn54IOASo4rZ9yia8qZAqoXrMm+thO+uQL88zNjEr01Dq74MWTy9hQatTeai8fXpwMiR7vApO0YpBwXW2wx/Fegpi6YoSDCeiaxRnrjC8++OO2ILTfiyAz6PRO0GWSqp+q/0Vr6pzkXdkqSXqIZUqlWy+qZpJeZAAAzMNv71omw7GYQqTU9jAdBAvF5ayWPBELor48858QX3dczIRntWO/adseDMSqYGaYRdZBGs0TNTemr5gva0d43BQpFzjxkVyrmL/CG//oSElPs17aPxG2REX2WeihZPgsjJDKToqIbom9asmNbItvbSbayqdnhYrw98N9wjWRfjzbjbWB1Bce2UnRxa6ATwUBN0FFBIiIrROQBEVklIud7Pu8Vkf+NPv+9iMyPlp8kIndZjxERWRJ9dnO0TfNZAxX2RoFqxz5PfxHQdbaiAfKCo15u+Ug8gsRXjiXDR5KGtx+8TZYfxMxw8mTXmuz4qiCxzVxZZcZTtD6zvayorW6kS27u/DjXRzBTjR+65L/q2F6ISBG4FDgK2BM4UUT2dFY7DXhBKbU7cDHwGQCl1LeVUkuUUkuAk4FHlFKWEZ2TzOdKqWc6dQxNUXAEg8uWdYmcjapG4gqSQrkx01aGsDCCJHWNLCFhtIdMO2000JvjMkIjrf6UK7jShG7vFECSgqRarLE7biAv48W0ZXCvnW4+t4EkXTJp6eQVswxYpZR6WCk1CFwBHOOscwzwjej194HDpHZEPDH67vjADPSpGsm6hE8i1bRVntBQra1CIvzX+cxNuXDJFCQ5NBIz8JjjKngESSL819FI0vxQhQL0TXWch8ZO1x03kJfxULQxi24+t4EkXfJfdVKQzAWesN4/GS3zrqOUGgbWA05RJY4Hvussuzwya/2LR/AAICJniMhKEVm5du3aZo/B3Wj9dXJpJHGBxNfsEUVnuM72cn9K1FZKQmIOjSR9hYzLIJePxJi2jEbiMW0lorZcU1pGQIPrwDfH0iUzMS9BIwl0HDOh6o7/qjv2IgUROQDYpJS611p8klJqMXBw9DjZ912l1GVKqaVKqaWzZ9fmVjRF2szZCI2hzfBi1MVPVeClv8G6x+Hhm3UiImgfiWXaevehL0tuw2gh5X5/HklG1FYasWmrCSdqtS5WxqViO9shWVnWXQfyayRmm4mBeTxoJF28b16CIBm3dMm11skrZg1gZyntFC3zriMiJWAq8Jz1+Qk42ohSak30/BLwHbQJreM8NDIXXv4m/4dGi7jyVLjzf6JlFbhoEVyyGL55DKz8ml6+5UVtrjG4Gox57pkIw1tqf8vMHu2aVpPnJDPba6K2UgTI3P39y21MEcZJGTENE7cDBKaZxClPjw7xaBWGNDMgwIwFyd82g1yX3EBezPGZhMpuJ63yc6B7WXysfu6SCVUndfDbgYUisgAtME4A3uGsczVwKnAbcCxwo1J6GBRdm+TtaK2DaFkJmKaUelZEysAbgV928BgA2GfLZQxQ5v4jjuauZ2HJ6i8mVxgZBnrhoWvjZa5Zast6LSQqA8ksaEnxkUyYAc96OvWZ+lXn/inSXpSe+X/2ttT9L6ZNF971M61FZbHknbDD3nHGrY95r4QP/BmmzNHvB6PMfVtgZs1yjeQ76Qcw18l0P/rzSUEj3aXSp3Le6vT6Zd1G/3SdHPeHL8OvLxrrvQnk4c1fhCM/1TXRix0TJEqpYRE5B7gWKAJfV0rdJyIXAiuVUlcDXwP+R0RWAc+jhY3hNcATSqmHrWW9wLWRECmihchXOnUMhvVM4qDdZ0GxxKy5u8FqZwVflV5Xm6gMwfCAfu3Lgq76SCLT1oRZWui4mB4edh0rsmttGf9JzUSz3F+/BEqxVDu4+zBCBOISMHaiY6YGEe1v35TaNqQ1PUvGgY8EGuv+2A1M3j6+FsesknIgN8UyTGqTyb4NdNQrqJS6BrjGWfZR6/UW4LiU794MLHeWbQRy2GPay+pPvr5qRd5puqcnu/FlSCGePQ+5gmQwFi62s7nGtBVty+0IaPAVXKTFPJJ2YwSJ3XUxax+qJc1zRDtVw3+7XJAEAtsQ4yy8ZGxI9ED3ZaybwV+K8aA47JiMKkOxGcmnkSjHR5ImSBxNxJA1ThvT1qhbvm3be9bAX+0y2Igg6Q6VPhAIdHnUVlfiC+utJhFag+WwY5YaGYo1EtucJGkaiRsFHdGTppGkJ5LEpq1RFiW2acsM/L5eKD7nfBrjIfx33BKc7IHmCIKkUbwaSeTXsGfdrhM7Ydqyy6s7gqRi+Uh8pPQ5z5IRo27aMtimrWr9LI8D2mhxucxV4yD8d9wTfCSBxgiCpFFGPKGqRgjY5hZXI6kM1REkTkJiqmnLr5FkCYviWAkSO2rLCAtfJFNVkOTYz2rUVpg9t51wTgNNEgRJo6T5SIY2J6Osanwkg7ED3tfwact6nWOy7nH9Pi3qJ8XZnkXd6r+dwjY/DWzQzz6NytdlMA2zTogs6hzh3AYaJAiSRpm5e+2ykWH494XJ3JHBTcl1KkOxcCl5BMl1H4FPz4Pf/IfWbNISAGe/zLvYDid3h4FR941MtPbddF40jvddD6ldf/5B+jlP3sWur9XPpdDatf0EjSTQHCFqq1EWHg5n/gpu+hQ8GLXTrQzB4EvJ9TY/n3yfyCOxGzs5A+LM3eEtlyXNQoajvwA7L69dTtLZPndaMjckEXU2Grzn9zAYaSBn3KzLwkyfD2f9Brbbq3b9N14Mr3pvvtyLN38JXntBqq8o0ApBEwk0RxAkzbDjPsn3vkiujU6hyMpg7IC3o7bchMBpO8NOKakyO+6duktG6Tj94AWc+3cLE5+Numlrwow4sbBvaiwUd1jsX7/UC9v5Na0ayn0we4/W9zEQCLSNYNpqGmv25stsd+tHpWW2F3tImBTsSCeXjEgls4WjFu9I2amJUhhtjSQwTgnXSaA5giBpFltQ+EqZuIzYPhI7j0SS5q0+p4CeTUYSnvGD+CK0Wqr+G9gGCSauQGMEQdIsdmTLpufT1zNUBv0aCSRtTm4lVpuMJDyzBZ8/ZMyitgLji3CBBJokCJJmsTWSTc/WX98ukZLZIz3js6yyICbhO0MjCQRyEcJ/Aw0SBEnTWDfbxufSVzNUExKlNlLLRlLfZJu2ome/RlKnZ3sgAIQrJNAsQZA0iz1rW/9E+nqGyiBseEbXk8qrIbimrAxBUhUWnk13ScuCQCCwlRLCf5vGEiSmK2IWLzyiH2V/9d4qU3eOX0sRsCLCMp3t+nnEY5YYsxIpgUBgmyDMVZslrT3sjF3hvXfG7/c9GfY7NX5/0PvTt7nsDNj77fF7VyPJdLZrYeEzb49Z9d/AOCX4SAKN0VFBIiIrROQBEVklIud7Pu8Vkf+NPv+9iMyPls8Xkc0iclf0+JL1nf1F5J7oO5+TsRod3RF7WqRJbLen1bscWHRkMkpr0ZHp23zZG5K2KTdvJIdG4hck0XP6LwcC4QIJNE3HBImIFIFLgaOAPYETRWRPZ7XTgBeUUrsDFwOfsT5brZRaEj3OspZ/ETgdWBg9VnTqGBrC1IlSI0nNoVBOOtezwnvt0ilQ69zIUTrdbbMLIQgnEAh0lk5qJMuAVUqph5VSg8AVwDHOOscA34hefx84LEvDEJEdgSlKqd8ppRTwTeDN7d/1HLimLVP7yS2XUijFhRkhO+HQFSQNaSTppq2qqSLMOAN5CDOPQIN0UpDMBexwpiejZd51lFLDwHrAtAZcICJ3isgtInKwtf6TdbYJgIicISIrRWTl2rVrfau0hnuzGSHglkspFGONRIrZxQbd/BJXcGT4SP7piEX0lgosmJXuzA9yJJBNuEICzdGtUVtPATsrpZ4Tkf2BH4mIp2xsOkqpy4DLAJYuXdqBKVaKIHE1lUIpFiS9k7JDf92M95rw3/TvHvby7XngE0f59zRMMAOBQAfppEayBphnvd8pWuZdR0RKwFTgOaXUgFLqOQCl1B3AamBRtP5OdbY5OtRoJJEQcBtfFctQjOR1Wuiv2Zab1d6AaSsLs6chaisQCHSCTgqS24GFIrJARHqAE4CrnXWuBkxs7LHAjUopJSKzI2c9IrIr2qn+sFLqKeBFEVke+VJOAX7cwWNIx9U8jFnKbcVrayQ9dXJI6mokoU95YDQIKmygMTomSCKfxznAtcBfgCuVUveJyIUicnS02teAmSKyCvgAYEKEXwPcLSJ3oZ3wZymlTGXEs4GvAqvQmsrPO3UMmUybl3xvmjJNdVw2hWJs9powEy+zFunnGme7G7XV3N+1/WS93eOXzquzZmCbZuLs5HMgkJOO+kiUUtcA1zjLPmq93gIc5/neD4AfpGxzJfCK9u5pE7zpP+Hlb4LvvUu/n7sUjv06LHTyRApl2OstMPBi3CbW5eSrYM0dyV7u0FBCYhZTJ5RZ/cnXE9qSBDLZ92StFS+uuSUDgUxCZnuz9E7WAsJQLMMr3qYd6jaFku4WeND7Yc6+/m1N2g728DjK2+QjAV3MMfhIApkUCrDPCU1PWAJVSYO4AAAIkklEQVTbLkGQtIu0ir6FFpS+GtNWuMEDgUD3EQRJuyiW/ctbmd01EP4bCAQCY0UQJO2iRiOJBv00AZOHGtNWECSBQKD7CIKkXRQcgWFMWq2YtkIjkUAgMA4II1W7cDUP874lH0nwiQQCge4nCJJ24Zq2qhpJG30kgUAg0IUEQdIuXI1kypzWtzlxu9a3EQgEAh2mW4s2jj9cQfLOq2D1DdA/vfltHvMFuOcQ2O118PTdre1fIBAIdIggSNqFa9qaOhf2O6W1bU6YAQecqV/PWtjatgKBQKBDBNNWu0hLSAwEAoGtnCBI2kUr0VmBQCAwjgmCpF0EjSQQCGyjBEHSLoIgCQQC2yhBkLSLkPMRCAS2UYIgaRehDlYgENhG6aggEZEVIvKAiKwSkfM9n/eKyP9Gn/9eROZHyw8XkTtE5J7o+XXWd26OtnlX9AhZe4FAIDCGdCzUKOq5filwOPAkcLuIXK2U+rO12mnAC0qp3UXkBOAzwPHAs8CblFJ/FZFXoNv12j1sT4o6JY49p9+kuxsGAoHANkonNZJlwCql1MNKqUHgCuAYZ51jgG9Er78PHCYiopS6Uyn112j5fUC/iPR2cF+bZ+5+sOz0sd6LQCAQGDM6KUjmAk9Y758kqVUk1lFKDQPrgZnOOm8D/qiUGrCWXR6Ztf5FUvrHisgZIrJSRFauXbu2leMIBAKBQAZd7WwXkb3Q5q4zrcUnKaUWAwdHj5N931VKXaaUWqqUWjp79uzO72wgEAhso3RSkKwB5lnvd4qWedcRkRIwFXguer8T8EPgFKXUavMFpdSa6Pkl4DtoE1ogEAgExohOCpLbgYUiskBEeoATgKudda4GTo1eHwvcqJRSIjIN+BlwvlLqVrOyiJREZFb0ugy8Ebi3g8cQCAQCgTp0TJBEPo9z0BFXfwGuVErdJyIXisjR0WpfA2aKyCrgA4AJET4H2B34qBPm2wtcKyJ3A3ehNZqvdOoYAoFAIFAfUUqN9T50nKVLl6qVK7sjWjgQCATGCyJyh1Jqab31utrZHggEAoHuJwiSQCAQCLTENmHaEpG1wGNNfn0WOtN+WyIc87ZBOOZtg1aOeRelVN38iW1CkLSCiKzMYyPcmgjHvG0QjnnbYDSOOZi2AoFAINASQZAEAoFAoCWCIKnPZWO9A2NAOOZtg3DM2wYdP+bgIwkEAoFASwSNJBAIBAItEQRJIBAIBFoiCJIM6rUKHq+IyNdF5BkRuddaNkNErheRh6Ln6dFyEZHPRefgbhHZb+z2vDlEZJ6I3CQifxaR+0Tk3Gj51nzMfSLyBxH5U3TM/y9aviBqa70qanPdEy33tr0ej4hIUUTuFJGfRu+36mMWkUejtuR3icjKaNmoXttBkKRgtQo+CtgTOFFE9hzbvWob/w2scJadD9yglFoI3EBcQPMoYGH0OAP44ijtYzsZBj6olNoTWA68J/ovt+ZjHgBep5TaB1gCrBCR5ej+PhcrpXYHXkC3uwar7TVwcbTeeOVcdKFYw7ZwzIcqpZZY+SKje20rpcLD8wAOBK613l8AXDDW+9XG45sP3Gu9fwDYMXq9I/BA9PrLwIm+9cbrA/gxcPi2cszABOCPwAHoDOdStLx6jaOrdB8YvS5F68lY73sTx7oTeuB8HfBTQLaBY34UmOUsG9VrO2gk6eRpFbw1sb1S6qno9dPA9tHrreo8ROaLfYHfs5Ufc2TiuQt4BrgeWA2sU7rFAySPK0/b6/HAJcCHgJHo/Uy2/mNWwHUicoeInBEtG9Vru9TqBgJbH0opJSJbXVy4iEwCfgC8Tyn1oohUP9saj1kpVQGWRI3ifgi8bIx3qaOIyBuBZ5RSd4jIa8d6f0aRg5RSa6KeTdeLyP32h6NxbQeNJJ08rYK3Jv4mIjsCRM/PRMu3ivMQddT8AfBtpdRV0eKt+pgNSql1wE1os8400W2tIXlcqW2vxxGvBo4WkUeBK9Dmrf9k6z5mVNx+/Bn0hGEZo3xtB0GSTp5WwVsTdtvjU9F+BLP8lCjaYzmw3lKZxwWiVY+vAX9RSv2H9dHWfMyzI00EEelH+4T+ghYox0arucdc0/Z69Pa4dZRSFyildlJKzUffrzcqpU5iKz5mEZkoIpPNa+AIdPvx0b22x9pR1M0P4PXAg2jb8kfGen/aeFzfBZ4ChtA20tPQtuEbgIeAXwIzonUFHb22GrgHWDrW+9/E8R6EtiObFs13Rf/t1nzMewN3Rsd8L/DRaPmuwB+AVcD3gN5oeV/0flX0+a5jfQwtHv9rgZ9u7cccHdufosd9Zpwa7Ws7lEgJBAKBQEsE01YgEAgEWiIIkkAgEAi0RBAkgUAgEGiJIEgCgUAg0BJBkAQCgUCgJYIgCQTagIhUouqr5tG2atEiMl+sSs2BQLcRSqQEAu1hs1JqyVjvRCAwFgSNJBDoIFGviM9G/SL+ICK7R8vni8iNUU+IG0Rk52j59iLyw6iPyJ9E5FXRpooi8pWot8h1UbZ6INAVBEESCLSHfse0dbz12Xql1GLgC+jqtACfB76hlNob+DbwuWj554BblO4jsh86Wxl0/4hLlVJ7AeuAt3X4eAKB3ITM9kCgDYjIBqXUJM/yR9ENph6OCkc+rZSaKSLPovtADEXLn1JKzRKRtcBOSqkBaxvzgeuVblKEiHwYKCulPtH5IwsE6hM0kkCg86iU140wYL2uEPybgS4iCJJAoPMcbz3fFr3+LbpCLcBJwK+j1zcA74ZqY6qpo7WTgUCzhFlNINAe+qNuhIZfKKVMCPB0EbkbrVWcGC37R+ByETkPWAv8fbT8XOAyETkNrXm8G12pORDoWoKPJBDoIJGPZKlS6tmx3pdAoFME01YgEAgEWiJoJIFAIBBoiaCRBAKBQKAlgiAJBAKBQEsEQRIIBAKBlgiCJBAIBAItEQRJIBAIBFri/wORJd0O4uu7rAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_and_saving(RNN,'RNNsimple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 2.3051 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 2/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.3039 - acc: 0.0625 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 3/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3033 - acc: 0.0875 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 4/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3004 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 5/500\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 2.3043 - acc: 0.0625 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 6/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 2.3010 - acc: 0.0542 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 7/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2973 - acc: 0.0583 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 8/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.2945 - acc: 0.0708 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 9/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.2939 - acc: 0.0958 - val_loss: 2.3014 - val_acc: 0.1182\n",
      "Epoch 10/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2967 - acc: 0.1083 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 11/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3020 - acc: 0.0708 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 12/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3010 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 13/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3001 - acc: 0.0792 - val_loss: 2.3026 - val_acc: 0.0909\n",
      "Epoch 14/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2984 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.0818\n",
      "Epoch 15/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2955 - acc: 0.0542 - val_loss: 2.3018 - val_acc: 0.0818\n",
      "Epoch 16/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2998 - acc: 0.1083 - val_loss: 2.3045 - val_acc: 0.0909\n",
      "Epoch 17/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.9532 - acc: 0.1083 - val_loss: 2.5014 - val_acc: 0.1000\n",
      "Epoch 18/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.4311 - acc: 0.0792 - val_loss: 2.3369 - val_acc: 0.1000\n",
      "Epoch 19/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3561 - acc: 0.1042 - val_loss: 2.3177 - val_acc: 0.0909\n",
      "Epoch 20/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3550 - acc: 0.0833 - val_loss: 2.3256 - val_acc: 0.1000\n",
      "Epoch 21/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3421 - acc: 0.0958 - val_loss: 2.3151 - val_acc: 0.1000\n",
      "Epoch 22/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3572 - acc: 0.0625 - val_loss: 2.3139 - val_acc: 0.1000\n",
      "Epoch 23/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3481 - acc: 0.1000 - val_loss: 2.3106 - val_acc: 0.1000\n",
      "Epoch 24/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3490 - acc: 0.0750 - val_loss: 2.3112 - val_acc: 0.1000\n",
      "Epoch 25/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3459 - acc: 0.0750 - val_loss: 2.3082 - val_acc: 0.1000\n",
      "Epoch 26/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3381 - acc: 0.0750 - val_loss: 2.3125 - val_acc: 0.1000\n",
      "Epoch 27/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3272 - acc: 0.0667 - val_loss: 2.3083 - val_acc: 0.1000\n",
      "Epoch 28/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3349 - acc: 0.0750 - val_loss: 2.3079 - val_acc: 0.1000\n",
      "Epoch 29/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3192 - acc: 0.0750 - val_loss: 2.3073 - val_acc: 0.1000\n",
      "Epoch 30/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3256 - acc: 0.0875 - val_loss: 2.3053 - val_acc: 0.1000\n",
      "Epoch 31/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3234 - acc: 0.0542 - val_loss: 2.3084 - val_acc: 0.1000\n",
      "Epoch 32/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3428 - acc: 0.0583 - val_loss: 2.3046 - val_acc: 0.1000\n",
      "Epoch 33/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3315 - acc: 0.0958 - val_loss: 2.3039 - val_acc: 0.1000\n",
      "Epoch 34/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3190 - acc: 0.0583 - val_loss: 2.3051 - val_acc: 0.1000\n",
      "Epoch 35/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3280 - acc: 0.0750 - val_loss: 2.3061 - val_acc: 0.1000\n",
      "Epoch 36/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3299 - acc: 0.0625 - val_loss: 2.3088 - val_acc: 0.1000\n",
      "Epoch 37/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3245 - acc: 0.0958 - val_loss: 2.3059 - val_acc: 0.1000\n",
      "Epoch 38/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3338 - acc: 0.0708 - val_loss: 2.3069 - val_acc: 0.1000\n",
      "Epoch 39/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3440 - acc: 0.0708 - val_loss: 2.3043 - val_acc: 0.1000\n",
      "Epoch 40/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3377 - acc: 0.0833 - val_loss: 2.3075 - val_acc: 0.1000\n",
      "Epoch 41/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3320 - acc: 0.0917 - val_loss: 2.3067 - val_acc: 0.1000\n",
      "Epoch 42/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3264 - acc: 0.0875 - val_loss: 2.3058 - val_acc: 0.1000\n",
      "Epoch 43/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3337 - acc: 0.0875 - val_loss: 2.3078 - val_acc: 0.1000\n",
      "Epoch 44/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3252 - acc: 0.1125 - val_loss: 2.3065 - val_acc: 0.1000\n",
      "Epoch 45/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3211 - acc: 0.0792 - val_loss: 2.3068 - val_acc: 0.1000\n",
      "Epoch 46/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3255 - acc: 0.1042 - val_loss: 2.3083 - val_acc: 0.1000\n",
      "Epoch 47/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3210 - acc: 0.0833 - val_loss: 2.3076 - val_acc: 0.1000\n",
      "Epoch 48/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3213 - acc: 0.1000 - val_loss: 2.3055 - val_acc: 0.1000\n",
      "Epoch 49/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3175 - acc: 0.0625 - val_loss: 2.3037 - val_acc: 0.1000\n",
      "Epoch 50/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3182 - acc: 0.0833 - val_loss: 2.3052 - val_acc: 0.1000\n",
      "Epoch 51/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3224 - acc: 0.0833 - val_loss: 2.3070 - val_acc: 0.1000\n",
      "Epoch 52/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3240 - acc: 0.0917 - val_loss: 2.3064 - val_acc: 0.1000\n",
      "Epoch 53/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3259 - acc: 0.0750 - val_loss: 2.3069 - val_acc: 0.1000\n",
      "Epoch 54/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3248 - acc: 0.0875 - val_loss: 2.3067 - val_acc: 0.1000\n",
      "Epoch 55/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3240 - acc: 0.1042 - val_loss: 2.3052 - val_acc: 0.1000\n",
      "Epoch 56/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3178 - acc: 0.0833 - val_loss: 2.3057 - val_acc: 0.1000\n",
      "Epoch 57/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3287 - acc: 0.0917 - val_loss: 2.3061 - val_acc: 0.1000\n",
      "Epoch 58/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3198 - acc: 0.1042 - val_loss: 2.3059 - val_acc: 0.1000\n",
      "Epoch 59/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3229 - acc: 0.0667 - val_loss: 2.3047 - val_acc: 0.1091\n",
      "Epoch 60/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3121 - acc: 0.0708 - val_loss: 2.3049 - val_acc: 0.1000\n",
      "Epoch 61/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3270 - acc: 0.0625 - val_loss: 2.3049 - val_acc: 0.1000\n",
      "Epoch 62/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3119 - acc: 0.0958 - val_loss: 2.3043 - val_acc: 0.1000\n",
      "Epoch 63/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3107 - acc: 0.0833 - val_loss: 2.3033 - val_acc: 0.1000\n",
      "Epoch 64/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3226 - acc: 0.0792 - val_loss: 2.3063 - val_acc: 0.1000\n",
      "Epoch 65/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.3249 - acc: 0.0792 - val_loss: 2.3045 - val_acc: 0.1000\n",
      "Epoch 66/500\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 2.3151 - acc: 0.0875 - val_loss: 2.3046 - val_acc: 0.0909\n",
      "Epoch 67/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.3109 - acc: 0.0708 - val_loss: 2.3042 - val_acc: 0.1000\n",
      "Epoch 68/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.3190 - acc: 0.0875 - val_loss: 2.3052 - val_acc: 0.1000\n",
      "Epoch 69/500\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 2.3188 - acc: 0.0667 - val_loss: 2.3056 - val_acc: 0.1091\n",
      "Epoch 70/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.3208 - acc: 0.0750 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 71/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3149 - acc: 0.0875 - val_loss: 2.3066 - val_acc: 0.1000\n",
      "Epoch 72/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.3150 - acc: 0.1125 - val_loss: 2.3075 - val_acc: 0.1000\n",
      "Epoch 73/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 2.3199 - acc: 0.0875 - val_loss: 2.3053 - val_acc: 0.1000\n",
      "Epoch 74/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.3156 - acc: 0.0917 - val_loss: 2.3069 - val_acc: 0.1000\n",
      "Epoch 75/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.3143 - acc: 0.0917 - val_loss: 2.3056 - val_acc: 0.1000\n",
      "Epoch 76/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3076 - acc: 0.0792 - val_loss: 2.3054 - val_acc: 0.1000\n",
      "Epoch 77/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.3093 - acc: 0.0917 - val_loss: 2.3049 - val_acc: 0.1000\n",
      "Epoch 78/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.4604 - acc: 0.1000 - val_loss: 2.4672 - val_acc: 0.0636\n",
      "Epoch 79/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 2.3694 - acc: 0.0708 - val_loss: 2.3434 - val_acc: 0.0727\n",
      "Epoch 80/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 2.3365 - acc: 0.0792 - val_loss: 2.2935 - val_acc: 0.1455\n",
      "Epoch 81/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.3195 - acc: 0.1000 - val_loss: 2.3110 - val_acc: 0.1273\n",
      "Epoch 82/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 2.3232 - acc: 0.1000 - val_loss: 2.3125 - val_acc: 0.1000\n",
      "Epoch 83/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.3389 - acc: 0.0583 - val_loss: 2.3043 - val_acc: 0.1000\n",
      "Epoch 84/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.3230 - acc: 0.0708 - val_loss: 2.3066 - val_acc: 0.1000\n",
      "Epoch 85/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3200 - acc: 0.0875 - val_loss: 2.3044 - val_acc: 0.1000\n",
      "Epoch 86/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3208 - acc: 0.0917 - val_loss: 2.3058 - val_acc: 0.1000\n",
      "Epoch 87/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 2.3192 - acc: 0.0792 - val_loss: 2.3046 - val_acc: 0.1000\n",
      "Epoch 88/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.3249 - acc: 0.0750 - val_loss: 2.3060 - val_acc: 0.1000\n",
      "Epoch 89/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3193 - acc: 0.0833 - val_loss: 2.3057 - val_acc: 0.1000\n",
      "Epoch 90/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3155 - acc: 0.0583 - val_loss: 2.3043 - val_acc: 0.1000\n",
      "Epoch 91/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3157 - acc: 0.0875 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 92/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.3321 - acc: 0.0833 - val_loss: 2.3050 - val_acc: 0.1000\n",
      "Epoch 93/500\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 2.3225 - acc: 0.0917 - val_loss: 2.3047 - val_acc: 0.1000\n",
      "Epoch 94/500\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 2.3138 - acc: 0.0875 - val_loss: 2.3060 - val_acc: 0.1000\n",
      "Epoch 95/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.3159 - acc: 0.0667 - val_loss: 2.3076 - val_acc: 0.0909\n",
      "Epoch 96/500\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 2.3082 - acc: 0.0833 - val_loss: 2.3072 - val_acc: 0.1182\n",
      "Epoch 97/500\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.3248 - acc: 0.0833 - val_loss: 2.3208 - val_acc: 0.1182\n",
      "Epoch 98/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.3067 - acc: 0.1000 - val_loss: 2.3327 - val_acc: 0.0545\n",
      "Epoch 99/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3491 - acc: 0.0750 - val_loss: 2.3070 - val_acc: 0.1000\n",
      "Epoch 100/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 2.3248 - acc: 0.0625 - val_loss: 2.3061 - val_acc: 0.1000\n",
      "Epoch 101/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.3205 - acc: 0.0875 - val_loss: 2.3041 - val_acc: 0.1091\n",
      "Epoch 102/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.3153 - acc: 0.0583 - val_loss: 2.3058 - val_acc: 0.1000\n",
      "Epoch 103/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.3213 - acc: 0.0667 - val_loss: 2.3050 - val_acc: 0.1000\n",
      "Epoch 104/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.3231 - acc: 0.0917 - val_loss: 2.3055 - val_acc: 0.1091\n",
      "Epoch 105/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.3087 - acc: 0.0875 - val_loss: 2.3051 - val_acc: 0.1000\n",
      "Epoch 106/500\n",
      "240/240 [==============================] - 11s 44ms/step - loss: 2.3216 - acc: 0.0875 - val_loss: 2.3060 - val_acc: 0.0909\n",
      "Epoch 107/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 2.3166 - acc: 0.1083 - val_loss: 2.3030 - val_acc: 0.1455\n",
      "Epoch 108/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 2.3143 - acc: 0.0958 - val_loss: 2.3028 - val_acc: 0.1091\n",
      "Epoch 109/500\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 2.3021 - acc: 0.1250 - val_loss: 2.2983 - val_acc: 0.1091\n",
      "Epoch 110/500\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 2.3158 - acc: 0.1167 - val_loss: 2.3028 - val_acc: 0.1364\n",
      "Epoch 111/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.3014 - acc: 0.1333 - val_loss: 2.3142 - val_acc: 0.1182\n",
      "Epoch 112/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 2.2922 - acc: 0.1583 - val_loss: 2.3025 - val_acc: 0.1818\n",
      "Epoch 113/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 2.2871 - acc: 0.1708 - val_loss: 2.3029 - val_acc: 0.1182\n",
      "Epoch 114/500\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.3067 - acc: 0.1208 - val_loss: 2.2949 - val_acc: 0.1455\n",
      "Epoch 115/500\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.3322 - acc: 0.0833 - val_loss: 2.3400 - val_acc: 0.1000\n",
      "Epoch 116/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.2979 - acc: 0.0958 - val_loss: 2.3182 - val_acc: 0.1273\n",
      "Epoch 117/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3095 - acc: 0.1125 - val_loss: 2.3654 - val_acc: 0.0818\n",
      "Epoch 118/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.3108 - acc: 0.1083 - val_loss: 2.3133 - val_acc: 0.1273\n",
      "Epoch 119/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.3201 - acc: 0.1083 - val_loss: 2.2930 - val_acc: 0.1545\n",
      "Epoch 120/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.2872 - acc: 0.1458 - val_loss: 2.2910 - val_acc: 0.1545\n",
      "Epoch 121/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 7s 30ms/step - loss: 2.2679 - acc: 0.1458 - val_loss: 2.2799 - val_acc: 0.1818\n",
      "Epoch 122/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.2728 - acc: 0.1750 - val_loss: 2.2979 - val_acc: 0.1182\n",
      "Epoch 123/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3060 - acc: 0.1250 - val_loss: 2.3133 - val_acc: 0.1182\n",
      "Epoch 124/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3365 - acc: 0.0875 - val_loss: 2.3413 - val_acc: 0.0909\n",
      "Epoch 125/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 2.3521 - acc: 0.0750 - val_loss: 2.3356 - val_acc: 0.0909\n",
      "Epoch 126/500\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.3486 - acc: 0.0625 - val_loss: 2.3194 - val_acc: 0.0818\n",
      "Epoch 127/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 2.3304 - acc: 0.0958 - val_loss: 2.3235 - val_acc: 0.1000\n",
      "Epoch 128/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.3269 - acc: 0.0833 - val_loss: 2.3199 - val_acc: 0.1091\n",
      "Epoch 129/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.3200 - acc: 0.1000 - val_loss: 2.3136 - val_acc: 0.1091\n",
      "Epoch 130/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.3067 - acc: 0.1083 - val_loss: 2.2989 - val_acc: 0.1364\n",
      "Epoch 131/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3016 - acc: 0.1083 - val_loss: 2.3039 - val_acc: 0.1182\n",
      "Epoch 132/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3117 - acc: 0.1000 - val_loss: 2.3035 - val_acc: 0.1182\n",
      "Epoch 133/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3022 - acc: 0.1292 - val_loss: 2.2990 - val_acc: 0.1455\n",
      "Epoch 134/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3145 - acc: 0.1083 - val_loss: 2.2888 - val_acc: 0.1182\n",
      "Epoch 135/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3017 - acc: 0.1042 - val_loss: 2.2984 - val_acc: 0.0727\n",
      "Epoch 136/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 2.2854 - acc: 0.1333 - val_loss: 2.2741 - val_acc: 0.1273\n",
      "Epoch 137/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2825 - acc: 0.1500 - val_loss: 2.2913 - val_acc: 0.1182\n",
      "Epoch 138/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2964 - acc: 0.1208 - val_loss: 2.2687 - val_acc: 0.1727\n",
      "Epoch 139/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2815 - acc: 0.1500 - val_loss: 2.2708 - val_acc: 0.1182\n",
      "Epoch 140/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3256 - acc: 0.1167 - val_loss: 2.2681 - val_acc: 0.1273\n",
      "Epoch 141/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 2.2733 - acc: 0.1542 - val_loss: 2.3111 - val_acc: 0.1091\n",
      "Epoch 142/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 2.3111 - acc: 0.1375 - val_loss: 2.2821 - val_acc: 0.1182\n",
      "Epoch 143/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 2.2779 - acc: 0.1292 - val_loss: 2.2803 - val_acc: 0.1364\n",
      "Epoch 144/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2590 - acc: 0.1667 - val_loss: 2.2328 - val_acc: 0.1818\n",
      "Epoch 145/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.2301 - acc: 0.1833 - val_loss: 2.2050 - val_acc: 0.1727\n",
      "Epoch 146/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.2070 - acc: 0.1875 - val_loss: 2.1704 - val_acc: 0.2000\n",
      "Epoch 147/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.1904 - acc: 0.1792 - val_loss: 2.1656 - val_acc: 0.1545\n",
      "Epoch 148/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.2143 - acc: 0.1667 - val_loss: 2.2345 - val_acc: 0.1364\n",
      "Epoch 149/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.1663 - acc: 0.2083 - val_loss: 2.1226 - val_acc: 0.1818\n",
      "Epoch 150/500\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.1516 - acc: 0.2125 - val_loss: 2.1953 - val_acc: 0.1909\n",
      "Epoch 151/500\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 2.1473 - acc: 0.1917 - val_loss: 2.1976 - val_acc: 0.1273\n",
      "Epoch 152/500\n",
      "240/240 [==============================] - 11s 46ms/step - loss: 2.1798 - acc: 0.1625 - val_loss: 2.1149 - val_acc: 0.2364\n",
      "Epoch 153/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 2.1316 - acc: 0.1958 - val_loss: 2.1223 - val_acc: 0.1727\n",
      "Epoch 154/500\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.1229 - acc: 0.1792 - val_loss: 2.1700 - val_acc: 0.1455\n",
      "Epoch 155/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 2.3349 - acc: 0.1375 - val_loss: 2.3600 - val_acc: 0.1000\n",
      "Epoch 156/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 2.3030 - acc: 0.1250 - val_loss: 2.3196 - val_acc: 0.1000\n",
      "Epoch 157/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.2838 - acc: 0.1292 - val_loss: 2.2586 - val_acc: 0.1818\n",
      "Epoch 158/500\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2301 - acc: 0.1625 - val_loss: 2.2483 - val_acc: 0.2091\n",
      "Epoch 159/500\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 2.2793 - acc: 0.1583 - val_loss: 2.2572 - val_acc: 0.1727\n",
      "Epoch 160/500\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 2.2409 - acc: 0.1917 - val_loss: 2.2373 - val_acc: 0.1636\n",
      "Epoch 161/500\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 2.2195 - acc: 0.1958 - val_loss: 2.2386 - val_acc: 0.1909\n",
      "Epoch 162/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 2.1844 - acc: 0.2042 - val_loss: 2.1968 - val_acc: 0.1727\n",
      "Epoch 163/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.1658 - acc: 0.1917 - val_loss: 2.2534 - val_acc: 0.1727\n",
      "Epoch 164/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 2.1585 - acc: 0.2292 - val_loss: 2.1845 - val_acc: 0.1727\n",
      "Epoch 165/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.1097 - acc: 0.1917 - val_loss: 2.1230 - val_acc: 0.1727\n",
      "Epoch 166/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.0479 - acc: 0.2750 - val_loss: 2.1565 - val_acc: 0.2182\n",
      "Epoch 167/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.0356 - acc: 0.2542 - val_loss: 2.1545 - val_acc: 0.2182\n",
      "Epoch 168/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.0131 - acc: 0.2708 - val_loss: 2.0659 - val_acc: 0.2364\n",
      "Epoch 169/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.0020 - acc: 0.3083 - val_loss: 2.1193 - val_acc: 0.2273\n",
      "Epoch 170/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.9532 - acc: 0.2583 - val_loss: 2.1430 - val_acc: 0.1909\n",
      "Epoch 171/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.9414 - acc: 0.3208 - val_loss: 2.0217 - val_acc: 0.2909\n",
      "Epoch 172/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.9344 - acc: 0.2625 - val_loss: 2.1094 - val_acc: 0.2455\n",
      "Epoch 173/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.9758 - acc: 0.2625 - val_loss: 2.1795 - val_acc: 0.2091\n",
      "Epoch 174/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.9135 - acc: 0.2958 - val_loss: 2.0325 - val_acc: 0.2818\n",
      "Epoch 175/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.8783 - acc: 0.3583 - val_loss: 2.1054 - val_acc: 0.2455\n",
      "Epoch 176/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.8904 - acc: 0.2750 - val_loss: 1.9522 - val_acc: 0.2909\n",
      "Epoch 177/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.9248 - acc: 0.2542 - val_loss: 2.1177 - val_acc: 0.1727\n",
      "Epoch 178/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.8884 - acc: 0.2875 - val_loss: 2.1466 - val_acc: 0.2091\n",
      "Epoch 179/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.9475 - acc: 0.2583 - val_loss: 2.0964 - val_acc: 0.2364\n",
      "Epoch 180/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 1.9189 - acc: 0.2708 - val_loss: 1.9931 - val_acc: 0.2636\n",
      "Epoch 181/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 6s 23ms/step - loss: 1.8431 - acc: 0.3333 - val_loss: 1.9982 - val_acc: 0.2727\n",
      "Epoch 182/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.7958 - acc: 0.2875 - val_loss: 1.9454 - val_acc: 0.2727\n",
      "Epoch 183/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.8430 - acc: 0.2833 - val_loss: 1.9654 - val_acc: 0.2545\n",
      "Epoch 184/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.9007 - acc: 0.2708 - val_loss: 1.9680 - val_acc: 0.3000\n",
      "Epoch 185/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.8394 - acc: 0.3000 - val_loss: 1.9340 - val_acc: 0.3091\n",
      "Epoch 186/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.7536 - acc: 0.3458 - val_loss: 1.9446 - val_acc: 0.2818\n",
      "Epoch 187/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.7715 - acc: 0.3250 - val_loss: 2.0309 - val_acc: 0.3000\n",
      "Epoch 188/500\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 1.7034 - acc: 0.3833 - val_loss: 1.9394 - val_acc: 0.2636\n",
      "Epoch 189/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.7070 - acc: 0.3583 - val_loss: 1.9881 - val_acc: 0.2364\n",
      "Epoch 190/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.8712 - acc: 0.3042 - val_loss: 1.8746 - val_acc: 0.2909\n",
      "Epoch 191/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.7009 - acc: 0.3417 - val_loss: 1.8577 - val_acc: 0.3091\n",
      "Epoch 192/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.6313 - acc: 0.4250 - val_loss: 1.8254 - val_acc: 0.3273\n",
      "Epoch 193/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.6346 - acc: 0.3500 - val_loss: 1.8193 - val_acc: 0.2909\n",
      "Epoch 194/500\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 1.6053 - acc: 0.3875 - val_loss: 1.7958 - val_acc: 0.3273\n",
      "Epoch 195/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.5672 - acc: 0.4250 - val_loss: 1.8464 - val_acc: 0.3364\n",
      "Epoch 196/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.5395 - acc: 0.4417 - val_loss: 1.8523 - val_acc: 0.3091\n",
      "Epoch 197/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 1.5738 - acc: 0.4458 - val_loss: 1.9052 - val_acc: 0.2818\n",
      "Epoch 198/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.6066 - acc: 0.4083 - val_loss: 2.1617 - val_acc: 0.2727\n",
      "Epoch 199/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.9317 - acc: 0.2750 - val_loss: 2.0820 - val_acc: 0.2727\n",
      "Epoch 200/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 1.7931 - acc: 0.3375 - val_loss: 2.0701 - val_acc: 0.2545\n",
      "Epoch 201/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.8012 - acc: 0.3208 - val_loss: 1.9275 - val_acc: 0.2909\n",
      "Epoch 202/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.5961 - acc: 0.4125 - val_loss: 1.8206 - val_acc: 0.3364\n",
      "Epoch 203/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.5417 - acc: 0.4583 - val_loss: 1.7795 - val_acc: 0.3091\n",
      "Epoch 204/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.4748 - acc: 0.4583 - val_loss: 1.7736 - val_acc: 0.3727\n",
      "Epoch 205/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 1.4335 - acc: 0.5000 - val_loss: 1.7286 - val_acc: 0.3636\n",
      "Epoch 206/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.4298 - acc: 0.5042 - val_loss: 1.7305 - val_acc: 0.3818\n",
      "Epoch 207/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.4293 - acc: 0.4667 - val_loss: 1.9239 - val_acc: 0.3091\n",
      "Epoch 208/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.4043 - acc: 0.4833 - val_loss: 1.7371 - val_acc: 0.3636\n",
      "Epoch 209/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.3405 - acc: 0.5167 - val_loss: 1.6495 - val_acc: 0.3636\n",
      "Epoch 210/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.3441 - acc: 0.4958 - val_loss: 1.6461 - val_acc: 0.4000\n",
      "Epoch 211/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.3399 - acc: 0.4583 - val_loss: 1.6282 - val_acc: 0.3818\n",
      "Epoch 212/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.2792 - acc: 0.5167 - val_loss: 1.5773 - val_acc: 0.4364\n",
      "Epoch 213/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.3254 - acc: 0.4583 - val_loss: 1.6193 - val_acc: 0.4000\n",
      "Epoch 214/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 1.2733 - acc: 0.5167 - val_loss: 1.6610 - val_acc: 0.4000\n",
      "Epoch 215/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.2718 - acc: 0.5000 - val_loss: 1.6850 - val_acc: 0.3727\n",
      "Epoch 216/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.2506 - acc: 0.5042 - val_loss: 1.6765 - val_acc: 0.3818\n",
      "Epoch 217/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.2722 - acc: 0.5000 - val_loss: 1.5162 - val_acc: 0.4273\n",
      "Epoch 218/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4194 - acc: 0.4083 - val_loss: 1.8359 - val_acc: 0.2636\n",
      "Epoch 219/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3842 - acc: 0.4542 - val_loss: 1.6519 - val_acc: 0.4000\n",
      "Epoch 220/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4192 - acc: 0.4250 - val_loss: 1.7036 - val_acc: 0.3364\n",
      "Epoch 221/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4523 - acc: 0.4042 - val_loss: 1.7126 - val_acc: 0.3273\n",
      "Epoch 222/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3001 - acc: 0.4875 - val_loss: 1.6331 - val_acc: 0.3364\n",
      "Epoch 223/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2836 - acc: 0.4875 - val_loss: 1.6193 - val_acc: 0.3364\n",
      "Epoch 224/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2564 - acc: 0.4833 - val_loss: 1.5181 - val_acc: 0.4000\n",
      "Epoch 225/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.1883 - acc: 0.5208 - val_loss: 1.5693 - val_acc: 0.4000\n",
      "Epoch 226/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2285 - acc: 0.5208 - val_loss: 1.6814 - val_acc: 0.3455\n",
      "Epoch 227/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2720 - acc: 0.5250 - val_loss: 1.5741 - val_acc: 0.3727\n",
      "Epoch 228/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.1739 - acc: 0.5583 - val_loss: 1.6998 - val_acc: 0.3727\n",
      "Epoch 229/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.2704 - acc: 0.5000 - val_loss: 1.5975 - val_acc: 0.3727\n",
      "Epoch 230/500\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 1.3546 - acc: 0.4250 - val_loss: 1.6519 - val_acc: 0.3182\n",
      "Epoch 231/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 1.2444 - acc: 0.4750 - val_loss: 1.7044 - val_acc: 0.3364\n",
      "Epoch 232/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.2024 - acc: 0.4958 - val_loss: 1.5989 - val_acc: 0.3818\n",
      "Epoch 233/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.1930 - acc: 0.5083 - val_loss: 1.4984 - val_acc: 0.4182\n",
      "Epoch 234/500\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 1.1750 - acc: 0.5125 - val_loss: 1.7120 - val_acc: 0.3909\n",
      "Epoch 235/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 1.1460 - acc: 0.5208 - val_loss: 1.5442 - val_acc: 0.4273\n",
      "Epoch 236/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.1321 - acc: 0.5500 - val_loss: 1.6892 - val_acc: 0.3727\n",
      "Epoch 237/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2444 - acc: 0.5125 - val_loss: 1.6457 - val_acc: 0.4273\n",
      "Epoch 238/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.1480 - acc: 0.5333 - val_loss: 1.6839 - val_acc: 0.3909\n",
      "Epoch 239/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2119 - acc: 0.4833 - val_loss: 1.8474 - val_acc: 0.3364\n",
      "Epoch 240/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.2546 - acc: 0.4750 - val_loss: 1.6972 - val_acc: 0.3545\n",
      "Epoch 241/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 9s 38ms/step - loss: 1.2043 - acc: 0.5042 - val_loss: 1.5850 - val_acc: 0.4273\n",
      "Epoch 242/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.2008 - acc: 0.5083 - val_loss: 1.5893 - val_acc: 0.4000\n",
      "Epoch 243/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.1586 - acc: 0.5583 - val_loss: 1.5117 - val_acc: 0.4364\n",
      "Epoch 244/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.1380 - acc: 0.5333 - val_loss: 1.4989 - val_acc: 0.4545\n",
      "Epoch 245/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.1394 - acc: 0.5042 - val_loss: 1.4891 - val_acc: 0.4182\n",
      "Epoch 246/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.1809 - acc: 0.5417 - val_loss: 1.4836 - val_acc: 0.4455\n",
      "Epoch 247/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.1664 - acc: 0.5208 - val_loss: 1.5489 - val_acc: 0.3818\n",
      "Epoch 248/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.1196 - acc: 0.5292 - val_loss: 1.5994 - val_acc: 0.4273\n",
      "Epoch 249/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0644 - acc: 0.5875 - val_loss: 1.5681 - val_acc: 0.4182\n",
      "Epoch 250/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0811 - acc: 0.5875 - val_loss: 1.5035 - val_acc: 0.4364\n",
      "Epoch 251/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.1311 - acc: 0.5458 - val_loss: 1.5395 - val_acc: 0.4364\n",
      "Epoch 252/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0976 - acc: 0.5708 - val_loss: 1.6122 - val_acc: 0.4000\n",
      "Epoch 253/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.1746 - acc: 0.5500 - val_loss: 1.9075 - val_acc: 0.3091\n",
      "Epoch 254/500\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 1.7546 - acc: 0.3250 - val_loss: 1.7390 - val_acc: 0.3091\n",
      "Epoch 255/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4377 - acc: 0.3917 - val_loss: 1.8132 - val_acc: 0.3727\n",
      "Epoch 256/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4330 - acc: 0.3875 - val_loss: 1.7220 - val_acc: 0.3273\n",
      "Epoch 257/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7516 - acc: 0.3292 - val_loss: 1.7101 - val_acc: 0.3727\n",
      "Epoch 258/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4038 - acc: 0.4542 - val_loss: 1.6639 - val_acc: 0.3455\n",
      "Epoch 259/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4059 - acc: 0.3875 - val_loss: 1.5681 - val_acc: 0.3545\n",
      "Epoch 260/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.2544 - acc: 0.5167 - val_loss: 1.6043 - val_acc: 0.3909\n",
      "Epoch 261/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.1596 - acc: 0.5125 - val_loss: 1.4900 - val_acc: 0.3909\n",
      "Epoch 262/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.1399 - acc: 0.5625 - val_loss: 1.6131 - val_acc: 0.3545\n",
      "Epoch 263/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.1853 - acc: 0.5125 - val_loss: 1.6298 - val_acc: 0.3545\n",
      "Epoch 264/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.1644 - acc: 0.5333 - val_loss: 1.5198 - val_acc: 0.3818\n",
      "Epoch 265/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.1316 - acc: 0.5542 - val_loss: 1.5509 - val_acc: 0.4000\n",
      "Epoch 266/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.1361 - acc: 0.5625 - val_loss: 1.5476 - val_acc: 0.3545\n",
      "Epoch 267/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.1035 - acc: 0.5833 - val_loss: 1.5604 - val_acc: 0.4000\n",
      "Epoch 268/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0550 - acc: 0.5875 - val_loss: 1.5474 - val_acc: 0.4182\n",
      "Epoch 269/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0205 - acc: 0.6208 - val_loss: 1.5047 - val_acc: 0.4000\n",
      "Epoch 270/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.9908 - acc: 0.6250 - val_loss: 1.5758 - val_acc: 0.4273\n",
      "Epoch 271/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.1573 - acc: 0.5625 - val_loss: 1.6983 - val_acc: 0.3545\n",
      "Epoch 272/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 1.0875 - acc: 0.5833 - val_loss: 1.4806 - val_acc: 0.3727\n",
      "Epoch 273/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.0847 - acc: 0.5750 - val_loss: 1.8910 - val_acc: 0.3545\n",
      "Epoch 274/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.1231 - acc: 0.5500 - val_loss: 1.5696 - val_acc: 0.4636\n",
      "Epoch 275/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0083 - acc: 0.6000 - val_loss: 1.6365 - val_acc: 0.4000\n",
      "Epoch 276/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 1.0065 - acc: 0.6000 - val_loss: 1.3836 - val_acc: 0.4636\n",
      "Epoch 277/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.9425 - acc: 0.6458 - val_loss: 1.4234 - val_acc: 0.4636\n",
      "Epoch 278/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.9284 - acc: 0.6667 - val_loss: 1.5309 - val_acc: 0.4273\n",
      "Epoch 279/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8991 - acc: 0.6750 - val_loss: 1.5259 - val_acc: 0.4364\n",
      "Epoch 280/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8905 - acc: 0.6875 - val_loss: 1.5234 - val_acc: 0.4455\n",
      "Epoch 281/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8651 - acc: 0.6958 - val_loss: 1.5379 - val_acc: 0.4727\n",
      "Epoch 282/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8543 - acc: 0.6917 - val_loss: 1.5785 - val_acc: 0.4545\n",
      "Epoch 283/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.8534 - acc: 0.6917 - val_loss: 1.5128 - val_acc: 0.4818\n",
      "Epoch 284/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8401 - acc: 0.6875 - val_loss: 1.5754 - val_acc: 0.4636\n",
      "Epoch 285/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8298 - acc: 0.6875 - val_loss: 1.5830 - val_acc: 0.4636\n",
      "Epoch 286/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8402 - acc: 0.6792 - val_loss: 1.7118 - val_acc: 0.4273\n",
      "Epoch 287/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8573 - acc: 0.6708 - val_loss: 1.7111 - val_acc: 0.4364\n",
      "Epoch 288/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8829 - acc: 0.6708 - val_loss: 1.5965 - val_acc: 0.4636\n",
      "Epoch 289/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8375 - acc: 0.6875 - val_loss: 1.6051 - val_acc: 0.4636\n",
      "Epoch 290/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8388 - acc: 0.6917 - val_loss: 1.5981 - val_acc: 0.4727\n",
      "Epoch 291/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.8279 - acc: 0.6875 - val_loss: 1.6222 - val_acc: 0.4818\n",
      "Epoch 292/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.8110 - acc: 0.6958 - val_loss: 1.5371 - val_acc: 0.5000\n",
      "Epoch 293/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.9798 - acc: 0.6542 - val_loss: 1.7776 - val_acc: 0.4182\n",
      "Epoch 294/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.1480 - acc: 0.5667 - val_loss: 1.6314 - val_acc: 0.4364\n",
      "Epoch 295/500\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 2.0970 - acc: 0.3208 - val_loss: 2.5440 - val_acc: 0.1818\n",
      "Epoch 296/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.0892 - acc: 0.2625 - val_loss: 2.0561 - val_acc: 0.1818\n",
      "Epoch 297/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.7619 - acc: 0.2917 - val_loss: 1.8657 - val_acc: 0.2182\n",
      "Epoch 298/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.6280 - acc: 0.3917 - val_loss: 1.7907 - val_acc: 0.2364\n",
      "Epoch 299/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.5452 - acc: 0.4250 - val_loss: 1.7514 - val_acc: 0.2818\n",
      "Epoch 300/500\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 1.4890 - acc: 0.4500 - val_loss: 1.7242 - val_acc: 0.3455\n",
      "Epoch 301/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 6s 25ms/step - loss: 1.4210 - acc: 0.4792 - val_loss: 1.6952 - val_acc: 0.3091\n",
      "Epoch 302/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.3727 - acc: 0.5333 - val_loss: 1.7272 - val_acc: 0.3273\n",
      "Epoch 303/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3944 - acc: 0.4750 - val_loss: 1.6176 - val_acc: 0.3818\n",
      "Epoch 304/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3020 - acc: 0.5250 - val_loss: 1.6141 - val_acc: 0.3545\n",
      "Epoch 305/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.3254 - acc: 0.5167 - val_loss: 1.6556 - val_acc: 0.4000\n",
      "Epoch 306/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2236 - acc: 0.5500 - val_loss: 1.5947 - val_acc: 0.4000\n",
      "Epoch 307/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.1803 - acc: 0.5708 - val_loss: 1.6163 - val_acc: 0.3545\n",
      "Epoch 308/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.1440 - acc: 0.5917 - val_loss: 1.5833 - val_acc: 0.4091\n",
      "Epoch 309/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.1135 - acc: 0.6250 - val_loss: 1.6065 - val_acc: 0.4182\n",
      "Epoch 310/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0846 - acc: 0.5958 - val_loss: 1.6253 - val_acc: 0.4000\n",
      "Epoch 311/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.0757 - acc: 0.6208 - val_loss: 1.5815 - val_acc: 0.4818\n",
      "Epoch 312/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0055 - acc: 0.6292 - val_loss: 1.6426 - val_acc: 0.4727\n",
      "Epoch 313/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.9896 - acc: 0.6375 - val_loss: 1.5391 - val_acc: 0.4636\n",
      "Epoch 314/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0051 - acc: 0.6417 - val_loss: 1.6380 - val_acc: 0.4273\n",
      "Epoch 315/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0115 - acc: 0.6208 - val_loss: 1.5769 - val_acc: 0.4364\n",
      "Epoch 316/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.9640 - acc: 0.6417 - val_loss: 1.6348 - val_acc: 0.4364\n",
      "Epoch 317/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.9553 - acc: 0.6292 - val_loss: 1.5573 - val_acc: 0.4727\n",
      "Epoch 318/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.9456 - acc: 0.6458 - val_loss: 1.5234 - val_acc: 0.4727\n",
      "Epoch 319/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.9006 - acc: 0.6583 - val_loss: 1.5911 - val_acc: 0.4727\n",
      "Epoch 320/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8884 - acc: 0.6875 - val_loss: 1.5739 - val_acc: 0.4364\n",
      "Epoch 321/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8908 - acc: 0.6625 - val_loss: 1.5248 - val_acc: 0.4909\n",
      "Epoch 322/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8904 - acc: 0.6833 - val_loss: 1.5237 - val_acc: 0.4818\n",
      "Epoch 323/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8558 - acc: 0.7083 - val_loss: 1.5143 - val_acc: 0.5091\n",
      "Epoch 324/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8430 - acc: 0.7167 - val_loss: 1.5624 - val_acc: 0.5000\n",
      "Epoch 325/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8392 - acc: 0.7042 - val_loss: 1.5314 - val_acc: 0.5091\n",
      "Epoch 326/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8258 - acc: 0.7042 - val_loss: 1.6007 - val_acc: 0.4909\n",
      "Epoch 327/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8140 - acc: 0.7208 - val_loss: 1.6348 - val_acc: 0.4818\n",
      "Epoch 328/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.8566 - acc: 0.6875 - val_loss: 1.6368 - val_acc: 0.4818\n",
      "Epoch 329/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.8528 - acc: 0.7042 - val_loss: 1.7305 - val_acc: 0.4545\n",
      "Epoch 330/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.8624 - acc: 0.7000 - val_loss: 1.5348 - val_acc: 0.5182\n",
      "Epoch 331/500\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 0.8351 - acc: 0.7125 - val_loss: 1.5262 - val_acc: 0.4909\n",
      "Epoch 332/500\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.8075 - acc: 0.7208 - val_loss: 1.5283 - val_acc: 0.5000\n",
      "Epoch 333/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.7761 - acc: 0.7333 - val_loss: 1.5618 - val_acc: 0.4909\n",
      "Epoch 334/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.7562 - acc: 0.7375 - val_loss: 1.5428 - val_acc: 0.5000\n",
      "Epoch 335/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.7535 - acc: 0.7375 - val_loss: 1.5965 - val_acc: 0.5000\n",
      "Epoch 336/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.7371 - acc: 0.7417 - val_loss: 1.5901 - val_acc: 0.5000\n",
      "Epoch 337/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7327 - acc: 0.7417 - val_loss: 1.6101 - val_acc: 0.4909\n",
      "Epoch 338/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7250 - acc: 0.7417 - val_loss: 1.6345 - val_acc: 0.4909\n",
      "Epoch 339/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7207 - acc: 0.7417 - val_loss: 1.6366 - val_acc: 0.4909\n",
      "Epoch 340/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7199 - acc: 0.7417 - val_loss: 1.6516 - val_acc: 0.4909\n",
      "Epoch 341/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.7202 - acc: 0.7417 - val_loss: 1.6640 - val_acc: 0.5000\n",
      "Epoch 342/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.7149 - acc: 0.7417 - val_loss: 1.6689 - val_acc: 0.4909\n",
      "Epoch 343/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.7131 - acc: 0.7417 - val_loss: 1.6696 - val_acc: 0.4909\n",
      "Epoch 344/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7112 - acc: 0.7417 - val_loss: 1.7000 - val_acc: 0.4909\n",
      "Epoch 345/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7086 - acc: 0.7417 - val_loss: 1.7212 - val_acc: 0.4818\n",
      "Epoch 346/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7354 - acc: 0.7250 - val_loss: 1.9716 - val_acc: 0.4091\n",
      "Epoch 347/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0865 - acc: 0.6042 - val_loss: 1.7505 - val_acc: 0.4545\n",
      "Epoch 348/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.0138 - acc: 0.6417 - val_loss: 1.6287 - val_acc: 0.4727\n",
      "Epoch 349/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.1371 - acc: 0.5792 - val_loss: 1.9298 - val_acc: 0.4000\n",
      "Epoch 350/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.0658 - acc: 0.5583 - val_loss: 1.6095 - val_acc: 0.4182\n",
      "Epoch 351/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.9279 - acc: 0.6417 - val_loss: 1.5359 - val_acc: 0.4727\n",
      "Epoch 352/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.8360 - acc: 0.7042 - val_loss: 1.5831 - val_acc: 0.4909\n",
      "Epoch 353/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.8045 - acc: 0.7042 - val_loss: 1.5529 - val_acc: 0.5000\n",
      "Epoch 354/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.8058 - acc: 0.7042 - val_loss: 1.5224 - val_acc: 0.5273\n",
      "Epoch 355/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8039 - acc: 0.6792 - val_loss: 1.6888 - val_acc: 0.4455\n",
      "Epoch 356/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7756 - acc: 0.7250 - val_loss: 1.5442 - val_acc: 0.5091\n",
      "Epoch 357/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7953 - acc: 0.7083 - val_loss: 1.6152 - val_acc: 0.5000\n",
      "Epoch 358/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7806 - acc: 0.7125 - val_loss: 1.6755 - val_acc: 0.5000\n",
      "Epoch 359/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7969 - acc: 0.7167 - val_loss: 1.6290 - val_acc: 0.4727\n",
      "Epoch 360/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7949 - acc: 0.7083 - val_loss: 1.5860 - val_acc: 0.5000\n",
      "Epoch 361/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 6s 23ms/step - loss: 0.7544 - acc: 0.7292 - val_loss: 1.6575 - val_acc: 0.4909\n",
      "Epoch 362/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.7300 - acc: 0.7458 - val_loss: 1.6328 - val_acc: 0.5091\n",
      "Epoch 363/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.7177 - acc: 0.7500 - val_loss: 1.6060 - val_acc: 0.5091\n",
      "Epoch 364/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.7118 - acc: 0.7458 - val_loss: 1.6121 - val_acc: 0.5091\n",
      "Epoch 365/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.7057 - acc: 0.7375 - val_loss: 1.6267 - val_acc: 0.4818\n",
      "Epoch 366/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.7044 - acc: 0.7500 - val_loss: 1.6436 - val_acc: 0.5182\n",
      "Epoch 367/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.7017 - acc: 0.7500 - val_loss: 1.6620 - val_acc: 0.5091\n",
      "Epoch 368/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.6975 - acc: 0.7375 - val_loss: 1.6529 - val_acc: 0.5091\n",
      "Epoch 369/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.6971 - acc: 0.7500 - val_loss: 1.6420 - val_acc: 0.5091\n",
      "Epoch 370/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6949 - acc: 0.7500 - val_loss: 1.6335 - val_acc: 0.5182\n",
      "Epoch 371/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6959 - acc: 0.7500 - val_loss: 1.6673 - val_acc: 0.5091\n",
      "Epoch 372/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.6932 - acc: 0.7500 - val_loss: 1.7047 - val_acc: 0.5182\n",
      "Epoch 373/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.6951 - acc: 0.7500 - val_loss: 1.6776 - val_acc: 0.4909\n",
      "Epoch 374/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.6890 - acc: 0.7500 - val_loss: 1.7157 - val_acc: 0.5091\n",
      "Epoch 375/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.6885 - acc: 0.7375 - val_loss: 1.6932 - val_acc: 0.5182\n",
      "Epoch 376/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.6869 - acc: 0.7500 - val_loss: 1.6584 - val_acc: 0.5000\n",
      "Epoch 377/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6847 - acc: 0.7333 - val_loss: 1.6979 - val_acc: 0.4909\n",
      "Epoch 378/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6798 - acc: 0.7500 - val_loss: 1.6611 - val_acc: 0.5091\n",
      "Epoch 379/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6794 - acc: 0.7500 - val_loss: 1.6505 - val_acc: 0.5000\n",
      "Epoch 380/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6829 - acc: 0.7458 - val_loss: 1.7987 - val_acc: 0.4909\n",
      "Epoch 381/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6854 - acc: 0.7292 - val_loss: 1.6479 - val_acc: 0.5000\n",
      "Epoch 382/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.7277 - acc: 0.7375 - val_loss: 1.7501 - val_acc: 0.4818\n",
      "Epoch 383/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.8836 - acc: 0.6833 - val_loss: 1.8176 - val_acc: 0.4364\n",
      "Epoch 384/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.9197 - acc: 0.6667 - val_loss: 1.9025 - val_acc: 0.4727\n",
      "Epoch 385/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.1737 - acc: 0.6042 - val_loss: 1.7644 - val_acc: 0.4273\n",
      "Epoch 386/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.9105 - acc: 0.6833 - val_loss: 1.5843 - val_acc: 0.4636\n",
      "Epoch 387/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.8515 - acc: 0.6583 - val_loss: 1.5598 - val_acc: 0.4636\n",
      "Epoch 388/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.7947 - acc: 0.6875 - val_loss: 1.7069 - val_acc: 0.4727\n",
      "Epoch 389/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.7320 - acc: 0.7458 - val_loss: 1.5942 - val_acc: 0.5000\n",
      "Epoch 390/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.7185 - acc: 0.7417 - val_loss: 1.6482 - val_acc: 0.5000\n",
      "Epoch 391/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.7149 - acc: 0.7417 - val_loss: 1.5510 - val_acc: 0.5182\n",
      "Epoch 392/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.7119 - acc: 0.7375 - val_loss: 1.5917 - val_acc: 0.5000\n",
      "Epoch 393/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.6861 - acc: 0.7458 - val_loss: 1.6289 - val_acc: 0.5091\n",
      "Epoch 394/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.6761 - acc: 0.7583 - val_loss: 1.6631 - val_acc: 0.5000\n",
      "Epoch 395/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.6764 - acc: 0.7583 - val_loss: 1.6782 - val_acc: 0.4909\n",
      "Epoch 396/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.7162 - acc: 0.7375 - val_loss: 1.7942 - val_acc: 0.4909\n",
      "Epoch 397/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.6846 - acc: 0.7458 - val_loss: 1.8404 - val_acc: 0.4545\n",
      "Epoch 398/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.6777 - acc: 0.7542 - val_loss: 1.8000 - val_acc: 0.4636\n",
      "Epoch 399/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.6735 - acc: 0.7583 - val_loss: 1.8024 - val_acc: 0.4727\n",
      "Epoch 400/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.6623 - acc: 0.7583 - val_loss: 1.7948 - val_acc: 0.4818\n",
      "Epoch 401/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.6605 - acc: 0.7583 - val_loss: 1.8704 - val_acc: 0.4455\n",
      "Epoch 402/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6583 - acc: 0.7417 - val_loss: 1.8626 - val_acc: 0.4545\n",
      "Epoch 403/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6529 - acc: 0.7583 - val_loss: 1.7451 - val_acc: 0.4727\n",
      "Epoch 404/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6728 - acc: 0.7458 - val_loss: 1.7807 - val_acc: 0.4909\n",
      "Epoch 405/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6847 - acc: 0.7583 - val_loss: 1.6645 - val_acc: 0.5091\n",
      "Epoch 406/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.6800 - acc: 0.7583 - val_loss: 1.8327 - val_acc: 0.4636\n",
      "Epoch 407/500\n",
      "240/240 [==============================] - 11s 44ms/step - loss: 0.6745 - acc: 0.7542 - val_loss: 1.7964 - val_acc: 0.5000\n",
      "Epoch 408/500\n",
      "240/240 [==============================] - 11s 44ms/step - loss: 0.6688 - acc: 0.7625 - val_loss: 1.8037 - val_acc: 0.4636\n",
      "Epoch 409/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.6955 - acc: 0.7417 - val_loss: 1.7982 - val_acc: 0.5000\n",
      "Epoch 410/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.7749 - acc: 0.7167 - val_loss: 1.9861 - val_acc: 0.4182\n",
      "Epoch 411/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.8198 - acc: 0.7042 - val_loss: 1.7957 - val_acc: 0.4818\n",
      "Epoch 412/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.7793 - acc: 0.7042 - val_loss: 1.9787 - val_acc: 0.4091\n",
      "Epoch 413/500\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.9208 - acc: 0.6667 - val_loss: 1.8873 - val_acc: 0.4182\n",
      "Epoch 414/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.1270 - acc: 0.5583 - val_loss: 2.3794 - val_acc: 0.2727\n",
      "Epoch 415/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.8844 - acc: 0.3833 - val_loss: 1.9094 - val_acc: 0.4273\n",
      "Epoch 416/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.2855 - acc: 0.5208 - val_loss: 1.6667 - val_acc: 0.4000\n",
      "Epoch 417/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.1232 - acc: 0.5917 - val_loss: 1.6685 - val_acc: 0.4545\n",
      "Epoch 418/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.9716 - acc: 0.6292 - val_loss: 1.7254 - val_acc: 0.4000\n",
      "Epoch 419/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.8992 - acc: 0.6833 - val_loss: 1.6496 - val_acc: 0.4545\n",
      "Epoch 420/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.8726 - acc: 0.6917 - val_loss: 1.7454 - val_acc: 0.4273\n",
      "Epoch 421/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 7s 29ms/step - loss: 0.8566 - acc: 0.6917 - val_loss: 1.6747 - val_acc: 0.4636\n",
      "Epoch 422/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.8007 - acc: 0.7250 - val_loss: 1.7068 - val_acc: 0.4455\n",
      "Epoch 423/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.7990 - acc: 0.7125 - val_loss: 1.6444 - val_acc: 0.4727\n",
      "Epoch 424/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.7943 - acc: 0.7208 - val_loss: 1.5944 - val_acc: 0.4818\n",
      "Epoch 425/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.9125 - acc: 0.6458 - val_loss: 1.6257 - val_acc: 0.4273\n",
      "Epoch 426/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.8830 - acc: 0.6500 - val_loss: 1.5983 - val_acc: 0.4182\n",
      "Epoch 427/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.8381 - acc: 0.6708 - val_loss: 1.6788 - val_acc: 0.4455\n",
      "Epoch 428/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.7958 - acc: 0.7167 - val_loss: 1.6919 - val_acc: 0.4727\n",
      "Epoch 429/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.7626 - acc: 0.7333 - val_loss: 1.7241 - val_acc: 0.4636\n",
      "Epoch 430/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.7417 - acc: 0.7375 - val_loss: 1.7215 - val_acc: 0.4545\n",
      "Epoch 431/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.7420 - acc: 0.7417 - val_loss: 1.6909 - val_acc: 0.4909\n",
      "Epoch 432/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.8868 - acc: 0.6750 - val_loss: 1.6178 - val_acc: 0.5091\n",
      "Epoch 433/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.8568 - acc: 0.6792 - val_loss: 1.6599 - val_acc: 0.4545\n",
      "Epoch 434/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.7550 - acc: 0.7292 - val_loss: 1.6445 - val_acc: 0.4909\n",
      "Epoch 435/500\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.7157 - acc: 0.7458 - val_loss: 1.6229 - val_acc: 0.4909\n",
      "Epoch 436/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.7344 - acc: 0.7417 - val_loss: 1.7185 - val_acc: 0.4909\n",
      "Epoch 437/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.7122 - acc: 0.7458 - val_loss: 1.7396 - val_acc: 0.4727\n",
      "Epoch 438/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.6817 - acc: 0.7583 - val_loss: 1.7752 - val_acc: 0.4818\n",
      "Epoch 439/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.6680 - acc: 0.7625 - val_loss: 1.6573 - val_acc: 0.5000\n",
      "Epoch 440/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.6616 - acc: 0.7667 - val_loss: 1.7470 - val_acc: 0.4818\n",
      "Epoch 441/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.6529 - acc: 0.7667 - val_loss: 1.7361 - val_acc: 0.4909\n",
      "Epoch 442/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.6497 - acc: 0.7708 - val_loss: 1.7547 - val_acc: 0.4818\n",
      "Epoch 443/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.6399 - acc: 0.7708 - val_loss: 1.7690 - val_acc: 0.4818\n",
      "Epoch 444/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.6418 - acc: 0.7708 - val_loss: 1.7760 - val_acc: 0.4727\n",
      "Epoch 445/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.6350 - acc: 0.7708 - val_loss: 1.7893 - val_acc: 0.4727\n",
      "Epoch 446/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.6308 - acc: 0.7708 - val_loss: 1.7777 - val_acc: 0.4727\n",
      "Epoch 447/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.6233 - acc: 0.7708 - val_loss: 1.7841 - val_acc: 0.4818\n",
      "Epoch 448/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.6228 - acc: 0.7708 - val_loss: 1.7954 - val_acc: 0.4727\n",
      "Epoch 449/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.6216 - acc: 0.7708 - val_loss: 1.7998 - val_acc: 0.4909\n",
      "Epoch 450/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.6207 - acc: 0.7750 - val_loss: 1.8079 - val_acc: 0.4818\n",
      "Epoch 451/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.6206 - acc: 0.7750 - val_loss: 1.7901 - val_acc: 0.4909\n",
      "Epoch 452/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.6192 - acc: 0.7750 - val_loss: 1.8280 - val_acc: 0.4818\n",
      "Epoch 453/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.6185 - acc: 0.7792 - val_loss: 1.8153 - val_acc: 0.4727\n",
      "Epoch 454/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.6110 - acc: 0.7750 - val_loss: 1.8325 - val_acc: 0.4727\n",
      "Epoch 455/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.6123 - acc: 0.7750 - val_loss: 1.8172 - val_acc: 0.4727\n",
      "Epoch 456/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.6121 - acc: 0.7792 - val_loss: 1.8430 - val_acc: 0.4727\n",
      "Epoch 457/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.6068 - acc: 0.7792 - val_loss: 1.8525 - val_acc: 0.4818\n",
      "Epoch 458/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.6034 - acc: 0.7833 - val_loss: 1.8933 - val_acc: 0.4909\n",
      "Epoch 459/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.6532 - acc: 0.7667 - val_loss: 1.7129 - val_acc: 0.5182\n",
      "Epoch 460/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.6271 - acc: 0.7708 - val_loss: 1.9209 - val_acc: 0.5000\n",
      "Epoch 461/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.6888 - acc: 0.7500 - val_loss: 1.8226 - val_acc: 0.4909\n",
      "Epoch 462/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.6359 - acc: 0.7667 - val_loss: 1.8368 - val_acc: 0.4909\n",
      "Epoch 463/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.6287 - acc: 0.7667 - val_loss: 1.8015 - val_acc: 0.5182\n",
      "Epoch 464/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.6181 - acc: 0.7667 - val_loss: 1.7972 - val_acc: 0.4818\n",
      "Epoch 465/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.6002 - acc: 0.7833 - val_loss: 1.8617 - val_acc: 0.5000\n",
      "Epoch 466/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.5873 - acc: 0.7917 - val_loss: 1.8249 - val_acc: 0.4727\n",
      "Epoch 467/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.5827 - acc: 0.7917 - val_loss: 1.7725 - val_acc: 0.5091\n",
      "Epoch 468/500\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.5795 - acc: 0.7917 - val_loss: 1.7913 - val_acc: 0.5091\n",
      "Epoch 469/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.5795 - acc: 0.7917 - val_loss: 1.7917 - val_acc: 0.5091\n",
      "Epoch 470/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.5763 - acc: 0.7917 - val_loss: 1.7896 - val_acc: 0.5182\n",
      "Epoch 471/500\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.5764 - acc: 0.7917 - val_loss: 1.8170 - val_acc: 0.5182\n",
      "Epoch 472/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.5731 - acc: 0.7917 - val_loss: 1.8198 - val_acc: 0.5000\n",
      "Epoch 473/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.5714 - acc: 0.7917 - val_loss: 1.8319 - val_acc: 0.5091\n",
      "Epoch 474/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.5708 - acc: 0.7917 - val_loss: 1.8256 - val_acc: 0.5000\n",
      "Epoch 475/500\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.5717 - acc: 0.7917 - val_loss: 1.8289 - val_acc: 0.4909\n",
      "Epoch 476/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.5695 - acc: 0.7917 - val_loss: 1.8331 - val_acc: 0.5000\n",
      "Epoch 477/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.5696 - acc: 0.7917 - val_loss: 1.8124 - val_acc: 0.5000\n",
      "Epoch 478/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.5687 - acc: 0.7917 - val_loss: 1.8156 - val_acc: 0.5000\n",
      "Epoch 479/500\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.5706 - acc: 0.7917 - val_loss: 1.8097 - val_acc: 0.5000\n",
      "Epoch 480/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.5670 - acc: 0.7917 - val_loss: 1.8056 - val_acc: 0.5000\n",
      "Epoch 481/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 6s 24ms/step - loss: 0.5717 - acc: 0.7917 - val_loss: 1.8170 - val_acc: 0.4909\n",
      "Epoch 482/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.5672 - acc: 0.7958 - val_loss: 1.7963 - val_acc: 0.4909\n",
      "Epoch 483/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.5660 - acc: 0.7958 - val_loss: 1.8159 - val_acc: 0.4909\n",
      "Epoch 484/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.5631 - acc: 0.7958 - val_loss: 1.8305 - val_acc: 0.4909\n",
      "Epoch 485/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.5635 - acc: 0.7958 - val_loss: 1.8352 - val_acc: 0.4909\n",
      "Epoch 486/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.5639 - acc: 0.7958 - val_loss: 1.8288 - val_acc: 0.4909\n",
      "Epoch 487/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.5637 - acc: 0.7958 - val_loss: 1.8395 - val_acc: 0.4909\n",
      "Epoch 488/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.5608 - acc: 0.7958 - val_loss: 1.8460 - val_acc: 0.4909\n",
      "Epoch 489/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.5639 - acc: 0.7958 - val_loss: 1.8626 - val_acc: 0.5000\n",
      "Epoch 490/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5647 - acc: 0.7917 - val_loss: 1.7998 - val_acc: 0.5091\n",
      "Epoch 491/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.5813 - acc: 0.7833 - val_loss: 1.8991 - val_acc: 0.4818\n",
      "Epoch 492/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6023 - acc: 0.7708 - val_loss: 1.8738 - val_acc: 0.5000\n",
      "Epoch 493/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6961 - acc: 0.7250 - val_loss: 1.9851 - val_acc: 0.5000\n",
      "Epoch 494/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8954 - acc: 0.7083 - val_loss: 2.3065 - val_acc: 0.4455\n",
      "Epoch 495/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.1333 - acc: 0.6500 - val_loss: 1.8352 - val_acc: 0.4364\n",
      "Epoch 496/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.8620 - acc: 0.6667 - val_loss: 1.7007 - val_acc: 0.4636\n",
      "Epoch 497/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.8195 - acc: 0.6875 - val_loss: 1.7994 - val_acc: 0.4455\n",
      "Epoch 498/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.8600 - acc: 0.6958 - val_loss: 1.6649 - val_acc: 0.4909\n",
      "Epoch 499/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.8800 - acc: 0.6833 - val_loss: 1.5235 - val_acc: 0.5000\n",
      "Epoch 500/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.7612 - acc: 0.7333 - val_loss: 1.6861 - val_acc: 0.4818\n"
     ]
    }
   ],
   "source": [
    "LSTM_SIMPLE=LSTM_simple(name='LSTM_simpledelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_and_saving(LSTM_SIMPLE,name='LSTM_simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/500\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 2.3052 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 2/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 2.2981 - acc: 0.0875 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 3/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 2.2939 - acc: 0.0875 - val_loss: 2.3018 - val_acc: 0.1182\n",
      "Epoch 4/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 2.2910 - acc: 0.0833 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 5/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.2942 - acc: 0.0792 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 6/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.2911 - acc: 0.0542 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 7/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.2966 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 8/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.2932 - acc: 0.0542 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 9/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.2877 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1091\n",
      "Epoch 10/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 2.2829 - acc: 0.1125 - val_loss: 2.3038 - val_acc: 0.1000\n",
      "Epoch 11/500\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 2.2897 - acc: 0.1292 - val_loss: 2.3031 - val_acc: 0.0909\n",
      "Epoch 12/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 2.2867 - acc: 0.0875 - val_loss: 2.3036 - val_acc: 0.1091\n",
      "Epoch 13/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.2746 - acc: 0.0792 - val_loss: 2.3037 - val_acc: 0.1000\n",
      "Epoch 14/500\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 2.2911 - acc: 0.0583 - val_loss: 2.3029 - val_acc: 0.0909\n",
      "Epoch 15/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 2.2860 - acc: 0.1083 - val_loss: 2.3033 - val_acc: 0.1000\n",
      "Epoch 16/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.2745 - acc: 0.1167 - val_loss: 2.3032 - val_acc: 0.1000\n",
      "Epoch 17/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.2762 - acc: 0.1250 - val_loss: 2.3006 - val_acc: 0.1182\n",
      "Epoch 18/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.2743 - acc: 0.1208 - val_loss: 2.3039 - val_acc: 0.1000\n",
      "Epoch 19/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.2838 - acc: 0.1208 - val_loss: 2.2967 - val_acc: 0.1000\n",
      "Epoch 20/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.2734 - acc: 0.1292 - val_loss: 2.2973 - val_acc: 0.1000\n",
      "Epoch 21/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2594 - acc: 0.1333 - val_loss: 2.2916 - val_acc: 0.1091\n",
      "Epoch 22/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.2754 - acc: 0.1125 - val_loss: 2.3040 - val_acc: 0.1000\n",
      "Epoch 23/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.2975 - acc: 0.1042 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 24/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.2924 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 25/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.2898 - acc: 0.0750 - val_loss: 2.3038 - val_acc: 0.1000\n",
      "Epoch 26/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.2762 - acc: 0.0875 - val_loss: 2.3144 - val_acc: 0.1091\n",
      "Epoch 27/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.3341 - acc: 0.0958 - val_loss: 2.3028 - val_acc: 0.1091\n",
      "Epoch 28/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.2975 - acc: 0.0625 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 29/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.2923 - acc: 0.1000 - val_loss: 2.3010 - val_acc: 0.0818\n",
      "Epoch 30/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.2861 - acc: 0.1083 - val_loss: 2.2976 - val_acc: 0.1091\n",
      "Epoch 31/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.2802 - acc: 0.1167 - val_loss: 2.3046 - val_acc: 0.1000\n",
      "Epoch 32/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 2.2706 - acc: 0.1292 - val_loss: 2.3328 - val_acc: 0.1364\n",
      "Epoch 33/500\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 2.2780 - acc: 0.1333 - val_loss: 2.3022 - val_acc: 0.1091\n",
      "Epoch 34/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.2719 - acc: 0.1292 - val_loss: 2.3033 - val_acc: 0.1000\n",
      "Epoch 35/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.2903 - acc: 0.1083 - val_loss: 2.3034 - val_acc: 0.1000\n",
      "Epoch 36/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 2.2862 - acc: 0.1083 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 37/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.2788 - acc: 0.1125 - val_loss: 2.3042 - val_acc: 0.1000\n",
      "Epoch 38/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2686 - acc: 0.1125 - val_loss: 2.3060 - val_acc: 0.1091\n",
      "Epoch 39/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.2626 - acc: 0.1250 - val_loss: 2.2962 - val_acc: 0.1182\n",
      "Epoch 40/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2580 - acc: 0.1333 - val_loss: 2.3060 - val_acc: 0.1000\n",
      "Epoch 41/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 2.2683 - acc: 0.1250 - val_loss: 2.3049 - val_acc: 0.1000\n",
      "Epoch 42/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.2630 - acc: 0.1250 - val_loss: 2.3051 - val_acc: 0.0909\n",
      "Epoch 43/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.2525 - acc: 0.1292 - val_loss: 2.3014 - val_acc: 0.1000\n",
      "Epoch 44/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.2670 - acc: 0.1208 - val_loss: 2.3096 - val_acc: 0.1000\n",
      "Epoch 45/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.2603 - acc: 0.1333 - val_loss: 2.3065 - val_acc: 0.1091\n",
      "Epoch 46/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 2.2504 - acc: 0.1417 - val_loss: 2.3057 - val_acc: 0.1000\n",
      "Epoch 47/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 2.2552 - acc: 0.1250 - val_loss: 2.2918 - val_acc: 0.1000\n",
      "Epoch 48/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.2509 - acc: 0.1333 - val_loss: 2.3021 - val_acc: 0.1000\n",
      "Epoch 49/500\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2625 - acc: 0.1167 - val_loss: 2.3040 - val_acc: 0.1000\n",
      "Epoch 50/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 2.2745 - acc: 0.0792 - val_loss: 2.2956 - val_acc: 0.0909\n",
      "Epoch 51/500\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2522 - acc: 0.1250 - val_loss: 2.2935 - val_acc: 0.1091\n",
      "Epoch 52/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 2.2352 - acc: 0.1208 - val_loss: 2.2896 - val_acc: 0.1091\n",
      "Epoch 53/500\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 2.2486 - acc: 0.1208 - val_loss: 2.3010 - val_acc: 0.1000\n",
      "Epoch 54/500\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2411 - acc: 0.1417 - val_loss: 2.3361 - val_acc: 0.1091\n",
      "Epoch 55/500\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 2.2386 - acc: 0.1458 - val_loss: 2.3296 - val_acc: 0.1091\n",
      "Epoch 56/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.2519 - acc: 0.1250 - val_loss: 2.3094 - val_acc: 0.1091\n",
      "Epoch 57/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.2271 - acc: 0.1542 - val_loss: 2.2802 - val_acc: 0.1091\n",
      "Epoch 58/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.2208 - acc: 0.1500 - val_loss: 2.3000 - val_acc: 0.1182\n",
      "Epoch 59/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.2253 - acc: 0.1375 - val_loss: 2.2927 - val_acc: 0.1091\n",
      "Epoch 60/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.2560 - acc: 0.1250 - val_loss: 2.3071 - val_acc: 0.1000\n",
      "Epoch 61/500\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 2.2540 - acc: 0.1208 - val_loss: 2.2756 - val_acc: 0.1000\n",
      "Epoch 62/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.2268 - acc: 0.1333 - val_loss: 2.2653 - val_acc: 0.1182\n",
      "Epoch 63/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.2248 - acc: 0.1375 - val_loss: 2.2777 - val_acc: 0.1273\n",
      "Epoch 64/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.2038 - acc: 0.1417 - val_loss: 2.2667 - val_acc: 0.1182\n",
      "Epoch 65/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.2341 - acc: 0.1375 - val_loss: 2.3127 - val_acc: 0.1000\n",
      "Epoch 66/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.2707 - acc: 0.1292 - val_loss: 2.2639 - val_acc: 0.1182\n",
      "Epoch 67/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 2.2317 - acc: 0.1417 - val_loss: 2.2761 - val_acc: 0.1273\n",
      "Epoch 68/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 2.2007 - acc: 0.1458 - val_loss: 2.2852 - val_acc: 0.1091\n",
      "Epoch 69/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 2.2163 - acc: 0.1583 - val_loss: 2.2941 - val_acc: 0.1364\n",
      "Epoch 70/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 2.1870 - acc: 0.1667 - val_loss: 2.2266 - val_acc: 0.1545\n",
      "Epoch 71/500\n",
      "240/240 [==============================] - 10s 42ms/step - loss: 2.2156 - acc: 0.1500 - val_loss: 2.2239 - val_acc: 0.1364\n",
      "Epoch 72/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 2.1102 - acc: 0.1750 - val_loss: 2.1618 - val_acc: 0.1636\n",
      "Epoch 73/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.0883 - acc: 0.1917 - val_loss: 2.0941 - val_acc: 0.2091\n",
      "Epoch 74/500\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 1.9424 - acc: 0.2417 - val_loss: 2.0472 - val_acc: 0.1818\n",
      "Epoch 75/500\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 1.9586 - acc: 0.2250 - val_loss: 2.2881 - val_acc: 0.1455\n",
      "Epoch 76/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 2.1874 - acc: 0.1333 - val_loss: 2.2609 - val_acc: 0.1364\n",
      "Epoch 77/500\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 2.1425 - acc: 0.1875 - val_loss: 2.2123 - val_acc: 0.1545\n",
      "Epoch 78/500\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.0637 - acc: 0.2083 - val_loss: 2.0674 - val_acc: 0.1727\n",
      "Epoch 79/500\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 2.1000 - acc: 0.1833 - val_loss: 2.0245 - val_acc: 0.1818\n",
      "Epoch 80/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.9889 - acc: 0.1875 - val_loss: 1.9447 - val_acc: 0.2091\n",
      "Epoch 81/500\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 1.8411 - acc: 0.2125 - val_loss: 1.8610 - val_acc: 0.1909\n",
      "Epoch 82/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 1.7837 - acc: 0.2292 - val_loss: 1.8874 - val_acc: 0.2636\n",
      "Epoch 83/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.7883 - acc: 0.2500 - val_loss: 1.8635 - val_acc: 0.2455\n",
      "Epoch 84/500\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 1.7074 - acc: 0.2750 - val_loss: 1.9221 - val_acc: 0.2091\n",
      "Epoch 85/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 1.8741 - acc: 0.1667 - val_loss: 2.0186 - val_acc: 0.2182\n",
      "Epoch 86/500\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 2.0508 - acc: 0.2000 - val_loss: 1.9945 - val_acc: 0.1909\n",
      "Epoch 87/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 1.8002 - acc: 0.2375 - val_loss: 1.8282 - val_acc: 0.2545\n",
      "Epoch 88/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.7528 - acc: 0.2750 - val_loss: 1.8230 - val_acc: 0.2545\n",
      "Epoch 89/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 1.7248 - acc: 0.2708 - val_loss: 1.7528 - val_acc: 0.2455\n",
      "Epoch 90/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.7429 - acc: 0.2333 - val_loss: 1.8850 - val_acc: 0.2364\n",
      "Epoch 91/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.8194 - acc: 0.2208 - val_loss: 2.0309 - val_acc: 0.2455\n",
      "Epoch 92/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 1.7592 - acc: 0.2375 - val_loss: 2.0578 - val_acc: 0.2273\n",
      "Epoch 93/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.8227 - acc: 0.2333 - val_loss: 1.9359 - val_acc: 0.2364\n",
      "Epoch 94/500\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 1.8695 - acc: 0.2500 - val_loss: 1.9285 - val_acc: 0.2091\n",
      "Epoch 95/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 2.0015 - acc: 0.1542 - val_loss: 2.5369 - val_acc: 0.1000\n",
      "Epoch 96/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 2.4511 - acc: 0.1083 - val_loss: 2.5780 - val_acc: 0.1091\n",
      "Epoch 97/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 2.3478 - acc: 0.1167 - val_loss: 2.3222 - val_acc: 0.1273\n",
      "Epoch 98/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 2.2639 - acc: 0.1083 - val_loss: 2.3002 - val_acc: 0.1000\n",
      "Epoch 99/500\n",
      "240/240 [==============================] - 10s 43ms/step - loss: 2.2364 - acc: 0.1167 - val_loss: 2.2996 - val_acc: 0.1091\n",
      "Epoch 100/500\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2357 - acc: 0.1792 - val_loss: 2.2204 - val_acc: 0.1545\n",
      "Epoch 101/500\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 2.1672 - acc: 0.1708 - val_loss: 2.1268 - val_acc: 0.1545\n",
      "Epoch 102/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 2.0385 - acc: 0.1583 - val_loss: 2.0498 - val_acc: 0.1909\n",
      "Epoch 103/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.9963 - acc: 0.1875 - val_loss: 2.0182 - val_acc: 0.1818\n",
      "Epoch 104/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.9678 - acc: 0.1583 - val_loss: 2.0683 - val_acc: 0.1818\n",
      "Epoch 105/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 1.9236 - acc: 0.1667 - val_loss: 1.9708 - val_acc: 0.1909\n",
      "Epoch 106/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 1.8917 - acc: 0.1917 - val_loss: 1.9331 - val_acc: 0.2455\n",
      "Epoch 107/500\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 1.7939 - acc: 0.2583 - val_loss: 1.9260 - val_acc: 0.2182\n",
      "Epoch 108/500\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 1.7508 - acc: 0.2458 - val_loss: 1.9381 - val_acc: 0.2545\n",
      "Epoch 109/500\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 1.7288 - acc: 0.2542 - val_loss: 2.0121 - val_acc: 0.1727\n",
      "Epoch 110/500\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 1.8006 - acc: 0.2208 - val_loss: 1.9958 - val_acc: 0.2000\n",
      "Epoch 111/500\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.8015 - acc: 0.2000 - val_loss: 2.5950 - val_acc: 0.1364\n",
      "Epoch 112/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.3553 - acc: 0.1250 - val_loss: 2.2717 - val_acc: 0.1364\n",
      "Epoch 113/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.1646 - acc: 0.1458 - val_loss: 2.1552 - val_acc: 0.1909\n",
      "Epoch 114/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 2.0374 - acc: 0.2000 - val_loss: 2.1356 - val_acc: 0.1909\n",
      "Epoch 115/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 2.1387 - acc: 0.1833 - val_loss: 2.9551 - val_acc: 0.1545\n",
      "Epoch 116/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 2.4835 - acc: 0.1708 - val_loss: 2.3834 - val_acc: 0.1182\n",
      "Epoch 117/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.2712 - acc: 0.1417 - val_loss: 2.2960 - val_acc: 0.1000\n",
      "Epoch 118/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.2443 - acc: 0.1500 - val_loss: 2.2822 - val_acc: 0.1091\n",
      "Epoch 119/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 2.2296 - acc: 0.1458 - val_loss: 2.2934 - val_acc: 0.1091\n",
      "Epoch 120/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.2159 - acc: 0.1250 - val_loss: 2.2907 - val_acc: 0.1000\n",
      "Epoch 121/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 8s 35ms/step - loss: 2.2222 - acc: 0.0958 - val_loss: 2.2874 - val_acc: 0.1091\n",
      "Epoch 122/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 2.2091 - acc: 0.1542 - val_loss: 2.2832 - val_acc: 0.1273\n",
      "Epoch 123/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 2.2153 - acc: 0.1250 - val_loss: 2.2981 - val_acc: 0.1273\n",
      "Epoch 124/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 2.2093 - acc: 0.1250 - val_loss: 2.2708 - val_acc: 0.1455\n",
      "Epoch 125/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.1859 - acc: 0.1750 - val_loss: 2.2831 - val_acc: 0.1182\n",
      "Epoch 126/500\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 2.1556 - acc: 0.1500 - val_loss: 2.2090 - val_acc: 0.1273\n",
      "Epoch 127/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 2.0757 - acc: 0.1875 - val_loss: 2.1290 - val_acc: 0.2273\n",
      "Epoch 128/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 1.9893 - acc: 0.2333 - val_loss: 1.9894 - val_acc: 0.2364\n",
      "Epoch 129/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.8347 - acc: 0.2208 - val_loss: 2.1980 - val_acc: 0.1727\n",
      "Epoch 130/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.8660 - acc: 0.2250 - val_loss: 2.0173 - val_acc: 0.2364\n",
      "Epoch 131/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.8492 - acc: 0.2042 - val_loss: 1.9079 - val_acc: 0.2182\n",
      "Epoch 132/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.9045 - acc: 0.2083 - val_loss: 1.8952 - val_acc: 0.2455\n",
      "Epoch 133/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 2.1099 - acc: 0.1708 - val_loss: 2.4191 - val_acc: 0.1000\n",
      "Epoch 134/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.3237 - acc: 0.1125 - val_loss: 2.3175 - val_acc: 0.0818\n",
      "Epoch 135/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.3124 - acc: 0.1083 - val_loss: 2.3087 - val_acc: 0.1091\n",
      "Epoch 136/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 2.3027 - acc: 0.0917 - val_loss: 2.3076 - val_acc: 0.1000\n",
      "Epoch 137/500\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.3011 - acc: 0.1083 - val_loss: 2.3063 - val_acc: 0.0909\n",
      "Epoch 138/500\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 2.2996 - acc: 0.1125 - val_loss: 2.3050 - val_acc: 0.1091\n",
      "Epoch 139/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 2.2985 - acc: 0.0875 - val_loss: 2.3065 - val_acc: 0.1091\n",
      "Epoch 140/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 2.2864 - acc: 0.1000 - val_loss: 2.3069 - val_acc: 0.0909\n",
      "Epoch 141/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 2.2960 - acc: 0.0875 - val_loss: 2.3039 - val_acc: 0.0909\n",
      "Epoch 142/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 2.2893 - acc: 0.1167 - val_loss: 2.3121 - val_acc: 0.0909\n",
      "Epoch 143/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.2846 - acc: 0.1208 - val_loss: 2.3113 - val_acc: 0.0909\n",
      "Epoch 144/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 2.2965 - acc: 0.0792 - val_loss: 2.3057 - val_acc: 0.0909\n",
      "Epoch 145/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 2.2767 - acc: 0.0792 - val_loss: 2.3048 - val_acc: 0.1000\n",
      "Epoch 146/500\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 2.2741 - acc: 0.0958 - val_loss: 2.3021 - val_acc: 0.1000\n",
      "Epoch 147/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.2669 - acc: 0.1083 - val_loss: 2.3006 - val_acc: 0.1000\n",
      "Epoch 148/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 2.2635 - acc: 0.1250 - val_loss: 2.2985 - val_acc: 0.1000\n",
      "Epoch 149/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.2554 - acc: 0.1250 - val_loss: 2.3079 - val_acc: 0.1000\n",
      "Epoch 150/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.2565 - acc: 0.1167 - val_loss: 2.2949 - val_acc: 0.1091\n",
      "Epoch 151/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 2.2458 - acc: 0.1000 - val_loss: 2.2163 - val_acc: 0.1091\n",
      "Epoch 152/500\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 2.1307 - acc: 0.1917 - val_loss: 2.1187 - val_acc: 0.1909\n",
      "Epoch 153/500\n",
      "240/240 [==============================] - 15s 61ms/step - loss: 2.1014 - acc: 0.2542 - val_loss: 1.9744 - val_acc: 0.2182\n",
      "Epoch 154/500\n",
      "240/240 [==============================] - 12s 52ms/step - loss: 1.9055 - acc: 0.2458 - val_loss: 1.9431 - val_acc: 0.2364\n",
      "Epoch 155/500\n",
      "240/240 [==============================] - 12s 52ms/step - loss: 1.8241 - acc: 0.2292 - val_loss: 1.8873 - val_acc: 0.2091\n",
      "Epoch 156/500\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 1.7643 - acc: 0.1958 - val_loss: 1.9735 - val_acc: 0.1818\n",
      "Epoch 157/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.7558 - acc: 0.2583 - val_loss: 1.8955 - val_acc: 0.2273\n",
      "Epoch 158/500\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 1.8002 - acc: 0.1667 - val_loss: 1.9073 - val_acc: 0.1727\n",
      "Epoch 159/500\n",
      "240/240 [==============================] - 11s 45ms/step - loss: 1.7420 - acc: 0.2375 - val_loss: 1.8432 - val_acc: 0.2636\n",
      "Epoch 160/500\n",
      "240/240 [==============================] - 11s 45ms/step - loss: 1.6644 - acc: 0.2583 - val_loss: 1.8870 - val_acc: 0.2273\n",
      "Epoch 161/500\n",
      "240/240 [==============================] - 11s 44ms/step - loss: 1.7088 - acc: 0.2375 - val_loss: 1.8727 - val_acc: 0.2727\n",
      "Epoch 162/500\n",
      "240/240 [==============================] - 10s 42ms/step - loss: 1.6880 - acc: 0.2292 - val_loss: 1.9021 - val_acc: 0.1909\n",
      "Epoch 163/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 1.8372 - acc: 0.2583 - val_loss: 2.0552 - val_acc: 0.1727\n",
      "Epoch 164/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.8507 - acc: 0.2250 - val_loss: 1.9121 - val_acc: 0.2000\n",
      "Epoch 165/500\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.7815 - acc: 0.2417 - val_loss: 1.8655 - val_acc: 0.2636\n",
      "Epoch 166/500\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 1.6969 - acc: 0.2083 - val_loss: 1.8050 - val_acc: 0.2455\n",
      "Epoch 167/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.6454 - acc: 0.3083 - val_loss: 1.7760 - val_acc: 0.2455\n",
      "Epoch 168/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 1.6216 - acc: 0.2750 - val_loss: 1.8148 - val_acc: 0.2000\n",
      "Epoch 169/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 1.6242 - acc: 0.2958 - val_loss: 1.8701 - val_acc: 0.2273\n",
      "Epoch 170/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.5879 - acc: 0.2875 - val_loss: 1.8297 - val_acc: 0.2545\n",
      "Epoch 171/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.5626 - acc: 0.3333 - val_loss: 1.7982 - val_acc: 0.3000\n",
      "Epoch 172/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.5435 - acc: 0.3208 - val_loss: 1.8209 - val_acc: 0.2727\n",
      "Epoch 173/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.5121 - acc: 0.3000 - val_loss: 1.8037 - val_acc: 0.3364\n",
      "Epoch 174/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.5527 - acc: 0.2833 - val_loss: 1.8396 - val_acc: 0.2273\n",
      "Epoch 175/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.5131 - acc: 0.2958 - val_loss: 1.7848 - val_acc: 0.3000\n",
      "Epoch 176/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.4938 - acc: 0.3208 - val_loss: 1.8345 - val_acc: 0.3182\n",
      "Epoch 177/500\n",
      "240/240 [==============================] - 9s 35ms/step - loss: 1.4784 - acc: 0.3292 - val_loss: 1.8486 - val_acc: 0.2818\n",
      "Epoch 178/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 1.4537 - acc: 0.3292 - val_loss: 1.8550 - val_acc: 0.2818\n",
      "Epoch 179/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.4557 - acc: 0.3292 - val_loss: 1.8197 - val_acc: 0.2545\n",
      "Epoch 180/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 1.5472 - acc: 0.3083 - val_loss: 1.8361 - val_acc: 0.2545\n",
      "Epoch 181/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 1.5640 - acc: 0.3208 - val_loss: 1.8554 - val_acc: 0.2818\n",
      "Epoch 182/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 1.5992 - acc: 0.2708 - val_loss: 1.8023 - val_acc: 0.2727\n",
      "Epoch 183/500\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.5177 - acc: 0.2958 - val_loss: 1.9012 - val_acc: 0.1909\n",
      "Epoch 184/500\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.4754 - acc: 0.3167 - val_loss: 1.8224 - val_acc: 0.2727\n",
      "Epoch 185/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.4883 - acc: 0.3500 - val_loss: 1.7476 - val_acc: 0.2727\n",
      "Epoch 186/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 1.5019 - acc: 0.2917 - val_loss: 1.8712 - val_acc: 0.3000\n",
      "Epoch 187/500\n",
      "240/240 [==============================] - 11s 46ms/step - loss: 1.4974 - acc: 0.3458 - val_loss: 1.8578 - val_acc: 0.2364\n",
      "Epoch 188/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 1.4664 - acc: 0.3375 - val_loss: 1.8337 - val_acc: 0.2818\n",
      "Epoch 189/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 1.3987 - acc: 0.3750 - val_loss: 1.9005 - val_acc: 0.2182\n",
      "Epoch 190/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.4088 - acc: 0.3833 - val_loss: 1.8603 - val_acc: 0.2455\n",
      "Epoch 191/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 1.3937 - acc: 0.3875 - val_loss: 1.9367 - val_acc: 0.2818\n",
      "Epoch 192/500\n",
      "240/240 [==============================] - 10s 42ms/step - loss: 1.5055 - acc: 0.3250 - val_loss: 1.8889 - val_acc: 0.2727\n",
      "Epoch 193/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.4976 - acc: 0.3333 - val_loss: 2.0854 - val_acc: 0.2545\n",
      "Epoch 194/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.4923 - acc: 0.3500 - val_loss: 1.7828 - val_acc: 0.2909\n",
      "Epoch 195/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.4912 - acc: 0.3125 - val_loss: 1.8103 - val_acc: 0.2727\n",
      "Epoch 196/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.4113 - acc: 0.3625 - val_loss: 1.7693 - val_acc: 0.3091\n",
      "Epoch 197/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.4320 - acc: 0.3042 - val_loss: 1.8347 - val_acc: 0.2909\n",
      "Epoch 198/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.4942 - acc: 0.3458 - val_loss: 1.9249 - val_acc: 0.2455\n",
      "Epoch 199/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.3935 - acc: 0.3583 - val_loss: 1.7691 - val_acc: 0.3091\n",
      "Epoch 200/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.3793 - acc: 0.3625 - val_loss: 1.7903 - val_acc: 0.2909\n",
      "Epoch 201/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.3587 - acc: 0.3458 - val_loss: 1.8003 - val_acc: 0.3000\n",
      "Epoch 202/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.3424 - acc: 0.3542 - val_loss: 1.8147 - val_acc: 0.3273\n",
      "Epoch 203/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.3837 - acc: 0.3208 - val_loss: 1.7941 - val_acc: 0.2545\n",
      "Epoch 204/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.4058 - acc: 0.3417 - val_loss: 1.8011 - val_acc: 0.3182\n",
      "Epoch 205/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.3499 - acc: 0.3500 - val_loss: 1.7963 - val_acc: 0.3182\n",
      "Epoch 206/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.3649 - acc: 0.3417 - val_loss: 1.8463 - val_acc: 0.2545\n",
      "Epoch 207/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 1.3540 - acc: 0.3542 - val_loss: 1.8892 - val_acc: 0.2727\n",
      "Epoch 208/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.3248 - acc: 0.3208 - val_loss: 1.8772 - val_acc: 0.2909\n",
      "Epoch 209/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 1.3012 - acc: 0.3625 - val_loss: 1.8840 - val_acc: 0.3000\n",
      "Epoch 210/500\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.3374 - acc: 0.3875 - val_loss: 1.8862 - val_acc: 0.3091\n",
      "Epoch 211/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.3269 - acc: 0.3750 - val_loss: 1.9052 - val_acc: 0.2727\n",
      "Epoch 212/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 1.2757 - acc: 0.4167 - val_loss: 1.8879 - val_acc: 0.2909\n",
      "Epoch 213/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.2786 - acc: 0.3917 - val_loss: 1.9573 - val_acc: 0.3000\n",
      "Epoch 214/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.2806 - acc: 0.3583 - val_loss: 1.9515 - val_acc: 0.2818\n",
      "Epoch 215/500\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 1.2844 - acc: 0.4083 - val_loss: 1.8962 - val_acc: 0.2727\n",
      "Epoch 216/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.2936 - acc: 0.4083 - val_loss: 1.8682 - val_acc: 0.3182\n",
      "Epoch 217/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 1.2652 - acc: 0.4417 - val_loss: 1.8935 - val_acc: 0.2909\n",
      "Epoch 218/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.2531 - acc: 0.4542 - val_loss: 1.9361 - val_acc: 0.3000\n",
      "Epoch 219/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.2307 - acc: 0.4292 - val_loss: 1.8908 - val_acc: 0.3273\n",
      "Epoch 220/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.2324 - acc: 0.4708 - val_loss: 2.0032 - val_acc: 0.2818\n",
      "Epoch 221/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.1965 - acc: 0.4667 - val_loss: 2.0684 - val_acc: 0.2727\n",
      "Epoch 222/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 1.3032 - acc: 0.4375 - val_loss: 1.9079 - val_acc: 0.3091\n",
      "Epoch 223/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.2636 - acc: 0.4042 - val_loss: 1.9262 - val_acc: 0.2818\n",
      "Epoch 224/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 1.2305 - acc: 0.4792 - val_loss: 1.8771 - val_acc: 0.2545\n",
      "Epoch 225/500\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 1.4105 - acc: 0.4000 - val_loss: 2.1383 - val_acc: 0.2818\n",
      "Epoch 226/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 1.4436 - acc: 0.3583 - val_loss: 1.7815 - val_acc: 0.3273\n",
      "Epoch 227/500\n",
      "240/240 [==============================] - 11s 44ms/step - loss: 1.4521 - acc: 0.3792 - val_loss: 1.6673 - val_acc: 0.3273\n",
      "Epoch 228/500\n",
      "240/240 [==============================] - 11s 45ms/step - loss: 1.3420 - acc: 0.4292 - val_loss: 1.7011 - val_acc: 0.3091\n",
      "Epoch 229/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.2216 - acc: 0.4542 - val_loss: 1.7991 - val_acc: 0.3364\n",
      "Epoch 230/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.2490 - acc: 0.4083 - val_loss: 1.8234 - val_acc: 0.3273\n",
      "Epoch 231/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.2111 - acc: 0.4500 - val_loss: 1.7816 - val_acc: 0.3182\n",
      "Epoch 232/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.2283 - acc: 0.4458 - val_loss: 1.6930 - val_acc: 0.3455\n",
      "Epoch 233/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.1148 - acc: 0.4667 - val_loss: 1.7932 - val_acc: 0.3364\n",
      "Epoch 234/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.0857 - acc: 0.4917 - val_loss: 1.7412 - val_acc: 0.3727\n",
      "Epoch 235/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.0502 - acc: 0.5083 - val_loss: 1.7014 - val_acc: 0.3909\n",
      "Epoch 236/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 1.0056 - acc: 0.5542 - val_loss: 1.7443 - val_acc: 0.3545\n",
      "Epoch 237/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.0373 - acc: 0.5000 - val_loss: 1.6719 - val_acc: 0.3455\n",
      "Epoch 238/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.9969 - acc: 0.5292 - val_loss: 1.8044 - val_acc: 0.3909\n",
      "Epoch 239/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.1525 - acc: 0.4958 - val_loss: 1.8024 - val_acc: 0.3909\n",
      "Epoch 240/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.1206 - acc: 0.4625 - val_loss: 1.6932 - val_acc: 0.3545\n",
      "Epoch 241/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 7s 28ms/step - loss: 1.1517 - acc: 0.4583 - val_loss: 1.6872 - val_acc: 0.3727\n",
      "Epoch 242/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 1.0868 - acc: 0.5125 - val_loss: 1.6366 - val_acc: 0.3818\n",
      "Epoch 243/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.0302 - acc: 0.5250 - val_loss: 1.7573 - val_acc: 0.3455\n",
      "Epoch 244/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.9944 - acc: 0.5500 - val_loss: 1.6710 - val_acc: 0.3818\n",
      "Epoch 245/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.0281 - acc: 0.5417 - val_loss: 1.7191 - val_acc: 0.4091\n",
      "Epoch 246/500\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 1.0131 - acc: 0.5292 - val_loss: 1.8062 - val_acc: 0.3364\n",
      "Epoch 247/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.9744 - acc: 0.5583 - val_loss: 1.7000 - val_acc: 0.4364\n",
      "Epoch 248/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.8789 - acc: 0.6208 - val_loss: 1.6007 - val_acc: 0.4455\n",
      "Epoch 249/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.9983 - acc: 0.5792 - val_loss: 1.7219 - val_acc: 0.4273\n",
      "Epoch 250/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.1117 - acc: 0.5083 - val_loss: 1.5566 - val_acc: 0.4182\n",
      "Epoch 251/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.0910 - acc: 0.5250 - val_loss: 1.6681 - val_acc: 0.4273\n",
      "Epoch 252/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 1.0332 - acc: 0.5125 - val_loss: 1.6654 - val_acc: 0.3818\n",
      "Epoch 253/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.1606 - acc: 0.4792 - val_loss: 1.7814 - val_acc: 0.3545\n",
      "Epoch 254/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.2614 - acc: 0.4292 - val_loss: 1.6311 - val_acc: 0.3545\n",
      "Epoch 255/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.1314 - acc: 0.4292 - val_loss: 1.5016 - val_acc: 0.3727\n",
      "Epoch 256/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.1056 - acc: 0.4875 - val_loss: 1.4866 - val_acc: 0.4091\n",
      "Epoch 257/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.9630 - acc: 0.5417 - val_loss: 1.4058 - val_acc: 0.4545\n",
      "Epoch 258/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.8773 - acc: 0.5708 - val_loss: 1.5027 - val_acc: 0.4273\n",
      "Epoch 259/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.8690 - acc: 0.5875 - val_loss: 1.5287 - val_acc: 0.4455\n",
      "Epoch 260/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.8754 - acc: 0.5958 - val_loss: 1.3974 - val_acc: 0.4545\n",
      "Epoch 261/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.8322 - acc: 0.5833 - val_loss: 1.5520 - val_acc: 0.4455\n",
      "Epoch 262/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.7865 - acc: 0.6292 - val_loss: 1.5097 - val_acc: 0.4818\n",
      "Epoch 263/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.7955 - acc: 0.6167 - val_loss: 1.4790 - val_acc: 0.4727\n",
      "Epoch 264/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.7695 - acc: 0.6167 - val_loss: 1.5686 - val_acc: 0.5000\n",
      "Epoch 265/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.8485 - acc: 0.5917 - val_loss: 1.7580 - val_acc: 0.4909\n",
      "Epoch 266/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.9295 - acc: 0.5500 - val_loss: 1.6059 - val_acc: 0.4182\n",
      "Epoch 267/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.8444 - acc: 0.6083 - val_loss: 1.7087 - val_acc: 0.4364\n",
      "Epoch 268/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.8743 - acc: 0.6042 - val_loss: 1.7115 - val_acc: 0.4364\n",
      "Epoch 269/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.8713 - acc: 0.5583 - val_loss: 1.8801 - val_acc: 0.4818\n",
      "Epoch 270/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.8339 - acc: 0.5833 - val_loss: 1.7211 - val_acc: 0.4455\n",
      "Epoch 271/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.7726 - acc: 0.5958 - val_loss: 1.7947 - val_acc: 0.4818\n",
      "Epoch 272/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.7259 - acc: 0.6458 - val_loss: 1.6191 - val_acc: 0.4545\n",
      "Epoch 273/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.7428 - acc: 0.6125 - val_loss: 1.7097 - val_acc: 0.5091\n",
      "Epoch 274/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.9779 - acc: 0.5875 - val_loss: 1.8396 - val_acc: 0.4364\n",
      "Epoch 275/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.1375 - acc: 0.5583 - val_loss: 1.6675 - val_acc: 0.4182\n",
      "Epoch 276/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.0261 - acc: 0.5750 - val_loss: 1.3015 - val_acc: 0.5091\n",
      "Epoch 277/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.8836 - acc: 0.6250 - val_loss: 1.3075 - val_acc: 0.5091\n",
      "Epoch 278/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.8066 - acc: 0.6375 - val_loss: 1.5376 - val_acc: 0.4636\n",
      "Epoch 279/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.8856 - acc: 0.5958 - val_loss: 1.5962 - val_acc: 0.4727\n",
      "Epoch 280/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.9368 - acc: 0.6000 - val_loss: 1.6198 - val_acc: 0.4182\n",
      "Epoch 281/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.8001 - acc: 0.6708 - val_loss: 1.5512 - val_acc: 0.4545\n",
      "Epoch 282/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.7676 - acc: 0.6667 - val_loss: 1.6752 - val_acc: 0.4273\n",
      "Epoch 283/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.9158 - acc: 0.5875 - val_loss: 1.7340 - val_acc: 0.4364\n",
      "Epoch 284/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.9857 - acc: 0.5500 - val_loss: 1.4399 - val_acc: 0.4091\n",
      "Epoch 285/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.0205 - acc: 0.5458 - val_loss: 1.7130 - val_acc: 0.4091\n",
      "Epoch 286/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.9202 - acc: 0.5542 - val_loss: 1.4937 - val_acc: 0.4545\n",
      "Epoch 287/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.8155 - acc: 0.6333 - val_loss: 1.5077 - val_acc: 0.5000\n",
      "Epoch 288/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.7879 - acc: 0.6417 - val_loss: 1.4301 - val_acc: 0.4818\n",
      "Epoch 289/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.7735 - acc: 0.6083 - val_loss: 1.5506 - val_acc: 0.4909\n",
      "Epoch 290/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.7612 - acc: 0.6583 - val_loss: 1.6190 - val_acc: 0.4818\n",
      "Epoch 291/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.6857 - acc: 0.6667 - val_loss: 1.6100 - val_acc: 0.4909\n",
      "Epoch 292/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.6384 - acc: 0.7000 - val_loss: 1.5591 - val_acc: 0.5182\n",
      "Epoch 293/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.6034 - acc: 0.6833 - val_loss: 1.5664 - val_acc: 0.5182\n",
      "Epoch 294/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.6237 - acc: 0.6750 - val_loss: 1.5804 - val_acc: 0.4909\n",
      "Epoch 295/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.5983 - acc: 0.7000 - val_loss: 1.5563 - val_acc: 0.5091\n",
      "Epoch 296/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.5959 - acc: 0.6833 - val_loss: 1.6823 - val_acc: 0.4636\n",
      "Epoch 297/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.7150 - acc: 0.6625 - val_loss: 1.5055 - val_acc: 0.5545\n",
      "Epoch 298/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.6965 - acc: 0.6250 - val_loss: 1.7036 - val_acc: 0.5091\n",
      "Epoch 299/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.7439 - acc: 0.6458 - val_loss: 2.4572 - val_acc: 0.3909\n",
      "Epoch 300/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3902 - acc: 0.2750 - val_loss: 1.9595 - val_acc: 0.3091\n",
      "Epoch 301/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.9391 - acc: 0.3042 - val_loss: 2.1549 - val_acc: 0.2727\n",
      "Epoch 302/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.6838 - acc: 0.3625 - val_loss: 1.8301 - val_acc: 0.4000\n",
      "Epoch 303/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.5115 - acc: 0.3625 - val_loss: 1.6955 - val_acc: 0.3091\n",
      "Epoch 304/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.4115 - acc: 0.3833 - val_loss: 1.6962 - val_acc: 0.3727\n",
      "Epoch 305/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.3025 - acc: 0.4500 - val_loss: 1.6768 - val_acc: 0.3909\n",
      "Epoch 306/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.2671 - acc: 0.4500 - val_loss: 1.6497 - val_acc: 0.4636\n",
      "Epoch 307/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.2230 - acc: 0.4833 - val_loss: 1.6851 - val_acc: 0.3364\n",
      "Epoch 308/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.1521 - acc: 0.5417 - val_loss: 1.6511 - val_acc: 0.3727\n",
      "Epoch 309/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.1126 - acc: 0.5167 - val_loss: 1.6804 - val_acc: 0.4000\n",
      "Epoch 310/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0382 - acc: 0.5875 - val_loss: 1.6295 - val_acc: 0.4182\n",
      "Epoch 311/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.0323 - acc: 0.5667 - val_loss: 1.7040 - val_acc: 0.4273\n",
      "Epoch 312/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.0686 - acc: 0.5708 - val_loss: 1.6698 - val_acc: 0.4000\n",
      "Epoch 313/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.1483 - acc: 0.4792 - val_loss: 1.7513 - val_acc: 0.3818\n",
      "Epoch 314/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.1705 - acc: 0.5167 - val_loss: 1.7880 - val_acc: 0.3636\n",
      "Epoch 315/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.0762 - acc: 0.5958 - val_loss: 1.7298 - val_acc: 0.4091\n",
      "Epoch 316/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.0426 - acc: 0.5917 - val_loss: 1.7496 - val_acc: 0.4455\n",
      "Epoch 317/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.0133 - acc: 0.6000 - val_loss: 1.6246 - val_acc: 0.4182\n",
      "Epoch 318/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.9651 - acc: 0.6250 - val_loss: 1.6683 - val_acc: 0.4727\n",
      "Epoch 319/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.9483 - acc: 0.6167 - val_loss: 1.7590 - val_acc: 0.4000\n",
      "Epoch 320/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.0163 - acc: 0.6167 - val_loss: 1.6421 - val_acc: 0.4364\n",
      "Epoch 321/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.1540 - acc: 0.5750 - val_loss: 1.9457 - val_acc: 0.3364\n",
      "Epoch 322/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.9902 - acc: 0.5833 - val_loss: 1.6488 - val_acc: 0.4636\n",
      "Epoch 323/500\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.9702 - acc: 0.6083 - val_loss: 1.7319 - val_acc: 0.4727\n",
      "Epoch 324/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.9533 - acc: 0.6042 - val_loss: 1.5671 - val_acc: 0.4545\n",
      "Epoch 325/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.8386 - acc: 0.6542 - val_loss: 1.5480 - val_acc: 0.4455\n",
      "Epoch 326/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.8139 - acc: 0.6542 - val_loss: 1.7149 - val_acc: 0.4273\n",
      "Epoch 327/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.8587 - acc: 0.6375 - val_loss: 1.8892 - val_acc: 0.4091\n",
      "Epoch 328/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.9659 - acc: 0.6083 - val_loss: 1.7750 - val_acc: 0.4091\n",
      "Epoch 329/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.8999 - acc: 0.5833 - val_loss: 1.7799 - val_acc: 0.4000\n",
      "Epoch 330/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.8344 - acc: 0.6458 - val_loss: 1.9338 - val_acc: 0.4091\n",
      "Epoch 331/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.8879 - acc: 0.6375 - val_loss: 1.7488 - val_acc: 0.4273\n",
      "Epoch 332/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.8111 - acc: 0.6333 - val_loss: 1.8991 - val_acc: 0.3818\n",
      "Epoch 333/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.8427 - acc: 0.6417 - val_loss: 1.7099 - val_acc: 0.5000\n",
      "Epoch 334/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.7811 - acc: 0.6333 - val_loss: 1.6804 - val_acc: 0.4818\n",
      "Epoch 335/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.6953 - acc: 0.7125 - val_loss: 1.8703 - val_acc: 0.4091\n",
      "Epoch 336/500\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.7070 - acc: 0.6958 - val_loss: 1.7348 - val_acc: 0.4091\n",
      "Epoch 337/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.6281 - acc: 0.7208 - val_loss: 1.7660 - val_acc: 0.4182\n",
      "Epoch 338/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.6025 - acc: 0.7542 - val_loss: 1.8140 - val_acc: 0.4727\n",
      "Epoch 339/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.5967 - acc: 0.7708 - val_loss: 1.7581 - val_acc: 0.4636\n",
      "Epoch 340/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.5888 - acc: 0.7458 - val_loss: 1.9978 - val_acc: 0.3909\n",
      "Epoch 341/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.6854 - acc: 0.7000 - val_loss: 1.7897 - val_acc: 0.4545\n",
      "Epoch 342/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.6562 - acc: 0.7167 - val_loss: 2.0220 - val_acc: 0.4818\n",
      "Epoch 343/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.8184 - acc: 0.6417 - val_loss: 1.7595 - val_acc: 0.4455\n",
      "Epoch 344/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.7706 - acc: 0.6375 - val_loss: 1.8120 - val_acc: 0.4182\n",
      "Epoch 345/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.7159 - acc: 0.6917 - val_loss: 1.8275 - val_acc: 0.5091\n",
      "Epoch 346/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.7039 - acc: 0.7125 - val_loss: 1.8321 - val_acc: 0.4909\n",
      "Epoch 347/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.6308 - acc: 0.7292 - val_loss: 1.7871 - val_acc: 0.5273\n",
      "Epoch 348/500\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.6118 - acc: 0.7375 - val_loss: 1.8787 - val_acc: 0.4909\n",
      "Epoch 349/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.5554 - acc: 0.7583 - val_loss: 1.8868 - val_acc: 0.5364\n",
      "Epoch 350/500\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.5425 - acc: 0.7500 - val_loss: 1.8202 - val_acc: 0.5636\n",
      "Epoch 351/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.5719 - acc: 0.7667 - val_loss: 1.9113 - val_acc: 0.5182\n",
      "Epoch 352/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.5610 - acc: 0.7750 - val_loss: 1.6944 - val_acc: 0.5182\n",
      "Epoch 353/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.6227 - acc: 0.7208 - val_loss: 1.8678 - val_acc: 0.4636\n",
      "Epoch 354/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.7353 - acc: 0.7000 - val_loss: 1.8575 - val_acc: 0.4455\n",
      "Epoch 355/500\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.6410 - acc: 0.7375 - val_loss: 1.8407 - val_acc: 0.5182\n",
      "Epoch 356/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.6213 - acc: 0.7250 - val_loss: 1.7623 - val_acc: 0.5455\n",
      "Epoch 357/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.5606 - acc: 0.7750 - val_loss: 1.8011 - val_acc: 0.5273\n",
      "Epoch 358/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.5259 - acc: 0.7958 - val_loss: 1.7365 - val_acc: 0.5364\n",
      "Epoch 359/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.6133 - acc: 0.7292 - val_loss: 1.9344 - val_acc: 0.4909\n",
      "Epoch 360/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.5997 - acc: 0.7542 - val_loss: 1.9286 - val_acc: 0.4818\n",
      "Epoch 361/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 8s 32ms/step - loss: 0.5420 - acc: 0.7833 - val_loss: 1.8416 - val_acc: 0.5091\n",
      "Epoch 362/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.5721 - acc: 0.7542 - val_loss: 1.8909 - val_acc: 0.4818\n",
      "Epoch 363/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.5975 - acc: 0.7625 - val_loss: 1.8884 - val_acc: 0.5273\n",
      "Epoch 364/500\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.6770 - acc: 0.7417 - val_loss: 2.1028 - val_acc: 0.4455\n",
      "Epoch 365/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.6130 - acc: 0.7542 - val_loss: 1.8056 - val_acc: 0.5455\n",
      "Epoch 366/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5454 - acc: 0.7708 - val_loss: 1.9199 - val_acc: 0.5364\n",
      "Epoch 367/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.5891 - acc: 0.7417 - val_loss: 1.8778 - val_acc: 0.5182\n",
      "Epoch 368/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.7673 - acc: 0.6542 - val_loss: 1.8994 - val_acc: 0.4818\n",
      "Epoch 369/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.7608 - acc: 0.7083 - val_loss: 1.7263 - val_acc: 0.5364\n",
      "Epoch 370/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.2205 - acc: 0.5625 - val_loss: 1.9531 - val_acc: 0.3727\n",
      "Epoch 371/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.2397 - acc: 0.5750 - val_loss: 1.7907 - val_acc: 0.4455\n",
      "Epoch 372/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.0218 - acc: 0.5958 - val_loss: 1.5617 - val_acc: 0.5091\n",
      "Epoch 373/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.8857 - acc: 0.6542 - val_loss: 1.6263 - val_acc: 0.5364\n",
      "Epoch 374/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.8257 - acc: 0.6958 - val_loss: 1.7657 - val_acc: 0.4727\n",
      "Epoch 375/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.8954 - acc: 0.6458 - val_loss: 1.6938 - val_acc: 0.5091\n",
      "Epoch 376/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.7847 - acc: 0.6875 - val_loss: 1.6935 - val_acc: 0.5273\n",
      "Epoch 377/500\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.7247 - acc: 0.7000 - val_loss: 1.7264 - val_acc: 0.5273\n",
      "Epoch 378/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.7487 - acc: 0.6833 - val_loss: 1.6268 - val_acc: 0.5455\n",
      "Epoch 379/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.7634 - acc: 0.7083 - val_loss: 1.5816 - val_acc: 0.5273\n",
      "Epoch 380/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.6544 - acc: 0.7417 - val_loss: 1.5833 - val_acc: 0.5636\n",
      "Epoch 381/500\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.6725 - acc: 0.7250 - val_loss: 1.6290 - val_acc: 0.5182\n",
      "Epoch 382/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.7304 - acc: 0.6750 - val_loss: 1.6295 - val_acc: 0.5273\n",
      "Epoch 383/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.7248 - acc: 0.7250 - val_loss: 1.5503 - val_acc: 0.5455\n",
      "Epoch 384/500\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.6386 - acc: 0.7542 - val_loss: 1.6601 - val_acc: 0.5273\n",
      "Epoch 385/500\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.7278 - acc: 0.7083 - val_loss: 1.8071 - val_acc: 0.5182\n",
      "Epoch 386/500\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.8670 - acc: 0.6417 - val_loss: 1.6301 - val_acc: 0.5636\n",
      "Epoch 387/500\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.7583 - acc: 0.6917 - val_loss: 1.5316 - val_acc: 0.5545\n",
      "Epoch 388/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6291 - acc: 0.7500 - val_loss: 1.4382 - val_acc: 0.6182\n",
      "Epoch 389/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5912 - acc: 0.7708 - val_loss: 1.5591 - val_acc: 0.5545\n",
      "Epoch 390/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.5923 - acc: 0.7583 - val_loss: 1.5985 - val_acc: 0.5364\n",
      "Epoch 391/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5605 - acc: 0.7458 - val_loss: 1.4420 - val_acc: 0.6000\n",
      "Epoch 392/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5387 - acc: 0.7500 - val_loss: 1.3902 - val_acc: 0.6000\n",
      "Epoch 393/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4671 - acc: 0.8083 - val_loss: 1.5360 - val_acc: 0.5636\n",
      "Epoch 394/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4547 - acc: 0.8083 - val_loss: 1.5721 - val_acc: 0.6000\n",
      "Epoch 395/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4304 - acc: 0.8167 - val_loss: 1.5623 - val_acc: 0.5909\n",
      "Epoch 396/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4656 - acc: 0.8208 - val_loss: 1.5714 - val_acc: 0.5727\n",
      "Epoch 397/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4637 - acc: 0.8042 - val_loss: 1.5898 - val_acc: 0.5636\n",
      "Epoch 398/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4541 - acc: 0.8125 - val_loss: 1.6770 - val_acc: 0.5182\n",
      "Epoch 399/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4755 - acc: 0.7958 - val_loss: 1.7454 - val_acc: 0.5364\n",
      "Epoch 400/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4220 - acc: 0.8042 - val_loss: 1.7619 - val_acc: 0.5818\n",
      "Epoch 401/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4053 - acc: 0.8042 - val_loss: 1.7051 - val_acc: 0.6000\n",
      "Epoch 402/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.8345 - acc: 0.6625 - val_loss: 2.1893 - val_acc: 0.3364\n",
      "Epoch 403/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5383 - acc: 0.4542 - val_loss: 1.6719 - val_acc: 0.4273\n",
      "Epoch 404/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.1810 - acc: 0.5125 - val_loss: 1.6331 - val_acc: 0.4364\n",
      "Epoch 405/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0919 - acc: 0.5542 - val_loss: 1.7025 - val_acc: 0.4545\n",
      "Epoch 406/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8537 - acc: 0.6125 - val_loss: 1.5765 - val_acc: 0.5000\n",
      "Epoch 407/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7884 - acc: 0.6875 - val_loss: 1.5192 - val_acc: 0.5182\n",
      "Epoch 408/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7046 - acc: 0.7083 - val_loss: 1.5113 - val_acc: 0.5364\n",
      "Epoch 409/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6385 - acc: 0.7458 - val_loss: 1.4588 - val_acc: 0.5727\n",
      "Epoch 410/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6357 - acc: 0.7625 - val_loss: 1.4515 - val_acc: 0.5636\n",
      "Epoch 411/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5982 - acc: 0.7542 - val_loss: 1.4904 - val_acc: 0.5455\n",
      "Epoch 412/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5898 - acc: 0.7833 - val_loss: 1.5758 - val_acc: 0.5545\n",
      "Epoch 413/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5148 - acc: 0.7875 - val_loss: 1.5355 - val_acc: 0.5636\n",
      "Epoch 414/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5623 - acc: 0.7917 - val_loss: 1.4389 - val_acc: 0.5545\n",
      "Epoch 415/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4854 - acc: 0.8167 - val_loss: 1.4970 - val_acc: 0.5909\n",
      "Epoch 416/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4520 - acc: 0.8208 - val_loss: 1.3501 - val_acc: 0.6091\n",
      "Epoch 417/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4605 - acc: 0.8125 - val_loss: 1.4351 - val_acc: 0.6000\n",
      "Epoch 418/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4813 - acc: 0.8000 - val_loss: 1.6050 - val_acc: 0.5818\n",
      "Epoch 419/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5524 - acc: 0.7833 - val_loss: 1.6706 - val_acc: 0.5182\n",
      "Epoch 420/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5843 - acc: 0.7417 - val_loss: 1.6033 - val_acc: 0.5636\n",
      "Epoch 421/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4824 - acc: 0.7917 - val_loss: 1.6028 - val_acc: 0.5909\n",
      "Epoch 422/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5462 - acc: 0.7792 - val_loss: 1.5419 - val_acc: 0.5636\n",
      "Epoch 423/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5683 - acc: 0.7708 - val_loss: 1.6772 - val_acc: 0.5000\n",
      "Epoch 424/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4728 - acc: 0.8083 - val_loss: 1.5311 - val_acc: 0.5545\n",
      "Epoch 425/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4145 - acc: 0.8417 - val_loss: 1.4925 - val_acc: 0.6000\n",
      "Epoch 426/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4776 - acc: 0.8000 - val_loss: 1.6248 - val_acc: 0.5727\n",
      "Epoch 427/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5023 - acc: 0.8000 - val_loss: 1.5206 - val_acc: 0.6182\n",
      "Epoch 428/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4327 - acc: 0.8125 - val_loss: 1.6769 - val_acc: 0.5909\n",
      "Epoch 429/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.3777 - acc: 0.8417 - val_loss: 1.6536 - val_acc: 0.6273\n",
      "Epoch 430/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.3854 - acc: 0.8417 - val_loss: 1.5723 - val_acc: 0.6273\n",
      "Epoch 431/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.3871 - acc: 0.8417 - val_loss: 1.6241 - val_acc: 0.6000\n",
      "Epoch 432/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.3352 - acc: 0.8583 - val_loss: 1.5329 - val_acc: 0.6273\n",
      "Epoch 433/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.3688 - acc: 0.8625 - val_loss: 1.7111 - val_acc: 0.6000\n",
      "Epoch 434/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.3490 - acc: 0.8708 - val_loss: 1.6866 - val_acc: 0.6091\n",
      "Epoch 435/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.2918 - acc: 0.8792 - val_loss: 1.6120 - val_acc: 0.6182\n",
      "Epoch 436/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.2684 - acc: 0.8958 - val_loss: 1.5702 - val_acc: 0.5818\n",
      "Epoch 437/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4646 - acc: 0.8000 - val_loss: 1.7799 - val_acc: 0.5545\n",
      "Epoch 438/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4522 - acc: 0.8042 - val_loss: 1.9252 - val_acc: 0.5273\n",
      "Epoch 439/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4283 - acc: 0.8292 - val_loss: 1.7137 - val_acc: 0.6000\n",
      "Epoch 440/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4055 - acc: 0.8417 - val_loss: 1.8764 - val_acc: 0.5364\n",
      "Epoch 441/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5378 - acc: 0.8083 - val_loss: 1.5693 - val_acc: 0.6182\n",
      "Epoch 442/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4466 - acc: 0.8250 - val_loss: 1.6828 - val_acc: 0.5364\n",
      "Epoch 443/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4453 - acc: 0.8125 - val_loss: 1.6505 - val_acc: 0.5818\n",
      "Epoch 444/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.3880 - acc: 0.8292 - val_loss: 1.7500 - val_acc: 0.5909\n",
      "Epoch 445/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.3547 - acc: 0.8500 - val_loss: 1.7201 - val_acc: 0.6091\n",
      "Epoch 446/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.3872 - acc: 0.8417 - val_loss: 1.6907 - val_acc: 0.5909\n",
      "Epoch 447/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.2965 - acc: 0.8833 - val_loss: 1.7307 - val_acc: 0.5727\n",
      "Epoch 448/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.3449 - acc: 0.8583 - val_loss: 1.9989 - val_acc: 0.5545\n",
      "Epoch 449/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0208 - acc: 0.6708 - val_loss: 2.1874 - val_acc: 0.4636\n",
      "Epoch 450/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0913 - acc: 0.6292 - val_loss: 1.6985 - val_acc: 0.4818\n",
      "Epoch 451/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8343 - acc: 0.6708 - val_loss: 1.7158 - val_acc: 0.4636\n",
      "Epoch 452/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6782 - acc: 0.7167 - val_loss: 1.6026 - val_acc: 0.5455\n",
      "Epoch 453/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6303 - acc: 0.7458 - val_loss: 1.6340 - val_acc: 0.5455\n",
      "Epoch 454/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4983 - acc: 0.8125 - val_loss: 1.6013 - val_acc: 0.5182\n",
      "Epoch 455/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4295 - acc: 0.8500 - val_loss: 1.6503 - val_acc: 0.5091\n",
      "Epoch 456/500\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.3982 - acc: 0.8417 - val_loss: 1.6544 - val_acc: 0.5545\n",
      "Epoch 457/500\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.4084 - acc: 0.8417 - val_loss: 1.6809 - val_acc: 0.5636\n",
      "Epoch 458/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.6364 - acc: 0.7333 - val_loss: 1.6563 - val_acc: 0.5091\n",
      "Epoch 459/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.6852 - acc: 0.7333 - val_loss: 1.7312 - val_acc: 0.5364\n",
      "Epoch 460/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.5310 - acc: 0.7708 - val_loss: 1.5086 - val_acc: 0.5545\n",
      "Epoch 461/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.4345 - acc: 0.8125 - val_loss: 1.7346 - val_acc: 0.5636\n",
      "Epoch 462/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.3663 - acc: 0.8583 - val_loss: 1.7165 - val_acc: 0.5364\n",
      "Epoch 463/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.3175 - acc: 0.8708 - val_loss: 1.7163 - val_acc: 0.5364\n",
      "Epoch 464/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.2895 - acc: 0.8875 - val_loss: 1.6916 - val_acc: 0.5364\n",
      "Epoch 465/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.2924 - acc: 0.8917 - val_loss: 1.7282 - val_acc: 0.5818\n",
      "Epoch 466/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.2729 - acc: 0.8833 - val_loss: 1.7853 - val_acc: 0.5727\n",
      "Epoch 467/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.2931 - acc: 0.8833 - val_loss: 1.6476 - val_acc: 0.5636\n",
      "Epoch 468/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.3282 - acc: 0.8625 - val_loss: 1.5644 - val_acc: 0.5545\n",
      "Epoch 469/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.2633 - acc: 0.8833 - val_loss: 1.7757 - val_acc: 0.5455\n",
      "Epoch 470/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.2272 - acc: 0.9083 - val_loss: 1.7347 - val_acc: 0.5364\n",
      "Epoch 471/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.2312 - acc: 0.9042 - val_loss: 1.9810 - val_acc: 0.5364\n",
      "Epoch 472/500\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.2729 - acc: 0.8750 - val_loss: 1.7287 - val_acc: 0.5636\n",
      "Epoch 473/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.3125 - acc: 0.8833 - val_loss: 1.5323 - val_acc: 0.6364\n",
      "Epoch 474/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.2786 - acc: 0.8875 - val_loss: 1.5504 - val_acc: 0.6364\n",
      "Epoch 475/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.2211 - acc: 0.9167 - val_loss: 1.5842 - val_acc: 0.5818\n",
      "Epoch 476/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.2125 - acc: 0.9167 - val_loss: 1.6278 - val_acc: 0.5727\n",
      "Epoch 477/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.2131 - acc: 0.9083 - val_loss: 1.6580 - val_acc: 0.5727\n",
      "Epoch 478/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.1934 - acc: 0.9208 - val_loss: 1.6629 - val_acc: 0.5909\n",
      "Epoch 479/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1976 - acc: 0.9083 - val_loss: 1.6010 - val_acc: 0.6273\n",
      "Epoch 480/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.2319 - acc: 0.8875 - val_loss: 1.6719 - val_acc: 0.6000\n",
      "Epoch 481/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 5s 22ms/step - loss: 0.2179 - acc: 0.9000 - val_loss: 1.7982 - val_acc: 0.5818\n",
      "Epoch 482/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.2163 - acc: 0.9083 - val_loss: 1.8698 - val_acc: 0.5727\n",
      "Epoch 483/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.2074 - acc: 0.9250 - val_loss: 1.8810 - val_acc: 0.5727\n",
      "Epoch 484/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.2044 - acc: 0.9125 - val_loss: 1.7563 - val_acc: 0.5909\n",
      "Epoch 485/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1747 - acc: 0.9333 - val_loss: 1.7778 - val_acc: 0.6000\n",
      "Epoch 486/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1674 - acc: 0.9208 - val_loss: 1.8770 - val_acc: 0.5455\n",
      "Epoch 487/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1615 - acc: 0.9333 - val_loss: 1.8551 - val_acc: 0.5818\n",
      "Epoch 488/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1342 - acc: 0.9542 - val_loss: 1.8930 - val_acc: 0.6000\n",
      "Epoch 489/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1334 - acc: 0.9583 - val_loss: 1.9129 - val_acc: 0.5909\n",
      "Epoch 490/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1141 - acc: 0.9625 - val_loss: 1.9648 - val_acc: 0.6000\n",
      "Epoch 491/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1103 - acc: 0.9583 - val_loss: 1.9627 - val_acc: 0.6000\n",
      "Epoch 492/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.2509 - acc: 0.8958 - val_loss: 2.0589 - val_acc: 0.5545\n",
      "Epoch 493/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4830 - acc: 0.8292 - val_loss: 2.0137 - val_acc: 0.5636\n",
      "Epoch 494/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4271 - acc: 0.8167 - val_loss: 2.0582 - val_acc: 0.5909\n",
      "Epoch 495/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.3448 - acc: 0.8500 - val_loss: 2.3698 - val_acc: 0.5273\n",
      "Epoch 496/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6683 - acc: 0.8292 - val_loss: 1.9404 - val_acc: 0.5091\n",
      "Epoch 497/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8621 - acc: 0.7167 - val_loss: 1.7991 - val_acc: 0.5455\n",
      "Epoch 498/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8581 - acc: 0.7167 - val_loss: 1.4894 - val_acc: 0.5818\n",
      "Epoch 499/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6968 - acc: 0.7167 - val_loss: 1.5641 - val_acc: 0.5545\n",
      "Epoch 500/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5301 - acc: 0.7833 - val_loss: 1.4086 - val_acc: 0.5727\n"
     ]
    }
   ],
   "source": [
    "LSTMD=LSTM_with_Dropout('LSTM_Dropout0.5',dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMD=LSTM_with_Dropout('LSTM_Dropoutdelta0.8',dropout=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnXd4HMXd+D9zXb27yt3GDReMMJhejOnlpQQSSkKJQ8Ib4A35BZKQQAhJIAkJxZRAqKETemihmGLABtu4gW1s3G3ZKrZ6vbv5/TG7t3unu9NJujtL8nyeR4/udmd3RydpvvPtQkqJRqPRaDQAjr09AY1Go9H0HrRQ0Gg0Gk0ILRQ0Go1GE0ILBY1Go9GE0EJBo9FoNCG0UNBoNBpNCC0UNH0eIcRIIYQUQriM928KIb6fyNhkPreTsT8QQizo6TO7gxBikxBidgLjkvbZaPou+pevSQtCiE3AQCAANAJvAv8rpWxI9rOklCcl+54azb6C1hQ06eQ0KWU2MAMoA27o6g30LlajSS1aKGjSjpRyO0pT2B9ACJEnhHhICFEuhNguhLhFCOE0zv1ACPGJEOLvQohq4CYhhFMI8VchRJUQYgNwiv3+QogPhBCXG687G3uJEGK1EKJeCLFBCPGjWPNO4F4xf4542Mw2lwghtgoh9gghrhBCHCSEWCGEqBFCzLONdwghbhBCbBZCVAghHhdC5NnOX2ScqxZC/DriWQ4hxPVCiG+N888JIQpjzGuIEOJVIcRuIcR6IcQPO/tZNH0fLRQ0aUcIMQw4GfjSOPQo4AfGAgcAc4DLbZccDGxAmZ/+APwQONUYWwacE+dxnY2tMM7nApcAfxdCzOjmvTr7OTrjYGAccB5wB/BrYDYwGfiOEOIoY9wPjK9jgNFANjAPQAgxCbgPuAgYAhQBpbZn/BQ4EzjKOL8HuCfGfJ4BthnjzgH+KIQ4tgs/j6YvIqXUX/or5V/AJqABqAE2A/cCGaiFvhXIsI39LjDfeP0DYEvEvd4HrrC9nwNIwGW8/wC4PJGxUeb5MnB1jHMx75Xgz7Egxn1HGvcZajtWDZxne/8CcI3x+j3gJ7Zz44F2Yx6/BZ6xncsC2oDZxvvVwHG284Nt15rzcAHDUP6fHNvYPwGP7u2/Jf2V2i9tn9WkkzOllO/aDwghpgBuoFwIYR52AFttw+yvQe1c7cc2x3lm3LFCiJOAG4H9jOdmAiu7ca8RdP5zdMYu2+vmKO+zbfOwP3szlmAKm6OUstEwu9nn+ZIQImg7FjCutTME2C2lrI94TlnCP42mT6KFgmZvsxW1wy6WUvpjjIks5VuO2smaDI9z/5hjhRBe1A78YuAVKWW7EOJlQBCdeM9N5OdIFjtQi7t9Hn6UECkHJponhBCZKBOSfZ6XSik/ibypEGJkxDMKhRA5NsEwHNiehPlrejHap6DZq0gpy4H/ArcLIXINR+gYm/08Gs8BVwkhSoUQBcD13RzrAbxAJeA3tIY53blXN3+O7vI08H9CiFFCiGzgj8CzhjD6N3CqEOJwIYQHuJnw//P7gT8IIUYACCFKhBBnRD5ASrkV+BT4kxDCJ4SYClwGPJGCn0fTi9BCQdMbuBi1QH+Ncnz+G2XrjsWDwNvAcmAp8GJ3xho74KtQi/0e4HvAqz14bld/ju7yMPAv4CNgI9CCciAjpfwKuBJ4CqU17EE5i03uRP2M/xVC1AMLUQ7uaHwX5WfYAbwE3Bhp/tP0P4SUusmORqPRaBRaU9BoNBpNCC0UNBqNRhNCCwWNRqPRhNBCQaPRaDQh+lyeQnFxsRw5cuTenoZGo9H0KZYsWVIlpSzpbFyfEwojR45k8eLFe3saGo1G06cQQsTL/A+hzUcajUajCaGFgkaj0WhCpEwoGKnxnwshlgshvhJC/C7KGK8Q4lmjVvuiiNorGo1Go0kzqfQptALHSikbhBBuYIEQ4k0p5ULbmMuAPVLKsUKI84HbULXku0R7ezvbtm2jpaUlOTPv5/h8PkpLS3G73Xt7KhqNppeRMqEgVf0Ms/+u2/iKrKlxBnCT8frfwDwhhJBdrL2xbds2cnJyGDlyJLayxZooSCmprq5m27ZtjBo1am9PR6PR9DJS6lMw2hcuQ3W3ekdKuShiyFCM2u9Ghcdawsv8mveZK4RYLIRYXFlZ2eE5LS0tFBUVaYGQAEIIioqKtFal0WiiklKhIKUMSCmno9oBzhRC7N/N+zwgpSyTUpaVlEQPs9UCIXH0Z6XRaGKRlugjKWUNMB84MeLUdoymJUIIF5CHakOoSRdbP4edsRqNaTSafY1URh+VCCHyjdcZwPHAmohhrwLfN16fA7zfVX9Cb6C6uprp06czffp0Bg0axNChQ0Pv29raErrHJZdcwtq1a+OOueeee3jyySeTMWWLh46H+w9P7j01Gk2fJZXRR4OBx4QQTpTweU5K+R8hxM3AYinlq8BDwL+EEOuB3cD5KZxPyigqKmLZsmUA3HTTTWRnZ/Pzn/88bIzZFNvhiC6HH3nkkU6fc+WVV/Z8shqNRhOHlGkKUsoVUsoDpJRTpZT7SylvNo7/1hAISClbpJTnSinHSilnSik3pGo+e4P169czadIkLrjgAiZPnkx5eTlz586lrKyMyZMnc/PNN4fGHn744Sxbtgy/309+fj7XX38906ZNY9asWVRUVABwww03cMcdd4TGX3/99cycOZPx48fz6aefAtDY2MjZZ5/NpEmTOOeccygrKwsJLI1Go+mMPlf7qDN+99pXfL2jLqn3nDQklxtPm9yta9esWcPjjz9OWVkZALfeeiuFhYX4/X6OOeYYzjnnHCZNmhR2TW1tLUcddRS33norP/vZz3j44Ye5/vqObYillHz++ee8+uqr3Hzzzbz11lvcfffdDBo0iBdeeIHly5czY8aMbs1bo9Hsm+gyFylmzJgxIYEA8PTTTzNjxgxmzJjB6tWr+frrrztck5GRwUknnQTAgQceyKZNm6Le+6yzzuowZsGCBZx/vrLCTZs2jcmTuyfMNBrNvkm/0xS6u6NPFVlZWaHX69at48477+Tzzz8nPz+fCy+8MGq+gMfjCb12Op34/f6o9/Z6vZ2O0Wg0mq6gNYU0UldXR05ODrm5uZSXl/P2228n/RmHHXYYzz33HAArV66MqoloNBpNLPqdptCbmTFjBpMmTWLChAmMGDGCww47LOnP+OlPf8rFF1/MpEmTQl95eXlJf45Go+mfiL6WFlBWViYjm+ysXr2aiRMn7qUZ9S78fj9+vx+fz8e6deuYM2cO69atw+UKl/+hz+wmQ2DcVLsXZqvRaNKFEGKJlLKss3FaU+hnNDQ0cNxxx+H3+5FS8o9//KODQNBoNJpY6NWin5Gfn8+SJUv29jQ0Gk0fRTuaNRqNRhNCCwWNRqPRhNBCQaPRaDQhtFDQaDQaTQgtFJJAMkpnAzz88MPs3LkzhTPVaDSa+OjooySQSOnsRHj44YeZMWMGgwYNSvYUNRqNJiG0UEgxjz32GPfccw9tbW0ceuihzJs3j2AwyCWXXMKyZcuQUjJ37lwGDhzIsmXLOO+888jIyODzzz8Pq4Gk0Wg06aD/CYU3r09+e8lBU+CkW7t82apVq3jppZf49NNPcblczJ07l2eeeYYxY8ZQVVXFypVqnjU1NeTn53P33Xczb948pk+fntz5azQaTYL0P6HQi3j33Xf54osvQqWzm5ubGTZsGCeccAJr167lqquu4pRTTmHOnDl7Z4LBoPVaShBi78xDo9H0GvqfUOjGjj5VSCm59NJL+f3vf9/h3IoVK3jzzTe55557eOGFF3jggQf2wgSD4a+FM/1z0Gg0vQodfZRCZs+ezXPPPUdVVRWgopS2bNlCZWUlUkrOPfdcbr75ZpYuXQpATk4O9fX16ZugDFivg7ofg0aj6Y+aQi9iypQp3HjjjcyePZtgMIjb7eb+++/H6XRy2WWXIaVECMFtt90GwCWXXMLll1+ePkdzMFIoeFP7PI1G0+vRpbP3UVavXs3E0aXwp1J14Pot4NN9FzSa/kqipbO1+WhfREpoa4RAu3XMrjVoNJp9Fm0+6m9ICf4WcGfEHtNUrb4W2tqBap+CRqOhH2kKfc0MljJqt0HlGgjELq8hA+2AhLod1kEtFDQaDf1EKPh8Pqqrq7VgAGhSkU5hOQg2pJRU1zbiq90QLji0UNBoNPQT81FpaSnbtm2jsrJyb09l71NTob7vdoAzevSSr3knpUtvg7FHWwe1UNBoNKRQKAghhgGPAwMBCTwgpbwzYszRwCvARuPQi1LKm7v6LLfbzahRo3o24f6AlPC7Q9Try96FYdOij1v4IbTVaEezRqPpQCo1BT9wrZRyqRAiB1gihHhHSvl1xLiPpZSnpnAe+w72hd3fHHucw8hcDjMfaaGg0WhS6FOQUpZLKZcar+uB1cDQVD1PQ7gJqL0l9jhh/NqDdk1Bm480Gk2aHM1CiJHAAcCiKKdnCSGWCyHeFEJMjnH9XCHEYiHEYu03iIO9bIU/jlAIaQqWUNjTGEez0Gg0+wwpFwpCiGzgBeAaKWVdxOmlwAgp5TTgbuDlaPeQUj4gpSyTUpaVlJSkdsJ9GftuP65QMKyGNvPR4wvWp2hSGo2mL5FSoSCEcKMEwpNSyhcjz0sp66SUDcbrNwC3EKI4lXPq19j9Au0J7PxtQiEY0OajPsmiB+Cfx+/tWWj6EamMPhLAQ8BqKeXfYowZBOySUkohxEyUkKpO1Zz6PTZNYXvV7tgOHFN4BLRPoc/z5v/b2zPQ9DNSGX10GHARsFIIscw49itgOICU8n7gHODHQgg/0AycL3UGWvexaQqNjY1xxhkCwKYpyEQ0hcYqZXrKyO/uDDUaTS8nZUJBSrkAiNvKS0o5D5iXqjnsc9h2++2tTXHGmZpCFzOa/zIGXD64YVc3J6jRaHo7/aLMhcbAtrD7W+P4FGQU85FM0HwUz4Gt2Wu0tGnznyY5aKHQn7C11wzE1RQ6mo+E9in0aS59ZOHenoKmn6CFQn/CtrAH40UfhYSCpSl4/Q2pmpUmDSzZqPN3+h3BIDx5Lnz7flofq4VCf8IuFNrimHkMn0K7bUyevwtBX4mEu2rSigtdpqTf0d4E6/4Lz1yY1sdqoZAgja1+Vm6rVW8CfqjqRrLXmteh8pvkTsyOLfoo2N65o9lhK3ORH+iCUGis6vLUNKnFqYVC/8P8/xRx43WSjhYKCXLdCys4bd4Cqhta4Z3fwLwDoWZr4jeo3wXPfA/uOSi8uU0ysWkKMl7tI2OcU1jRvwVdEApVu7Z3fW6alOLWQqH/4W9V30V6l+l+0U8hEVrq9/DuoiWcPHkQDoHhlJWq3LT5XUpVF8jlg4IRKiZ/+1Jo3sMv1l1DvvNEvlw/ntlLH1c3XfYkjDpS7ZyzSqC+XH1f8x/IGwaTzoDmPVAyATYvsCbzxT/hsGuU5jDtfNizCV65Er7zOGT1IKHbNAtJJ6PaN6j3Zp2jsHHhTuVW6SY/sDvhxyx+4gaOOOFcsjK8SvPZ9gUMnAQTT4OhB8JXL8G4EyBP1z9MF06iN1XS9GG0UEgtS99/nlO//H+woPOxAGQUqAXdYDhwi/sRePkRa8wHf1Jfsfjvr9X3wdNhz0bw5qpF8+Pb1RdAXiksewo2fwKrXgRPFhSPg2Ez1fmWOvDlJjZnI9T0ucDRXOB6j8D9R+D8yacxx5nskIWMDayHBXfA6KPg07th3BwlsGwEnD6cgRaOdizD9+4XoeMt7jzc25bgXPKoNXjQVPjRR2lXffdV3OjosX6HGR2ohUJqmHXUSXwoBf9dtZOqJj8gUDqCQCIIGt8nFDk5Nm8X3srl7C8auKv9NFYFR7FGDmOa2MB+jq34MrIpOeAUPlu8mB0tbo4ZncOl2QtxTD9fSfeisVD1Dbx2DXLc8cjNn+FoqYXZvwN3JmyYb01s+TPwzZvq9VvXqwV7/Mnw3aehah3MK4PT58GMizr/IQ0N4I3gTA4Jfs2Yiq9UCW23L2JcuFD4LDiJ7znmw7s3WgdXvQA1W+CoX4QOCRngXv/p5J16M8G6nTyzcCP1zS3sbCkki2ZOHrCbm6bV4l77H9i5Ahp2Qc6gLvyWNN3FKbSm0O/QmkJqEfnDOOrMH3L46ZLGNj9OIWjzB7n3g/XsbmznhaXbAJhfCfdVAhyvdl9ON/deeCA/fHwxV589m2GFmVz9zJfs+qgVmIHLIfhkvWThxJnIhTBxcC7137Zz0pRjOOS6TfzqldW8XLuFDy8ZxoBRU5SpaeVzcMrt8N8bYNkT1iRlQJms9mxW7+t3qu/v3dwlodAuXdwXOJ2/Ov6hTFqFo6KOM3kmcCxBVwYXnH0OoqkK3v61cnLN/0O4UAj68eNg1pgSRpeM4riZ01ldXkd1YxuPfbqJJ3fksmh5NndMH8X+FVdA3XYtFNKE1hT6IQFTKKRX295nhIKJ0yHI9bkByPLCr0+ZBMA1s8cxOM/Hyu21BIKSLbub+Nlzy7ls1kiOnzSQ5b+dQ47PhcMheP5Hh/LSl9sZkOvlfw4YyqOfbuLWN9cA8N4a1SP5sc82hz339qVwjmMPW6pbyZ71BAP9Pv5c/h3uzi6nKFDNziZJhcxn8oHH4FzxrPJvmNEHjRXqfWd/HMZiL5wudgSL1LG67Z0KBT9Obmi5kGkFhzNlSh5M+y78ebR6fjAIDgcElS4VkE4yPerPZkh+BkPyMwA498BS3vl6F7977Wuue2c3r3uhascGiocemOBvRtMTtE+hH6I1hb3LsMJMAA4YXgBA2chCxg/KYcIgZc/Py3SHxg4vyuTq2eNC7684agzHTxrI9j3NrNhWQ3VjGyu21bJtTxNTS/NpaQ/w7OKtPLvYila66JARfFpTyCzn73nrmiM49vYPAckC1zeUtjdCU3V497S6HZ07boNqYSjOy6LVORDqYNe2DQwceXjEuHDzkdPpwhUUPPX5Fv5UOkX5ME78E7zxcyWQcgZZWghOMtwdnddCCOZMHsSR+5XwwFsZsAQWLF7OmQedG3/OmqSgo4/6ISGhECVYJIVooRCHyUPyEh47piSbMSXZHLlfxyZAq7bXsnbnFwzJz2DZ1hoA/rVwMy6HoC0QNAQCgOCL2lxKgcB7N+McfZR1k11fJSAUDE1BODn+4APgHVi2ahUnHB59nEl+to8LJ43g0U83UVnfyo2nTWJozlAVr1y7PUwoBHCS4Yn9R+pzO7nq1ENoXeLB1Vgef76apKHzFPohe8nRrPMU0sD+Q/NY9KvjePnKw/jmlpM4YfJASnK8PH7ZTE6bNiQ0blhhBr9Zlsd2WUTj0ufDM4d3rer8QTbz0XmHTaBBZOFoiLIwR2gKDqeTa+fsR1GWh3dX7+KIP8/nZ/81EtRqDe3GMGVJ4cTj6uTPRghqXcVkt1Z0PmdNUtAZzf0Q/97xKWihkCaE8Yv1uBz846IyPv/VcRw6ppi/nDMVgFOmDOagEYU0kMmD/lPIpSk8Oa4hgQXWCDUVTqUA1rlL8DZHuS5CU3A6XOT43Lz0k8O49vj9GF6YyQflHnVy8yfw1/Gwe4O6t8sdebeoNHiKyfEnnvug6Rn7pFBoqFRf6aS1PmSmTTkhTUE7mvcJTCHhcztZ9tvjyfA4aW5T/9gblw8GILBzJU6gVmaS21ITvzkFWOUrjB7Mrb4B5NZUEQxKHA7b1RF5Ck6XMgcNL8rkp8eN43+PHcuJf/+I1jov3s8fUIO+fDLs3p3R5i0irzGFJT00YbjEPigU/jpWfb+pNj3Pa9oNfx4Fx/w6LCovZewlR7PWFHoB+ZkevC4n+Zkebv/ONEbup7QHWb4CgEqZT2tDTec3CpmP1CIfzBlMidhDRX1rh3FNWLkLTmf4Qi+E4KSpg9keLLQOGrsWR4Kagj+jmCJqQ4JOk1r2SU0h3dQZ5V2+ejk9zzN7l6TZ0ayFQi9DCMGsA6fTJp246rbix0k1uTTVJWCKCZrmI7Vwi9zBDKCGyrrmDuP2CMuJ7nR2/KM7ZvwAtssi64AhFJwJCgWZXUKBaGB3fZy2oJqk8bjntrAMfE0K8BvmHJcnPc/bS+YjLRR6IUU5mWyWKumrTXiplxn4mxLXFEwTjyN3MG4RoGnPrg7jGskKvXU5O5qEJgzOoTxMKChHc6KagiN7IAD11X0oAmnlv+GLh/b2LLrP1s/39gz6N2YymcsXf1yy0OYjjUlhlocNUvkV2oSXOrJwttV1fmGE+chdoEJYW2u2RYwL4MfBT9quYnVwOGQUEonX5aTGPcA6YOxaXAkKBW++Emq7K7Z1MrIX8cJl8PrP9vYsuk+04oea5GGac5zp1hS0UNjnKcrysNEQCq14qJcZeAINSCnjX2i043QY5iOfIRSCtRGluoN+/Dh5I3gIJ7XdSn5udtTbBXwFtjddMx8NHzYcgLXfbkhovCYJOBL73aSV2m0qYqc/YCaTpltTkOnNVtdCoReSl+GmNlMtqi14qCOLjEAjZ9/7SfwLTfORYQ7KKi4FQNbt7DDOL61ffXG2N+rtXJn51psWpam43IntkjxZSvvYumNnJyM1PUHaY9LSvKNMiL9PhodP2tuzSA5thn8sXT4FUzOxtc1NB73wr0gjhGDMhOkANATd1MsMXCLImq274l8YIRR8+UMISoGrMVIoBAjYfvVFMYSCN9umKbSosL9EzUf4lCPbkYjZq7uUL4eb8mBTJ8KyP2MXBIHW2OP2JrtW7u0ZJIc2o495us1HwfQWO9RCoZeSOXg/ABqDbuoMp3AecSJ52ppC6q3TZTiOnS52izwO3PksPHGO0VAIkIEwTaEoO/ofuS/X5mhuUY5utztRoaBqRvn8KTQdmA3Nv3mr+/do3gP3HKwETF/ELhTM6JjeQrCfhcmGNIU0mI8aq1VeBFjCIU1oodBL8eYNok5m0CI9eEtUldPRjh0hv8K6XfXc98G31gV/HAzzbwHAYbMt73YUkRlsgPXvWDudoJ92LKdkUVZ0oZCTZxMKzYZQ8CS4S3JnEhBOMmQjgWCEL+Sze+G2kYndJx7mDirBhLqorH8PKtdYTY/6GvZwxd6mKcTrE94XMYWCMw2+m7+MhlX/Vq/7i/lICDFMCDFfCPG1EOIrIcTVUcYIIcRdQoj1QogVQogZqZpPXyMnw8Oi4ES+lUPIH3MQANPEBpqMZLBz7v+M295aQ6s/ABVrwq51uKwFv8JTap0wS2VE+BR8UaqeAuQV2or7tat/CHei9lQhaHflkEsTTW0R6u/bv1Q7dH8PFzFzJ9oTodBo1HjK7EEb1L2JTVMItvc2odDc+Zi+hLmp6izgI9n0I/ORH7hWSjkJOAS4UggxKWLMScA442sucF8K59OnyM1w8cP2a/md//uIjALqM4czxbGB3Y1KlTywdREZtNDSHoSNH4Zda8872FFQZp1oNOrEBAP4peDkKYP47sxhTBiUE3UORUUdK74mrCkA7e4cckRTSJB1oKWH/oZkaArmZ+JLvCJu78LSFAL2UuvJprEK3vktBLqwQLX1s8RF8+dJ9SIdKUz7i6YgpSyXUi41XtcDq4HI2s9nAI9LxUIgXwgxOFVz6kvk+NyY//AZbicteWMYLiqUUKjdzsOev/JP9+20tgdU7wWDdunE5bR+rWLcHOumDRWw+j+waxU5NLPfwBz+dNbUsPF2BhQVdTjm6YJQ8LtzDU0hhlBoTZZQ6EF8fo3RDMlvW1DTVfAsCUhhFwop1BTe/AV8cies+2/i1/Q7TcEQCqlepO3FLzOL+6dPQQgxEjgAWBRxaihgKwXKNjoKjn2SHJ+1+83wOCFvCIPEbnY3tYXadB7m/IqWtkAoMggggAO3bZEfO3Y8h7Tcrd40VsAyVdhuvGMLLkf89Pn8KL4GbxeEQtCrNIXG1hg7q5YEsrTjPiAZQsH487MJ1nT/E/YIm/lIpkoofHCr6tkNXYuZ73c+Bcsnl1JM7bXsMjjoMlXAMo0mq5QLBSFENvACcI2UsltbQyHEXCHEYiHE4srKNJfK3Utkeyyh4HM7ceUNpUjUU1tXrxZ3g9aWxpATGFRbxtwMyxG2/9A8WnzFBBGqzLBharmy/Wqcjvi/fhGl5kpXzEfSm0cuTfhryy3bvZ2WHla3NH0KPYlyMYVBo+3vqi8JBdtiEeypjyYWH/zJet2VOjypFAr2RTJdC6apTQa7qCkseUyZ3hKlwQg9n3GRFf6aRhNSSoWCEMKNEghPSilfjDJkOzDM9r7UOBaGlPIBKWWZlLKspKSjnbs/Yi917XM7cRUoh3GgtjxMvWxvqglbXN0iQJ5NKLidDo4YP5g95CLrtkPtNvyjjuGz4ORONQWAk/Nf419FVoxAVzQFmVnMYLGb6c8dDH8Z03FAT4WCuXh3ZRFvqQsXIqZQsNflT7MNt0fYdu7pcTR3QSi0pVAo2Hfr6cr4NYVuVzchr12lTG+JEAzCyz9Rr7MGWJFOXRVEPSCV0UcCeAhYLaX8W4xhrwIXG1FIhwC1Uso+VEEtPeRluPEWGla1+h1hmkJ7c32HxdUuFAAOHVPEqsAI2rcshtptBHOUgHEmIBRyMtxUBCxHtK8LQqG19FByRZyFoaeOZtNmnegO2d+qMmzvOkAt/MGAVVm0j2oKwtYbQ/q74GjesrBrTmPrKYkPjdQU9mxWn31tEuph2YVCuqJzzL+3VG4aqtdbZtXsgVbpkjT+TaZSUzgMuAg4VgixzPg6WQhxhRDiCmPMG8AGYD3wIPCTFM6nz3LYmCI8BUqhcjWEawqB5jolFDzWwh0pFKYMzWNxcD881auhsQJ/jhIwLmcCQsHnYpffqqjq8UbPfo7K6GPin++JprBzVcg/krBQqNmqnNs1m6FyLbx1PaFFziZoe128fzyCAR7xn0CrdBFMNHlt+1J4+AT44I/hx3euhG/nx782EcGz/FnY+HFHobD0MdXBb9lTic0zHvaFOV2aXUhTSOHzKr5W3+d+AE6XpSmkUXtNWec1KeUCOtE1pcrEujJVc+jrvH/tUcp05HRAjgrKcjfuBG8UoTDqCFj7Bo3S20EojBuYza+ZwbWoZJiW0XPgvZ2JaQo+N+U2oeDrglDw5hbTJp14zK5gLbXh2aA9EQovXWG9DrQqQXnvLLjwBRgyPfo1ZqQFTCQ3AAAgAElEQVQRwOZPwewqJ5zh3ej6kPlIyAB1ZNKMF5mocDRt1jsj+n7ff7j6Hq+TWWdhr1LCS3PV6yOutY6ve9dqFpOMnX0qNYVnL1RRP6fdEX485FNIYaZ25RpAQPF49d5rbPbaGoABsa5KKjqjuRczuiSbIfkZ6o0vlyZ8+Fp2Qc0WaqRaqIOt9UrdLBjFv4+dz+ltt3QQCl6XE1fpAVyX9xe46CWai1S6SCI+hWyvi+2tmaH3GV0QClleJw1kWAf+83/hFTObE+zhLCVU2lp7tjaECxR/K3zzNjRVwcIYqS5tTfDGz633K56x3T/in7yvmI+M0NmgdNCGO3khqfGES6SmcP8R8OZ10a/d9bX1+smzLc2htwuF1a/Bkkc6Hu9pgbpEQp23L4GCkeAx/ufM/Jme+t+6gBYKfYhqZzHjGpfAjqWsCI5WB5tr1C7Cl0dFMJdv5dAOQgHgyHElPFcxlN2DDicQUCaTzqKPQJmPtrZaC3t2Rkac0eFkuJ00YgkUVr0Aa1633lcm2MP5i3/CPQfB1i/U+4fmQO0W67y/1VpwPJnh11auhS2LYP4flOkCIG+4+uczOe7G8GtSFcWTbAxhFsBBG67uh6Q2VsMGWwLkLQOU4I2GXShUrIGdK2DR/dYxe8LaN2+GX/vZPPU9GTtt+8KcLp9CSFPo5vM6M73t2QTr3oH9z7KOaaGgiUezM5dh7ZsAWClVPSRvo9ErwZdHbXM7HqcDn7vjr/XAEQVICWt31uM3diwJaQo+F+1BwU3DHuEh53fIyEu8HIQQgjfcs403hungtavU94mnKRu2lJbTNxbbFqvvu1apBaziq/Dz/hZLKLgjhMIT58DDc6wFKWcwjDzMOp8zWMWCjzrKOpYO89F7N6tObz3B+MyCOGiV7sTNRyEMf8rT58Hjp4efat4dvcCe6Wxd8ijce3CU8wlkMfd2TcHk61fD37d3MyTVJJpQ2PAhPHSC2qQ8dT4g4YCLrPNaKGjiMbx9Y+j12qDqt+BtMspi+/KoaWwnL9MdNb+gJEeZfaoaWkMF6hJzNCut49F1Xj4YcnmX+8W+U3ghcwc+B9+3/YMNmARjjoXWWmXn/9MweOq8jhdLqb7MMhYf/UUVCgv9UBNg8HRl7jGjiOxVQ6W0NIqjfwW/2AhXfQljjlPHDv0pXLtG/eOd8AfrunSYjz6+XXV66wmRmkKiQiEyrn/XVx3HPH4G3BIl/Nt8xlcvhR9/4BilXUSGoR5wYcd7JENTsAuCZApx+72euyj8XE99CtEyvB8/HbYuhEdPhcrV6ljBSOu8V1Ub1kJBE5W3BykHXuOQWXwQnEpACjKbjQheXx7fVNQzujgr6rXFRnnsqoZW/KZQSMTR7LViERJxTEcyMD+DdY1eKBgVOiYvfYtH1hlmqJ2rwN+sqriGBkh49acqt+G1q2HZE+p4XUQKy8FXgMurFqp6w3lq91mY40/+Kxx9HWQWgjsDJv8PnHI7HP1La+ygKXCpUcKhr0QfBe1CwZ34vCOFXrT+ALtjdMzzGwubvRQDwI6lSvuJrHdUaOSn5NoKFfiTUP4izHyURMdvrC5xwYClIXRXCEVqCrak05CQKxwdvvHSmoImHqtKz2e8/xlWz3mKOrJpIIOsFmU+CnhzWVNez6QhuVGvLcj04HSIME0hEZ+CvW7RFUdFSUDrhMG5Psprm5E5qmczY2fz6poG5i03dqv2WjrNe+Cx0+EvY2Hp4yqxbOlj0W985n1QdoklFBoMjcn+T73TaO4yaGr4tU4XHHQ5eCIEaLrC/yIdjg8eCy/+qOv3kZb5qB1X4v0UIjWKeE1jIj+Ltkb46mUrdNLOkkes34OJuTvOHmgdS0Z7zlSZjyIXX1OrCquN1YW/D/vvOlIo1Noq/JiC+uIIk5UnW2m/WihoojGsMJNWf5ANVWo3tksWUNy8CYB/LKqiuT3ApMHRhYLDISjM8lBV39YlTWH2xAEcNraIT68/lkNGdyyQ1xmD8ny0tAepbQnAz1bDeU+wfGst1eTSKDLDG+Tcd7iq+NpUBbmlYbkXIZxeGDjFyoFwetUO2UyIaq1XJTUaKqB8BSBg4OTEJhsqKdAGC+8Pj6pJJm0RTtztS8KjoRLFWHACOGiRbkQgweS1SI0inlCwL1wAix+G578f475tVsTRuY/B1SsszcHcFEBsJ3ZXsC/MycwbiFx8zcXaLki7IoTsgiAynLcm4rPd70TIHxZ+zOFQJiQtFDTRGF2cDcCKbUrtvNN/dujcv5ap7OBxA6OXwQbVi7mqoZWNVeqfMhFz0IBcH09efogVGttFhhUqx++anfWUywJwZ1Df0g4INstBVsw8QJ0t03XIdDh4brjTDWDELPjxAsg1iuk6nLDjS5UJCioz+e+T4W8T1QJWOBq82YlN1mWE27Y1wVvXqaga++57w4cq5NVuG/7inyrnoStECoXuYvMp1JGFO9HWp5GaQrweGXcdEPvclHOt10YeDSueVd8HTISCEdbPmqimEPDDf34GuzfGHmOOM0mmphBZudf8rOy/865kgtuFQqTZLFLgZsUo4ePL00JBE53RJcrc8cRC5TxdKK32FHVG6OeIwsyOFxoUZ3uobGjl1jdVU57CGB3Xkonp4zj/gYXM+tP7SCmpb1H/VKv8xq6oZAJkDwq/0JMNx/0WzpgXfjyjIPz91s/D3+9Yqv4Rg35lyhgwMfHJmuajzQusY6/8xIoSeuVKlQW91hZq+fq18EgXG9PbF8VXepC7aYs+qpOZuGO1Pm1rDM9U7or5KBqm83PcHOWsByhW7WOpXqe+m6a5Q69Smp3d4RxPKGxfAosf6vxzCTMfJdGnELn4mp+Vubi7sxITQq1G+Rm7MInUFGq3Kk3XjJjLjpGc5tOagiYGg3LDe8MOL7VUzUbUufzM2K0CRxVnsW5XA1UNbZw5fQj7D019Y5lhhZlhfrOqhjbqW5W6/0FwmjooHPDD9+HHn8LFrxgXHmRd9Ns9ylkMHYWCL4q57KDL4bBr4LCrYfZNiU/WXByrbU7Wlc9bUULmP6bpZI1mBnn/Fnj4xPjPsV/35ROJzy8Sm6ZQSxbe9hiL7UtXwL/OtExskeajrtRMAjj+d+p7yQS1SAIUjgofYy50xWOVZpc/wjrXFkcomAtuZ0XugikqcxFZj8v8rEzh4MlKzFx1+0S4dXh4lFakptC029AOjH+QWJqCK6Prv6MeoIVCH8LhENx61pTQ+4NG2W386g8rWjiqyZSheTS3BwgEJQeOLEzVNMPwuZ0MzLGE2YbKBuqa/WR7XXwQnE5d0XQ46TbIG6ps/6OPVnVfymzhmg4H5BkCMCNi3he/CkXj1Gtz4TnqOrVwHX8zFI/rwmQNIWmaouzYwzibjKbqu1Z1HPfRX2DLZ9HvL6WqO9TT5kImIU1BUCuzcMvW6GUoTL9N1TplDlv/njUfsIRUbmnHa00Ose3cyy6FX26DwVNVNBeoHa+dSCe+3YTX3gJv/xo+uavjc8xFWHTSI2PRP6zXyTQfRZr2QpqCsaB7sxMzH5mC77+/to5F/m6a96hNjpnbMXD/6PdyeRMPIkgCXRIKQogBQojh5leqJqWJzexJlm12amn4Tv/I/eKXFZ9amh96XVrQPR9Bdzhxf8s0tKGqkfqWdsYOyKYJH2/NegJGHRl+wZADOuZD5BkhjZGaQsEIuGIBfP81uOwduPz92Gp4Z7gz1eLWWKG0BnuLztWvWYt5UxX8eZQqKheLaDX+P38AHjwG1r7Rvfl1eIahKUjlUwA6mhmCActZ+q8zVV2izZ+o9+YC3NagzDw/fC/2s0rLYMThVmixWZPHNLkJR3ito0iTlL3mVXuzSiZ85zcdn2OaluLlw2z8GNb8x/YzJlEoRBbxa62HF35o1YnyZHf+vFgd5yI1heY9kJFv+WNGHh79OqcnrWHSCRXEE0KcDtwODAEqgBGo9poJhnVokkVhpvXPdvCoIk5u/SMFop7fnDqJSw8bGffasQOs3VppNx3H3eHG0yZx1oyhnHPfZ2yqaqS+xU/ZyEKWba1hV22CanHRWBh5hHI0R+L2WYIlZ2DH84kiBGQWqfLkWSXhKrs9kSlaw6BgUGk0Jm2NHR3cZohs+fLoz/e3Ws7uxmr49C449jcqhDYatuijWmkKhZrwzyAyn8Buztj4kaE9tKhFPmuAch6vfD78mus2KwFpL79gYpp5HE7lA/r4dvU+clG3v7cvvO3NShCbn51pvonXTW/lc+Hvk6opRAiFiq/V83auUO+9udHNR9/OV5pjZhEMnhb93tE0heJx8KOPlYCPJQjNsOs0kaim8HvgEOAbKeUo4DhgYcpmpYmJvflOSY6XdY5RfBKcwpnTh8Q1HYGKNjr3QGUiKC2I7ZBONkIIppbmMzjfx/aaZupb/BRleyjIdLOzLkGh4M6AH/wHhh6Y2slmGia5rJLYJoymKIX8Hj89vJ5SNMegudA1x2hDavc1vHYVfHIHfP1y7M5itjyFkKYQee/6HdGvNZlXpr57stXCfPY/lQ3b5Aevq91srL8t08lrZpJf9o7l/4mFfVH9wyBVl8rE1MbimY/2bIq4XxKEgpk9H6kpmGGjlSo4g8xC9Tx7OGmgXWlh/70BXv4xzI8oSW7SQVOoUZpvdkl4yG4kvVQotEspqwGHEMIhpZwPlKVwXpoE+c9Pj+Cpyw+mKDux6qW3nT2Vz399nOr7nGYG5/n4z4py2gJBcn1uBub62FXXy7KHMw2fRfaA6LtVh0uZjyLZ9DH8+1LrfVShYOz4q9ZGf7bdAVtlFAt84TJYEKNHlS2jOaQpmOU+QC0kb16vXv/gdeLitYUymwLg9LtjmzRMZIRQGDYTZv4w+tifLLKilewsf9p6nUiUzZ7N4e83fAg1W6KPTZQHjlKlPSKFQmTYqLl4P2kLx62LELx20xbA8b9X3+1aiJSWT6EzzFycNJGoUKgxei1/BDwphLgTSKDylSYVPHDRgdxxnuoZMH5QDoeOTbxIncMhGJDj63xgChiSZ+1A61v8DDSynXsVGYbfJXcI+IzXw2yF34rGWrvGSOy25GiLm333e8BF8J1/hZ+3h2rau5Otfi368wxfgR8nezBMVU+fB3VGI6YVz8E2I2S3eHzHYoF27KauorHquysBE6MZfeRLIJJtwITwuj4mZjgrWOajWHb5gF99NuPmWFrdovusXhDdpXy5SpxsqID84XD2Q+p4TYQAMsNx7Z367L8r+88SuiZbfZb2YoHtzWqhT0QouDy90tF8BtAM/B/wFvAtcFqqJqWJz5zJgzjzgKGdD+xleFzWn9uR44oZXZLFhspGgsE0NV5PBHPXN/xQOP9JOPxncMmbVoRT2aWxr7WHM0YVCrZ/t8n/09HnYDcf2Xes0cIzv3xC7W5R4cib5UD+m3GyOve3CfDXcfDq/1rjM4viL0D27PHxJ3WcQyzKLlW+hFkJ5lvYBVOWERBgFwCm+ShW2Gr9DqWdTDgFLn3bOh5PwwgGrWS4BXeoVqSgIpjWRzjX17+n5mgu7hs/Ut9nXAxnPaic6YWjreTJmi3w6MnW9cMOVjW5ZtrKlrizVDSWvS6UqdElqin0tpBUKWWjlDIgpfRLKR+TUt5lmJM0moQJGrbxe743g0PHFjN+YA7N7QG27elF2oK54x11BBSNgdk3KjNS2SXq+KQzwv+RD7rceu3vRFOwmwCySjqW8YiV6RzNp2BrJtQsvXhcTu7w/ljlDkTDLJcQC7uAOuJamPMHmPqd2ONNXB413pVg8yV7FNLZD8Lks8J33ebnFqsURq1R5DCvtGPYaywW/A3umg5V6+HdG62osTd/AU+cFf75+puVUIj8eU6/W30enkwYcajlV1r6ePg4d6YKsZ52vu1YhrrONB+t/o+V+xIZYh0NlzetjZ/iRh8JIeqJ06lbShnnr0yjCefnc8aT63NzvBFWa5bk+GZXPcOL0uf4jsuZ9ymHce6Q8OOH/ESZfHy5KoSweY8aO+VcVeoikmhCwb5TzCqxGrSbRCupANE1BVvCViM+crwuGtsDMGJGR/PWNUY4pX3xjcRjEwouLxz6v7HH9gS7puDLU76baEIhloCsN6oC5wy2Qjk7wyy6aJamjmTHl+HvPVnxhVxGocpV2b4UPo7w95h5GxlW+DeeTKUttDWoqLJnL7DORdY6ikZvcjRLKXOMhf9O4HpgKFAKXAfcEe9ajSaSAbk+bjh1UsiMNH5QDh6ng0++jeK43VtkD7DMJ3aEsLKnzdIZuUOsOH2Tw65W3zsTCplFHXe65m7Q7iyG6ELBFsHThJccn4uGFr9K2iu71JoHWAtPNAe5iTd2zayk4rb5KXx5kFWsTEa122DZ01b11cgS3Cb1RhXWnMHhEVHxtCATe3tQ+yJrhpuG5pgZnox33pPh5zOLlDnnwWOUKeuKBZa5yRR6mbbEUtN81N4E698Nv1deAuleTq96TldqLvWARH0Kp0sp75VS1ksp66SU96H8DBpNt8n2ujhu4gAe+WQTf3k7hvO2N3LK7XDsDSpvIpKcwWphiNQCIHz36/KE785B7f7bGuG5iCqkMqhMHO/eBNuMsFfbAtEsfWT7XDS0+pVQO/XvKpvb4YIJp1r3MXsaXLcJrt8Ks2zaQNqEgl1TyLdqXr12Nbx8hdqBg1pAozlX68tVMpdpwvuuUYAvXlkMUwDY80NusSU4vnZ1+Hh3RrimMPHU8PP2Bb9wjOrFYRb8M4WeXUiFzEeNsGF+uAktMxHzkVm9Nz3aQqJCoVEIcYEQwimEcAghLkBHH2mSwNWzlQP39RXlMcds3d2kFrzeQkYBHPn/ooesZhbFrmoZufv15SuH8/8YJRsCbaoyqxkxZCKDKjRywd/hn8cq81LQbj7yku110eoP4g/YFscbKuA8W22lS99WXxkFSuuxL1yRAipV2DWFjALVhQ/Cd9DmottYqTQIe22jhl0qLNTUEsafCMfcoARurAgdM6x0bSdhuWYkVWfmI7sAivw9mz+fXYvxZKnPt61JmapGH22dS6SToSlE0mRCSlQofA/4DrDL+DrXOKbR9IgJg3L51ckT2FTdREV9xwiL9kCQI/48nyv+tSTK1b2E0pnW68zCOELBcDSeYtihHQ4491GrN0SgTcXcRyKD4bH5lWvCFsoWPKG2qY2ttoqhDmf4opM/DIYfYr23awfxymcnE7tQEAIGTuo4xhQUO1eoMugf3Gqdq9vR0Zdg2u+jaWcBv6V9dIb52bTWdazlZGf0UVbOydHXh5+LFvbrzlRfjRVQuVa1kC0cA6UHdRwbDXufjzSQaPTRJinlGVLKYilliZTyTCnlphTPTbOPMGu0yrP4YE1HR+iq7WpxXbC+F/kdIrn0bcs2nFkcRyg0wNTz4aCI3sz2jm/RciBkMDxe/olzwvwDEkeobWpDWxc0qnSZjOxELpruDKtlp4kpFNYYO/vtS1To59evqlLpg6aEjzdNSaYvZsOHsMTo2Gea7Obc0vncRqsQXyrWxC4tAirX4rfVcFNtx0Q9d5TcDneG0hYadgFS1fa6ailc/m7HsdEwtZbeoCkIIX5hfL9bCHFX5FdaZqjp9+w/NJcRRZm8urxjSYYF69TiNzSNtZq6jMNhmXPiaQqt9dHDKM2dYFN1eNMhExkMz9iN4jDO8alFrLErZrZoZcdTjbnAOWwO+nMfVZ3aRhmLcpEhJMzqrkVjVLvS5y5SdvXInAgzy9hMInv8dFUmJBiwhEKs5Dp7Zdjhh6rvpnCAcC0wEexCzww39WRZv3fhCNfWEsHUWl6c27XruklnBfHMGK7FqZ6IZt9FCMHZM0r52zvfMOqXrzN74kAevLiMlvYAj322CVBmpF7N1PNUrSLTp1C1zjr37EWqiF7z7ugVXE2hECtk0jQf5ZaqBaVue4fy3NmGUOiS7yWaozzV+PKVtmRPAhw8VX2tf0e9N81DZqiqvwW2G0vQ+U+p5DE7ZuRP1ToYe5x1vGK15feJ5TP5/qtw7yHKNJNVDD9fb5mjrlkZ7lROBLsv4vJ3la/E5bWEwuDp4eGqXbnn1vSUm4srFKSUrxnfY3RPj40Q4mHgVKBCStmhULgQ4mjgFcDsu/eilPLmrj5H0z+46JAR/O2db5AS3vla7ZbNhkDjBmSzvrKB9kAQt7OXtgA57kaVxOXJUgufqSlsXwKrbc3Ys6NUcTXNRxWGUDj/KVV07bmL1ftgUNmjcwbCOUb5habdqny3eVuv6VPoglDILIRT70hrYhQOB5z1j+jn5vxBmWYmnKKc4GZ28/alao5n3KvOGVTUtTDzj+9x53nTOMObZ3V9M9n2hdWjwJsD40/p6Gz25qrfWXObMvNk28rP53ejO4Ddh1M0xtJ66oxACtv8E8YuaAL++KatJNBZ8tprxE9eOz3O5Y8C84DH44z5WEp5apzzmn2EgiwPGW4nze3KUVpe2xxyPM8YXsC6igYq6lt7rxnJ4bDMMab5qLEaHjw2fFy0aphCKHOKuTMeWhZe/jrQquzlmbYaVxGhjN0yH4GVqd0byMhXUV2gkvtMoWAKS7Mmk8G6CmUaeuaLbZxRPFYJD38rquGUVH6YAqPxkicbvvOY8lM8bwv59ebABf9WUV+xOp8lgxkXK9PgwVd0/Vp7b4rWusTCWHtAZ9uuv6L6KGxE1T560PhqQNU/iomU8iMgSo1hjSY63zvY2pm9t7qCynrlWCsbqRyJ89dU8MgnG0MmkjvfXcc989f3rtpJoISCDMCKZzqei9UAyOmxtItIZ2VjpQpljFMnxxQKZv/rPk+YRmX8fiN8IA5jVx6QUmWW71hqdHMzxu/eYPW+8GYrjWzMMdYNjrtR9eIoLVMlw+P1cOgMszNgLDPV8IPhwn93rHeVCPaaWfH6WyeJzsxHHwIIIW6XUtpLZb8mhEiGn2GWEGI5sAP4uZTyq2iDhBBzgbkAw4frhm/9lV+eNIGLZ43gp09/yT8/3sDp01Wy1TET1EJ6w8uqXMOa8npuO2cqf39XlZd+bvFWrjp2HNc+v5znr5jFQWlqNRoT02Tw7k0dz2VH0RRAhYSaVTSjRbBAxx3iGfeyqsoP70FRljIx7GlKoykolWRFqfwbkbXsNHqLBINS7cDn/zG8q93Xr6gvsCKt7A7nI36WvPme/BeVf1Cago4Czba9dbJaucYhUQNtlhAi5N0RQowCEqxGFZOlwAgp5TTgbuDlWAOllA9IKcuklGUlJSlU8TR7FZfTwYiiLK4+bhybqpuY9/468jPdFGd7GV2s/tw8Lgfvrt5FMCjxuR0UZnnYXN3Eb15RAuPZL7bGe0R62O8k5fyMZquPpymAin+PLJ1hEqkpHHABu0pPBJSm4HE5qG7oJ0IhWrx/RASR6V4KSKlMcCUTlLYAHctH2IsPXvginP80ScWbDdPOS+49TcbYnOdp0BQSFQr/B3wghPhACPEhMB+4upNr4mKUy2gwXr8BuIUQiTcG0PRbjp0wgP2H5hKUMCBH7YC/f+hIfnz0GG47ewrVjW18uXUPLe1BLj9iFGNKsmhqU76IbG/PnXD+nkY6ORxWfSSTmT9SpZdjLfimUIi2GE40qtRHqahpFvgUAoqyPFQ39hOhYDpTzZ4OwtkhnNdptPAMmObDkvHquzfX8iWY2M02Y4+DCSfTZ/Dlqt7jEF6ePUV0+h8khHAAdcA4wKzLu0ZK2aNMCiHEIGCXlFIKIWaiBJQux61BCMH/HFDKqu1fM8xoG/r9Q0cCsGan+qdYslklKhVmehicl8G3lT2vuiKl5IonlrBkcw2LfnVcyDzRLXIiqqwOmR6/FLUpLKImPxmLobtjcySzHLlDCIqyPVQ39LJOdt3FYfs8/M1qUY9REsL8DBhzLHz5L5X8Zt9RO9yJl/burZj+lL3tUwCQUgaFEPdIKQ8AYnQc74gQ4mngaKBYCLENuBFwG/e8HzgH+LEQwo9yYp8vZaxmtJp9jYtnjWDioBymDguP6TaFxPJtyilbkOVhUJ61WFb1YFFcXV7P21+pcNiapraEW5xGJTeiFENn2cMhTSFGRix0bPxOeGhgYZaX3f1FUzD7QgycrFqdBgMdhpgaQkix2/8s5XfJHw6f3Anly9Tx7jh3exvm309rAu1Ke0iiuvZ7QoizUbkECS3cUsrvdnJ+HipkVaPpgNvpiNpmNMvrojDLw7Itqs5NYZaHTFu/6Z7Y1D+xldLY09TeM6EQmbkcy3lsEtIUbOajX2xUi2HDTrUD3m9Oh8vM/0aHEBRnefi2IkYfgr7GzLlQbISgbvo4an8FU0MIBG3mvtFHq+8n3qqywL99PzyUt68SEgq9x6fwI+B5oE0IUSeEqBdCpN64pdFEoaU9wPYa1YimINPDyCK1AA/K9VHdqDSFd77exZVPLaUryufizVaUR4+jeCLr+3c2DVNTiCyrnF2iav38tjpqf2Pz5xNCCch+oyk4HDB2tlUHKQqWphDlw3VnwKgj1euuZhD3RtyZyq+SBp9CogXxcqSUDimlW0qZa2u+o9GkndOnWfb6oiwPF88awfyfH83sSQMor2mhuS3ADx9fzOsryqnqguawp6mdLEPr2NPTxXXSmaq/s5mM1Vl2rFnfJpqjOQ7mcigEFGV7aW4P0NSVoni9nTjd1cz8lJhpKma0Uhc/016JEDDn90pQppiEzEdCCAFcAIySUv5eCDEMGCyl/LyTSzWapHPLmfvzv8eO5cstNRRkqR32qOIsTp82lCcWbuH6F61OWusrGijJScwM1NTmZ1hhJmt21vdcU3B5VH9nKeHAH6iewvGI52iOg918VGR8FtUNbWQWprYUQtoQAk68LapQDcg4mgJY2lqivZx7O5GFAFNEouaje4FZWD0UGoB7UjIjjaYTXE4HpQWZnDYtPMJn5qhCZk8cwCvLrGqr331wIZ99m1hQW2NrgNICtSjvaWrvZHSCCNG5QID4juY4mHZ1ARRlG0Khv5iQTGSQvigAACAASURBVA65ImoIqT+e+QhU/SjoH5pCGklUKBwspbwSaAGQUu4B0tSVQ6NJnEsPH9Xh2K9eWkl7INhpOYzGVj/F2V48LkfPzUddJV6eQhzs5qNCQ1PY3dhPwlI7wTIfxfi9mv6ZKL4YTWwS1THbhRBOjL9BIUQJ0MtrGWv2RQ4dU8zMkYUU53g4fdpQPlpXyVOLtjDj9+8wdkA2z/9oFq4YlVYbW/0quinTk/5yESHzUcdchHhYjmZBsREt1RU/Sl8mrqMZYOLpcNqdMC1uIKQmgkSFwl3AS8AAIcQfUDkGN6RsVhpND3j2R4cgjESnKaV5PLVoC/Utfr7cUsOC9VUcPb5jqYlgUNLUHiDL4yQ/083uxiSZjxKlu5qCmdGMpSn0m1IXnRDszKfgcCh/jqZLJCQUpJRPCiGWAMeh/v7OlFLG6Aii0exdhC3zNbLU9pqd9Rw9fgBSytC4JZt388bKnUip8iAKMj3UpFtTMDu3xaqyGQOJpSlkepz43I7+k9XcCWbSWkDnvCaVztpx+oQQ1wgh5gFHAf+QUs7TAkHTl/jnxWUcNLKAoiwPK7fV8uSizUy/+Z1QqYxXlu3goQWq11OmkRy3O91CYfwpKvGqiztbM2/LIZRgGFGYxdpdqU9w6g34jR++15VO7+N05mh+DCgDVgInoforaDR9itmTBvL8FYcyeWger68s59cvraK2uZ1/L1E9fe3ROtleZT6qSVb0UaJMPRcufgXyhnbpspCjGaX1zBxVyJLNe3p/+9IkYJqPtExILp0JhUlSygullP9A+RGOTMOcNJqUcPnho/jBoSN54rKDOX7SQN7+aie7G9vYbbPBZ3qUplDT1NatHaiUkp89u4zPN6anv5Q9oxng4NGFNLUF+HpH/y84YMo9f7D/C8B00plQCG2XpJT9KE1Ssy9y5H4l3HT6ZA4fV8w1s8dR39LOne9+E1YaItvrIj/TQ1DC9x/pem5mbXM7L365nYsfXpTMqcfEXjobYFqpKumwYnvqC6d1h92NbWzd3ZSUe4VCUrVMSCqdCYVpRq2jOiFEPTBV1z7S9AcmD8nj5CmDeeyzzWE2+KCU5GWo8NCP11Xx+GebunRfMxzU7Ug0Bahn2B3NAKUFGeRnulm1rXcKhRm/f4cj/jw/KfcKZTRrR3NSifuXK6V0GrWOzHpHLl37SNNfmHtkqJkgp0wdzLETBnDA8AK8Luvf4revfNWlaB5zrMvZg14MXcAqc6G+CyHYf0geX5X3PqFg9sJIFp1mNGu6RXq2MxpNL2TykDyuO1HV7S/M9PDwDw4i2+vi5CmDue3sKaFxXak8ajqtYyXIJZtgKE/BEkIjizPZurs5Lc/vCjtrO/aD6Ak66ig1aKGg2ac5erzq+T211Or/63QIzjtoOHd99wCga0LBbPLj7knXti5gmY+sY6UFmdQ2t1PfkuYIqk5I9o5eawipQQsFzT7NxMG5LL5hNucc2LFo3ZgSVV2zKyUvTJ+CiNE6MtlEOprBStgze07saWzjpS+3pWU+8WgPWIt4j/tgE17zSDdtTB5aKGj2eYqzvVEXcbNshL1i6ubqRmqa2mjzR1/UTJ9CQ2t6gvVCIak285FZ6XX7HiUUznvgM/7v2eXsqrPMN0s2707KwtwV7KGjLTE+v65g1xSSVtVWo4WCRhOLgkyz6qja/X9b2cBRf/mA6Te/w/UvrIh6jalV1LW0d8nmXVHXPXu7vUqqybBCVT9pY1Uj/kCQb3Y1GM9QAmv51hrOvu8z7nxvXbee2V38Nk2hua1jz+WuYo86qqhPrr9iX0YLBY0mBj63k0yPM1RG215O+8Uvt0e9prZZ7VilVIIhEZZs3s3MP77HK8ui3zMepuBx2KRCcbaXIXk+lm2toaLeipyqbFALZ7nh8F1dnt5yGPYs66QIBZuQMQWepudooaDRxKEg0+p7bDcJDYjo5lbb1M4n66uoaWrH51b/Vgs3JJbVvHan2sl/sr6qy/OzylyEc8CIAr7cUhMSAACVhoAwbfFp8oWH8Ns0p+b2ZGsKWigkCy0UNJo4jCjK5CujZER9ixIKXpeDPU1tYTb5P7+9hgv+uYivdtRxwuRBFGZ5ePurnQk9w23kNNjNK4lib8dpZ+rQPLbXNLN2p6UNmELB9IdEXpNq7J9XMoSC3Ty3q5vmN01HtFDQaOJw7IQBrN1Vz9bdTSFN4cdHj6E9INlRYy1EdsdzUZaXsQOy2VGTWK6AubS1dcPxG7Q3VLBh+hXMSrBgCQUzVNWZZlXBHn3U1NZzR3xASpwOQY7XFfrZUs2/Fm5m1C9fT7uTPp1ooaDRxOGYCaohz4L1VTQYmoKZ07CxujE0zu5Tzstwk+tzU9eS2MLXaAibWBFNiRC56R9ihKUu2bybTI+TMSVZ7DR20+a80qwohEcfJcN8FFSCLdvnCn2GqeY3L69CSmhMgk+kt6KFgkYTh9HFWZTkeFm4oZr6lnaEUJnQAJuqLKFgb8qTn+km1+eirjkxR7MpbLqjKcQyHw3JV209N1U3UVqQwf5D81iyeQ/BoAw5w9NdXjvMp9CWjJDUIE4hyHA7kxLi2hVa/VooaDT7JEIIDh5VyKINu/lqRx3ZHhcDcrxkeZxstAkFe4JbUEpyM9wJZxSbZqmGBDULO8FQnkI4xVleXIZ56MARhRw5roSqhja+Lq8LCat05VKY+JNtPjI0Ba/bmZRopq7Q2q7NR11GCPGwEKJCCLEqxnkhhLhLCLFeCLFCCDEjVXPRaHrC9GH57Kxr4b01FdS3+lWHs6Is3vl6Fw9+tAEpZVjylNMhyPW5qG/1J5SrUG8sztG6vXWWqRstTwHA4RAUZ6sIqYNHFXLEfsUAfPhNZShUtqE1vQup3Q6fDPNRUEocAjLcjrTs3O2/i2TMv7eSSk3hUeDEOOdPAsYZX3OB+1I4F42m25jmIjsTB+eyvaaZP7yxmre/2smepja+O3M4N58xmfMPGk5uhhspoSGBHbGpIeyJqLFUXtvMqF++wWvLd8S8Npb5COD5K2Zx7fH7ccLkQQzI8TFpcC4ffVNJXbOpmaQ3C7g9aNcUkuFTUI5mn9uZlkW63qZZtWhNoetIKT8C4gVqnwE8LhULgXwhxOBUzUej6S6Th3asEn/wqMLQ6+cWb6O2uZ2SbA8XzxqJx+Ugx+cCSMivYJpx6lv8YbvRj76pBOCNleUxrw3G0SSGFWby0+PGkeFxAnDomCK+3FoTqomUfvNRkAy3E6dDJJzYFw8z+sjndiYlxLUz7CYj7VNIDUOBrbb324xjHRBCzBVCLBZCLK6srEzL5DQak1yfm8cunUmOz8VR+6mqqjNtQuH9NRVICQVGrSTzGrByG+Jhagr+oAzbgS43GuUMzPV1eo9EIokmDcmlzR8M+UJqm9vTuri1ByQupzCc8EnwKQSUUMhwO9Oycw+GmY+0prBXkVI+IKUsk1KWlZSU7O3paPZBjtqvhBU3zuGxS2cCMLI4i49/cQx/Osvqu2DWSgLINbq3JaIp2M0S9h306nKVNFcb5x7RylzEYuJgS+OZPXEgLe1BXjbKdeyoaY77nGTgDwZxOx3kZbiT8qyAlDiFwOt2pMXRbC/Ap30KqWE7MMz2vtQ4ptH0SiIrqQ4rzGTsgOzQ+/xMd+i1qSkksvi1tAdCO327ENlmVDmtitP5LVaZi2iMKbHm+r2Dh7H/0Fzu/3ADgaDkoocWcdtbaxK4S/fxByQuhyA3w50U81EwKHEYmkI6NJ4woaDNRynhVeBiIwrpEKBWShnbeKrR9EJKsq0aSHZNocSojVSZQCvP5rYAA3OUiaiupZ2NVY00twVCWbrVDbH7OcRzNEficTlCvpARRVlccugoNlY1smZnHVv3NPPNztQWyPMHJW6ng1xfEjUF06eQZk2hP4ekulJ1YyHE08DRQLEQYhtwI+AGkFLeD7wBnAysB5qAS1I1F40mVRTbCuMV2nwKxdkehIBdEdU7X1m2nZqmdr5/6MjQsRZ/gOGFmeysa+HjdVXc8e46fmCc9zgdVDfGFiyhPIUEs5MfueQgPvqmijEl2aFCf1t3N9HmD7Jld1NiN+km/kAQp0OQl+GmvLbn7UIDQZnW5DV7Ab7+rCmkTChIKb/byXkJXJmq52s06SDLiOyBcPORy+mgONvboU/C1c8sAwgTCs1tgVDV1flrVSDFe2t2ATBtWB7LttYgpYzaCMjKU0hMKmR6XJy4/yDA0mzWVxj9FupbaW4LhKKVkk170HA0Z7ioTYajORSS6iAQlLQHlM8iVYT7FPqvptAnHM0aTW/Fvhhne8P3WINyfTGrd5qhp8GgpNUfpMQwH63bpUw4Zie18YNyaA/I2HWUpOx2DaMCQ4h9W2llZm/b8//bO/f4OMsy73+vmckkk/OpOadNT0BbKCkEKBTkJAeVFRQUWFfQBREWhHV1VdZXXl/Wz37A3VdQV99dBAUFkVU8sMJyRkVAoAVKKW3pgZ7SpmnSnE+TmbnfP55DnplMDk0ykya5vp9PPnnmnifz3HeaPtdzXdd9/a7UeQuRaIwMn8/KKfQN8uLWg4fViCgRb50CTI3y6ljXc9BEs6IoY5L4tF6enxkXPvLeAJ0tmQN22KM83/IUnKIup5PYwlIrOdw6Qm4iZsaXZE5GQSgDkSFPAeC8u/7EqztaJ/iJoxNxt6RmEI7G+PR9r/HQq7sm/HlWRfOQUUj1jToup5BmraV0okZBUSZJkSds5KWqMMS7+ztZ/S/PcagnHCdjcfztT/PC5mb3RlYYyiCUMRS2ccITC0stCezWnuTJZkPysNJ4CNhJ3+0Hu+PGv/jIWxP6vLGwwke+uAZF+zqGe1LtvWHW7hy7QVGip9A/BSJ7Y13PYSDNnsJYcidTiRoFRZkkf/zK2az7Xx8cNn7dBxYB0NTZz7pdbTQl3AB/+IdtbsgjK8NPZWF8kVpmwEdFviWBPZKnYMzkOqgV5wSHSU5kZ6Ym1WiFj4SFpTnumNcQOnzmJ69z2X+8MqaKa9TgbkmF1Cd/o9OkffR3D61j5TefZpdHqj2VqFFQlEmSn5VBSW7msPGaomw23X4hPoENjR1xrTEB1u/pcLdmhoJ+CkLxHkdeVgaluVYyuGWEbalW+GjiVsFJjjvXASuc9OQ7U7873AkfeY1Csj4I6/e2A/HKs8mIxay6B0dSpL03tcV3sWkKHz2xoYmugYhb4Z5q1CgoSgoJBf0sKctlY2MHTfY2zCtOquUbFy0nHI2x1u6MlhnwD7u152cFXOmMkWoVDJNIKjDUjGdZZX7cTqrrH3xj4h86AoN2RbN36+6hJGGxDJ9vxPe8ROx+Ck6XuZRvqZ3iHtPjxYkOpquRkBoFRUkxx1YVuJ5Chl/4l48dx7l2R7d391lPf6Gg380NOJLXeaEMMvw+CrMzONg90i6myYWPzltWDlhG6YV/PMt96k7Gbb97h3+YRL7ByQGICB+0r5vMG3DahI5pFGzPo7owhEjqjYLXU0jXDRqGChMn0m9jQtdLy1UUZQ5zbHUBzV0D3Pvi+5TnZ+HzCdVFIfw+YdN+awtqVsDHmiVWz4NllXmA5SkALKvI59UdyROvxphJhY8uPLaCS+qr+PIFR1GWl8Xdl9e77yXGzTc0dvDH9yYuSDkYNQRsL+Deqxs4fUlp0gR6wD8+o+AkroMBH1UFIfak2Cg4OQWfjE/ocKpw/nW71FNQlNnBsdVWP4ZwNOZ2Q8vw+6gtCrG5yRK9CwX93HLuUp79hzM5+2jLi3BqEy5YUc7W5m7eaRweU56sp5CV4efuK1ZxTIUllnfusnK+d+UqAHa1xt9ku/sjtPaER9ViGo1INEaGf2iyRTnBpDf+wLg9BStxDTC/ODvliVgnfFSYHUybUQhHYu51NXykKLOE+tpCTre9gJ2eG+2Ckhx362mW3WdgSVkupy+1zl2/x0q4XrKqmtLcILf+ekNc9zKwE80TrV4bgfl2jD7xydvpv/DegcPXSGrtHmBrc3ecRlNFfiZNHf109A7G9XZwzhlv+Ais3Eji7q6pxgkfFYYy0taLwqvppOEjRZklBAM+Hrz2FD5+QrX7FA6w1KOw6t2aubQsl3l5mXzjouWA9WR6+8XHsqGxg9++Fd+FzWAmk2dOSoXdv+FAV/xN1rkpTUQ476evWEVqkdiQUasrzWEgEuP425/m6h+/5o47W2THDB95ZC3K8zNp7hqYVIX0WDh1CvlpNAq9g0PXSdc1U6Z9pChKPN/5ZH3ca29Ht8yMoeczEeH1r8fXPXzo2AqCAZ8rg+FgDJPafZSM0twgPoEDnidvY4zbWnTLge5hP9PY3kdpbpDMQHLdpF77Z79y4THumHdr6jp7F1Y4EnN39oy1xdTZzQRQUZBFJGZo6RmgLG/spkQTIeqGjzLYuG9wRD2qqaTH00dbjYKizHKWVw71fi7JGV7n4EXE2mXjtNJ02NvW6z7ZTxWOmJ9XoqM3HHVluhPDRwORKGvueJ5L6qu4+4pVJKMnHKU0NxjX08FrFCrys7j+Z+usLbY27WPIazv9GWCoO92BjhQaBTMUPhqMWppVWUmK76aSuPCR5hQUZXazeF4Oa5aU8KOrGtxtmKNRWZDFPo9RuPvZ93h2UzPLq4b3kJ4s5flZvLS9xX3Cd25ImQEfm/d3xjXJaeuxjh8fpZd0z0CEnIRK6fK8LFZU5ZMd9NPU2c+TG5t4auMB9/2xei5Y7T1tT8ExCiMIEE4FUU+iGdKzA6nH/v3nZQU0p6Aos52A38dD167mvOXl4zq/qjAUVxV997NbAagsCE353Nr7wuxt6+P7z28Dhm6AnzplAf2RGD98Ybt7rhP7j4wSz+8ZiJAdjDcKPp/w+M1ncMu5S4edX56fOWYr08FojKCdaK4osIzC/jQYBafyPB1P7o6nUJ6fpZ6CoijxVBWGONDZP0wT6OL6qim/1l+fvACAnS3WNs8v/3I9AKcvLeHo8ry4EJJTgJZMs62tJ0z/YJSegSi5mclDLUWeCmeHpWV5tI8hcxGJxlxPYV5uJkG/j70prFUYZhQ8T+7ffGwjr2yfenVZx1Moy8tUo6AoSjyLSnOIGXi/pQdjrHj63521mGWVUx8+uuGsxdTXFtLVHyESjfGWvT02JxiguihEY9tQGGs0jaJV//wMf3v/6/SEh4ePHEqSGYXyXDr6BkfdTeQ07QHL66gpDqW0qtnpclfi6FHZHfEOdg1w/8s7ueaB16f8mr12otkxCulQS1WjoCgzBOfmv2l/J10DESIxE9cXeqqpKsxiX0df3NbQjIDPTXg7N6i2EbaOOqGPl7e3WjmFYHKjUJhEeryqIETM4O54SobTtMdhfnF2So2CEx47usKqOHe25m6xvxcnMW6TxdmJNS8vk6jdkCnVqFFQlBnConk5BAM+3t3XSbud3E12Q50qKvKtgrCDdgVzQSiDFVX5VBeG6B6IuI2CDvUMxf69VbdNnvh+z0CUnBHCR0dX5HPqohJ+/4XT3TEnRNMxwrbUaMwQM8S135xfnM3GfZ0jyoxPFsdrKcnJpCI/i037rWp0pyq9unDqczth2wgU27vT0pHcVqOgKDOEDL+PZRV5PLJ2D795sxEgpZ5CZUEWveGo25ntvqsbyAz4qS6ybn7b7OY83vDRUxub3OP9np1SXf2DI4aPcjMDPHzdao6tLuDyhlo+clwlBbaxG6lWwcmrBDyyGacsLAHgtsc2Ht5Cx4mTU/D7hGWVeWy2PYT37bxLMDD1t9Nw1DEK6Utua52CoswgTllUwvq9Hdz17HtAaj2FlTVWHcWv37AMkKPeetriErKDfh56dRcnLiiiuavfrTn43Vv7eGN3G2cdVRa3pbQnHB0xfOTlzstWArCt2brhbtrfyXE1BcPOc0I5Xi2lj6ys5KmNVby8vSUlhWURj1GoLAzxtt3fwAmTpeIp3gkXOcY/HdtS1VNQlBnECfOL4l4XptBTOKmumIr8LFcZtdRuo1mYHeT85eW8tK0FgJ0tvdSVZHNsdQGb9nfy4F92c+1P17K1Ob7yeSRPIRmL5+VSlJ1hdacLD+9d4GhABXzxt7BTF5fQ0h1mQxLxwMniJJr9PqEglEFHn1XV7MT9u/qnvslPOBIj6PeRl5U+T0GNgqLMIC5YUc6PrmrgkvoqjqsuoKZo6uPYDj6f8H8/ebz72tuE56iKPA50DtDZP8jO1h4WlOSwsCSb5q6heP4v1+6J+7zcUXo1JCIirF5Uws7WXn780vvD3h+MDvcUAM49pozS3CD/9JsNceMPvLyTX7y2e9zXT4azE9gvllGIxAy94ajHKEz9DTsciREM+Mi1DaqGjxRFiUNEOG95+bgL3ibLmiWlvPS1c9hzqDcuHLOo1JKrOOPOF+gNR6krySY/oZ1oa0+Yz5xWx/0v7wSsCu7D4Y5LV/LnrS38YUszN569JO49J6fgTTQDlOVn8fETavjJS++zt62XmqJsojHD/7bzDN0DERrqiqmvLTysucBwTwGsqmvHk0nFDTscjVpGIcsxCqltOQrqKSiKMgbVhSFWLyqJG1tSZt3gnbzB4rLcOC0jh4+srHSPnb4S46UglMFVpy3gjd3tw3YURWxPIeAffgurKshiMGo4/c4XaOuJDyV96/FN3PTzibUada6ZaBT67bh/bzg6TNp8sjjhoyFPIfVtQNUoKIpy2NSVDBmA2y5azprFpXFFdPPyMinNDcblQPKzDj8pfnF9NdGY4dE39saND8YcT2F4MrnKszW0sb2Pt/e2x71fkju6+KDDk+/sZ7en/4W381qcUfDkPHqm+KY9LHyUhkRzSsNHInIh8F3AD9xrjLkj4f3PAP8KNNpD/26MuTeVc1IUZfIE/D6e/PszeOqdA3x2TR0iQpZvKOfwzb9agcHqyfzcl84c1tpzvBxVnsfR5Xm8sr2V6z6w2B13PQVfEk/BYxT2tfexty1eWTapHgeJpxiuf/ANsoN+3r39QsCqU3B6TMeFjzxr6+wfdLfTTgXhqGUUsjJ8+H2SlvBRyoyCiPiBHwDnAXuB10XkMWPMuwmnPmKMuSlV81AUJTUcU5HvtvF0+NFVDazddSgubOSVy54IC0qy2ZnQanMopzDcU/AWke3v6I+T5ABLlsIYY7UyHUGd1mn00+vxAiIxg9/OqyQahfJ8S2q8tSdMrd25bioIRwxBvw8R4YsfXMqqhN1nqSCV4aOTgW3GmB3GmDDwC+DiFF5PUZRp5rzl5dz6oWVT+pmO1pJX92ekRDNYAnvfvtSqd9jX0cfetnjpi5buMP/29BYW/dMTbkFaIslku2PG4Dgm+Z6K6/5wlNoiyxC0dE1tNbXjKQDcdM5S1thtXVNJKo1CNeDdk7bXHkvkUhF5W0R+JSK1yT5IRK4TkbUisvbgwYOpmKuiKEco1YUhesJRt7p5IBJ1t74GkngKAJ88qZb5xdnsbbPCR95GROFojB/Y0t8j9V9IZhSiMeOGq/KzAmQGfBzo7Kc/EnW9g4NTJLHRPRDhq796m4NdAymplB6N6d6S+t/Aw8aYARH5PPAAcE7iScaYe4B7ABoaGlIvE6goyhFDjf0U/tbedrY0dXHPn3a4In3JcgoOK6ryefxtq/HP1z+8jLW7DrGiqoDvPPOee86eQ71xOYjO/kFefK8lTtzOqY6OxgxOtElEqCkKsbO1h8GocetFpspT+O2bjTxi13mcsTT13oGXVJqgRsD75F/DUEIZAGNMqzHG+S3eC5yYwvkoijIDWVlTQDDg47M/eZ07/mdznGprMDCylMVpnlDL5SfX8p+fbhgWfklMQj/y2h5u/Pkb3PnkZnfMuV7UTjQ71BZnu1XbBaEM8rMCtEyRp+A1SsEkIbJUksqrvQ4sFZGFIhIErgAe854gIpWelx8FNqVwPoqizECqCkNcf+bQzqPS3KEb5miewvnLy6mvLeSeT5/obodNLKBLNApOgZrTPwLgRruuIWoSjEJRNrvsLatZGX5K8zJp6R69MdB4iXnyJ8nyJqkkZVczxkSAm4CnsG72/2WM2Sgit4vIR+3TbhaRjSKyHrgZ+Eyq5qMoyszlEyfWAHD20fN44uYz3PGRcgpgtbD87Y1rOH9FhTvm1Yoqy8tk16H4XU19CVtnqwtDbGu2zolGEz2FobBTVoafsrzMKesR7dV7mlU5BWPME8ATCWO3eY5vBW5N5RwURZn51BZn8+A1p7CiKj9OGXYyT9FLynLZcTDeKPSGo4gMlTJ8avV8vv3kFjr7By1PwSP14S3MC2X4qSnK5s9bWyY8Hy/9nmY66TYKWtGsKMqM4PSlpRTlBBERvnCOpYU0Eenw3964hv/6/KksKctle3N3nDRFbzhCUXaQM4+aB8ASu8Zie3M3sZiJq2vw6ictmpdDbVE2B7r6GYhMvqrZWyU91dIZYzHdu48URVEOmy+dfzTXnrHILSI7HJybudPWdMnX/4fvXlHPxfXV9A5ECWX4ue/qBsLRGPs7rHDQx374MgB1JUOFaQG/j+9eUU9mwMeyynw27e/EGGhs62PRJAv2vGGsthEaDaUKNQqKosxIJmIQvJxUV0yGXxiMGm75xVv0hqP0hq22oQG/j4Dfx8KS+MR0YgX0xfVDpVdOrcKeKTAKXlmQQyP0wE4VGj5SFGVOsrwqny3//CGOs9Vbb/31Blq6Bwh5OsT5fBLXR8I/Sje3BbYXsT2hudBE6FOjoCiKkn58PqHT0zFt7a62OCMA8PPPrXaPR0tsz8vNpCQnyOamzknPq38w6s5jWWXepD/vcFCjoCjKnObmc5bGvc5OMArH1xZy3QcWASTtGeEgIiyrzGdzk9Vf+pHXd3PWv74wor7SaPQPxijODfLYTWu46/L6w/75yaBGQVGUOc2lJ9aw846PMM/uQZ0dHJ5qdQxF9RjtT5dV5rG5qYu+cJSvPrqBna29NHX285cdrfzNva+Oe2dSX9hKeK+sKXT7M6cLNQqKoijAItsLWaD8uAAACP1JREFUSPQUwHpyB6vgbTTOPKqMcCTGDQ+tc8d2tfbw5V+u58/bWli3s21cc+kbtIzCdKBGQVEUBdzOcbEkTXiuPWMhn2yo4cqT54/6GacsKiYrw8cftgypOe9u7cVnJ6j/sqN1XHPpH4ySqUZBURRl+vir46sAXD0jL6W5mXz7suPJyRx9F3+G38eLX4kXet7c1EVju6Wx9Oae9mQ/Noz+afQUtE5BURQFOGF+Ibecu5QLPFpJE2FeXiYvfuVswtEY1/10LY+u20s0ZsjLCgyT1RiJvsEoleopKIqiTB8iwhfPO4rlVfljnzwGtcXZLJ6Xy0l1xXQNRAD4+KpqGtv7XLG7zU2dxEbYmdQzEE2a20gHahQURVFSxMkLiwEr/HSSfbz9YDcb93Vw4d0v8oWH3yQcGa5t1Nk/6Lb8TDcaPlIURUkRHz6uktbuMBesqMDnsxRPL/r+n916h8c37GdfRx//9onjWWxLY8Rihu6ByLQZBfUUFEVRUkRWhp/PfWAR80uyqSnK5uHPrSaU4ef9lh7qSrL51iXH8ubudq7/2dAW1q6BCMZYfaCnAzUKiqIoaeLEBUU88Lcns6Iqn29ctJy/Wb2Ab1y0nK3N3exqtZLQnX2W7IZ6CoqiKHOAkxcW8/jNZ3DusnLAahvq9wmf/9k6drf2ulpM+WmuZHZQo6AoijKN1BZnc+9VDTS29fGtx9+ls8/arZQfmp7wkSaaFUVRppmzjynj0hNruP/lndTZSWj1FBRFUeYwH1tlNey55087gMk3EZooahQURVGOAI6vLeTRG051X+dN0+4jDR8piqIcIZy4oJi7L69n96HeafMU1CgoiqIcQVyyqnrsk1KIho8URVEUFzUKiqIoiktKjYKIXCgiW0Rkm4h8Lcn7mSLyiP3+qyJSl8r5KIqiKKOTMqMgIn7gB8CHgOXAlSKyPOG0a4A2Y8wS4C7gzlTNR1EURRmbVHoKJwPbjDE7jDFh4BfAxQnnXAw8YB//CjhXxO5bpyiKoqSdVBqFamCP5/VeeyzpOcaYCNABlKRwToqiKMoozIhEs4hcJyJrRWTtwYMHx/4BRVEUZUKk0ig0ArWe1zX2WNJzRCQAFACtiR9kjLnHGNNgjGmYN29eiqarKIqipLJ47XVgqYgsxLr5XwH8dcI5jwFXA68AlwHPG2OSNy21WbduXYuI7JrgnEqBlgn+7ExF1zw30DXPDSaz5gXjOSllRsEYExGRm4CnAD/wY2PMRhG5HVhrjHkMuA/4mYhsAw5hGY6xPnfCroKIrDXGNEz052ciuua5ga55bpCONadU5sIY8wTwRMLYbZ7jfuATqZyDoiiKMn5mRKJZURRFSQ9zzSjcM90TmAZ0zXMDXfPcIOVrljHyuoqiKMocYq55CoqiKMooqFFQFEVRXOaMURhLsXWmIiI/FpFmEXnHM1YsIs+IyFb7e5E9LiLyPft38LaInDB9M584IlIrIi+IyLsislFEbrHHZ+26RSRLRF4TkfX2mv+PPb7QVhjeZisOB+3xWaFALCJ+EXlTRH5vv57V6wUQkZ0iskFE3hKRtfZY2v6254RRGKdi60zlfuDChLGvAc8ZY5YCz9mvwVr/UvvrOuD/pWmOU00E+JIxZjmwGrjR/veczeseAM4xxhwP1AMXishqLGXhu2yl4TYs5WGYPQrEtwCbPK9n+3odzjbG1HtqEtL3t22MmfVfwKnAU57XtwK3Tve8pnB9dcA7ntdbgEr7uBLYYh//J3BlsvNm8hfwO+C8ubJuIBt4AzgFq7o1YI+7f+dYRaOn2scB+zyZ7rkf5jpr7BvgOcDvAZnN6/WseydQmjCWtr/tOeEpMD7F1tlEuTFmv33cBJTbx7Pu92CHCVYBrzLL122HUt4CmoFngO1Au7EUhiF+XbNBgfhu4CtAzH5dwuxer4MBnhaRdSJynT2Wtr/tlFY0K9OPMcaIyKzcdywiucCjwN8bYzq9rThm47qNMVGgXkQKgd8Ax0zzlFKGiFwENBtj1onIWdM9nzRzujGmUUTKgGdEZLP3zVT/bc8VT2E8iq2ziQMiUglgf2+2x2fN70FEMrAMwkPGmF/bw7N+3QDGmHbgBazwSaGtMAzx6xqXAvERzBrgoyKyE6tB1znAd5m963UxxjTa35uxjP/JpPFve64YBVex1d6tcAWWQutsxVGfxf7+O8/4VfaOhdVAh8clnTGI5RLcB2wyxnzH89asXbeIzLM9BEQkhJVD2YRlHC6zT0tcs/O7GJcC8ZGEMeZWY0yNMaYO6//r88aYTzFL1+sgIjkikuccA+cD75DOv+3pTqqkMXnzYeA9rDjs16d7PlO4roeB/cAgVjzxGqxY6nPAVuBZoNg+V7B2YW0HNgAN0z3/Ca75dKy469vAW/bXh2fzuoGVwJv2mt8BbrPHFwGvAduAXwKZ9niW/Xqb/f6i6V7DJNZ+FvD7ubBee33r7a+Nzr0qnX/bKnOhKIqiuMyV8JGiKIoyDtQoKIqiKC5qFBRFURQXNQqKoiiKixoFRVEUxUWNgqIkICJRW6HS+ZoyVV0RqROPoq2iHGmozIWiDKfPGFM/3ZNQlOlAPQVFGSe2zv23ba3710RkiT1eJyLP23r2z4nIfHu8XER+Y/dAWC8ip9kf5ReRH9l9EZ62K5QV5YhAjYKiDCeUED663PNehzHmOODfsVQ8Ab4PPGCMWQk8BHzPHv8e8Edj9UA4AatCFSzt+x8YY1YA7cClKV6PoowbrWhWlAREpNsYk5tkfCdWo5sdtiBfkzGmRERasDTsB+3x/caYUhE5CNQYYwY8n1EHPGOsZimIyFeBDGPMt1K/MkUZG/UUFOXwMCMcHw4DnuMomttTjiDUKCjK4XG55/sr9vHLWEqeAJ8CXrSPnwNuALdBTkG6JqkoE0WfUBRlOCG7w5nDk8YYZ1tqkYi8jfW0f6U99gXgJyLyj8BB4LP2+C3APSJyDZZHcAOWoq2iHLFoTkFRxomdU2gwxrRM91wUJVVo+EhRFEVxUU9BURRFcVFPQVEURXFRo6AoiqK4qFFQFEVRXNQoKIqiKC5qFBRFURSX/w88LyejPv5+twAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_and_saving(LSTMD,name='LSTM_Dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/500\n",
      "240/240 [==============================] - 21s 87ms/step - loss: 2.3062 - acc: 0.0750 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 2/500\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 2.3005 - acc: 0.1042 - val_loss: 2.3038 - val_acc: 0.1091\n",
      "Epoch 3/500\n",
      "240/240 [==============================] - 18s 73ms/step - loss: 2.2983 - acc: 0.1167 - val_loss: 2.3034 - val_acc: 0.0909\n",
      "Epoch 4/500\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 2.2946 - acc: 0.0917 - val_loss: 2.3054 - val_acc: 0.1091\n",
      "Epoch 5/500\n",
      "240/240 [==============================] - 18s 73ms/step - loss: 2.2933 - acc: 0.1000 - val_loss: 2.3078 - val_acc: 0.1000\n",
      "Epoch 6/500\n",
      "240/240 [==============================] - 21s 88ms/step - loss: 2.2876 - acc: 0.0792 - val_loss: 2.3051 - val_acc: 0.0909\n",
      "Epoch 7/500\n",
      "240/240 [==============================] - 17s 69ms/step - loss: 2.2893 - acc: 0.1000 - val_loss: 2.3128 - val_acc: 0.0909\n",
      "Epoch 8/500\n",
      "240/240 [==============================] - 20s 82ms/step - loss: 2.2948 - acc: 0.1500 - val_loss: 2.3049 - val_acc: 0.0909\n",
      "Epoch 9/500\n",
      "240/240 [==============================] - 21s 88ms/step - loss: 2.2794 - acc: 0.0958 - val_loss: 2.3084 - val_acc: 0.1000\n",
      "Epoch 10/500\n",
      "240/240 [==============================] - 17s 71ms/step - loss: 2.2798 - acc: 0.1583 - val_loss: 2.3033 - val_acc: 0.1000\n",
      "Epoch 11/500\n",
      "240/240 [==============================] - 17s 69ms/step - loss: 2.2811 - acc: 0.1583 - val_loss: 2.3043 - val_acc: 0.0818\n",
      "Epoch 12/500\n",
      "240/240 [==============================] - 19s 81ms/step - loss: 2.2969 - acc: 0.0917 - val_loss: 2.3032 - val_acc: 0.1000\n",
      "Epoch 13/500\n",
      "240/240 [==============================] - 24s 99ms/step - loss: 2.2804 - acc: 0.0875 - val_loss: 2.3029 - val_acc: 0.1091\n",
      "Epoch 14/500\n",
      "240/240 [==============================] - 20s 83ms/step - loss: 2.2816 - acc: 0.0958 - val_loss: 2.3010 - val_acc: 0.1091\n",
      "Epoch 15/500\n",
      "240/240 [==============================] - 18s 77ms/step - loss: 2.2693 - acc: 0.1333 - val_loss: 2.3002 - val_acc: 0.1091\n",
      "Epoch 16/500\n",
      "240/240 [==============================] - 25s 103ms/step - loss: 2.2688 - acc: 0.1208 - val_loss: 2.2942 - val_acc: 0.1091\n",
      "Epoch 17/500\n",
      "240/240 [==============================] - 19s 80ms/step - loss: 2.2679 - acc: 0.1042 - val_loss: 2.2710 - val_acc: 0.1455\n",
      "Epoch 18/500\n",
      "240/240 [==============================] - 20s 81ms/step - loss: 2.2743 - acc: 0.1375 - val_loss: 2.2788 - val_acc: 0.1000\n",
      "Epoch 19/500\n",
      "240/240 [==============================] - 26s 110ms/step - loss: 2.3100 - acc: 0.1167 - val_loss: 2.3007 - val_acc: 0.1000\n",
      "Epoch 20/500\n",
      "240/240 [==============================] - 27s 110ms/step - loss: 2.3098 - acc: 0.0708 - val_loss: 2.3032 - val_acc: 0.1000\n",
      "Epoch 21/500\n",
      "240/240 [==============================] - 19s 79ms/step - loss: 2.2996 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 22/500\n",
      "240/240 [==============================] - 19s 79ms/step - loss: 2.2989 - acc: 0.1167 - val_loss: 2.3011 - val_acc: 0.1182\n",
      "Epoch 23/500\n",
      "240/240 [==============================] - 17s 73ms/step - loss: 2.2905 - acc: 0.1125 - val_loss: 2.3055 - val_acc: 0.1091\n",
      "Epoch 24/500\n",
      "240/240 [==============================] - 20s 83ms/step - loss: 2.2952 - acc: 0.1208 - val_loss: 2.2985 - val_acc: 0.1455\n",
      "Epoch 25/500\n",
      "240/240 [==============================] - 20s 85ms/step - loss: 2.2800 - acc: 0.1333 - val_loss: 2.3000 - val_acc: 0.0727\n",
      "Epoch 26/500\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 2.2886 - acc: 0.1125 - val_loss: 2.3016 - val_acc: 0.1000\n",
      "Epoch 27/500\n",
      "240/240 [==============================] - 21s 86ms/step - loss: 2.2818 - acc: 0.1125 - val_loss: 2.3171 - val_acc: 0.1182\n",
      "Epoch 28/500\n",
      "240/240 [==============================] - 24s 98ms/step - loss: 2.2643 - acc: 0.1500 - val_loss: 2.3078 - val_acc: 0.1182\n",
      "Epoch 29/500\n",
      "240/240 [==============================] - 20s 85ms/step - loss: 2.2773 - acc: 0.1250 - val_loss: 2.3216 - val_acc: 0.1273\n",
      "Epoch 30/500\n",
      "240/240 [==============================] - 20s 82ms/step - loss: 2.2649 - acc: 0.1250 - val_loss: 2.3087 - val_acc: 0.0727\n",
      "Epoch 31/500\n",
      "240/240 [==============================] - 20s 85ms/step - loss: 2.2779 - acc: 0.1042 - val_loss: 2.3079 - val_acc: 0.1000\n",
      "Epoch 32/500\n",
      "240/240 [==============================] - 27s 111ms/step - loss: 2.2530 - acc: 0.1542 - val_loss: 2.3291 - val_acc: 0.0909\n",
      "Epoch 33/500\n",
      "240/240 [==============================] - 24s 102ms/step - loss: 2.2711 - acc: 0.1083 - val_loss: 2.3330 - val_acc: 0.0909\n",
      "Epoch 34/500\n",
      "240/240 [==============================] - 26s 107ms/step - loss: 2.2614 - acc: 0.1125 - val_loss: 2.3246 - val_acc: 0.0909\n",
      "Epoch 35/500\n",
      "240/240 [==============================] - 25s 105ms/step - loss: 2.2411 - acc: 0.1042 - val_loss: 2.3338 - val_acc: 0.1000\n",
      "Epoch 36/500\n",
      "240/240 [==============================] - 25s 102ms/step - loss: 2.2592 - acc: 0.1667 - val_loss: 2.3254 - val_acc: 0.0818\n",
      "Epoch 37/500\n",
      "240/240 [==============================] - 24s 101ms/step - loss: 2.2374 - acc: 0.1458 - val_loss: 2.3570 - val_acc: 0.1091\n",
      "Epoch 38/500\n",
      "240/240 [==============================] - 25s 103ms/step - loss: 2.2424 - acc: 0.1583 - val_loss: 2.3490 - val_acc: 0.0818\n",
      "Epoch 39/500\n",
      "240/240 [==============================] - 20s 84ms/step - loss: 2.2919 - acc: 0.1250 - val_loss: 2.3085 - val_acc: 0.0909\n",
      "Epoch 40/500\n",
      "240/240 [==============================] - 22s 90ms/step - loss: 2.2681 - acc: 0.1458 - val_loss: 2.3080 - val_acc: 0.1000\n",
      "Epoch 41/500\n",
      "240/240 [==============================] - 23s 94ms/step - loss: 2.2395 - acc: 0.1625 - val_loss: 2.3267 - val_acc: 0.0818\n",
      "Epoch 42/500\n",
      "240/240 [==============================] - 30s 125ms/step - loss: 2.2282 - acc: 0.1333 - val_loss: 2.3291 - val_acc: 0.1364\n",
      "Epoch 43/500\n",
      "240/240 [==============================] - 27s 113ms/step - loss: 2.2218 - acc: 0.1708 - val_loss: 2.3740 - val_acc: 0.0909\n",
      "Epoch 44/500\n",
      "240/240 [==============================] - 25s 103ms/step - loss: 2.2365 - acc: 0.1458 - val_loss: 2.3753 - val_acc: 0.1182\n",
      "Epoch 45/500\n",
      "240/240 [==============================] - 26s 109ms/step - loss: 2.1988 - acc: 0.1583 - val_loss: 2.4406 - val_acc: 0.0727\n",
      "Epoch 46/500\n",
      "240/240 [==============================] - 25s 103ms/step - loss: 2.2236 - acc: 0.1583 - val_loss: 2.3878 - val_acc: 0.1091\n",
      "Epoch 47/500\n",
      "240/240 [==============================] - 23s 98ms/step - loss: 2.2657 - acc: 0.1500 - val_loss: 2.3260 - val_acc: 0.0909\n",
      "Epoch 48/500\n",
      "240/240 [==============================] - 24s 100ms/step - loss: 2.2368 - acc: 0.1167 - val_loss: 2.3317 - val_acc: 0.1000\n",
      "Epoch 49/500\n",
      "240/240 [==============================] - 25s 105ms/step - loss: 2.2163 - acc: 0.1667 - val_loss: 2.3616 - val_acc: 0.0909\n",
      "Epoch 50/500\n",
      "240/240 [==============================] - 25s 105ms/step - loss: 2.1924 - acc: 0.1542 - val_loss: 2.3828 - val_acc: 0.1273\n",
      "Epoch 51/500\n",
      "240/240 [==============================] - 20s 83ms/step - loss: 2.2076 - acc: 0.1500 - val_loss: 2.3434 - val_acc: 0.1091\n",
      "Epoch 52/500\n",
      "240/240 [==============================] - 22s 93ms/step - loss: 2.2057 - acc: 0.1292 - val_loss: 2.3385 - val_acc: 0.1000\n",
      "Epoch 53/500\n",
      "240/240 [==============================] - 22s 90ms/step - loss: 2.2245 - acc: 0.1708 - val_loss: 2.3278 - val_acc: 0.1273\n",
      "Epoch 54/500\n",
      "240/240 [==============================] - 21s 87ms/step - loss: 2.1899 - acc: 0.1875 - val_loss: 2.3616 - val_acc: 0.1545\n",
      "Epoch 55/500\n",
      "240/240 [==============================] - 23s 96ms/step - loss: 2.1873 - acc: 0.1708 - val_loss: 2.3367 - val_acc: 0.1091\n",
      "Epoch 56/500\n",
      "240/240 [==============================] - 22s 90ms/step - loss: 2.1765 - acc: 0.1792 - val_loss: 2.3541 - val_acc: 0.1364\n",
      "Epoch 57/500\n",
      "240/240 [==============================] - 23s 97ms/step - loss: 2.1661 - acc: 0.1292 - val_loss: 2.3552 - val_acc: 0.1273\n",
      "Epoch 58/500\n",
      "240/240 [==============================] - 24s 102ms/step - loss: 2.1429 - acc: 0.1875 - val_loss: 2.4866 - val_acc: 0.0909\n",
      "Epoch 59/500\n",
      "240/240 [==============================] - 25s 103ms/step - loss: 2.1694 - acc: 0.1792 - val_loss: 2.3524 - val_acc: 0.1455\n",
      "Epoch 60/500\n",
      "240/240 [==============================] - 26s 107ms/step - loss: 2.2081 - acc: 0.1417 - val_loss: 2.3225 - val_acc: 0.1364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/500\n",
      "240/240 [==============================] - 28s 115ms/step - loss: 2.1414 - acc: 0.1917 - val_loss: 2.4123 - val_acc: 0.1182\n",
      "Epoch 62/500\n",
      "240/240 [==============================] - 25s 106ms/step - loss: 2.2533 - acc: 0.1625 - val_loss: 2.3141 - val_acc: 0.1000\n",
      "Epoch 63/500\n",
      "240/240 [==============================] - 25s 104ms/step - loss: 2.2549 - acc: 0.1208 - val_loss: 2.3236 - val_acc: 0.0909\n",
      "Epoch 64/500\n",
      "240/240 [==============================] - 24s 100ms/step - loss: 2.1941 - acc: 0.1583 - val_loss: 2.3801 - val_acc: 0.1182\n",
      "Epoch 65/500\n",
      "240/240 [==============================] - 22s 94ms/step - loss: 2.2330 - acc: 0.1167 - val_loss: 2.3543 - val_acc: 0.0909\n",
      "Epoch 66/500\n",
      "240/240 [==============================] - 23s 94ms/step - loss: 2.1900 - acc: 0.1625 - val_loss: 2.3574 - val_acc: 0.1364\n",
      "Epoch 67/500\n",
      "240/240 [==============================] - 23s 95ms/step - loss: 2.0908 - acc: 0.2250 - val_loss: 2.4447 - val_acc: 0.1364\n",
      "Epoch 68/500\n",
      "240/240 [==============================] - 21s 89ms/step - loss: 2.0837 - acc: 0.2292 - val_loss: 2.3990 - val_acc: 0.0909\n",
      "Epoch 69/500\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 2.1182 - acc: 0.1917 - val_loss: 2.3937 - val_acc: 0.0727\n",
      "Epoch 70/500\n",
      "240/240 [==============================] - 17s 71ms/step - loss: 2.0647 - acc: 0.2083 - val_loss: 2.4276 - val_acc: 0.1364\n",
      "Epoch 71/500\n",
      "240/240 [==============================] - 18s 75ms/step - loss: 2.0594 - acc: 0.1958 - val_loss: 2.4456 - val_acc: 0.1182\n",
      "Epoch 72/500\n",
      "240/240 [==============================] - 18s 75ms/step - loss: 2.0546 - acc: 0.2375 - val_loss: 2.4079 - val_acc: 0.0909\n",
      "Epoch 73/500\n",
      "240/240 [==============================] - 18s 75ms/step - loss: 2.0191 - acc: 0.2250 - val_loss: 2.3778 - val_acc: 0.1545\n",
      "Epoch 74/500\n",
      "240/240 [==============================] - 18s 76ms/step - loss: 2.0670 - acc: 0.2458 - val_loss: 2.4781 - val_acc: 0.1091\n",
      "Epoch 75/500\n",
      "240/240 [==============================] - 19s 80ms/step - loss: 2.1136 - acc: 0.1875 - val_loss: 2.4946 - val_acc: 0.1545\n",
      "Epoch 76/500\n",
      "240/240 [==============================] - 20s 84ms/step - loss: 2.0432 - acc: 0.2417 - val_loss: 2.4793 - val_acc: 0.1000\n",
      "Epoch 77/500\n",
      "240/240 [==============================] - 19s 80ms/step - loss: 2.1172 - acc: 0.1708 - val_loss: 2.3897 - val_acc: 0.1727\n",
      "Epoch 78/500\n",
      "240/240 [==============================] - 19s 80ms/step - loss: 1.9941 - acc: 0.2042 - val_loss: 2.5804 - val_acc: 0.1545\n",
      "Epoch 79/500\n",
      "240/240 [==============================] - 19s 78ms/step - loss: 1.9939 - acc: 0.2417 - val_loss: 2.5773 - val_acc: 0.1182\n",
      "Epoch 80/500\n",
      "240/240 [==============================] - 19s 80ms/step - loss: 1.9070 - acc: 0.2458 - val_loss: 2.6188 - val_acc: 0.1000\n",
      "Epoch 81/500\n",
      "240/240 [==============================] - 18s 77ms/step - loss: 1.9661 - acc: 0.2458 - val_loss: 2.5121 - val_acc: 0.1091\n",
      "Epoch 82/500\n",
      "240/240 [==============================] - 20s 82ms/step - loss: 2.0295 - acc: 0.2542 - val_loss: 2.4537 - val_acc: 0.2000\n",
      "Epoch 83/500\n",
      "240/240 [==============================] - 21s 86ms/step - loss: 1.9438 - acc: 0.2708 - val_loss: 2.3981 - val_acc: 0.1273\n",
      "Epoch 84/500\n",
      "240/240 [==============================] - 20s 85ms/step - loss: 2.0068 - acc: 0.2458 - val_loss: 2.5682 - val_acc: 0.0818\n",
      "Epoch 85/500\n",
      "240/240 [==============================] - 21s 86ms/step - loss: 2.0594 - acc: 0.2333 - val_loss: 2.4940 - val_acc: 0.1091\n",
      "Epoch 86/500\n",
      "240/240 [==============================] - 20s 81ms/step - loss: 2.0242 - acc: 0.2292 - val_loss: 2.4418 - val_acc: 0.1364\n",
      "Epoch 87/500\n",
      "240/240 [==============================] - 20s 84ms/step - loss: 1.9030 - acc: 0.2875 - val_loss: 2.6046 - val_acc: 0.1364\n",
      "Epoch 88/500\n",
      "240/240 [==============================] - 20s 84ms/step - loss: 1.9523 - acc: 0.2833 - val_loss: 2.4649 - val_acc: 0.1273\n",
      "Epoch 89/500\n",
      "240/240 [==============================] - 20s 82ms/step - loss: 1.9340 - acc: 0.2458 - val_loss: 2.4914 - val_acc: 0.1636\n",
      "Epoch 90/500\n",
      "240/240 [==============================] - 21s 86ms/step - loss: 1.8768 - acc: 0.2833 - val_loss: 2.4249 - val_acc: 0.2000\n",
      "Epoch 91/500\n",
      "240/240 [==============================] - 20s 83ms/step - loss: 1.7788 - acc: 0.3250 - val_loss: 2.5646 - val_acc: 0.1909\n",
      "Epoch 92/500\n",
      "240/240 [==============================] - 22s 90ms/step - loss: 1.7978 - acc: 0.3708 - val_loss: 2.4740 - val_acc: 0.2000\n",
      "Epoch 93/500\n",
      "240/240 [==============================] - 20s 84ms/step - loss: 1.7913 - acc: 0.3708 - val_loss: 2.4132 - val_acc: 0.2182\n",
      "Epoch 94/500\n",
      "240/240 [==============================] - 19s 77ms/step - loss: 1.8724 - acc: 0.3000 - val_loss: 2.3926 - val_acc: 0.2000\n",
      "Epoch 95/500\n",
      "240/240 [==============================] - 19s 81ms/step - loss: 1.8268 - acc: 0.3458 - val_loss: 2.6242 - val_acc: 0.1000\n",
      "Epoch 96/500\n",
      "240/240 [==============================] - 18s 76ms/step - loss: 1.9624 - acc: 0.2667 - val_loss: 2.6788 - val_acc: 0.1364\n",
      "Epoch 97/500\n",
      "240/240 [==============================] - 19s 78ms/step - loss: 1.9117 - acc: 0.2958 - val_loss: 2.7044 - val_acc: 0.1455\n",
      "Epoch 98/500\n",
      "240/240 [==============================] - 20s 83ms/step - loss: 1.7879 - acc: 0.3708 - val_loss: 2.4060 - val_acc: 0.2000\n",
      "Epoch 99/500\n",
      "240/240 [==============================] - 20s 84ms/step - loss: 1.9881 - acc: 0.3000 - val_loss: 2.6019 - val_acc: 0.1364\n",
      "Epoch 100/500\n",
      "240/240 [==============================] - 21s 88ms/step - loss: 2.0123 - acc: 0.2583 - val_loss: 2.6181 - val_acc: 0.1182\n",
      "Epoch 101/500\n",
      "240/240 [==============================] - 22s 91ms/step - loss: 1.9401 - acc: 0.2625 - val_loss: 2.5871 - val_acc: 0.1455\n",
      "Epoch 102/500\n",
      "240/240 [==============================] - 20s 82ms/step - loss: 1.7951 - acc: 0.3625 - val_loss: 2.7727 - val_acc: 0.1000\n",
      "Epoch 103/500\n",
      "240/240 [==============================] - 20s 85ms/step - loss: 1.8720 - acc: 0.2792 - val_loss: 2.6852 - val_acc: 0.1182\n",
      "Epoch 104/500\n",
      "240/240 [==============================] - 20s 84ms/step - loss: 1.8389 - acc: 0.2917 - val_loss: 2.6786 - val_acc: 0.1182\n",
      "Epoch 105/500\n",
      "240/240 [==============================] - 22s 92ms/step - loss: 1.8838 - acc: 0.2708 - val_loss: 2.7745 - val_acc: 0.1182\n",
      "Epoch 106/500\n",
      "240/240 [==============================] - 20s 84ms/step - loss: 1.8098 - acc: 0.3042 - val_loss: 2.5485 - val_acc: 0.1091\n",
      "Epoch 107/500\n",
      "240/240 [==============================] - 23s 95ms/step - loss: 1.7926 - acc: 0.2958 - val_loss: 2.7623 - val_acc: 0.1455\n",
      "Epoch 108/500\n",
      "240/240 [==============================] - 21s 87ms/step - loss: 1.7690 - acc: 0.2958 - val_loss: 2.7419 - val_acc: 0.1091\n",
      "Epoch 109/500\n",
      "240/240 [==============================] - 20s 84ms/step - loss: 1.7079 - acc: 0.3333 - val_loss: 2.6631 - val_acc: 0.1455\n",
      "Epoch 110/500\n",
      "240/240 [==============================] - 20s 85ms/step - loss: 1.6671 - acc: 0.3500 - val_loss: 2.6372 - val_acc: 0.2545\n",
      "Epoch 111/500\n",
      "240/240 [==============================] - 21s 88ms/step - loss: 1.8561 - acc: 0.3583 - val_loss: 2.6744 - val_acc: 0.1545\n",
      "Epoch 112/500\n",
      "240/240 [==============================] - 21s 87ms/step - loss: 1.6892 - acc: 0.3583 - val_loss: 2.7665 - val_acc: 0.1545\n",
      "Epoch 113/500\n",
      "240/240 [==============================] - 22s 90ms/step - loss: 1.7338 - acc: 0.3500 - val_loss: 2.7035 - val_acc: 0.1636\n",
      "Epoch 114/500\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 1.6631 - acc: 0.3958 - val_loss: 2.7309 - val_acc: 0.2545\n",
      "Epoch 115/500\n",
      "240/240 [==============================] - 19s 81ms/step - loss: 1.6369 - acc: 0.4000 - val_loss: 2.6189 - val_acc: 0.1727\n",
      "Epoch 116/500\n",
      "240/240 [==============================] - 21s 88ms/step - loss: 1.7769 - acc: 0.3542 - val_loss: 2.8199 - val_acc: 0.1727\n",
      "Epoch 117/500\n",
      "240/240 [==============================] - 28s 115ms/step - loss: 1.6931 - acc: 0.3625 - val_loss: 2.7810 - val_acc: 0.1636\n",
      "Epoch 118/500\n",
      "240/240 [==============================] - 26s 109ms/step - loss: 1.7271 - acc: 0.3417 - val_loss: 2.5852 - val_acc: 0.1455\n",
      "Epoch 119/500\n",
      "240/240 [==============================] - 22s 92ms/step - loss: 1.6278 - acc: 0.4000 - val_loss: 2.5859 - val_acc: 0.2000\n",
      "Epoch 120/500\n",
      "240/240 [==============================] - 26s 108ms/step - loss: 1.5949 - acc: 0.4333 - val_loss: 2.8799 - val_acc: 0.1273\n",
      "Epoch 121/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 24s 99ms/step - loss: 1.5715 - acc: 0.4125 - val_loss: 2.7473 - val_acc: 0.2091\n",
      "Epoch 122/500\n",
      "240/240 [==============================] - 23s 94ms/step - loss: 1.6903 - acc: 0.3750 - val_loss: 2.8236 - val_acc: 0.1182\n",
      "Epoch 123/500\n",
      "240/240 [==============================] - 19s 80ms/step - loss: 1.9161 - acc: 0.2875 - val_loss: 2.4801 - val_acc: 0.1636\n",
      "Epoch 124/500\n",
      "240/240 [==============================] - 22s 90ms/step - loss: 1.9684 - acc: 0.3292 - val_loss: 2.4614 - val_acc: 0.1364\n",
      "Epoch 125/500\n",
      "240/240 [==============================] - 27s 112ms/step - loss: 1.6217 - acc: 0.3750 - val_loss: 2.6264 - val_acc: 0.2000\n",
      "Epoch 126/500\n",
      "240/240 [==============================] - 26s 107ms/step - loss: 1.5883 - acc: 0.4208 - val_loss: 2.8091 - val_acc: 0.1455\n",
      "Epoch 127/500\n",
      "240/240 [==============================] - 24s 100ms/step - loss: 1.6167 - acc: 0.3958 - val_loss: 2.7133 - val_acc: 0.1636\n",
      "Epoch 128/500\n",
      "240/240 [==============================] - 26s 108ms/step - loss: 1.4823 - acc: 0.4750 - val_loss: 2.8375 - val_acc: 0.1545\n",
      "Epoch 129/500\n",
      "240/240 [==============================] - 24s 100ms/step - loss: 1.4633 - acc: 0.4583 - val_loss: 2.6340 - val_acc: 0.2455\n",
      "Epoch 130/500\n",
      "240/240 [==============================] - 23s 97ms/step - loss: 1.4292 - acc: 0.4708 - val_loss: 2.6353 - val_acc: 0.2182\n",
      "Epoch 131/500\n",
      "240/240 [==============================] - 23s 96ms/step - loss: 1.4150 - acc: 0.4792 - val_loss: 2.6917 - val_acc: 0.2182\n",
      "Epoch 132/500\n",
      "240/240 [==============================] - 23s 97ms/step - loss: 1.4851 - acc: 0.4750 - val_loss: 2.6170 - val_acc: 0.2273\n",
      "Epoch 133/500\n",
      "240/240 [==============================] - 24s 99ms/step - loss: 1.6695 - acc: 0.3792 - val_loss: 2.4895 - val_acc: 0.2000\n",
      "Epoch 134/500\n",
      "240/240 [==============================] - 24s 100ms/step - loss: 1.3783 - acc: 0.4875 - val_loss: 2.7020 - val_acc: 0.1545\n",
      "Epoch 135/500\n",
      "240/240 [==============================] - 24s 101ms/step - loss: 1.5532 - acc: 0.4417 - val_loss: 2.5676 - val_acc: 0.2000\n",
      "Epoch 136/500\n",
      "240/240 [==============================] - 22s 93ms/step - loss: 1.5965 - acc: 0.3875 - val_loss: 2.4358 - val_acc: 0.1818\n",
      "Epoch 137/500\n",
      "240/240 [==============================] - 24s 100ms/step - loss: 1.5049 - acc: 0.4292 - val_loss: 2.5595 - val_acc: 0.1636\n",
      "Epoch 138/500\n",
      "240/240 [==============================] - 22s 92ms/step - loss: 1.5465 - acc: 0.4458 - val_loss: 2.6784 - val_acc: 0.2000\n",
      "Epoch 139/500\n",
      "240/240 [==============================] - 26s 110ms/step - loss: 1.4081 - acc: 0.4708 - val_loss: 2.3817 - val_acc: 0.2364\n",
      "Epoch 140/500\n",
      "240/240 [==============================] - 20s 85ms/step - loss: 1.3460 - acc: 0.5000 - val_loss: 2.4998 - val_acc: 0.2182\n",
      "Epoch 141/500\n",
      "240/240 [==============================] - 17s 71ms/step - loss: 1.3231 - acc: 0.4875 - val_loss: 2.5264 - val_acc: 0.2818\n",
      "Epoch 142/500\n",
      "240/240 [==============================] - 19s 79ms/step - loss: 1.2179 - acc: 0.5750 - val_loss: 2.6882 - val_acc: 0.2000\n",
      "Epoch 143/500\n",
      "240/240 [==============================] - 19s 78ms/step - loss: 1.2701 - acc: 0.5292 - val_loss: 2.5821 - val_acc: 0.2455\n",
      "Epoch 144/500\n",
      "240/240 [==============================] - 19s 79ms/step - loss: 1.2284 - acc: 0.5625 - val_loss: 2.6071 - val_acc: 0.2636\n",
      "Epoch 145/500\n",
      "240/240 [==============================] - 22s 94ms/step - loss: 1.2136 - acc: 0.5417 - val_loss: 2.7092 - val_acc: 0.2182\n",
      "Epoch 146/500\n",
      "240/240 [==============================] - 25s 103ms/step - loss: 1.0862 - acc: 0.5917 - val_loss: 2.5148 - val_acc: 0.2364\n",
      "Epoch 147/500\n",
      "240/240 [==============================] - 23s 94ms/step - loss: 1.2212 - acc: 0.6000 - val_loss: 2.6259 - val_acc: 0.2273\n",
      "Epoch 148/500\n",
      "240/240 [==============================] - 23s 98ms/step - loss: 1.7416 - acc: 0.4083 - val_loss: 2.8714 - val_acc: 0.1727\n",
      "Epoch 149/500\n",
      "240/240 [==============================] - 31s 127ms/step - loss: 2.1945 - acc: 0.2458 - val_loss: 2.7509 - val_acc: 0.1545\n",
      "Epoch 150/500\n",
      "240/240 [==============================] - 24s 102ms/step - loss: 2.1723 - acc: 0.2417 - val_loss: 2.7280 - val_acc: 0.1273\n",
      "Epoch 151/500\n",
      "240/240 [==============================] - 27s 113ms/step - loss: 2.0088 - acc: 0.2667 - val_loss: 2.6551 - val_acc: 0.1455\n",
      "Epoch 152/500\n",
      "240/240 [==============================] - 27s 111ms/step - loss: 1.8591 - acc: 0.2958 - val_loss: 2.6942 - val_acc: 0.1273\n",
      "Epoch 153/500\n",
      "240/240 [==============================] - 30s 126ms/step - loss: 1.8592 - acc: 0.3292 - val_loss: 2.6626 - val_acc: 0.1545\n",
      "Epoch 154/500\n",
      "240/240 [==============================] - 19s 78ms/step - loss: 1.6848 - acc: 0.3542 - val_loss: 2.7031 - val_acc: 0.1455\n",
      "Epoch 155/500\n",
      "240/240 [==============================] - 18s 74ms/step - loss: 1.6127 - acc: 0.3750 - val_loss: 2.8097 - val_acc: 0.1636\n",
      "Epoch 156/500\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 1.5953 - acc: 0.4292 - val_loss: 2.5896 - val_acc: 0.1545\n",
      "Epoch 157/500\n",
      "240/240 [==============================] - 18s 73ms/step - loss: 1.5364 - acc: 0.4542 - val_loss: 2.7002 - val_acc: 0.2000\n",
      "Epoch 158/500\n",
      "240/240 [==============================] - 20s 84ms/step - loss: 1.4499 - acc: 0.4750 - val_loss: 2.5237 - val_acc: 0.2364\n",
      "Epoch 159/500\n",
      "240/240 [==============================] - 19s 81ms/step - loss: 1.4572 - acc: 0.4875 - val_loss: 2.4504 - val_acc: 0.2727\n",
      "Epoch 160/500\n",
      "240/240 [==============================] - 18s 75ms/step - loss: 1.3716 - acc: 0.4750 - val_loss: 2.4189 - val_acc: 0.2818\n",
      "Epoch 161/500\n",
      "240/240 [==============================] - 21s 87ms/step - loss: 1.2684 - acc: 0.5375 - val_loss: 2.5802 - val_acc: 0.2636\n",
      "Epoch 162/500\n",
      "240/240 [==============================] - 25s 106ms/step - loss: 1.3243 - acc: 0.5000 - val_loss: 2.9249 - val_acc: 0.2091\n",
      "Epoch 163/500\n",
      "240/240 [==============================] - 22s 90ms/step - loss: 1.3021 - acc: 0.5000 - val_loss: 2.7307 - val_acc: 0.1727\n",
      "Epoch 164/500\n",
      "240/240 [==============================] - 19s 78ms/step - loss: 1.2864 - acc: 0.5500 - val_loss: 2.6342 - val_acc: 0.2364\n",
      "Epoch 165/500\n",
      "240/240 [==============================] - 19s 79ms/step - loss: 1.2182 - acc: 0.5583 - val_loss: 2.5449 - val_acc: 0.2909\n",
      "Epoch 166/500\n",
      "240/240 [==============================] - 18s 75ms/step - loss: 1.2887 - acc: 0.5125 - val_loss: 2.6320 - val_acc: 0.2273\n",
      "Epoch 167/500\n",
      "240/240 [==============================] - 20s 82ms/step - loss: 1.1156 - acc: 0.5833 - val_loss: 2.5476 - val_acc: 0.2545\n",
      "Epoch 168/500\n",
      "240/240 [==============================] - 23s 95ms/step - loss: 1.1811 - acc: 0.5417 - val_loss: 2.7273 - val_acc: 0.2091\n",
      "Epoch 169/500\n",
      "240/240 [==============================] - 24s 98ms/step - loss: 1.1957 - acc: 0.5458 - val_loss: 2.5092 - val_acc: 0.2727\n",
      "Epoch 170/500\n",
      "240/240 [==============================] - 21s 86ms/step - loss: 1.1075 - acc: 0.5833 - val_loss: 2.5281 - val_acc: 0.2909\n",
      "Epoch 171/500\n",
      "240/240 [==============================] - 20s 83ms/step - loss: 0.9108 - acc: 0.6750 - val_loss: 2.7122 - val_acc: 0.2909\n",
      "Epoch 172/500\n",
      "240/240 [==============================] - 20s 82ms/step - loss: 1.0365 - acc: 0.6333 - val_loss: 2.4653 - val_acc: 0.2636\n",
      "Epoch 173/500\n",
      "240/240 [==============================] - 19s 81ms/step - loss: 0.9623 - acc: 0.6500 - val_loss: 2.7533 - val_acc: 0.2818\n",
      "Epoch 174/500\n",
      "240/240 [==============================] - 20s 85ms/step - loss: 0.8763 - acc: 0.6792 - val_loss: 2.7240 - val_acc: 0.2636\n",
      "Epoch 175/500\n",
      "240/240 [==============================] - 20s 82ms/step - loss: 0.9375 - acc: 0.6708 - val_loss: 2.7611 - val_acc: 0.2909\n",
      "Epoch 176/500\n",
      "240/240 [==============================] - 22s 92ms/step - loss: 0.8471 - acc: 0.6917 - val_loss: 2.9412 - val_acc: 0.1909\n",
      "Epoch 177/500\n",
      "240/240 [==============================] - 24s 100ms/step - loss: 0.8757 - acc: 0.6417 - val_loss: 2.7272 - val_acc: 0.3000\n",
      "Epoch 178/500\n",
      "240/240 [==============================] - 20s 83ms/step - loss: 0.9793 - acc: 0.6375 - val_loss: 2.6378 - val_acc: 0.2545\n",
      "Epoch 179/500\n",
      "240/240 [==============================] - 21s 86ms/step - loss: 0.9531 - acc: 0.6667 - val_loss: 2.6349 - val_acc: 0.3091\n",
      "Epoch 180/500\n",
      "240/240 [==============================] - 26s 110ms/step - loss: 0.9870 - acc: 0.6458 - val_loss: 2.5694 - val_acc: 0.3182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/500\n",
      "240/240 [==============================] - 18s 76ms/step - loss: 0.8491 - acc: 0.6750 - val_loss: 2.7114 - val_acc: 0.3000\n",
      "Epoch 182/500\n",
      "240/240 [==============================] - 18s 74ms/step - loss: 0.8789 - acc: 0.6375 - val_loss: 2.8324 - val_acc: 0.2909\n",
      "Epoch 183/500\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 0.8819 - acc: 0.6583 - val_loss: 2.8509 - val_acc: 0.3182\n",
      "Epoch 184/500\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 0.8844 - acc: 0.6708 - val_loss: 2.9585 - val_acc: 0.3000\n",
      "Epoch 185/500\n",
      "240/240 [==============================] - 17s 70ms/step - loss: 0.9635 - acc: 0.6333 - val_loss: 2.7405 - val_acc: 0.2727\n",
      "Epoch 186/500\n",
      "240/240 [==============================] - 17s 70ms/step - loss: 1.4078 - acc: 0.5333 - val_loss: 3.2745 - val_acc: 0.1909\n",
      "Epoch 187/500\n",
      "240/240 [==============================] - 25s 104ms/step - loss: 1.4395 - acc: 0.5208 - val_loss: 2.6636 - val_acc: 0.2545\n",
      "Epoch 188/500\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 1.0466 - acc: 0.5833 - val_loss: 2.7767 - val_acc: 0.2364\n",
      "Epoch 189/500\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 0.9425 - acc: 0.6500 - val_loss: 2.9108 - val_acc: 0.2364\n",
      "Epoch 190/500\n",
      "240/240 [==============================] - 23s 97ms/step - loss: 0.9966 - acc: 0.6375 - val_loss: 2.9637 - val_acc: 0.1636\n",
      "Epoch 191/500\n",
      "240/240 [==============================] - 17s 70ms/step - loss: 0.9124 - acc: 0.6458 - val_loss: 2.7805 - val_acc: 0.2455\n",
      "Epoch 192/500\n",
      "240/240 [==============================] - 20s 85ms/step - loss: 0.7516 - acc: 0.7250 - val_loss: 2.8801 - val_acc: 0.2909\n",
      "Epoch 193/500\n",
      "240/240 [==============================] - 23s 94ms/step - loss: 0.7146 - acc: 0.7500 - val_loss: 3.1524 - val_acc: 0.2909\n",
      "Epoch 194/500\n",
      "240/240 [==============================] - 24s 99ms/step - loss: 0.8440 - acc: 0.6917 - val_loss: 3.1654 - val_acc: 0.2455\n",
      "Epoch 195/500\n",
      "240/240 [==============================] - 23s 95ms/step - loss: 0.6854 - acc: 0.7333 - val_loss: 3.2245 - val_acc: 0.2182\n",
      "Epoch 196/500\n",
      "240/240 [==============================] - 24s 98ms/step - loss: 0.6636 - acc: 0.7708 - val_loss: 3.1200 - val_acc: 0.2727\n",
      "Epoch 197/500\n",
      "240/240 [==============================] - 22s 93ms/step - loss: 0.7637 - acc: 0.7208 - val_loss: 3.1129 - val_acc: 0.2909\n",
      "Epoch 198/500\n",
      "240/240 [==============================] - 27s 112ms/step - loss: 0.9036 - acc: 0.6750 - val_loss: 3.2263 - val_acc: 0.2091\n",
      "Epoch 199/500\n",
      "240/240 [==============================] - 24s 100ms/step - loss: 0.8929 - acc: 0.6458 - val_loss: 3.1841 - val_acc: 0.2182\n",
      "Epoch 200/500\n",
      "240/240 [==============================] - 22s 93ms/step - loss: 0.9061 - acc: 0.6708 - val_loss: 3.2187 - val_acc: 0.2818\n",
      "Epoch 201/500\n",
      "240/240 [==============================] - 23s 97ms/step - loss: 0.8394 - acc: 0.7125 - val_loss: 2.9863 - val_acc: 0.2182\n",
      "Epoch 202/500\n",
      "240/240 [==============================] - 24s 98ms/step - loss: 0.9241 - acc: 0.6833 - val_loss: 3.0862 - val_acc: 0.2727\n",
      "Epoch 203/500\n",
      "240/240 [==============================] - 20s 84ms/step - loss: 0.7656 - acc: 0.7250 - val_loss: 2.9397 - val_acc: 0.2455\n",
      "Epoch 204/500\n",
      "240/240 [==============================] - 19s 77ms/step - loss: 1.3818 - acc: 0.5792 - val_loss: 3.2369 - val_acc: 0.2273\n",
      "Epoch 205/500\n",
      "240/240 [==============================] - 19s 77ms/step - loss: 1.2126 - acc: 0.5917 - val_loss: 2.6613 - val_acc: 0.2545\n",
      "Epoch 206/500\n",
      "240/240 [==============================] - 20s 85ms/step - loss: 0.9928 - acc: 0.6208 - val_loss: 2.7144 - val_acc: 0.2727\n",
      "Epoch 207/500\n",
      "240/240 [==============================] - 22s 90ms/step - loss: 0.9790 - acc: 0.6375 - val_loss: 2.7605 - val_acc: 0.2545\n",
      "Epoch 208/500\n",
      "240/240 [==============================] - 21s 89ms/step - loss: 0.9216 - acc: 0.6625 - val_loss: 2.8150 - val_acc: 0.2273\n",
      "Epoch 209/500\n",
      "240/240 [==============================] - 24s 99ms/step - loss: 0.8355 - acc: 0.6708 - val_loss: 2.8576 - val_acc: 0.2455\n",
      "Epoch 210/500\n",
      "240/240 [==============================] - 26s 109ms/step - loss: 0.7639 - acc: 0.7250 - val_loss: 2.9196 - val_acc: 0.2636\n",
      "Epoch 211/500\n",
      "240/240 [==============================] - 19s 77ms/step - loss: 0.8310 - acc: 0.6917 - val_loss: 2.9611 - val_acc: 0.2727\n",
      "Epoch 212/500\n",
      "240/240 [==============================] - 27s 114ms/step - loss: 0.8964 - acc: 0.6542 - val_loss: 2.9701 - val_acc: 0.2545\n",
      "Epoch 213/500\n",
      "240/240 [==============================] - 21s 89ms/step - loss: 0.8993 - acc: 0.6375 - val_loss: 2.8319 - val_acc: 0.2455\n",
      "Epoch 214/500\n",
      "240/240 [==============================] - 17s 70ms/step - loss: 0.7455 - acc: 0.7417 - val_loss: 2.7991 - val_acc: 0.2909\n",
      "Epoch 215/500\n",
      "240/240 [==============================] - 17s 71ms/step - loss: 0.7703 - acc: 0.7083 - val_loss: 2.8273 - val_acc: 0.2727\n",
      "Epoch 216/500\n",
      "240/240 [==============================] - 18s 76ms/step - loss: 0.5994 - acc: 0.7750 - val_loss: 3.0669 - val_acc: 0.2545\n",
      "Epoch 217/500\n",
      "240/240 [==============================] - 28s 116ms/step - loss: 0.6289 - acc: 0.7625 - val_loss: 3.0834 - val_acc: 0.2182\n",
      "Epoch 218/500\n",
      "240/240 [==============================] - 23s 97ms/step - loss: 0.6251 - acc: 0.7667 - val_loss: 3.1368 - val_acc: 0.2909\n",
      "Epoch 219/500\n",
      "240/240 [==============================] - 37s 153ms/step - loss: 0.4950 - acc: 0.8083 - val_loss: 3.2186 - val_acc: 0.2727\n",
      "Epoch 220/500\n",
      "240/240 [==============================] - 29s 120ms/step - loss: 0.5901 - acc: 0.7708 - val_loss: 3.2838 - val_acc: 0.2545\n",
      "Epoch 221/500\n",
      "240/240 [==============================] - 25s 103ms/step - loss: 0.5358 - acc: 0.7958 - val_loss: 3.3878 - val_acc: 0.2636\n",
      "Epoch 222/500\n",
      "240/240 [==============================] - 24s 99ms/step - loss: 0.5633 - acc: 0.7917 - val_loss: 3.3837 - val_acc: 0.2818\n",
      "Epoch 223/500\n",
      "240/240 [==============================] - 24s 101ms/step - loss: 0.4710 - acc: 0.8250 - val_loss: 3.4625 - val_acc: 0.2818\n",
      "Epoch 224/500\n",
      "240/240 [==============================] - 24s 100ms/step - loss: 0.4532 - acc: 0.8375 - val_loss: 3.5092 - val_acc: 0.2455\n",
      "Epoch 225/500\n",
      "240/240 [==============================] - 20s 82ms/step - loss: 0.4923 - acc: 0.8167 - val_loss: 3.5300 - val_acc: 0.2727\n",
      "Epoch 226/500\n",
      "240/240 [==============================] - 28s 115ms/step - loss: 0.5505 - acc: 0.8250 - val_loss: 3.4919 - val_acc: 0.2182\n",
      "Epoch 227/500\n",
      "240/240 [==============================] - 24s 101ms/step - loss: 0.6808 - acc: 0.7958 - val_loss: 3.5516 - val_acc: 0.2636\n",
      "Epoch 228/500\n",
      "240/240 [==============================] - 21s 88ms/step - loss: 1.5790 - acc: 0.5042 - val_loss: 2.7940 - val_acc: 0.2091\n",
      "Epoch 229/500\n",
      "240/240 [==============================] - 20s 82ms/step - loss: 2.0502 - acc: 0.2958 - val_loss: 2.4052 - val_acc: 0.2182\n",
      "Epoch 230/500\n",
      "240/240 [==============================] - 20s 83ms/step - loss: 2.1526 - acc: 0.2583 - val_loss: 2.1799 - val_acc: 0.2182\n",
      "Epoch 231/500\n",
      "240/240 [==============================] - 28s 117ms/step - loss: 1.4702 - acc: 0.4208 - val_loss: 2.1362 - val_acc: 0.2364\n",
      "Epoch 232/500\n",
      "240/240 [==============================] - 30s 127ms/step - loss: 1.2427 - acc: 0.5208 - val_loss: 2.4122 - val_acc: 0.2636\n",
      "Epoch 233/500\n",
      "240/240 [==============================] - 30s 124ms/step - loss: 1.2113 - acc: 0.5208 - val_loss: 2.3362 - val_acc: 0.2727\n",
      "Epoch 234/500\n",
      "240/240 [==============================] - 20s 83ms/step - loss: 1.1194 - acc: 0.5375 - val_loss: 2.7994 - val_acc: 0.2182\n",
      "Epoch 235/500\n",
      "240/240 [==============================] - 18s 76ms/step - loss: 1.9095 - acc: 0.3583 - val_loss: 2.4161 - val_acc: 0.2182\n",
      "Epoch 236/500\n",
      "240/240 [==============================] - 18s 75ms/step - loss: 1.3936 - acc: 0.4500 - val_loss: 2.3201 - val_acc: 0.2727\n",
      "Epoch 237/500\n",
      "240/240 [==============================] - 18s 74ms/step - loss: 1.2618 - acc: 0.4458 - val_loss: 2.3904 - val_acc: 0.2909\n",
      "Epoch 238/500\n",
      "240/240 [==============================] - 18s 73ms/step - loss: 1.1995 - acc: 0.5208 - val_loss: 2.4892 - val_acc: 0.2727\n",
      "Epoch 239/500\n",
      "240/240 [==============================] - 18s 74ms/step - loss: 1.0465 - acc: 0.6000 - val_loss: 2.4712 - val_acc: 0.2727\n",
      "Epoch 240/500\n",
      "240/240 [==============================] - 26s 110ms/step - loss: 0.9443 - acc: 0.6417 - val_loss: 2.5987 - val_acc: 0.2636\n",
      "Epoch 241/500\n",
      "240/240 [==============================] - 19s 81ms/step - loss: 0.8687 - acc: 0.6583 - val_loss: 2.7525 - val_acc: 0.2273\n",
      "Epoch 242/500\n",
      "240/240 [==============================] - 20s 83ms/step - loss: 0.9292 - acc: 0.6208 - val_loss: 2.6376 - val_acc: 0.2545\n",
      "Epoch 243/500\n",
      "240/240 [==============================] - 24s 101ms/step - loss: 0.8530 - acc: 0.6542 - val_loss: 2.7235 - val_acc: 0.2455\n",
      "Epoch 244/500\n",
      "240/240 [==============================] - 23s 95ms/step - loss: 0.8819 - acc: 0.6417 - val_loss: 2.8259 - val_acc: 0.2364\n",
      "Epoch 245/500\n",
      "240/240 [==============================] - 17s 69ms/step - loss: 0.7448 - acc: 0.6958 - val_loss: 3.0050 - val_acc: 0.2636\n",
      "Epoch 246/500\n",
      "240/240 [==============================] - 20s 83ms/step - loss: 0.6584 - acc: 0.7500 - val_loss: 3.0325 - val_acc: 0.2545\n",
      "Epoch 247/500\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 0.7077 - acc: 0.7208 - val_loss: 3.1079 - val_acc: 0.2727\n",
      "Epoch 248/500\n",
      "240/240 [==============================] - 23s 95ms/step - loss: 0.6693 - acc: 0.7500 - val_loss: 3.0589 - val_acc: 0.2818\n",
      "Epoch 249/500\n",
      "240/240 [==============================] - 21s 86ms/step - loss: 0.6877 - acc: 0.7458 - val_loss: 3.2325 - val_acc: 0.2818\n",
      "Epoch 250/500\n",
      "240/240 [==============================] - 21s 86ms/step - loss: 0.7148 - acc: 0.7167 - val_loss: 3.2702 - val_acc: 0.2273\n",
      "Epoch 251/500\n",
      "240/240 [==============================] - 18s 74ms/step - loss: 1.0544 - acc: 0.5833 - val_loss: 3.0188 - val_acc: 0.2364\n",
      "Epoch 252/500\n",
      "240/240 [==============================] - 18s 73ms/step - loss: 0.6965 - acc: 0.7333 - val_loss: 3.3797 - val_acc: 0.2364\n",
      "Epoch 253/500\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 0.6514 - acc: 0.7750 - val_loss: 3.2706 - val_acc: 0.2545\n",
      "Epoch 254/500\n",
      "240/240 [==============================] - 17s 73ms/step - loss: 0.6658 - acc: 0.7292 - val_loss: 3.2285 - val_acc: 0.2818\n",
      "Epoch 255/500\n",
      "240/240 [==============================] - 18s 76ms/step - loss: 0.6225 - acc: 0.7750 - val_loss: 3.1726 - val_acc: 0.2636\n",
      "Epoch 256/500\n",
      "240/240 [==============================] - 19s 80ms/step - loss: 0.6616 - acc: 0.7125 - val_loss: 3.4334 - val_acc: 0.2182\n",
      "Epoch 257/500\n",
      "240/240 [==============================] - 22s 93ms/step - loss: 0.6740 - acc: 0.7333 - val_loss: 3.2767 - val_acc: 0.3273\n",
      "Epoch 258/500\n",
      "240/240 [==============================] - 24s 99ms/step - loss: 0.5683 - acc: 0.7792 - val_loss: 3.4913 - val_acc: 0.2636\n",
      "Epoch 259/500\n",
      "240/240 [==============================] - 20s 82ms/step - loss: 0.5129 - acc: 0.7958 - val_loss: 3.7101 - val_acc: 0.2727\n",
      "Epoch 260/500\n",
      "240/240 [==============================] - 18s 75ms/step - loss: 0.6342 - acc: 0.7667 - val_loss: 3.8398 - val_acc: 0.2000\n",
      "Epoch 261/500\n",
      "240/240 [==============================] - 17s 70ms/step - loss: 0.8699 - acc: 0.7500 - val_loss: 3.8434 - val_acc: 0.2000\n",
      "Epoch 262/500\n",
      "240/240 [==============================] - 18s 76ms/step - loss: 0.7641 - acc: 0.7083 - val_loss: 3.1922 - val_acc: 0.2818\n",
      "Epoch 263/500\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 0.6616 - acc: 0.7792 - val_loss: 3.4688 - val_acc: 0.2727\n",
      "Epoch 264/500\n",
      "240/240 [==============================] - 17s 73ms/step - loss: 0.6670 - acc: 0.7667 - val_loss: 3.4590 - val_acc: 0.2182\n",
      "Epoch 265/500\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 0.6848 - acc: 0.7458 - val_loss: 3.6454 - val_acc: 0.2000\n",
      "Epoch 266/500\n",
      "240/240 [==============================] - 17s 70ms/step - loss: 1.1831 - acc: 0.6667 - val_loss: 3.3781 - val_acc: 0.2364\n",
      "Epoch 267/500\n",
      "240/240 [==============================] - 16s 69ms/step - loss: 1.0141 - acc: 0.6375 - val_loss: 3.1275 - val_acc: 0.2455\n",
      "Epoch 268/500\n",
      "240/240 [==============================] - 23s 95ms/step - loss: 0.8308 - acc: 0.7250 - val_loss: 3.1646 - val_acc: 0.2000\n",
      "Epoch 269/500\n",
      "240/240 [==============================] - 18s 76ms/step - loss: 0.9341 - acc: 0.6875 - val_loss: 3.1204 - val_acc: 0.2273\n",
      "Epoch 270/500\n",
      "240/240 [==============================] - 19s 78ms/step - loss: 0.5912 - acc: 0.7833 - val_loss: 3.3230 - val_acc: 0.2455\n",
      "Epoch 271/500\n",
      "240/240 [==============================] - 20s 82ms/step - loss: 0.5267 - acc: 0.8083 - val_loss: 3.1030 - val_acc: 0.2636\n",
      "Epoch 272/500\n",
      "240/240 [==============================] - 17s 73ms/step - loss: 0.8536 - acc: 0.6958 - val_loss: 3.4684 - val_acc: 0.2545\n",
      "Epoch 273/500\n",
      "240/240 [==============================] - 17s 73ms/step - loss: 0.6845 - acc: 0.7375 - val_loss: 3.4763 - val_acc: 0.2182\n",
      "Epoch 274/500\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 0.5892 - acc: 0.7708 - val_loss: 3.6636 - val_acc: 0.2182\n",
      "Epoch 275/500\n",
      "240/240 [==============================] - 18s 75ms/step - loss: 0.5200 - acc: 0.8167 - val_loss: 3.6583 - val_acc: 0.2455\n",
      "Epoch 276/500\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 0.5098 - acc: 0.8292 - val_loss: 3.6720 - val_acc: 0.2000\n",
      "Epoch 277/500\n",
      "240/240 [==============================] - 18s 76ms/step - loss: 0.4724 - acc: 0.8417 - val_loss: 3.7247 - val_acc: 0.2364\n",
      "Epoch 278/500\n",
      "240/240 [==============================] - 20s 82ms/step - loss: 0.3893 - acc: 0.8708 - val_loss: 3.6621 - val_acc: 0.2727\n",
      "Epoch 279/500\n",
      "240/240 [==============================] - 19s 80ms/step - loss: 0.3229 - acc: 0.9042 - val_loss: 3.9543 - val_acc: 0.2545\n",
      "Epoch 280/500\n",
      "240/240 [==============================] - 22s 93ms/step - loss: 0.3275 - acc: 0.9042 - val_loss: 3.9888 - val_acc: 0.2182\n",
      "Epoch 281/500\n",
      "240/240 [==============================] - 18s 75ms/step - loss: 0.3368 - acc: 0.8875 - val_loss: 3.7694 - val_acc: 0.2636\n",
      "Epoch 282/500\n",
      "240/240 [==============================] - 21s 88ms/step - loss: 0.2818 - acc: 0.9083 - val_loss: 4.1348 - val_acc: 0.2182\n",
      "Epoch 283/500\n",
      "240/240 [==============================] - 19s 78ms/step - loss: 0.2841 - acc: 0.9125 - val_loss: 4.1075 - val_acc: 0.2364\n",
      "Epoch 284/500\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 0.3159 - acc: 0.9083 - val_loss: 4.5020 - val_acc: 0.2545\n",
      "Epoch 285/500\n",
      "240/240 [==============================] - 17s 71ms/step - loss: 0.7150 - acc: 0.7500 - val_loss: 4.0029 - val_acc: 0.2545\n",
      "Epoch 286/500\n",
      "240/240 [==============================] - 18s 77ms/step - loss: 0.4704 - acc: 0.8500 - val_loss: 3.8638 - val_acc: 0.2455\n",
      "Epoch 287/500\n",
      "240/240 [==============================] - 19s 78ms/step - loss: 0.4634 - acc: 0.8417 - val_loss: 3.8892 - val_acc: 0.2909\n",
      "Epoch 288/500\n",
      "240/240 [==============================] - 19s 77ms/step - loss: 0.3188 - acc: 0.9208 - val_loss: 4.0066 - val_acc: 0.2273\n",
      "Epoch 289/500\n",
      "240/240 [==============================] - 20s 82ms/step - loss: 0.3219 - acc: 0.9125 - val_loss: 4.2595 - val_acc: 0.2455\n",
      "Epoch 290/500\n",
      "240/240 [==============================] - 38s 158ms/step - loss: 0.4985 - acc: 0.8458 - val_loss: 3.9716 - val_acc: 0.2455\n",
      "Epoch 291/500\n",
      "240/240 [==============================] - 39s 161ms/step - loss: 0.3806 - acc: 0.8542 - val_loss: 4.1155 - val_acc: 0.2273\n",
      "Epoch 292/500\n",
      "240/240 [==============================] - 38s 158ms/step - loss: 0.4820 - acc: 0.8167 - val_loss: 4.3091 - val_acc: 0.2545\n",
      "Epoch 293/500\n",
      "240/240 [==============================] - 37s 154ms/step - loss: 0.4514 - acc: 0.8375 - val_loss: 4.2779 - val_acc: 0.2636\n",
      "Epoch 294/500\n",
      "240/240 [==============================] - 38s 160ms/step - loss: 0.3700 - acc: 0.8833 - val_loss: 4.2782 - val_acc: 0.2364\n",
      "Epoch 295/500\n",
      "240/240 [==============================] - 37s 153ms/step - loss: 0.3087 - acc: 0.9000 - val_loss: 4.4960 - val_acc: 0.2364\n",
      "Epoch 296/500\n",
      "240/240 [==============================] - 36s 152ms/step - loss: 0.1990 - acc: 0.9417 - val_loss: 4.3958 - val_acc: 0.2273\n",
      "Epoch 297/500\n",
      "240/240 [==============================] - 21s 89ms/step - loss: 0.2094 - acc: 0.9417 - val_loss: 4.4286 - val_acc: 0.2636\n",
      "Epoch 298/500\n",
      "240/240 [==============================] - 18s 73ms/step - loss: 0.1974 - acc: 0.9333 - val_loss: 4.4631 - val_acc: 0.2364\n",
      "Epoch 299/500\n",
      "240/240 [==============================] - 18s 74ms/step - loss: 0.1955 - acc: 0.9542 - val_loss: 4.5992 - val_acc: 0.2455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/500\n",
      "240/240 [==============================] - 18s 76ms/step - loss: 0.2127 - acc: 0.9208 - val_loss: 4.5536 - val_acc: 0.2455\n",
      "Epoch 301/500\n",
      "240/240 [==============================] - 18s 73ms/step - loss: 0.2347 - acc: 0.9375 - val_loss: 4.6214 - val_acc: 0.2273\n",
      "Epoch 302/500\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 0.2206 - acc: 0.9375 - val_loss: 4.5938 - val_acc: 0.2091\n",
      "Epoch 303/500\n",
      "240/240 [==============================] - 18s 74ms/step - loss: 0.1955 - acc: 0.9333 - val_loss: 4.6530 - val_acc: 0.2455\n",
      "Epoch 304/500\n",
      "240/240 [==============================] - 17s 71ms/step - loss: 0.1707 - acc: 0.9583 - val_loss: 4.8936 - val_acc: 0.2818\n",
      "Epoch 305/500\n",
      "240/240 [==============================] - 17s 71ms/step - loss: 0.4457 - acc: 0.8417 - val_loss: 4.3116 - val_acc: 0.2545\n",
      "Epoch 306/500\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 0.3579 - acc: 0.8792 - val_loss: 4.3647 - val_acc: 0.2818\n",
      "Epoch 307/500\n",
      "240/240 [==============================] - 17s 71ms/step - loss: 0.3402 - acc: 0.9042 - val_loss: 4.6894 - val_acc: 0.2091\n",
      "Epoch 308/500\n",
      "240/240 [==============================] - 17s 70ms/step - loss: 0.4161 - acc: 0.8458 - val_loss: 4.4286 - val_acc: 0.2727\n",
      "Epoch 309/500\n",
      "240/240 [==============================] - 17s 71ms/step - loss: 0.3897 - acc: 0.8458 - val_loss: 4.3466 - val_acc: 0.2182\n",
      "Epoch 310/500\n",
      "240/240 [==============================] - 17s 73ms/step - loss: 0.4381 - acc: 0.8667 - val_loss: 3.9170 - val_acc: 0.3091\n",
      "Epoch 311/500\n",
      "240/240 [==============================] - 17s 69ms/step - loss: 0.6205 - acc: 0.8000 - val_loss: 4.0151 - val_acc: 0.3182\n",
      "Epoch 312/500\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 0.6466 - acc: 0.8125 - val_loss: 3.8589 - val_acc: 0.2364\n",
      "Epoch 313/500\n",
      "240/240 [==============================] - 17s 70ms/step - loss: 0.5866 - acc: 0.8125 - val_loss: 3.7653 - val_acc: 0.2818\n",
      "Epoch 314/500\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 0.5371 - acc: 0.8167 - val_loss: 3.9229 - val_acc: 0.2545\n",
      "Epoch 315/500\n",
      "240/240 [==============================] - 17s 71ms/step - loss: 0.4795 - acc: 0.8208 - val_loss: 4.2015 - val_acc: 0.2636\n",
      "Epoch 316/500\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 0.4127 - acc: 0.8500 - val_loss: 3.9582 - val_acc: 0.2636\n",
      "Epoch 317/500\n",
      "240/240 [==============================] - 17s 71ms/step - loss: 0.2987 - acc: 0.9042 - val_loss: 4.1696 - val_acc: 0.2273\n",
      "Epoch 318/500\n",
      "240/240 [==============================] - 18s 76ms/step - loss: 0.2282 - acc: 0.9375 - val_loss: 4.2858 - val_acc: 0.2545\n",
      "Epoch 319/500\n",
      "240/240 [==============================] - 17s 71ms/step - loss: 0.1722 - acc: 0.9542 - val_loss: 4.3070 - val_acc: 0.2364\n",
      "Epoch 320/500\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 0.1203 - acc: 0.9792 - val_loss: 4.5844 - val_acc: 0.2364\n",
      "Epoch 321/500\n",
      "240/240 [==============================] - 18s 73ms/step - loss: 0.1500 - acc: 0.9667 - val_loss: 4.5885 - val_acc: 0.2091\n",
      "Epoch 322/500\n",
      "240/240 [==============================] - 17s 73ms/step - loss: 0.1331 - acc: 0.9583 - val_loss: 4.7963 - val_acc: 0.2636\n",
      "Epoch 323/500\n",
      "240/240 [==============================] - 21s 86ms/step - loss: 0.1626 - acc: 0.9458 - val_loss: 4.7742 - val_acc: 0.2364\n",
      "Epoch 324/500\n",
      "240/240 [==============================] - 21s 86ms/step - loss: 0.1687 - acc: 0.9542 - val_loss: 4.8876 - val_acc: 0.2182\n",
      "Epoch 325/500\n",
      "240/240 [==============================] - 21s 86ms/step - loss: 0.1163 - acc: 0.9708 - val_loss: 4.8284 - val_acc: 0.2727\n",
      "Epoch 326/500\n",
      "240/240 [==============================] - 22s 90ms/step - loss: 0.0793 - acc: 0.9792 - val_loss: 5.1719 - val_acc: 0.2455\n",
      "Epoch 327/500\n",
      "240/240 [==============================] - 19s 81ms/step - loss: 0.1110 - acc: 0.9708 - val_loss: 5.0806 - val_acc: 0.2545\n",
      "Epoch 328/500\n",
      "240/240 [==============================] - 18s 75ms/step - loss: 0.0697 - acc: 0.9875 - val_loss: 5.4611 - val_acc: 0.2000\n",
      "Epoch 329/500\n",
      "240/240 [==============================] - 20s 83ms/step - loss: 0.0856 - acc: 0.9750 - val_loss: 5.0819 - val_acc: 0.2455\n",
      "Epoch 330/500\n",
      "240/240 [==============================] - 17s 73ms/step - loss: 0.0690 - acc: 0.9917 - val_loss: 5.2951 - val_acc: 0.2455\n",
      "Epoch 331/500\n",
      "240/240 [==============================] - 19s 79ms/step - loss: 0.0606 - acc: 0.9875 - val_loss: 5.3252 - val_acc: 0.2545\n",
      "Epoch 332/500\n",
      "240/240 [==============================] - 22s 92ms/step - loss: 0.1019 - acc: 0.9708 - val_loss: 5.4780 - val_acc: 0.2455\n",
      "Epoch 333/500\n",
      "240/240 [==============================] - 17s 71ms/step - loss: 0.2947 - acc: 0.9083 - val_loss: 4.9439 - val_acc: 0.2545\n",
      "Epoch 334/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.4428 - acc: 0.8708 - val_loss: 5.1879 - val_acc: 0.2455\n",
      "Epoch 335/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.4495 - acc: 0.8708 - val_loss: 4.6173 - val_acc: 0.2364\n",
      "Epoch 336/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.2914 - acc: 0.8792 - val_loss: 4.7085 - val_acc: 0.2364\n",
      "Epoch 337/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.5494 - acc: 0.8542 - val_loss: 5.1121 - val_acc: 0.1545\n",
      "Epoch 338/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.3648 - acc: 0.9000 - val_loss: 4.5543 - val_acc: 0.2455\n",
      "Epoch 339/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.2904 - acc: 0.9208 - val_loss: 4.4130 - val_acc: 0.2727\n",
      "Epoch 340/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.2752 - acc: 0.9250 - val_loss: 4.4212 - val_acc: 0.2364\n",
      "Epoch 341/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.1770 - acc: 0.9458 - val_loss: 5.0730 - val_acc: 0.2364\n",
      "Epoch 342/500\n",
      "240/240 [==============================] - 16s 68ms/step - loss: 0.2331 - acc: 0.9250 - val_loss: 4.6127 - val_acc: 0.2364\n",
      "Epoch 343/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.3451 - acc: 0.8958 - val_loss: 4.6238 - val_acc: 0.2455\n",
      "Epoch 344/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.3459 - acc: 0.8708 - val_loss: 4.3747 - val_acc: 0.2455\n",
      "Epoch 345/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.2969 - acc: 0.8958 - val_loss: 4.8501 - val_acc: 0.2545\n",
      "Epoch 346/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.2700 - acc: 0.9083 - val_loss: 4.6707 - val_acc: 0.2545\n",
      "Epoch 347/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.2569 - acc: 0.9167 - val_loss: 4.5650 - val_acc: 0.2455\n",
      "Epoch 348/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.3384 - acc: 0.9042 - val_loss: 4.4798 - val_acc: 0.2636\n",
      "Epoch 349/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.2308 - acc: 0.9208 - val_loss: 4.4236 - val_acc: 0.2636\n",
      "Epoch 350/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.2703 - acc: 0.9042 - val_loss: 4.7238 - val_acc: 0.2455\n",
      "Epoch 351/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.3632 - acc: 0.9000 - val_loss: 4.6543 - val_acc: 0.2182\n",
      "Epoch 352/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.2724 - acc: 0.9125 - val_loss: 4.7772 - val_acc: 0.2727\n",
      "Epoch 353/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.1903 - acc: 0.9458 - val_loss: 4.7194 - val_acc: 0.2364\n",
      "Epoch 354/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.1085 - acc: 0.9750 - val_loss: 4.7817 - val_acc: 0.2545\n",
      "Epoch 355/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.1168 - acc: 0.9667 - val_loss: 5.1059 - val_acc: 0.2273\n",
      "Epoch 356/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.1168 - acc: 0.9667 - val_loss: 4.9143 - val_acc: 0.2636\n",
      "Epoch 357/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.1339 - acc: 0.9625 - val_loss: 5.0143 - val_acc: 0.2636\n",
      "Epoch 358/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.2217 - acc: 0.9208 - val_loss: 4.9556 - val_acc: 0.2545\n",
      "Epoch 359/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.2542 - acc: 0.9208 - val_loss: 4.8460 - val_acc: 0.2182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.3240 - acc: 0.8875 - val_loss: 4.9910 - val_acc: 0.2636\n",
      "Epoch 361/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.3486 - acc: 0.8833 - val_loss: 5.2892 - val_acc: 0.2455\n",
      "Epoch 362/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 1.0428 - acc: 0.7125 - val_loss: 3.2515 - val_acc: 0.3182\n",
      "Epoch 363/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.8679 - acc: 0.7292 - val_loss: 3.7247 - val_acc: 0.3182\n",
      "Epoch 364/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.5179 - acc: 0.8167 - val_loss: 3.7212 - val_acc: 0.2545\n",
      "Epoch 365/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.5547 - acc: 0.8125 - val_loss: 3.7941 - val_acc: 0.2636\n",
      "Epoch 366/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.6015 - acc: 0.8500 - val_loss: 3.8550 - val_acc: 0.2818\n",
      "Epoch 367/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.5550 - acc: 0.8458 - val_loss: 3.8735 - val_acc: 0.2091\n",
      "Epoch 368/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.2882 - acc: 0.9208 - val_loss: 4.1048 - val_acc: 0.2364\n",
      "Epoch 369/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.4433 - acc: 0.8875 - val_loss: 3.9527 - val_acc: 0.2000\n",
      "Epoch 370/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.5618 - acc: 0.8708 - val_loss: 3.6768 - val_acc: 0.2091\n",
      "Epoch 371/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.3718 - acc: 0.8917 - val_loss: 4.2018 - val_acc: 0.2364\n",
      "Epoch 372/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.4208 - acc: 0.8708 - val_loss: 4.0281 - val_acc: 0.2727\n",
      "Epoch 373/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.3005 - acc: 0.9125 - val_loss: 4.2229 - val_acc: 0.2455\n",
      "Epoch 374/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.2089 - acc: 0.9500 - val_loss: 4.4250 - val_acc: 0.2636\n",
      "Epoch 375/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.1991 - acc: 0.9542 - val_loss: 4.7065 - val_acc: 0.2545\n",
      "Epoch 376/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.3396 - acc: 0.8917 - val_loss: 4.4371 - val_acc: 0.2455\n",
      "Epoch 377/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.2445 - acc: 0.9333 - val_loss: 4.9802 - val_acc: 0.2364\n",
      "Epoch 378/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.1237 - acc: 0.9667 - val_loss: 4.7544 - val_acc: 0.2364\n",
      "Epoch 379/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.1904 - acc: 0.9375 - val_loss: 4.5707 - val_acc: 0.2545\n",
      "Epoch 380/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.2774 - acc: 0.9000 - val_loss: 4.8191 - val_acc: 0.2455\n",
      "Epoch 381/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.2811 - acc: 0.9167 - val_loss: 4.7748 - val_acc: 0.2545\n",
      "Epoch 382/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.3308 - acc: 0.8958 - val_loss: 4.2358 - val_acc: 0.2636\n",
      "Epoch 383/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.2761 - acc: 0.9083 - val_loss: 4.6920 - val_acc: 0.2545\n",
      "Epoch 384/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.2454 - acc: 0.9208 - val_loss: 4.5681 - val_acc: 0.2545\n",
      "Epoch 385/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.1590 - acc: 0.9500 - val_loss: 4.7281 - val_acc: 0.2909\n",
      "Epoch 386/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.1427 - acc: 0.9542 - val_loss: 4.9260 - val_acc: 0.2727\n",
      "Epoch 387/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.2096 - acc: 0.9333 - val_loss: 4.9015 - val_acc: 0.2636\n",
      "Epoch 388/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.2654 - acc: 0.9167 - val_loss: 4.6559 - val_acc: 0.2364\n",
      "Epoch 389/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.1650 - acc: 0.9625 - val_loss: 4.8238 - val_acc: 0.2545\n",
      "Epoch 390/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.1448 - acc: 0.9708 - val_loss: 4.9807 - val_acc: 0.2455\n",
      "Epoch 391/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.3099 - acc: 0.9125 - val_loss: 4.9271 - val_acc: 0.2455\n",
      "Epoch 392/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.2478 - acc: 0.9125 - val_loss: 5.2370 - val_acc: 0.2364\n",
      "Epoch 393/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.3540 - acc: 0.9000 - val_loss: 4.6474 - val_acc: 0.2545\n",
      "Epoch 394/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.4804 - acc: 0.8375 - val_loss: 4.8537 - val_acc: 0.2636\n",
      "Epoch 395/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.5022 - acc: 0.8375 - val_loss: 4.4936 - val_acc: 0.2545\n",
      "Epoch 396/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.2915 - acc: 0.9125 - val_loss: 4.4237 - val_acc: 0.2273\n",
      "Epoch 397/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.1824 - acc: 0.9333 - val_loss: 4.8421 - val_acc: 0.2636\n",
      "Epoch 398/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.2503 - acc: 0.9333 - val_loss: 5.0026 - val_acc: 0.2727\n",
      "Epoch 399/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.2045 - acc: 0.9458 - val_loss: 4.9112 - val_acc: 0.2727\n",
      "Epoch 400/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.1430 - acc: 0.9500 - val_loss: 4.8358 - val_acc: 0.2545\n",
      "Epoch 401/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.1906 - acc: 0.9458 - val_loss: 4.8033 - val_acc: 0.2364\n",
      "Epoch 402/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.1632 - acc: 0.9500 - val_loss: 5.0035 - val_acc: 0.2182\n",
      "Epoch 403/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.1705 - acc: 0.9625 - val_loss: 4.9653 - val_acc: 0.2455\n",
      "Epoch 404/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.0933 - acc: 0.9792 - val_loss: 5.0113 - val_acc: 0.2636\n",
      "Epoch 405/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.0539 - acc: 0.9917 - val_loss: 5.2570 - val_acc: 0.2455\n",
      "Epoch 406/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.0558 - acc: 0.9833 - val_loss: 5.4487 - val_acc: 0.2455\n",
      "Epoch 407/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.0871 - acc: 0.9750 - val_loss: 5.1799 - val_acc: 0.2273\n",
      "Epoch 408/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.2136 - acc: 0.9125 - val_loss: 5.2385 - val_acc: 0.2273\n",
      "Epoch 409/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.5845 - acc: 0.8333 - val_loss: 4.6916 - val_acc: 0.2545\n",
      "Epoch 410/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.6022 - acc: 0.8500 - val_loss: 4.4916 - val_acc: 0.2273\n",
      "Epoch 411/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.4797 - acc: 0.8875 - val_loss: 4.3722 - val_acc: 0.2455\n",
      "Epoch 412/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.3563 - acc: 0.9000 - val_loss: 4.0234 - val_acc: 0.2545\n",
      "Epoch 413/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.3978 - acc: 0.8917 - val_loss: 3.9477 - val_acc: 0.3182\n",
      "Epoch 414/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.1928 - acc: 0.9375 - val_loss: 4.7572 - val_acc: 0.2545\n",
      "Epoch 415/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.1903 - acc: 0.9417 - val_loss: 4.3260 - val_acc: 0.3182\n",
      "Epoch 416/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.1787 - acc: 0.9333 - val_loss: 4.1106 - val_acc: 0.3182\n",
      "Epoch 417/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.4199 - acc: 0.8708 - val_loss: 4.6673 - val_acc: 0.2909\n",
      "Epoch 418/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.9524 - acc: 0.7750 - val_loss: 4.3816 - val_acc: 0.2182\n",
      "Epoch 419/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 1.2516 - acc: 0.6375 - val_loss: 3.2394 - val_acc: 0.2091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 420/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.9040 - acc: 0.7333 - val_loss: 3.2956 - val_acc: 0.3000\n",
      "Epoch 421/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.6616 - acc: 0.8208 - val_loss: 3.4428 - val_acc: 0.2364\n",
      "Epoch 422/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.4701 - acc: 0.8458 - val_loss: 3.4261 - val_acc: 0.2455\n",
      "Epoch 423/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.4104 - acc: 0.8708 - val_loss: 3.2395 - val_acc: 0.2909\n",
      "Epoch 424/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.3402 - acc: 0.9042 - val_loss: 3.8766 - val_acc: 0.2636\n",
      "Epoch 425/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.3134 - acc: 0.9000 - val_loss: 3.8041 - val_acc: 0.2818\n",
      "Epoch 426/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.4319 - acc: 0.8583 - val_loss: 3.8249 - val_acc: 0.2182\n",
      "Epoch 427/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.3169 - acc: 0.8917 - val_loss: 4.1510 - val_acc: 0.2818\n",
      "Epoch 428/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.2609 - acc: 0.9208 - val_loss: 4.1989 - val_acc: 0.2636\n",
      "Epoch 429/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.2305 - acc: 0.9375 - val_loss: 4.0149 - val_acc: 0.2727\n",
      "Epoch 430/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.2133 - acc: 0.9292 - val_loss: 4.2788 - val_acc: 0.2727\n",
      "Epoch 431/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.1619 - acc: 0.9625 - val_loss: 4.2941 - val_acc: 0.2455\n",
      "Epoch 432/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.1447 - acc: 0.9583 - val_loss: 4.3102 - val_acc: 0.2818\n",
      "Epoch 433/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.1355 - acc: 0.9625 - val_loss: 4.3775 - val_acc: 0.2727\n",
      "Epoch 434/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.2488 - acc: 0.9208 - val_loss: 4.3515 - val_acc: 0.2636\n",
      "Epoch 435/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.1606 - acc: 0.9500 - val_loss: 4.5177 - val_acc: 0.2636\n",
      "Epoch 436/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.1092 - acc: 0.9542 - val_loss: 4.5476 - val_acc: 0.3000\n",
      "Epoch 437/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.1357 - acc: 0.9667 - val_loss: 4.5742 - val_acc: 0.2636\n",
      "Epoch 438/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.0988 - acc: 0.9708 - val_loss: 4.8073 - val_acc: 0.2545\n",
      "Epoch 439/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.1085 - acc: 0.9708 - val_loss: 4.7009 - val_acc: 0.2455\n",
      "Epoch 440/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.0646 - acc: 0.9833 - val_loss: 4.8669 - val_acc: 0.2455\n",
      "Epoch 441/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.0429 - acc: 0.9875 - val_loss: 4.9423 - val_acc: 0.2545\n",
      "Epoch 442/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.0513 - acc: 0.9958 - val_loss: 4.8667 - val_acc: 0.2455\n",
      "Epoch 443/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.0797 - acc: 0.9792 - val_loss: 4.8459 - val_acc: 0.2545\n",
      "Epoch 444/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.0544 - acc: 0.9917 - val_loss: 4.9028 - val_acc: 0.2909\n",
      "Epoch 445/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.0495 - acc: 0.9917 - val_loss: 5.0720 - val_acc: 0.2818\n",
      "Epoch 446/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.0415 - acc: 0.9958 - val_loss: 4.9531 - val_acc: 0.2545\n",
      "Epoch 447/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.0565 - acc: 0.9833 - val_loss: 4.8603 - val_acc: 0.2545\n",
      "Epoch 448/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.0506 - acc: 0.9833 - val_loss: 5.0742 - val_acc: 0.2636\n",
      "Epoch 449/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.0514 - acc: 0.9792 - val_loss: 5.2681 - val_acc: 0.2364\n",
      "Epoch 450/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.0582 - acc: 0.9833 - val_loss: 5.2989 - val_acc: 0.2455\n",
      "Epoch 451/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.0622 - acc: 0.9792 - val_loss: 5.3685 - val_acc: 0.2909\n",
      "Epoch 452/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.0608 - acc: 0.9750 - val_loss: 4.9619 - val_acc: 0.2727\n",
      "Epoch 453/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.1235 - acc: 0.9500 - val_loss: 5.3796 - val_acc: 0.2364\n",
      "Epoch 454/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.7964 - acc: 0.8000 - val_loss: 4.8760 - val_acc: 0.2000\n",
      "Epoch 455/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.9758 - acc: 0.7417 - val_loss: 4.1435 - val_acc: 0.2727\n",
      "Epoch 456/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 1.4961 - acc: 0.6583 - val_loss: 3.6041 - val_acc: 0.2273\n",
      "Epoch 457/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 2.1046 - acc: 0.4083 - val_loss: 3.1392 - val_acc: 0.1636\n",
      "Epoch 458/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 2.2485 - acc: 0.3375 - val_loss: 2.6402 - val_acc: 0.1909\n",
      "Epoch 459/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 1.9495 - acc: 0.2792 - val_loss: 2.5577 - val_acc: 0.1273\n",
      "Epoch 460/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 2.3581 - acc: 0.1708 - val_loss: 2.4037 - val_acc: 0.1273\n",
      "Epoch 461/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 2.2233 - acc: 0.1958 - val_loss: 2.2411 - val_acc: 0.1364\n",
      "Epoch 462/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 2.0577 - acc: 0.2083 - val_loss: 2.4598 - val_acc: 0.1455\n",
      "Epoch 463/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 2.0690 - acc: 0.2875 - val_loss: 2.4359 - val_acc: 0.1455\n",
      "Epoch 464/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 1.9733 - acc: 0.3208 - val_loss: 2.5626 - val_acc: 0.1727\n",
      "Epoch 465/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 1.9818 - acc: 0.3583 - val_loss: 2.7171 - val_acc: 0.1818\n",
      "Epoch 466/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 1.9653 - acc: 0.3333 - val_loss: 2.4833 - val_acc: 0.2273\n",
      "Epoch 467/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 1.8647 - acc: 0.3875 - val_loss: 2.6522 - val_acc: 0.2000\n",
      "Epoch 468/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 1.7593 - acc: 0.4083 - val_loss: 2.5878 - val_acc: 0.2364\n",
      "Epoch 469/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 1.7536 - acc: 0.3708 - val_loss: 2.5756 - val_acc: 0.1818\n",
      "Epoch 470/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 1.6466 - acc: 0.3792 - val_loss: 2.5533 - val_acc: 0.2273\n",
      "Epoch 471/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 1.6199 - acc: 0.4000 - val_loss: 2.5026 - val_acc: 0.1364\n",
      "Epoch 472/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 1.7357 - acc: 0.3958 - val_loss: 2.5848 - val_acc: 0.1545\n",
      "Epoch 473/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 1.4246 - acc: 0.4917 - val_loss: 2.5009 - val_acc: 0.2364\n",
      "Epoch 474/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 1.3492 - acc: 0.5250 - val_loss: 2.5335 - val_acc: 0.2545\n",
      "Epoch 475/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 1.5363 - acc: 0.4500 - val_loss: 2.8852 - val_acc: 0.1364\n",
      "Epoch 476/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 1.5715 - acc: 0.4458 - val_loss: 2.5809 - val_acc: 0.1818\n",
      "Epoch 477/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 1.5945 - acc: 0.4417 - val_loss: 2.8543 - val_acc: 0.1909\n",
      "Epoch 478/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 2.0351 - acc: 0.3875 - val_loss: 2.4863 - val_acc: 0.1818\n",
      "Epoch 479/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 1.8019 - acc: 0.3792 - val_loss: 2.4957 - val_acc: 0.1727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 1.6576 - acc: 0.4125 - val_loss: 2.3777 - val_acc: 0.2273\n",
      "Epoch 481/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 1.4062 - acc: 0.5292 - val_loss: 2.3859 - val_acc: 0.2091\n",
      "Epoch 482/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 1.2705 - acc: 0.5833 - val_loss: 2.4352 - val_acc: 0.2545\n",
      "Epoch 483/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 1.1624 - acc: 0.6042 - val_loss: 2.5391 - val_acc: 0.2545\n",
      "Epoch 484/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 1.0401 - acc: 0.6417 - val_loss: 2.6001 - val_acc: 0.2455\n",
      "Epoch 485/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.9551 - acc: 0.6542 - val_loss: 2.4162 - val_acc: 0.2636\n",
      "Epoch 486/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.8223 - acc: 0.7083 - val_loss: 2.6568 - val_acc: 0.2364\n",
      "Epoch 487/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.8421 - acc: 0.7458 - val_loss: 2.9002 - val_acc: 0.2364\n",
      "Epoch 488/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.8345 - acc: 0.7500 - val_loss: 2.7698 - val_acc: 0.2364\n",
      "Epoch 489/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.7454 - acc: 0.7667 - val_loss: 2.8772 - val_acc: 0.2455\n",
      "Epoch 490/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.6670 - acc: 0.8000 - val_loss: 2.9871 - val_acc: 0.2182\n",
      "Epoch 491/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.5611 - acc: 0.8375 - val_loss: 3.0662 - val_acc: 0.2091\n",
      "Epoch 492/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.5540 - acc: 0.8333 - val_loss: 3.1101 - val_acc: 0.2455\n",
      "Epoch 493/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.5346 - acc: 0.8250 - val_loss: 3.1506 - val_acc: 0.2364\n",
      "Epoch 494/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.5273 - acc: 0.8417 - val_loss: 3.2701 - val_acc: 0.2182\n",
      "Epoch 495/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.4858 - acc: 0.8583 - val_loss: 3.3045 - val_acc: 0.2364\n",
      "Epoch 496/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.4613 - acc: 0.8500 - val_loss: 3.4161 - val_acc: 0.2182\n",
      "Epoch 497/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.5433 - acc: 0.8375 - val_loss: 3.1908 - val_acc: 0.2909\n",
      "Epoch 498/500\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.5470 - acc: 0.8292 - val_loss: 3.3467 - val_acc: 0.2182\n",
      "Epoch 499/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.4393 - acc: 0.8708 - val_loss: 3.3999 - val_acc: 0.2182\n",
      "Epoch 500/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.4120 - acc: 0.8750 - val_loss: 3.5515 - val_acc: 0.2273\n"
     ]
    }
   ],
   "source": [
    "Lstm_mlayer=LSTM_with_3layers('LSTM3layer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.3046 - acc: 0.0583 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 2/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3037 - acc: 0.0667 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 3/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3024 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.0909\n",
      "Epoch 4/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3018 - acc: 0.0667 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 5/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2999 - acc: 0.0583 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 6/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2959 - acc: 0.1083 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 7/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2948 - acc: 0.0750 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 8/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2948 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1091\n",
      "Epoch 9/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2940 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 10/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2940 - acc: 0.0708 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 11/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2941 - acc: 0.1042 - val_loss: 2.3026 - val_acc: 0.1091\n",
      "Epoch 12/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.2939 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 13/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.2943 - acc: 0.0667 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 14/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.2935 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 15/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2942 - acc: 0.0792 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 16/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2942 - acc: 0.0917 - val_loss: 2.3025 - val_acc: 0.1000\n",
      "Epoch 17/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.2931 - acc: 0.0833 - val_loss: 2.3029 - val_acc: 0.0818\n",
      "Epoch 18/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3088 - acc: 0.0667 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 19/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3028 - acc: 0.0792 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 20/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3018 - acc: 0.0750 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 21/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3003 - acc: 0.0875 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 22/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3020 - acc: 0.0583 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 23/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3024 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 24/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3011 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 25/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.2993 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.0818\n",
      "Epoch 26/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.2950 - acc: 0.0833 - val_loss: 2.3033 - val_acc: 0.0818\n",
      "Epoch 27/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3013 - acc: 0.0667 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 28/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3035 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 29/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.2994 - acc: 0.1000 - val_loss: 3.2462 - val_acc: 0.0636\n",
      "Epoch 30/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.7054 - acc: 0.0750 - val_loss: 2.3309 - val_acc: 0.1091\n",
      "Epoch 31/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3543 - acc: 0.0833 - val_loss: 2.3038 - val_acc: 0.1091\n",
      "Epoch 32/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3257 - acc: 0.0708 - val_loss: 2.2850 - val_acc: 0.1182\n",
      "Epoch 33/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3208 - acc: 0.0542 - val_loss: 2.2791 - val_acc: 0.1182\n",
      "Epoch 34/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3105 - acc: 0.0875 - val_loss: 2.2819 - val_acc: 0.1273\n",
      "Epoch 35/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3107 - acc: 0.0708 - val_loss: 2.2810 - val_acc: 0.1091\n",
      "Epoch 36/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3162 - acc: 0.0625 - val_loss: 2.2760 - val_acc: 0.1091\n",
      "Epoch 37/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3109 - acc: 0.0583 - val_loss: 2.2663 - val_acc: 0.1273\n",
      "Epoch 38/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3103 - acc: 0.0833 - val_loss: 2.2707 - val_acc: 0.1273\n",
      "Epoch 39/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3105 - acc: 0.0708 - val_loss: 2.2740 - val_acc: 0.1273\n",
      "Epoch 40/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3051 - acc: 0.0750 - val_loss: 2.2829 - val_acc: 0.1182\n",
      "Epoch 41/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3040 - acc: 0.1000 - val_loss: 2.2653 - val_acc: 0.1273\n",
      "Epoch 42/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3101 - acc: 0.0792 - val_loss: 2.2686 - val_acc: 0.1273\n",
      "Epoch 43/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3033 - acc: 0.1083 - val_loss: 2.2763 - val_acc: 0.1182\n",
      "Epoch 44/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2988 - acc: 0.0875 - val_loss: 2.2780 - val_acc: 0.1182\n",
      "Epoch 45/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2952 - acc: 0.0875 - val_loss: 2.2751 - val_acc: 0.1273\n",
      "Epoch 46/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2976 - acc: 0.0875 - val_loss: 2.2805 - val_acc: 0.1091\n",
      "Epoch 47/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3032 - acc: 0.0875 - val_loss: 2.2959 - val_acc: 0.1000\n",
      "Epoch 48/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3145 - acc: 0.0875 - val_loss: 2.2769 - val_acc: 0.1091\n",
      "Epoch 49/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2962 - acc: 0.0792 - val_loss: 2.2695 - val_acc: 0.1091\n",
      "Epoch 50/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2966 - acc: 0.0750 - val_loss: 2.2769 - val_acc: 0.1091\n",
      "Epoch 51/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2952 - acc: 0.0792 - val_loss: 2.2958 - val_acc: 0.1000\n",
      "Epoch 52/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3016 - acc: 0.0625 - val_loss: 2.2768 - val_acc: 0.1091\n",
      "Epoch 53/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2951 - acc: 0.0917 - val_loss: 2.2722 - val_acc: 0.1091\n",
      "Epoch 54/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2981 - acc: 0.0917 - val_loss: 2.2953 - val_acc: 0.1000\n",
      "Epoch 55/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2992 - acc: 0.0958 - val_loss: 2.2662 - val_acc: 0.1273\n",
      "Epoch 56/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2938 - acc: 0.0750 - val_loss: 2.2917 - val_acc: 0.1091\n",
      "Epoch 57/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3045 - acc: 0.0958 - val_loss: 2.2657 - val_acc: 0.1273\n",
      "Epoch 58/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2996 - acc: 0.0958 - val_loss: 2.2639 - val_acc: 0.1273\n",
      "Epoch 59/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2991 - acc: 0.0958 - val_loss: 2.2622 - val_acc: 0.1273\n",
      "Epoch 60/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2970 - acc: 0.0917 - val_loss: 2.2662 - val_acc: 0.1273\n",
      "Epoch 61/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3046 - acc: 0.0625 - val_loss: 2.2593 - val_acc: 0.1273\n",
      "Epoch 62/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3053 - acc: 0.0917 - val_loss: 2.2664 - val_acc: 0.1182\n",
      "Epoch 63/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2966 - acc: 0.0833 - val_loss: 2.2845 - val_acc: 0.1273\n",
      "Epoch 64/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2993 - acc: 0.0750 - val_loss: 2.2644 - val_acc: 0.1273\n",
      "Epoch 65/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2974 - acc: 0.0958 - val_loss: 2.2612 - val_acc: 0.1273\n",
      "Epoch 66/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3021 - acc: 0.0917 - val_loss: 2.2663 - val_acc: 0.1273\n",
      "Epoch 67/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2957 - acc: 0.0708 - val_loss: 2.2858 - val_acc: 0.1273\n",
      "Epoch 68/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2950 - acc: 0.1042 - val_loss: 2.2639 - val_acc: 0.1273\n",
      "Epoch 69/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3009 - acc: 0.1000 - val_loss: 2.2641 - val_acc: 0.1273\n",
      "Epoch 70/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2915 - acc: 0.1083 - val_loss: 2.2626 - val_acc: 0.1273\n",
      "Epoch 71/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2913 - acc: 0.1042 - val_loss: 2.2833 - val_acc: 0.1182\n",
      "Epoch 72/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2939 - acc: 0.0667 - val_loss: 2.2837 - val_acc: 0.1273\n",
      "Epoch 73/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2953 - acc: 0.0750 - val_loss: 2.2631 - val_acc: 0.1273\n",
      "Epoch 74/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2922 - acc: 0.0917 - val_loss: 2.2614 - val_acc: 0.1273\n",
      "Epoch 75/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2958 - acc: 0.0792 - val_loss: 2.2633 - val_acc: 0.1273\n",
      "Epoch 76/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2902 - acc: 0.0958 - val_loss: 2.2647 - val_acc: 0.1273\n",
      "Epoch 77/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2918 - acc: 0.1125 - val_loss: 2.2865 - val_acc: 0.1182\n",
      "Epoch 78/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2915 - acc: 0.0958 - val_loss: 2.2583 - val_acc: 0.1273\n",
      "Epoch 79/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2992 - acc: 0.1083 - val_loss: 2.2600 - val_acc: 0.1273\n",
      "Epoch 80/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2998 - acc: 0.0958 - val_loss: 2.2638 - val_acc: 0.1273\n",
      "Epoch 81/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3002 - acc: 0.0750 - val_loss: 2.2616 - val_acc: 0.1182\n",
      "Epoch 82/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2884 - acc: 0.0958 - val_loss: 2.2661 - val_acc: 0.1182\n",
      "Epoch 83/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2948 - acc: 0.0708 - val_loss: 2.2600 - val_acc: 0.1273\n",
      "Epoch 84/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2978 - acc: 0.0792 - val_loss: 2.2642 - val_acc: 0.1273\n",
      "Epoch 85/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2958 - acc: 0.0792 - val_loss: 2.2621 - val_acc: 0.1182\n",
      "Epoch 86/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2960 - acc: 0.0958 - val_loss: 2.2621 - val_acc: 0.1273\n",
      "Epoch 87/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2929 - acc: 0.0833 - val_loss: 2.2602 - val_acc: 0.1273\n",
      "Epoch 88/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3072 - acc: 0.0875 - val_loss: 2.2929 - val_acc: 0.1091\n",
      "Epoch 89/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3093 - acc: 0.0792 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 90/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3117 - acc: 0.0500 - val_loss: 2.3038 - val_acc: 0.1000\n",
      "Epoch 91/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3175 - acc: 0.0458 - val_loss: 2.3038 - val_acc: 0.1000\n",
      "Epoch 92/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3189 - acc: 0.0750 - val_loss: 2.3035 - val_acc: 0.1000\n",
      "Epoch 93/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3116 - acc: 0.0958 - val_loss: 2.3035 - val_acc: 0.1000\n",
      "Epoch 94/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3110 - acc: 0.0667 - val_loss: 2.3035 - val_acc: 0.1000\n",
      "Epoch 95/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3100 - acc: 0.0750 - val_loss: 2.3035 - val_acc: 0.1000\n",
      "Epoch 96/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3093 - acc: 0.0750 - val_loss: 2.3032 - val_acc: 0.1000\n",
      "Epoch 97/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3094 - acc: 0.0917 - val_loss: 2.3033 - val_acc: 0.1000\n",
      "Epoch 98/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3105 - acc: 0.0708 - val_loss: 2.3032 - val_acc: 0.1000\n",
      "Epoch 99/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3121 - acc: 0.0792 - val_loss: 2.3037 - val_acc: 0.1000\n",
      "Epoch 100/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3118 - acc: 0.0708 - val_loss: 2.3034 - val_acc: 0.1000\n",
      "Epoch 101/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3115 - acc: 0.0708 - val_loss: 2.3036 - val_acc: 0.1000\n",
      "Epoch 102/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3083 - acc: 0.0833 - val_loss: 2.3033 - val_acc: 0.1000\n",
      "Epoch 103/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3103 - acc: 0.0792 - val_loss: 2.3032 - val_acc: 0.1000\n",
      "Epoch 104/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3091 - acc: 0.0750 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 105/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3158 - acc: 0.0667 - val_loss: 2.3041 - val_acc: 0.1000\n",
      "Epoch 106/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3094 - acc: 0.0833 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 107/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3112 - acc: 0.0708 - val_loss: 2.3032 - val_acc: 0.1000\n",
      "Epoch 108/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3119 - acc: 0.0542 - val_loss: 2.3032 - val_acc: 0.1000\n",
      "Epoch 109/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3120 - acc: 0.0875 - val_loss: 2.3032 - val_acc: 0.1000\n",
      "Epoch 110/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3092 - acc: 0.0792 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 111/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3072 - acc: 0.0750 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 112/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3078 - acc: 0.0542 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 113/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3080 - acc: 0.0625 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 114/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3099 - acc: 0.0833 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 115/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3094 - acc: 0.1000 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 116/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3062 - acc: 0.0917 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 117/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3095 - acc: 0.0958 - val_loss: 2.3035 - val_acc: 0.1000\n",
      "Epoch 118/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3075 - acc: 0.0917 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 119/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3093 - acc: 0.0875 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 120/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3088 - acc: 0.0708 - val_loss: 2.3033 - val_acc: 0.1000\n",
      "Epoch 121/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3081 - acc: 0.0792 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 122/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3091 - acc: 0.0583 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 123/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3085 - acc: 0.0750 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 124/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3085 - acc: 0.0542 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 125/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3094 - acc: 0.0542 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 126/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3123 - acc: 0.1000 - val_loss: 2.3035 - val_acc: 0.1000\n",
      "Epoch 127/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3112 - acc: 0.0667 - val_loss: 2.3036 - val_acc: 0.1000\n",
      "Epoch 128/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3100 - acc: 0.0625 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 129/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3095 - acc: 0.0542 - val_loss: 2.3032 - val_acc: 0.1000\n",
      "Epoch 130/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3087 - acc: 0.0750 - val_loss: 2.3033 - val_acc: 0.1000\n",
      "Epoch 131/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3088 - acc: 0.0750 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 132/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3116 - acc: 0.0833 - val_loss: 2.3036 - val_acc: 0.1000\n",
      "Epoch 133/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3103 - acc: 0.0583 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 134/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3114 - acc: 0.0917 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 135/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3097 - acc: 0.0958 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 136/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3092 - acc: 0.1000 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 137/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3092 - acc: 0.0917 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 138/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3098 - acc: 0.0792 - val_loss: 2.3032 - val_acc: 0.1000\n",
      "Epoch 139/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3115 - acc: 0.0917 - val_loss: 2.3034 - val_acc: 0.1000\n",
      "Epoch 140/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3113 - acc: 0.0917 - val_loss: 2.3036 - val_acc: 0.1000\n",
      "Epoch 141/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3111 - acc: 0.0708 - val_loss: 2.3032 - val_acc: 0.1000\n",
      "Epoch 142/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3119 - acc: 0.0792 - val_loss: 2.3033 - val_acc: 0.1000\n",
      "Epoch 143/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3091 - acc: 0.0583 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 144/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3089 - acc: 0.0750 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 145/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3076 - acc: 0.0750 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 146/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3107 - acc: 0.0833 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 147/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3102 - acc: 0.0667 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 148/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3071 - acc: 0.0917 - val_loss: 2.3032 - val_acc: 0.1000\n",
      "Epoch 149/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3083 - acc: 0.0833 - val_loss: 2.3034 - val_acc: 0.1000\n",
      "Epoch 150/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3100 - acc: 0.0667 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 151/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.3174 - acc: 0.0958 - val_loss: 2.3032 - val_acc: 0.1000\n",
      "Epoch 152/500\n",
      "240/240 [==============================] - 10s 42ms/step - loss: 2.3071 - acc: 0.0792 - val_loss: 2.3034 - val_acc: 0.1000\n",
      "Epoch 153/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.3122 - acc: 0.1000 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 154/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3098 - acc: 0.0792 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 155/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3073 - acc: 0.1000 - val_loss: 2.3035 - val_acc: 0.1000\n",
      "Epoch 156/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3082 - acc: 0.1042 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 157/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3035 - acc: 0.0750 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 158/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3086 - acc: 0.0750 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 159/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3454 - acc: 0.0917 - val_loss: 2.3126 - val_acc: 0.1000\n",
      "Epoch 160/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3080 - acc: 0.1042 - val_loss: 2.3047 - val_acc: 0.1000\n",
      "Epoch 161/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3116 - acc: 0.1000 - val_loss: 2.3035 - val_acc: 0.1000\n",
      "Epoch 162/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3086 - acc: 0.0542 - val_loss: 2.3032 - val_acc: 0.1000\n",
      "Epoch 163/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3084 - acc: 0.0458 - val_loss: 2.3040 - val_acc: 0.1000\n",
      "Epoch 164/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3098 - acc: 0.0625 - val_loss: 2.3040 - val_acc: 0.0909\n",
      "Epoch 165/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3123 - acc: 0.0750 - val_loss: 2.3032 - val_acc: 0.1182\n",
      "Epoch 166/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3068 - acc: 0.0833 - val_loss: 2.3005 - val_acc: 0.0818\n",
      "Epoch 167/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3046 - acc: 0.1208 - val_loss: 2.2967 - val_acc: 0.0909\n",
      "Epoch 168/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2926 - acc: 0.1167 - val_loss: 2.2912 - val_acc: 0.1091\n",
      "Epoch 169/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2861 - acc: 0.1375 - val_loss: 2.2780 - val_acc: 0.1545\n",
      "Epoch 170/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.2881 - acc: 0.1417 - val_loss: 2.2943 - val_acc: 0.1273\n",
      "Epoch 171/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 2.2849 - acc: 0.1458 - val_loss: 2.2913 - val_acc: 0.1182\n",
      "Epoch 172/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2289 - acc: 0.1500 - val_loss: 2.2184 - val_acc: 0.1636\n",
      "Epoch 173/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2329 - acc: 0.1458 - val_loss: 2.2804 - val_acc: 0.1455\n",
      "Epoch 174/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2599 - acc: 0.1417 - val_loss: 2.2802 - val_acc: 0.1091\n",
      "Epoch 175/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2396 - acc: 0.1625 - val_loss: 2.2301 - val_acc: 0.1636\n",
      "Epoch 176/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.1800 - acc: 0.1917 - val_loss: 2.1866 - val_acc: 0.1727\n",
      "Epoch 177/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.1316 - acc: 0.2250 - val_loss: 2.1509 - val_acc: 0.2091\n",
      "Epoch 178/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.0717 - acc: 0.2042 - val_loss: 2.1508 - val_acc: 0.1727\n",
      "Epoch 179/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.0488 - acc: 0.2292 - val_loss: 2.0741 - val_acc: 0.1909\n",
      "Epoch 180/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.9756 - acc: 0.2250 - val_loss: 2.0889 - val_acc: 0.2091\n",
      "Epoch 181/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 5s 22ms/step - loss: 1.9152 - acc: 0.2500 - val_loss: 1.9900 - val_acc: 0.2909\n",
      "Epoch 182/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.8747 - acc: 0.2458 - val_loss: 2.2010 - val_acc: 0.1364\n",
      "Epoch 183/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.1480 - acc: 0.1833 - val_loss: 2.0501 - val_acc: 0.2455\n",
      "Epoch 184/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.1033 - acc: 0.1958 - val_loss: 2.2802 - val_acc: 0.1727\n",
      "Epoch 185/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.2135 - acc: 0.1458 - val_loss: 2.0844 - val_acc: 0.1636\n",
      "Epoch 186/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.9943 - acc: 0.2083 - val_loss: 2.0625 - val_acc: 0.2273\n",
      "Epoch 187/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 2.1876 - acc: 0.1917 - val_loss: 2.2273 - val_acc: 0.1545\n",
      "Epoch 188/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 2.1148 - acc: 0.1958 - val_loss: 2.1265 - val_acc: 0.1818\n",
      "Epoch 189/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 2.0060 - acc: 0.2250 - val_loss: 2.0563 - val_acc: 0.2273\n",
      "Epoch 190/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.9261 - acc: 0.2208 - val_loss: 2.0142 - val_acc: 0.2182\n",
      "Epoch 191/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.8517 - acc: 0.2917 - val_loss: 2.0334 - val_acc: 0.2455\n",
      "Epoch 192/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.8157 - acc: 0.2875 - val_loss: 1.9865 - val_acc: 0.2545\n",
      "Epoch 193/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.7814 - acc: 0.2833 - val_loss: 2.0502 - val_acc: 0.2182\n",
      "Epoch 194/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.7400 - acc: 0.2417 - val_loss: 2.1358 - val_acc: 0.2182\n",
      "Epoch 195/500\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 1.9714 - acc: 0.2208 - val_loss: 2.2407 - val_acc: 0.2091\n",
      "Epoch 196/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 1.7517 - acc: 0.2708 - val_loss: 1.9694 - val_acc: 0.2455\n",
      "Epoch 197/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6807 - acc: 0.2792 - val_loss: 1.9360 - val_acc: 0.2636\n",
      "Epoch 198/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.6420 - acc: 0.3125 - val_loss: 1.9113 - val_acc: 0.2727\n",
      "Epoch 199/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.6159 - acc: 0.3250 - val_loss: 1.9134 - val_acc: 0.2909\n",
      "Epoch 200/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.5595 - acc: 0.3417 - val_loss: 1.9399 - val_acc: 0.2182\n",
      "Epoch 201/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.6777 - acc: 0.2583 - val_loss: 2.3433 - val_acc: 0.1455\n",
      "Epoch 202/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.9275 - acc: 0.2583 - val_loss: 2.0531 - val_acc: 0.2545\n",
      "Epoch 203/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.7046 - acc: 0.2792 - val_loss: 1.9430 - val_acc: 0.2364\n",
      "Epoch 204/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.5538 - acc: 0.3583 - val_loss: 1.9425 - val_acc: 0.2455\n",
      "Epoch 205/500\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 1.4759 - acc: 0.3708 - val_loss: 1.8679 - val_acc: 0.3182\n",
      "Epoch 206/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 1.4363 - acc: 0.3708 - val_loss: 1.9511 - val_acc: 0.3364\n",
      "Epoch 207/500\n",
      "240/240 [==============================] - 10s 43ms/step - loss: 1.4406 - acc: 0.3000 - val_loss: 1.7945 - val_acc: 0.2727\n",
      "Epoch 208/500\n",
      "240/240 [==============================] - 10s 44ms/step - loss: 1.4201 - acc: 0.3708 - val_loss: 1.8795 - val_acc: 0.2818\n",
      "Epoch 209/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 1.4457 - acc: 0.3833 - val_loss: 1.9122 - val_acc: 0.3000\n",
      "Epoch 210/500\n",
      "240/240 [==============================] - 11s 45ms/step - loss: 1.3746 - acc: 0.3375 - val_loss: 1.9250 - val_acc: 0.2818\n",
      "Epoch 211/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 1.3669 - acc: 0.3958 - val_loss: 1.9369 - val_acc: 0.2545\n",
      "Epoch 212/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.5011 - acc: 0.3500 - val_loss: 1.8100 - val_acc: 0.3091\n",
      "Epoch 213/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.5627 - acc: 0.3250 - val_loss: 1.7520 - val_acc: 0.2636\n",
      "Epoch 214/500\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 1.6868 - acc: 0.2708 - val_loss: 1.9971 - val_acc: 0.3091\n",
      "Epoch 215/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 1.5750 - acc: 0.2708 - val_loss: 1.7256 - val_acc: 0.3455\n",
      "Epoch 216/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 1.4488 - acc: 0.4125 - val_loss: 1.6329 - val_acc: 0.3909\n",
      "Epoch 217/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 1.3249 - acc: 0.4583 - val_loss: 1.6384 - val_acc: 0.3364\n",
      "Epoch 218/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3011 - acc: 0.4458 - val_loss: 1.7045 - val_acc: 0.3182\n",
      "Epoch 219/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3170 - acc: 0.4125 - val_loss: 1.9302 - val_acc: 0.3273\n",
      "Epoch 220/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4314 - acc: 0.3208 - val_loss: 1.7920 - val_acc: 0.3182\n",
      "Epoch 221/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.9131 - acc: 0.3250 - val_loss: 2.5947 - val_acc: 0.2182\n",
      "Epoch 222/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.5213 - acc: 0.1375 - val_loss: 2.4565 - val_acc: 0.1364\n",
      "Epoch 223/500\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 2.2962 - acc: 0.1458 - val_loss: 2.4769 - val_acc: 0.1727\n",
      "Epoch 224/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.1611 - acc: 0.2042 - val_loss: 2.2442 - val_acc: 0.1636\n",
      "Epoch 225/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.1196 - acc: 0.1667 - val_loss: 2.2135 - val_acc: 0.2000\n",
      "Epoch 226/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 1.9823 - acc: 0.2167 - val_loss: 2.1358 - val_acc: 0.2000\n",
      "Epoch 227/500\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 1.8319 - acc: 0.2625 - val_loss: 2.0705 - val_acc: 0.1818\n",
      "Epoch 228/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 2.1585 - acc: 0.1667 - val_loss: 2.1348 - val_acc: 0.1455\n",
      "Epoch 229/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.9783 - acc: 0.2333 - val_loss: 2.0636 - val_acc: 0.2455\n",
      "Epoch 230/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.8797 - acc: 0.2458 - val_loss: 1.9591 - val_acc: 0.2273\n",
      "Epoch 231/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.7346 - acc: 0.2875 - val_loss: 1.9081 - val_acc: 0.2273\n",
      "Epoch 232/500\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 1.6620 - acc: 0.2875 - val_loss: 1.8785 - val_acc: 0.3000\n",
      "Epoch 233/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.5996 - acc: 0.3250 - val_loss: 1.8510 - val_acc: 0.2636\n",
      "Epoch 234/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5947 - acc: 0.3458 - val_loss: 1.8439 - val_acc: 0.2818\n",
      "Epoch 235/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.5679 - acc: 0.3542 - val_loss: 1.8574 - val_acc: 0.2727\n",
      "Epoch 236/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.5210 - acc: 0.3083 - val_loss: 1.8914 - val_acc: 0.2364\n",
      "Epoch 237/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4622 - acc: 0.3583 - val_loss: 1.8894 - val_acc: 0.2727\n",
      "Epoch 238/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4667 - acc: 0.3625 - val_loss: 1.8881 - val_acc: 0.2818\n",
      "Epoch 239/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.4719 - acc: 0.3292 - val_loss: 1.8411 - val_acc: 0.2818\n",
      "Epoch 240/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.5314 - acc: 0.3583 - val_loss: 1.8331 - val_acc: 0.2636\n",
      "Epoch 241/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4275 - acc: 0.3917 - val_loss: 1.8666 - val_acc: 0.2636\n",
      "Epoch 242/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.3168 - acc: 0.4125 - val_loss: 1.8692 - val_acc: 0.3273\n",
      "Epoch 243/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.6893 - acc: 0.2917 - val_loss: 1.9724 - val_acc: 0.2364\n",
      "Epoch 244/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.6003 - acc: 0.3125 - val_loss: 1.8817 - val_acc: 0.2455\n",
      "Epoch 245/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4367 - acc: 0.3917 - val_loss: 1.7355 - val_acc: 0.3364\n",
      "Epoch 246/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2969 - acc: 0.4542 - val_loss: 1.9164 - val_acc: 0.2636\n",
      "Epoch 247/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2919 - acc: 0.4458 - val_loss: 2.6955 - val_acc: 0.2000\n",
      "Epoch 248/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.4746 - acc: 0.2750 - val_loss: 2.1573 - val_acc: 0.2818\n",
      "Epoch 249/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7235 - acc: 0.3083 - val_loss: 1.7796 - val_acc: 0.2636\n",
      "Epoch 250/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5797 - acc: 0.3292 - val_loss: 1.7289 - val_acc: 0.2909\n",
      "Epoch 251/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.5600 - acc: 0.3458 - val_loss: 1.7927 - val_acc: 0.3545\n",
      "Epoch 252/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5031 - acc: 0.2958 - val_loss: 1.6432 - val_acc: 0.3273\n",
      "Epoch 253/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.4244 - acc: 0.3958 - val_loss: 1.6572 - val_acc: 0.3364\n",
      "Epoch 254/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3471 - acc: 0.3958 - val_loss: 1.6138 - val_acc: 0.4000\n",
      "Epoch 255/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2759 - acc: 0.4750 - val_loss: 1.5805 - val_acc: 0.3727\n",
      "Epoch 256/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2241 - acc: 0.4417 - val_loss: 1.5497 - val_acc: 0.3727\n",
      "Epoch 257/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.1971 - acc: 0.4292 - val_loss: 1.5442 - val_acc: 0.3273\n",
      "Epoch 258/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.1261 - acc: 0.4708 - val_loss: 1.5243 - val_acc: 0.4000\n",
      "Epoch 259/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0759 - acc: 0.4542 - val_loss: 1.4976 - val_acc: 0.4182\n",
      "Epoch 260/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0725 - acc: 0.4625 - val_loss: 1.5176 - val_acc: 0.3545\n",
      "Epoch 261/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0813 - acc: 0.4375 - val_loss: 1.6938 - val_acc: 0.3545\n",
      "Epoch 262/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4116 - acc: 0.3375 - val_loss: 1.5100 - val_acc: 0.2727\n",
      "Epoch 263/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3838 - acc: 0.3458 - val_loss: 1.7305 - val_acc: 0.3364\n",
      "Epoch 264/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3682 - acc: 0.3833 - val_loss: 1.4995 - val_acc: 0.4000\n",
      "Epoch 265/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.1917 - acc: 0.4750 - val_loss: 1.4418 - val_acc: 0.4364\n",
      "Epoch 266/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.0934 - acc: 0.4708 - val_loss: 1.4541 - val_acc: 0.4182\n",
      "Epoch 267/500\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.0218 - acc: 0.5583 - val_loss: 1.4777 - val_acc: 0.4091\n",
      "Epoch 268/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.0637 - acc: 0.5042 - val_loss: 1.3784 - val_acc: 0.4636\n",
      "Epoch 269/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.1119 - acc: 0.4667 - val_loss: 1.3388 - val_acc: 0.4091\n",
      "Epoch 270/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.9803 - acc: 0.5333 - val_loss: 1.4475 - val_acc: 0.4545\n",
      "Epoch 271/500\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.9536 - acc: 0.5208 - val_loss: 1.3214 - val_acc: 0.4818\n",
      "Epoch 272/500\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.9335 - acc: 0.5375 - val_loss: 1.2668 - val_acc: 0.4818\n",
      "Epoch 273/500\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.8771 - acc: 0.6042 - val_loss: 1.3499 - val_acc: 0.4182\n",
      "Epoch 274/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.8412 - acc: 0.5917 - val_loss: 1.3316 - val_acc: 0.4818\n",
      "Epoch 275/500\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.8510 - acc: 0.6000 - val_loss: 1.3608 - val_acc: 0.4545\n",
      "Epoch 276/500\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.9159 - acc: 0.5125 - val_loss: 1.4707 - val_acc: 0.4091\n",
      "Epoch 277/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.8312 - acc: 0.5833 - val_loss: 1.3937 - val_acc: 0.4818\n",
      "Epoch 278/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.7709 - acc: 0.6375 - val_loss: 1.3169 - val_acc: 0.4636\n",
      "Epoch 279/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.8086 - acc: 0.6000 - val_loss: 1.3563 - val_acc: 0.4727\n",
      "Epoch 280/500\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.8152 - acc: 0.6000 - val_loss: 1.3582 - val_acc: 0.4909\n",
      "Epoch 281/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.7774 - acc: 0.6208 - val_loss: 1.6214 - val_acc: 0.4182\n",
      "Epoch 282/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.0080 - acc: 0.4917 - val_loss: 1.4141 - val_acc: 0.4545\n",
      "Epoch 283/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.9294 - acc: 0.5708 - val_loss: 1.5353 - val_acc: 0.4545\n",
      "Epoch 284/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8462 - acc: 0.5958 - val_loss: 1.4282 - val_acc: 0.4636\n",
      "Epoch 285/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8146 - acc: 0.6042 - val_loss: 1.3543 - val_acc: 0.4727\n",
      "Epoch 286/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7522 - acc: 0.6833 - val_loss: 1.3572 - val_acc: 0.4727\n",
      "Epoch 287/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7290 - acc: 0.6708 - val_loss: 1.4307 - val_acc: 0.4636\n",
      "Epoch 288/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7391 - acc: 0.6250 - val_loss: 1.5269 - val_acc: 0.4545\n",
      "Epoch 289/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7918 - acc: 0.6208 - val_loss: 1.4418 - val_acc: 0.4545\n",
      "Epoch 290/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7792 - acc: 0.6542 - val_loss: 1.4266 - val_acc: 0.4273\n",
      "Epoch 291/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7534 - acc: 0.6500 - val_loss: 1.3695 - val_acc: 0.4182\n",
      "Epoch 292/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7027 - acc: 0.7083 - val_loss: 1.3866 - val_acc: 0.4545\n",
      "Epoch 293/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6422 - acc: 0.7375 - val_loss: 1.3327 - val_acc: 0.5091\n",
      "Epoch 294/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6188 - acc: 0.6750 - val_loss: 1.3482 - val_acc: 0.5000\n",
      "Epoch 295/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5984 - acc: 0.7000 - val_loss: 1.3813 - val_acc: 0.5091\n",
      "Epoch 296/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.6491 - acc: 0.7042 - val_loss: 1.5712 - val_acc: 0.4545\n",
      "Epoch 297/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6876 - acc: 0.7208 - val_loss: 1.4361 - val_acc: 0.4818\n",
      "Epoch 298/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7423 - acc: 0.5958 - val_loss: 1.3313 - val_acc: 0.4545\n",
      "Epoch 299/500\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.6511 - acc: 0.6875 - val_loss: 1.5685 - val_acc: 0.4727\n",
      "Epoch 300/500\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.9158 - acc: 0.5417 - val_loss: 1.5444 - val_acc: 0.4364\n",
      "Epoch 301/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 7s 30ms/step - loss: 0.9252 - acc: 0.5375 - val_loss: 1.3343 - val_acc: 0.5000\n",
      "Epoch 302/500\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.7523 - acc: 0.6250 - val_loss: 1.3655 - val_acc: 0.5273\n",
      "Epoch 303/500\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.6461 - acc: 0.7250 - val_loss: 1.3906 - val_acc: 0.4909\n",
      "Epoch 304/500\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.6079 - acc: 0.7000 - val_loss: 1.3515 - val_acc: 0.5636\n",
      "Epoch 305/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.6257 - acc: 0.7292 - val_loss: 1.4692 - val_acc: 0.5000\n",
      "Epoch 306/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.7172 - acc: 0.7167 - val_loss: 1.6146 - val_acc: 0.4727\n",
      "Epoch 307/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.7451 - acc: 0.6250 - val_loss: 1.6218 - val_acc: 0.4000\n",
      "Epoch 308/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.9914 - acc: 0.5958 - val_loss: 1.4460 - val_acc: 0.4364\n",
      "Epoch 309/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7926 - acc: 0.6292 - val_loss: 1.4419 - val_acc: 0.4727\n",
      "Epoch 310/500\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.7151 - acc: 0.6792 - val_loss: 1.3914 - val_acc: 0.5182\n",
      "Epoch 311/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.5952 - acc: 0.7292 - val_loss: 1.3362 - val_acc: 0.5091\n",
      "Epoch 312/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5912 - acc: 0.6750 - val_loss: 1.2635 - val_acc: 0.5091\n",
      "Epoch 313/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5554 - acc: 0.7542 - val_loss: 1.2806 - val_acc: 0.5364\n",
      "Epoch 314/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5244 - acc: 0.7375 - val_loss: 1.2209 - val_acc: 0.5091\n",
      "Epoch 315/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4788 - acc: 0.7750 - val_loss: 1.3182 - val_acc: 0.5455\n",
      "Epoch 316/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4517 - acc: 0.7750 - val_loss: 1.3665 - val_acc: 0.5273\n",
      "Epoch 317/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4429 - acc: 0.7667 - val_loss: 1.3866 - val_acc: 0.5273\n",
      "Epoch 318/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6534 - acc: 0.6583 - val_loss: 1.4396 - val_acc: 0.4818\n",
      "Epoch 319/500\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7886 - acc: 0.6125 - val_loss: 1.3613 - val_acc: 0.5000\n",
      "Epoch 320/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6348 - acc: 0.6917 - val_loss: 1.2590 - val_acc: 0.5182\n",
      "Epoch 321/500\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.6345 - acc: 0.6875 - val_loss: 1.2552 - val_acc: 0.5636\n",
      "Epoch 322/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5904 - acc: 0.7208 - val_loss: 1.2628 - val_acc: 0.5182\n",
      "Epoch 323/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5318 - acc: 0.7833 - val_loss: 1.4400 - val_acc: 0.5000\n",
      "Epoch 324/500\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.5077 - acc: 0.7375 - val_loss: 1.3547 - val_acc: 0.5455\n",
      "Epoch 325/500\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.4693 - acc: 0.7792 - val_loss: 1.3733 - val_acc: 0.5545\n",
      "Epoch 326/500\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.4463 - acc: 0.7792 - val_loss: 1.3345 - val_acc: 0.5727\n",
      "Epoch 327/500\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.4154 - acc: 0.7833 - val_loss: 1.3759 - val_acc: 0.5455\n",
      "Epoch 328/500\n",
      "240/240 [==============================] - 9s 35ms/step - loss: 0.3916 - acc: 0.8042 - val_loss: 1.3551 - val_acc: 0.5909\n",
      "Epoch 329/500\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.3840 - acc: 0.8000 - val_loss: 1.3961 - val_acc: 0.5818\n",
      "Epoch 330/500\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.3757 - acc: 0.7750 - val_loss: 1.6420 - val_acc: 0.4727\n",
      "Epoch 331/500\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.8539 - acc: 0.6333 - val_loss: 1.6303 - val_acc: 0.5000\n",
      "Epoch 332/500\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.9442 - acc: 0.6042 - val_loss: 1.3058 - val_acc: 0.5818\n",
      "Epoch 333/500\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.7824 - acc: 0.6250 - val_loss: 1.2855 - val_acc: 0.5000\n",
      "Epoch 334/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.6623 - acc: 0.6958 - val_loss: 1.3068 - val_acc: 0.5273\n",
      "Epoch 335/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.5466 - acc: 0.7417 - val_loss: 1.2332 - val_acc: 0.5727\n",
      "Epoch 336/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.5059 - acc: 0.7458 - val_loss: 1.2937 - val_acc: 0.5818\n",
      "Epoch 337/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.4595 - acc: 0.7958 - val_loss: 1.2583 - val_acc: 0.5545\n",
      "Epoch 338/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.4314 - acc: 0.8167 - val_loss: 1.2798 - val_acc: 0.5818\n",
      "Epoch 339/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.4114 - acc: 0.7875 - val_loss: 1.2757 - val_acc: 0.5909\n",
      "Epoch 340/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.3859 - acc: 0.8208 - val_loss: 1.2897 - val_acc: 0.6000\n",
      "Epoch 341/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.3740 - acc: 0.8125 - val_loss: 1.3406 - val_acc: 0.6182\n",
      "Epoch 342/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.3584 - acc: 0.8208 - val_loss: 1.3238 - val_acc: 0.6000\n",
      "Epoch 343/500\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.3523 - acc: 0.8208 - val_loss: 1.3315 - val_acc: 0.5909\n",
      "Epoch 344/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.3362 - acc: 0.8375 - val_loss: 1.3651 - val_acc: 0.5545\n",
      "Epoch 345/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.3441 - acc: 0.8000 - val_loss: 1.3980 - val_acc: 0.5455\n",
      "Epoch 346/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.3783 - acc: 0.7917 - val_loss: 1.5649 - val_acc: 0.5727\n",
      "Epoch 347/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.5440 - acc: 0.7417 - val_loss: 2.0095 - val_acc: 0.4636\n",
      "Epoch 348/500\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.1279 - acc: 0.5333 - val_loss: 1.8001 - val_acc: 0.4909\n",
      "Epoch 349/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8077 - acc: 0.6250 - val_loss: 1.2779 - val_acc: 0.5909\n",
      "Epoch 350/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6665 - acc: 0.7417 - val_loss: 1.5431 - val_acc: 0.4909\n",
      "Epoch 351/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7158 - acc: 0.6792 - val_loss: 1.4959 - val_acc: 0.4909\n",
      "Epoch 352/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5501 - acc: 0.7250 - val_loss: 1.3736 - val_acc: 0.5091\n",
      "Epoch 353/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4840 - acc: 0.7833 - val_loss: 1.3203 - val_acc: 0.6636\n",
      "Epoch 354/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4457 - acc: 0.8042 - val_loss: 1.3513 - val_acc: 0.6273\n",
      "Epoch 355/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.3968 - acc: 0.8083 - val_loss: 1.3404 - val_acc: 0.6000\n",
      "Epoch 356/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.3763 - acc: 0.8375 - val_loss: 1.4081 - val_acc: 0.6364\n",
      "Epoch 357/500\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.3552 - acc: 0.8500 - val_loss: 1.4141 - val_acc: 0.5818\n",
      "Epoch 358/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.3454 - acc: 0.8750 - val_loss: 1.4675 - val_acc: 0.6273\n",
      "Epoch 359/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.3341 - acc: 0.8292 - val_loss: 1.4970 - val_acc: 0.5727\n",
      "Epoch 360/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.3322 - acc: 0.8667 - val_loss: 1.5434 - val_acc: 0.6000\n",
      "Epoch 361/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 8s 33ms/step - loss: 0.3378 - acc: 0.8500 - val_loss: 1.5681 - val_acc: 0.5636\n",
      "Epoch 362/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.3395 - acc: 0.8500 - val_loss: 1.6847 - val_acc: 0.5636\n",
      "Epoch 363/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.3255 - acc: 0.8458 - val_loss: 1.4737 - val_acc: 0.6182\n",
      "Epoch 364/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.2902 - acc: 0.8792 - val_loss: 1.4942 - val_acc: 0.6818\n",
      "Epoch 365/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.2912 - acc: 0.8667 - val_loss: 1.6664 - val_acc: 0.5364\n",
      "Epoch 366/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.3764 - acc: 0.8083 - val_loss: 1.7148 - val_acc: 0.5273\n",
      "Epoch 367/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.2846 - acc: 0.5833 - val_loss: 2.3265 - val_acc: 0.3909\n",
      "Epoch 368/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 2.0241 - acc: 0.3958 - val_loss: 2.0732 - val_acc: 0.3000\n",
      "Epoch 369/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 1.4902 - acc: 0.4583 - val_loss: 1.9124 - val_acc: 0.3636\n",
      "Epoch 370/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.3836 - acc: 0.4833 - val_loss: 1.8078 - val_acc: 0.4273\n",
      "Epoch 371/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 1.0776 - acc: 0.6167 - val_loss: 1.7114 - val_acc: 0.3818\n",
      "Epoch 372/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.9297 - acc: 0.6500 - val_loss: 1.5233 - val_acc: 0.4727\n",
      "Epoch 373/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.7919 - acc: 0.7250 - val_loss: 1.5605 - val_acc: 0.4636\n",
      "Epoch 374/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.7765 - acc: 0.7375 - val_loss: 1.4258 - val_acc: 0.5091\n",
      "Epoch 375/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.7982 - acc: 0.7167 - val_loss: 1.5328 - val_acc: 0.5091\n",
      "Epoch 376/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.8082 - acc: 0.7417 - val_loss: 1.4860 - val_acc: 0.5273\n",
      "Epoch 377/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.7440 - acc: 0.7833 - val_loss: 1.5470 - val_acc: 0.4909\n",
      "Epoch 378/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.6846 - acc: 0.7875 - val_loss: 1.5378 - val_acc: 0.4636\n",
      "Epoch 379/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.7003 - acc: 0.7667 - val_loss: 2.0746 - val_acc: 0.3636\n",
      "Epoch 380/500\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.9154 - acc: 0.6833 - val_loss: 2.0609 - val_acc: 0.4636\n",
      "Epoch 381/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.9340 - acc: 0.7000 - val_loss: 1.5880 - val_acc: 0.4909\n",
      "Epoch 382/500\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.7910 - acc: 0.7250 - val_loss: 1.4126 - val_acc: 0.5455\n",
      "Epoch 383/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.5989 - acc: 0.7792 - val_loss: 1.3041 - val_acc: 0.6182\n",
      "Epoch 384/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.5095 - acc: 0.8167 - val_loss: 1.4201 - val_acc: 0.6091\n",
      "Epoch 385/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.5658 - acc: 0.8042 - val_loss: 1.3358 - val_acc: 0.6364\n",
      "Epoch 386/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.4946 - acc: 0.8417 - val_loss: 1.3211 - val_acc: 0.6364\n",
      "Epoch 387/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.4401 - acc: 0.8667 - val_loss: 1.4454 - val_acc: 0.5727\n",
      "Epoch 388/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.3784 - acc: 0.8750 - val_loss: 1.3694 - val_acc: 0.6273\n",
      "Epoch 389/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.3786 - acc: 0.8667 - val_loss: 1.3658 - val_acc: 0.6273\n",
      "Epoch 390/500\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.3282 - acc: 0.8667 - val_loss: 1.4646 - val_acc: 0.6182\n",
      "Epoch 391/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.3070 - acc: 0.9042 - val_loss: 1.4176 - val_acc: 0.6545\n",
      "Epoch 392/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.9739 - acc: 0.7333 - val_loss: 2.7430 - val_acc: 0.3636\n",
      "Epoch 393/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.9168 - acc: 0.4250 - val_loss: 2.3674 - val_acc: 0.3273\n",
      "Epoch 394/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 1.3147 - acc: 0.5083 - val_loss: 1.9932 - val_acc: 0.4455\n",
      "Epoch 395/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.9381 - acc: 0.6750 - val_loss: 1.9280 - val_acc: 0.4818\n",
      "Epoch 396/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.8517 - acc: 0.6958 - val_loss: 1.9201 - val_acc: 0.5091\n",
      "Epoch 397/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.7379 - acc: 0.7750 - val_loss: 1.8649 - val_acc: 0.4818\n",
      "Epoch 398/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.7062 - acc: 0.7750 - val_loss: 2.0782 - val_acc: 0.4273\n",
      "Epoch 399/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.9270 - acc: 0.7167 - val_loss: 1.9148 - val_acc: 0.4545\n",
      "Epoch 400/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.7309 - acc: 0.7583 - val_loss: 1.7611 - val_acc: 0.5364\n",
      "Epoch 401/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.6451 - acc: 0.7917 - val_loss: 1.6771 - val_acc: 0.5545\n",
      "Epoch 402/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.5958 - acc: 0.7833 - val_loss: 1.7618 - val_acc: 0.5182\n",
      "Epoch 403/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.5806 - acc: 0.8042 - val_loss: 1.7217 - val_acc: 0.5273\n",
      "Epoch 404/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.5712 - acc: 0.7875 - val_loss: 1.6113 - val_acc: 0.5909\n",
      "Epoch 405/500\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.5253 - acc: 0.8292 - val_loss: 1.5801 - val_acc: 0.5455\n",
      "Epoch 406/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.6358 - acc: 0.7625 - val_loss: 1.5966 - val_acc: 0.5727\n",
      "Epoch 407/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.5251 - acc: 0.7833 - val_loss: 1.5461 - val_acc: 0.5636\n",
      "Epoch 408/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.4388 - acc: 0.8500 - val_loss: 1.4963 - val_acc: 0.5909\n",
      "Epoch 409/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.8060 - acc: 0.6917 - val_loss: 1.7178 - val_acc: 0.4818\n",
      "Epoch 410/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.7426 - acc: 0.7292 - val_loss: 1.6458 - val_acc: 0.4727\n",
      "Epoch 411/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.6264 - acc: 0.7500 - val_loss: 1.6963 - val_acc: 0.4818\n",
      "Epoch 412/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.5662 - acc: 0.8125 - val_loss: 1.6093 - val_acc: 0.4727\n",
      "Epoch 413/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.5391 - acc: 0.8083 - val_loss: 1.5754 - val_acc: 0.5091\n",
      "Epoch 414/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.5424 - acc: 0.8000 - val_loss: 1.5006 - val_acc: 0.5364\n",
      "Epoch 415/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.5399 - acc: 0.7833 - val_loss: 1.5821 - val_acc: 0.5455\n",
      "Epoch 416/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.4835 - acc: 0.8250 - val_loss: 1.5511 - val_acc: 0.5636\n",
      "Epoch 417/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.4473 - acc: 0.8292 - val_loss: 1.5942 - val_acc: 0.5818\n",
      "Epoch 418/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.5520 - acc: 0.7917 - val_loss: 1.4458 - val_acc: 0.5727\n",
      "Epoch 419/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.4642 - acc: 0.8208 - val_loss: 1.4943 - val_acc: 0.5909\n",
      "Epoch 420/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.5462 - acc: 0.7917 - val_loss: 1.4318 - val_acc: 0.6091\n",
      "Epoch 421/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 8s 32ms/step - loss: 0.5341 - acc: 0.7917 - val_loss: 1.4000 - val_acc: 0.5818\n",
      "Epoch 422/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.4884 - acc: 0.8083 - val_loss: 1.5838 - val_acc: 0.5364\n",
      "Epoch 423/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.5694 - acc: 0.8000 - val_loss: 1.6849 - val_acc: 0.5636\n",
      "Epoch 424/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.5615 - acc: 0.7958 - val_loss: 1.5770 - val_acc: 0.6091\n",
      "Epoch 425/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.3991 - acc: 0.8500 - val_loss: 1.5842 - val_acc: 0.6000\n",
      "Epoch 426/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.3809 - acc: 0.8708 - val_loss: 1.5792 - val_acc: 0.5909\n",
      "Epoch 427/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.3906 - acc: 0.8500 - val_loss: 1.6154 - val_acc: 0.5636\n",
      "Epoch 428/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.3576 - acc: 0.8750 - val_loss: 1.6437 - val_acc: 0.6000\n",
      "Epoch 429/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.3953 - acc: 0.8250 - val_loss: 1.8042 - val_acc: 0.5000\n",
      "Epoch 430/500\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.3429 - acc: 0.8792 - val_loss: 1.6355 - val_acc: 0.5909\n",
      "Epoch 431/500\n",
      "240/240 [==============================] - 10s 44ms/step - loss: 0.4407 - acc: 0.8250 - val_loss: 1.9993 - val_acc: 0.5182\n",
      "Epoch 432/500\n",
      "240/240 [==============================] - 10s 42ms/step - loss: 0.6322 - acc: 0.7625 - val_loss: 1.7578 - val_acc: 0.5455\n",
      "Epoch 433/500\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.5898 - acc: 0.8167 - val_loss: 1.6831 - val_acc: 0.5636\n",
      "Epoch 434/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.4406 - acc: 0.8500 - val_loss: 1.5180 - val_acc: 0.6182\n",
      "Epoch 435/500\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.3828 - acc: 0.8667 - val_loss: 1.4630 - val_acc: 0.6273\n",
      "Epoch 436/500\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.3349 - acc: 0.8792 - val_loss: 1.5512 - val_acc: 0.6091\n",
      "Epoch 437/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.3288 - acc: 0.8792 - val_loss: 1.5691 - val_acc: 0.5909\n",
      "Epoch 438/500\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 0.3075 - acc: 0.8875 - val_loss: 1.5848 - val_acc: 0.6182\n",
      "Epoch 439/500\n",
      "240/240 [==============================] - 10s 42ms/step - loss: 0.2924 - acc: 0.9000 - val_loss: 1.5872 - val_acc: 0.6182\n",
      "Epoch 440/500\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.2688 - acc: 0.9042 - val_loss: 1.5258 - val_acc: 0.6273\n",
      "Epoch 441/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.2662 - acc: 0.9000 - val_loss: 1.5463 - val_acc: 0.6455\n",
      "Epoch 442/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.2520 - acc: 0.9083 - val_loss: 1.5884 - val_acc: 0.6273\n",
      "Epoch 443/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.2686 - acc: 0.9042 - val_loss: 1.7015 - val_acc: 0.6091\n",
      "Epoch 444/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.2513 - acc: 0.9083 - val_loss: 1.6269 - val_acc: 0.6455\n",
      "Epoch 445/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.2314 - acc: 0.9167 - val_loss: 1.7019 - val_acc: 0.6182\n",
      "Epoch 446/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.3188 - acc: 0.8875 - val_loss: 1.6990 - val_acc: 0.5727\n",
      "Epoch 447/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.2847 - acc: 0.8958 - val_loss: 1.5299 - val_acc: 0.6000\n",
      "Epoch 448/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.2613 - acc: 0.9125 - val_loss: 1.5991 - val_acc: 0.5909\n",
      "Epoch 449/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.2561 - acc: 0.9208 - val_loss: 1.6578 - val_acc: 0.6000\n",
      "Epoch 450/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.5172 - acc: 0.8542 - val_loss: 1.6126 - val_acc: 0.5000\n",
      "Epoch 451/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.4508 - acc: 0.8667 - val_loss: 1.4630 - val_acc: 0.5909\n",
      "Epoch 452/500\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.3551 - acc: 0.8917 - val_loss: 1.3523 - val_acc: 0.5727\n",
      "Epoch 453/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.2700 - acc: 0.9292 - val_loss: 1.4240 - val_acc: 0.5636\n",
      "Epoch 454/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.2555 - acc: 0.9292 - val_loss: 1.4113 - val_acc: 0.5909\n",
      "Epoch 455/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.2382 - acc: 0.9292 - val_loss: 1.4795 - val_acc: 0.5727\n",
      "Epoch 456/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.2242 - acc: 0.9333 - val_loss: 1.4978 - val_acc: 0.6000\n",
      "Epoch 457/500\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.2169 - acc: 0.9333 - val_loss: 1.4632 - val_acc: 0.6182\n",
      "Epoch 458/500\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.2981 - acc: 0.9042 - val_loss: 1.4927 - val_acc: 0.6182\n",
      "Epoch 459/500\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.2715 - acc: 0.9250 - val_loss: 1.4594 - val_acc: 0.6455\n",
      "Epoch 460/500\n",
      "240/240 [==============================] - 11s 45ms/step - loss: 0.2340 - acc: 0.9333 - val_loss: 1.5062 - val_acc: 0.6182\n",
      "Epoch 461/500\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 0.2316 - acc: 0.9292 - val_loss: 1.5387 - val_acc: 0.6273\n",
      "Epoch 462/500\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.3699 - acc: 0.8833 - val_loss: 1.6737 - val_acc: 0.5545\n",
      "Epoch 463/500\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.2928 - acc: 0.9042 - val_loss: 1.6661 - val_acc: 0.6091\n",
      "Epoch 464/500\n",
      "240/240 [==============================] - 9s 40ms/step - loss: 0.2366 - acc: 0.9250 - val_loss: 1.6652 - val_acc: 0.5818\n",
      "Epoch 465/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.2381 - acc: 0.9333 - val_loss: 1.7813 - val_acc: 0.5909\n",
      "Epoch 466/500\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.4234 - acc: 0.8458 - val_loss: 1.5285 - val_acc: 0.5545\n",
      "Epoch 467/500\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.3150 - acc: 0.8917 - val_loss: 1.9298 - val_acc: 0.5636\n",
      "Epoch 468/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.9274 - acc: 0.7208 - val_loss: 1.4776 - val_acc: 0.6000\n",
      "Epoch 469/500\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.5411 - acc: 0.8292 - val_loss: 1.5907 - val_acc: 0.5273\n",
      "Epoch 470/500\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.4732 - acc: 0.8500 - val_loss: 1.6448 - val_acc: 0.5727\n",
      "Epoch 471/500\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.5078 - acc: 0.8208 - val_loss: 1.6957 - val_acc: 0.5364\n",
      "Epoch 472/500\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.4856 - acc: 0.8167 - val_loss: 1.8522 - val_acc: 0.5545\n",
      "Epoch 473/500\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.6951 - acc: 0.7958 - val_loss: 1.7776 - val_acc: 0.5273\n",
      "Epoch 474/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.7048 - acc: 0.7708 - val_loss: 1.5228 - val_acc: 0.5364\n",
      "Epoch 475/500\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.6277 - acc: 0.7833 - val_loss: 1.4860 - val_acc: 0.5455\n",
      "Epoch 476/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.5349 - acc: 0.8292 - val_loss: 1.5822 - val_acc: 0.5364\n",
      "Epoch 477/500\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.4535 - acc: 0.8583 - val_loss: 1.4280 - val_acc: 0.5727\n",
      "Epoch 478/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 1.4118 - acc: 0.6708 - val_loss: 4.2006 - val_acc: 0.3000\n",
      "Epoch 479/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 2.8374 - acc: 0.3583 - val_loss: 2.6449 - val_acc: 0.2636\n",
      "Epoch 480/500\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 1.9243 - acc: 0.3667 - val_loss: 2.0693 - val_acc: 0.2545\n",
      "Epoch 481/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 9s 39ms/step - loss: 1.5805 - acc: 0.3667 - val_loss: 1.8429 - val_acc: 0.3636\n",
      "Epoch 482/500\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 1.4038 - acc: 0.4958 - val_loss: 1.6515 - val_acc: 0.4636\n",
      "Epoch 483/500\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 1.2355 - acc: 0.5333 - val_loss: 1.7122 - val_acc: 0.4273\n",
      "Epoch 484/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 1.1263 - acc: 0.5708 - val_loss: 1.7829 - val_acc: 0.4273\n",
      "Epoch 485/500\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 1.0484 - acc: 0.5958 - val_loss: 1.6192 - val_acc: 0.4455\n",
      "Epoch 486/500\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.9271 - acc: 0.6042 - val_loss: 1.5452 - val_acc: 0.5182\n",
      "Epoch 487/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.8297 - acc: 0.6708 - val_loss: 1.4682 - val_acc: 0.5909\n",
      "Epoch 488/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.8161 - acc: 0.6833 - val_loss: 1.4644 - val_acc: 0.5636\n",
      "Epoch 489/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.7122 - acc: 0.7375 - val_loss: 1.3906 - val_acc: 0.5545\n",
      "Epoch 490/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.7102 - acc: 0.7125 - val_loss: 1.3879 - val_acc: 0.5455\n",
      "Epoch 491/500\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.6869 - acc: 0.7292 - val_loss: 1.4507 - val_acc: 0.5727\n",
      "Epoch 492/500\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.6001 - acc: 0.7667 - val_loss: 1.3971 - val_acc: 0.5909\n",
      "Epoch 493/500\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.7153 - acc: 0.7125 - val_loss: 2.0179 - val_acc: 0.5000\n",
      "Epoch 494/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.6982 - acc: 0.7000 - val_loss: 1.8020 - val_acc: 0.5000\n",
      "Epoch 495/500\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 0.6202 - acc: 0.7458 - val_loss: 1.8008 - val_acc: 0.5545\n",
      "Epoch 496/500\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.5014 - acc: 0.7375 - val_loss: 1.7516 - val_acc: 0.5727\n",
      "Epoch 497/500\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.4378 - acc: 0.8000 - val_loss: 1.6842 - val_acc: 0.5545\n",
      "Epoch 498/500\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.4227 - acc: 0.8333 - val_loss: 1.8068 - val_acc: 0.5545\n",
      "Epoch 499/500\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.4048 - acc: 0.8208 - val_loss: 1.6370 - val_acc: 0.6000\n",
      "Epoch 500/500\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.3858 - acc: 0.8458 - val_loss: 1.6242 - val_acc: 0.6000\n"
     ]
    }
   ],
   "source": [
    "LSTMDD5=LSTM_with_Dropout('LSTM_Dropoutdelta5',dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_and_saving(LSTMDD5,name='LSTM_Dropoutdelta5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/500\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 2.3046 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 2/500\n",
      "130/240 [===============>..............] - ETA: 2s - loss: 2.3018 - acc: 0.0923"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-ebaa2dcfd284>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLSTMDD8\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLSTM_with_Dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM_Dropoutdelta5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-3711124a06f0>\u001b[0m in \u001b[0;36mLSTM_with_Dropout\u001b[0;34m(name, n_units, time_steps, n_inputs, batch_size, n_epochs, dropout)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtimei\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtimef\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LSTMDD8=LSTM_with_Dropout('LSTM_Dropoutdelta08',dropout=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Models/Model_LSTM_Dropoutdelta08/prec.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-6456148bdd03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_and_saving\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTMDD8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'LSTM_Dropoutdelta08'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-57-345342058afd>\u001b[0m in \u001b[0;36mplot_and_saving\u001b[0;34m(history, name)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'upper left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/prec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Plot training & validation loss values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, frameon, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   2092\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_frameon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2094\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2096\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2073\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2075\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2076\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                 \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             _png.write_png(renderer._renderer, fh,\n\u001b[1;32m    523\u001b[0m                             self.figure.dpi, metadata=metadata)\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mopen_file_cm\u001b[0;34m(path_or_file, mode, encoding)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;34mr\"\"\"Pass through file objects and context-manage `.PathLike`\\s.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m     \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_filehandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mto_filehandle\u001b[0;34m(fname, flag, return_opened, encoding)\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seek'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Models/Model_LSTM_Dropoutdelta08/prec.png'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_and_saving(LSTMDD8,'LSTM_Dropoutdelta08')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/500\n",
      "240/240 [==============================] - 14s 59ms/step - loss: 2.3041 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 2/500\n",
      "240/240 [==============================] - 14s 59ms/step - loss: 2.3037 - acc: 0.0958 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 3/500\n",
      "240/240 [==============================] - 20s 85ms/step - loss: 2.3036 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 4/500\n",
      "240/240 [==============================] - 18s 74ms/step - loss: 2.3040 - acc: 0.0750 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 5/500\n",
      "240/240 [==============================] - 14s 57ms/step - loss: 2.3024 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 6/500\n",
      "240/240 [==============================] - 15s 63ms/step - loss: 2.3019 - acc: 0.1042 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 7/500\n",
      "240/240 [==============================] - 18s 76ms/step - loss: 2.2992 - acc: 0.1125 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 8/500\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 2.2956 - acc: 0.1083 - val_loss: 2.3036 - val_acc: 0.1000\n",
      "Epoch 9/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2984 - acc: 0.1000 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 10/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2965 - acc: 0.1042 - val_loss: 2.3036 - val_acc: 0.1000\n",
      "Epoch 11/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2971 - acc: 0.0750 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 12/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2950 - acc: 0.0833 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 13/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.3002 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 14/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2950 - acc: 0.1000 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 15/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2969 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 16/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2946 - acc: 0.0958 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 17/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2985 - acc: 0.1167 - val_loss: 2.3026 - val_acc: 0.0909\n",
      "Epoch 18/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.3136 - acc: 0.1250 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 19/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2943 - acc: 0.1333 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 20/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2976 - acc: 0.0708 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 21/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2997 - acc: 0.0750 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 22/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2966 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 23/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2957 - acc: 0.1208 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 24/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2947 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 25/500\n",
      "240/240 [==============================] - 11s 46ms/step - loss: 2.2949 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 26/500\n",
      "240/240 [==============================] - 19s 77ms/step - loss: 2.2948 - acc: 0.1292 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 27/500\n",
      "240/240 [==============================] - 17s 71ms/step - loss: 2.2953 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 28/500\n",
      "240/240 [==============================] - 17s 70ms/step - loss: 2.2937 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 29/500\n",
      "240/240 [==============================] - 17s 70ms/step - loss: 2.2941 - acc: 0.0917 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 30/500\n",
      "240/240 [==============================] - 18s 74ms/step - loss: 2.2963 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 31/500\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 2.2936 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 32/500\n",
      "240/240 [==============================] - 15s 62ms/step - loss: 2.2938 - acc: 0.1083 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 33/500\n",
      "240/240 [==============================] - 15s 64ms/step - loss: 2.2948 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 34/500\n",
      "240/240 [==============================] - 15s 63ms/step - loss: 2.2946 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 35/500\n",
      "240/240 [==============================] - 14s 60ms/step - loss: 2.2950 - acc: 0.0583 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 36/500\n",
      "240/240 [==============================] - 15s 64ms/step - loss: 2.2941 - acc: 0.0917 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 37/500\n",
      "240/240 [==============================] - 14s 60ms/step - loss: 2.2924 - acc: 0.1125 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 38/500\n",
      "240/240 [==============================] - 15s 63ms/step - loss: 2.2924 - acc: 0.1083 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 39/500\n",
      "240/240 [==============================] - 14s 57ms/step - loss: 2.2954 - acc: 0.0875 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 40/500\n",
      "240/240 [==============================] - 14s 56ms/step - loss: 2.2930 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 41/500\n",
      "240/240 [==============================] - 13s 53ms/step - loss: 2.2955 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 42/500\n",
      "240/240 [==============================] - 18s 73ms/step - loss: 2.2974 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 43/500\n",
      "240/240 [==============================] - 14s 60ms/step - loss: 2.2964 - acc: 0.0542 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 44/500\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 2.2936 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 45/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2940 - acc: 0.0875 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 46/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2934 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 47/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2919 - acc: 0.1042 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 48/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2921 - acc: 0.1083 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 49/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2988 - acc: 0.0875 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 50/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2938 - acc: 0.1125 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 51/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2966 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 52/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2928 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.0909\n",
      "Epoch 53/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2955 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 54/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2949 - acc: 0.0958 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 55/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2948 - acc: 0.0958 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 56/500\n",
      "240/240 [==============================] - 11s 46ms/step - loss: 2.2950 - acc: 0.1250 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 57/500\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 2.2954 - acc: 0.1042 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 58/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2948 - acc: 0.0792 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 59/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2940 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 60/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2962 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2943 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 62/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2939 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 63/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2942 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 64/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2939 - acc: 0.1250 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 65/500\n",
      "240/240 [==============================] - 11s 46ms/step - loss: 2.2944 - acc: 0.1042 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 66/500\n",
      "240/240 [==============================] - 11s 46ms/step - loss: 2.2940 - acc: 0.1083 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 67/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2943 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 68/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2940 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 69/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2948 - acc: 0.1042 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 70/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2944 - acc: 0.0792 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 71/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2948 - acc: 0.1167 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 72/500\n",
      "240/240 [==============================] - 11s 46ms/step - loss: 2.2945 - acc: 0.1125 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 73/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2940 - acc: 0.1125 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 74/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2924 - acc: 0.0792 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 75/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2951 - acc: 0.1042 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 76/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2939 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 77/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2938 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 78/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2953 - acc: 0.0708 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 79/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2955 - acc: 0.0750 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 80/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2936 - acc: 0.1083 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 81/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2920 - acc: 0.1042 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 82/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2930 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 83/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2953 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 84/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2917 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 85/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2919 - acc: 0.1208 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 86/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2941 - acc: 0.0958 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 87/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2951 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 88/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2948 - acc: 0.0750 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 89/500\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 2.2924 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 90/500\n",
      "240/240 [==============================] - 16s 65ms/step - loss: 2.2952 - acc: 0.0625 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 91/500\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 2.2947 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 92/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 2.2930 - acc: 0.1042 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 93/500\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 2.2944 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 94/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2939 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 95/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2929 - acc: 0.1125 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 96/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2932 - acc: 0.1250 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 97/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2947 - acc: 0.0667 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 98/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2928 - acc: 0.0917 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 99/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2944 - acc: 0.0958 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 100/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2937 - acc: 0.1250 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 101/500\n",
      "240/240 [==============================] - 13s 53ms/step - loss: 2.2942 - acc: 0.1083 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 102/500\n",
      "240/240 [==============================] - 12s 51ms/step - loss: 2.2944 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 103/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2947 - acc: 0.0958 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 104/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2961 - acc: 0.0792 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 105/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2915 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 106/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2940 - acc: 0.0792 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 107/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2933 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 108/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2914 - acc: 0.1125 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 109/500\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 2.2959 - acc: 0.0500 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 110/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2932 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 111/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2946 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 112/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2951 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 113/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2927 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 114/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2936 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 115/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2947 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 116/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2922 - acc: 0.1458 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 117/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2936 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 118/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2941 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 119/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2952 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 120/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2917 - acc: 0.1250 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 121/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2971 - acc: 0.1250 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 122/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2973 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 123/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2947 - acc: 0.1042 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 124/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2933 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 125/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2930 - acc: 0.1542 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 126/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2953 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 127/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2935 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 128/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2933 - acc: 0.1167 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 129/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2937 - acc: 0.0875 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 130/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2937 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 131/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2937 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 132/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2938 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 133/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2948 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 134/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2971 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 135/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2926 - acc: 0.0792 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 136/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2932 - acc: 0.1208 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 137/500\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 2.2939 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 138/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2945 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 139/500\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 2.2937 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 140/500\n",
      "240/240 [==============================] - 14s 58ms/step - loss: 2.2930 - acc: 0.0750 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 141/500\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 2.2953 - acc: 0.0792 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 142/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2943 - acc: 0.0958 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 143/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2938 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 144/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2935 - acc: 0.0875 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 145/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2940 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 146/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2933 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 147/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2923 - acc: 0.1250 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 148/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2928 - acc: 0.0958 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 149/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2948 - acc: 0.0708 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 150/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2955 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 151/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2936 - acc: 0.0917 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 152/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2940 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 153/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2934 - acc: 0.1000 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 154/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2936 - acc: 0.1042 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 155/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2937 - acc: 0.1000 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 156/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2936 - acc: 0.1083 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 157/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2938 - acc: 0.1042 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 158/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2936 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 159/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2948 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 160/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2944 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 161/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2920 - acc: 0.1208 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 162/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2943 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 163/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2943 - acc: 0.0875 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 164/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2934 - acc: 0.1292 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 165/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2933 - acc: 0.1250 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 166/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2921 - acc: 0.0958 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 167/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2971 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 168/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2953 - acc: 0.0667 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 169/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2948 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 170/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2936 - acc: 0.0708 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 171/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2930 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 172/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2943 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 173/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2934 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 174/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2931 - acc: 0.1208 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 175/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2949 - acc: 0.0875 - val_loss: 2.3032 - val_acc: 0.1000\n",
      "Epoch 176/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2935 - acc: 0.1333 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 177/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2946 - acc: 0.1125 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 178/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2934 - acc: 0.1000 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 179/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2956 - acc: 0.1125 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 180/500\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 2.2940 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2934 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 182/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2923 - acc: 0.0917 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 183/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2946 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 184/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2952 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 185/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2928 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 186/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2923 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 187/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2944 - acc: 0.1292 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 188/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2930 - acc: 0.0750 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 189/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2953 - acc: 0.0667 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 190/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2913 - acc: 0.1083 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 191/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2949 - acc: 0.1125 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 192/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2957 - acc: 0.0750 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 193/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2943 - acc: 0.1208 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 194/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2944 - acc: 0.0667 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 195/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2930 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 196/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2926 - acc: 0.1208 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 197/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2943 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 198/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2955 - acc: 0.0542 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 199/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2946 - acc: 0.0875 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 200/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2931 - acc: 0.1083 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 201/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2936 - acc: 0.1250 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 202/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2944 - acc: 0.0708 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 203/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2933 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 204/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2938 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 205/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2944 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 206/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2938 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 207/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2943 - acc: 0.0917 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 208/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2942 - acc: 0.0417 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 209/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2936 - acc: 0.0708 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 210/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2933 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 211/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2927 - acc: 0.0750 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 212/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2940 - acc: 0.0542 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 213/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2945 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 214/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2916 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 215/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2928 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 216/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2935 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 217/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2952 - acc: 0.0875 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 218/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2936 - acc: 0.1125 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 219/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2939 - acc: 0.0958 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 220/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2946 - acc: 0.0875 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 221/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2937 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 222/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2943 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 223/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2937 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 224/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2949 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 225/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2942 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 226/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2940 - acc: 0.0625 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 227/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2935 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 228/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2932 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 229/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2925 - acc: 0.0875 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 230/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2938 - acc: 0.1125 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 231/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2929 - acc: 0.1042 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 232/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2957 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 233/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2942 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 234/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2932 - acc: 0.0958 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 235/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2943 - acc: 0.0875 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 236/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2929 - acc: 0.0875 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 237/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2952 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 238/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2942 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 239/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2938 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 240/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2943 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2942 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 242/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2933 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 243/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2934 - acc: 0.1208 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 244/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2934 - acc: 0.0875 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 245/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2946 - acc: 0.1083 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 246/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2937 - acc: 0.1208 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 247/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2943 - acc: 0.1000 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 248/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2931 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 249/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2935 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 250/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2936 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 251/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2930 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 252/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2943 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 253/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2940 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 254/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2932 - acc: 0.1000 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 255/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2940 - acc: 0.0708 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 256/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2933 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 257/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2932 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 258/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2960 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 259/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2940 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 260/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2934 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 261/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2924 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 262/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2940 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 263/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2942 - acc: 0.0708 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 264/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2932 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 265/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2934 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 266/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2942 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 267/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2941 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 268/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2940 - acc: 0.1083 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 269/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2927 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 270/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2927 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 271/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2926 - acc: 0.1000 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 272/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2938 - acc: 0.0917 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 273/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2929 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 274/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2923 - acc: 0.1042 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 275/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2938 - acc: 0.1000 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 276/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2940 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 277/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2934 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 278/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2949 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 279/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2923 - acc: 0.1083 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 280/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2937 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 281/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2942 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 282/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2946 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 283/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2929 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 284/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2937 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 285/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2936 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 286/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2949 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 287/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2929 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 288/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2932 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 289/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2937 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 290/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2933 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 291/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2922 - acc: 0.1292 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 292/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2943 - acc: 0.0667 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 293/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2947 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 294/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2935 - acc: 0.1208 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 295/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2931 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 296/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2919 - acc: 0.1250 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 297/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2958 - acc: 0.0542 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 298/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2941 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 299/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2938 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 300/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2940 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2935 - acc: 0.1167 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 302/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2937 - acc: 0.0875 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 303/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2941 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 304/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2946 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 305/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2939 - acc: 0.0708 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 306/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2935 - acc: 0.1208 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 307/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2935 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 308/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2942 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 309/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2945 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 310/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2920 - acc: 0.0958 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 311/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2938 - acc: 0.1292 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 312/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2943 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 313/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2943 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 314/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2936 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 315/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2943 - acc: 0.0750 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 316/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2934 - acc: 0.1167 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 317/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2940 - acc: 0.1167 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 318/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2943 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 319/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2939 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 320/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2929 - acc: 0.1250 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 321/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2932 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 322/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2946 - acc: 0.0958 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 323/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2930 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 324/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2927 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 325/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2934 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 326/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2929 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 327/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2949 - acc: 0.0750 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 328/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2958 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 329/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2944 - acc: 0.1000 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 330/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2935 - acc: 0.0625 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 331/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2927 - acc: 0.0708 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 332/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2941 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 333/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2947 - acc: 0.0708 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 334/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2934 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 335/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2931 - acc: 0.0750 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 336/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2928 - acc: 0.1042 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 337/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2945 - acc: 0.1125 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 338/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2935 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 339/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2946 - acc: 0.0750 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 340/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2951 - acc: 0.0667 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 341/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2935 - acc: 0.1292 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 342/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2941 - acc: 0.0625 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 343/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2938 - acc: 0.0750 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 344/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2931 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 345/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2935 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 346/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2932 - acc: 0.0667 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 347/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2919 - acc: 0.1458 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 348/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2939 - acc: 0.0833 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 349/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2941 - acc: 0.0917 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 350/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2941 - acc: 0.0667 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 351/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2944 - acc: 0.0583 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 352/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2931 - acc: 0.1000 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 353/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2942 - acc: 0.0958 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 354/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2924 - acc: 0.1375 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 355/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2950 - acc: 0.0917 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 356/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2941 - acc: 0.0708 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 357/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2945 - acc: 0.0708 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 358/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2926 - acc: 0.1292 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 359/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2940 - acc: 0.0667 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 360/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2935 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2946 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 362/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2924 - acc: 0.1333 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 363/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2929 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 364/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2933 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 365/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2929 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 366/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2938 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 367/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2944 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 368/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2933 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 369/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2930 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 370/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2949 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 371/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2932 - acc: 0.0750 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 372/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2930 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 373/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2939 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 374/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2937 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 375/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2941 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 376/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2919 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 377/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2926 - acc: 0.1250 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 378/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2936 - acc: 0.1208 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 379/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2935 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 380/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2932 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 381/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2947 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 382/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2930 - acc: 0.1250 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 383/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2944 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 384/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2948 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 385/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2937 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 386/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2921 - acc: 0.1375 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 387/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2927 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 388/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2933 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 389/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2928 - acc: 0.0875 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 390/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2944 - acc: 0.1333 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 391/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2925 - acc: 0.1208 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 392/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2943 - acc: 0.0750 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 393/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2921 - acc: 0.1167 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 394/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2925 - acc: 0.1250 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 395/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2941 - acc: 0.1125 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 396/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2942 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 397/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2919 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 398/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2933 - acc: 0.1000 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 399/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2952 - acc: 0.1083 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 400/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2938 - acc: 0.0792 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 401/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2968 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 402/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2947 - acc: 0.0958 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 403/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2951 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 404/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2923 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 405/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2942 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 406/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2926 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 407/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2928 - acc: 0.0958 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 408/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2926 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 409/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2940 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 410/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2930 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 411/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2933 - acc: 0.1083 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 412/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2933 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 413/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2937 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 414/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2943 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 415/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2933 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 416/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2953 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 417/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2938 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 418/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2931 - acc: 0.1333 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 419/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2934 - acc: 0.0875 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 420/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2952 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2942 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 422/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2927 - acc: 0.1208 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 423/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2931 - acc: 0.1125 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 424/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2934 - acc: 0.0792 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 425/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2932 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 426/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2941 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 427/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2929 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 428/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2941 - acc: 0.0750 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 429/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2939 - acc: 0.0875 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 430/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2932 - acc: 0.0958 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 431/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2929 - acc: 0.0958 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 432/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2935 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 433/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2947 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 434/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2936 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 435/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2927 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 436/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2929 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 437/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2938 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 438/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2927 - acc: 0.1042 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 439/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2924 - acc: 0.1167 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 440/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2928 - acc: 0.0917 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 441/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2935 - acc: 0.1208 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 442/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2929 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 443/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2953 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 444/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2947 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 445/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2932 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 446/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2934 - acc: 0.1083 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 447/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2931 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 448/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2925 - acc: 0.1125 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 449/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2925 - acc: 0.1208 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 450/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2958 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 451/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2934 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 452/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2942 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 453/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2944 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 454/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2939 - acc: 0.0667 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 455/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2933 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 456/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2936 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 457/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2948 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 458/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2929 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 459/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2923 - acc: 0.1208 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 460/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2956 - acc: 0.0667 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 461/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2933 - acc: 0.0875 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 462/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2928 - acc: 0.1250 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 463/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2926 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 464/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2924 - acc: 0.1250 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 465/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2930 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 466/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2947 - acc: 0.0708 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 467/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2935 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 468/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2935 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 469/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2935 - acc: 0.0708 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 470/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2939 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 471/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2944 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 472/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2939 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 473/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2928 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 474/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2943 - acc: 0.0750 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 475/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2928 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 476/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2941 - acc: 0.0583 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 477/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2933 - acc: 0.0792 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 478/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2928 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 479/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2939 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 480/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2925 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2934 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 482/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2931 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 483/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2959 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 484/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2922 - acc: 0.1250 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 485/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2922 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 486/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2925 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 487/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2934 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 488/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2952 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 489/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2926 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 490/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2961 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 491/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2937 - acc: 0.0750 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 492/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2929 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 493/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2943 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 494/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2922 - acc: 0.0583 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 495/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2929 - acc: 0.1250 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 496/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2941 - acc: 0.1250 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 497/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2940 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 498/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2925 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 499/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2923 - acc: 0.1042 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 500/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2934 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa41573f048>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_with_2layers_1D('LSTM_2Layer1DDelta5',dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/500\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 2.3044 - acc: 0.0667 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 2/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.3025 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 3/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.3039 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 4/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.3037 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 5/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.3036 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 6/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.3024 - acc: 0.1208 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 7/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.3041 - acc: 0.1083 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 8/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.3040 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 9/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.3016 - acc: 0.0792 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 10/500\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 2.3045 - acc: 0.0875 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 11/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.3051 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 12/500\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 2.2976 - acc: 0.1042 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 13/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.3032 - acc: 0.1292 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 14/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2935 - acc: 0.1083 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 15/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.3035 - acc: 0.0958 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 16/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2999 - acc: 0.1083 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 17/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2953 - acc: 0.1375 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 18/500\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 2.3052 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 19/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.3019 - acc: 0.1000 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 20/500\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 2.3022 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 21/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.3051 - acc: 0.0625 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 22/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2977 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 23/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2979 - acc: 0.0625 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 24/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.3028 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 25/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2981 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 26/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2986 - acc: 0.0708 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 27/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2959 - acc: 0.1208 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 28/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2940 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 29/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2979 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 30/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2961 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 31/500\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 2.2923 - acc: 0.1417 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 32/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2992 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 33/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2963 - acc: 0.1583 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 34/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.3023 - acc: 0.1208 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 35/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2960 - acc: 0.1125 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 36/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2944 - acc: 0.1125 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 37/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2933 - acc: 0.1042 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 38/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.3004 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 39/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.3019 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 40/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2955 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 41/500\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 2.2971 - acc: 0.1000 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 42/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.3038 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 43/500\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 2.2935 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 44/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2964 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 45/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.3048 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 46/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2992 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 47/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2942 - acc: 0.1333 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 48/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2975 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 49/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2947 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 50/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2887 - acc: 0.1167 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 51/500\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 2.3034 - acc: 0.1333 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 52/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2967 - acc: 0.0792 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 53/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.3002 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 54/500\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 2.2932 - acc: 0.1208 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 55/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2914 - acc: 0.1042 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 56/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2991 - acc: 0.0708 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 57/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2938 - acc: 0.1250 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 58/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2994 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 59/500\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 2.2979 - acc: 0.1167 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 60/500\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 2.2954 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2931 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 62/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2939 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 63/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.3049 - acc: 0.0708 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 64/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2999 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 65/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2936 - acc: 0.1208 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 66/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.3020 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 67/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2943 - acc: 0.1125 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 68/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2963 - acc: 0.0792 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 69/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.3085 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 70/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2999 - acc: 0.1125 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 71/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2950 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 72/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2995 - acc: 0.1167 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 73/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2942 - acc: 0.0875 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 74/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2919 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 75/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2946 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 76/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2968 - acc: 0.1417 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 77/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2916 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 78/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2966 - acc: 0.0750 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 79/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2971 - acc: 0.0708 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 80/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2944 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 81/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2957 - acc: 0.0750 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 82/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2974 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 83/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2956 - acc: 0.0583 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 84/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2955 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 85/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2949 - acc: 0.1208 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 86/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2964 - acc: 0.0708 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 87/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.3033 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 88/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2924 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 89/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2950 - acc: 0.0875 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 90/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.3008 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 91/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2974 - acc: 0.0875 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 92/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2959 - acc: 0.0792 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 93/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2941 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 94/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2973 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 95/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2949 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 96/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.3018 - acc: 0.0958 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 97/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2972 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 98/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2938 - acc: 0.1250 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 99/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2960 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 100/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2956 - acc: 0.1250 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 101/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2936 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 102/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2957 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 103/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2982 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 104/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2946 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 105/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2940 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 106/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2983 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 107/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2930 - acc: 0.1292 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 108/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2923 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 109/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.3206 - acc: 0.1000 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 110/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2955 - acc: 0.0792 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 111/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.3055 - acc: 0.0875 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 112/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.3049 - acc: 0.0625 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 113/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2970 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 114/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2946 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 115/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2950 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 116/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2942 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 117/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2945 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 118/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2951 - acc: 0.0667 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 119/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2972 - acc: 0.1083 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 120/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2987 - acc: 0.0625 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 121/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2963 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 122/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2960 - acc: 0.1208 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 123/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2921 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 124/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2941 - acc: 0.1125 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 125/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2887 - acc: 0.1417 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 126/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2972 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 127/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2931 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 128/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2916 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 129/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2984 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 130/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2907 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 131/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2987 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 132/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2959 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 133/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2936 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 134/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2940 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 135/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2953 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 136/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2940 - acc: 0.1250 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 137/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2938 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 138/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2927 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 139/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2963 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 140/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2951 - acc: 0.0667 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 141/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2966 - acc: 0.1292 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 142/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2903 - acc: 0.1167 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 143/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2923 - acc: 0.1167 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 144/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2935 - acc: 0.1208 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 145/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2936 - acc: 0.1417 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 146/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2916 - acc: 0.1250 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 147/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2864 - acc: 0.1125 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 148/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2949 - acc: 0.0875 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 149/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2972 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 150/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2922 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 151/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2918 - acc: 0.0750 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 152/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2924 - acc: 0.0625 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 153/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2938 - acc: 0.1083 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 154/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2956 - acc: 0.0917 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 155/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2957 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 156/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2868 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 157/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2990 - acc: 0.0583 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 158/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2901 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 159/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2925 - acc: 0.0750 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 160/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2923 - acc: 0.1208 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 161/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2972 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 162/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2930 - acc: 0.1083 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 163/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2888 - acc: 0.0875 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 164/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2900 - acc: 0.0958 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 165/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2850 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 166/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2866 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 167/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2856 - acc: 0.1292 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 168/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2851 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 169/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2928 - acc: 0.1000 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 170/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2840 - acc: 0.1250 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 171/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2905 - acc: 0.1208 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 172/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2900 - acc: 0.1125 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 173/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2839 - acc: 0.1208 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 174/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2868 - acc: 0.0917 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 175/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2926 - acc: 0.0667 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 176/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2878 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 177/500\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 2.2878 - acc: 0.0917 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 178/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2836 - acc: 0.1167 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 179/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2839 - acc: 0.1125 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 180/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2833 - acc: 0.1292 - val_loss: 2.3029 - val_acc: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2853 - acc: 0.1042 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 182/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2844 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 183/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2869 - acc: 0.1042 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 184/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2890 - acc: 0.0875 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 185/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2827 - acc: 0.1000 - val_loss: 2.3032 - val_acc: 0.1000\n",
      "Epoch 186/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2902 - acc: 0.0875 - val_loss: 2.3033 - val_acc: 0.1000\n",
      "Epoch 187/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2894 - acc: 0.0958 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 188/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2858 - acc: 0.1417 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 189/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2902 - acc: 0.1167 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 190/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2791 - acc: 0.1333 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 191/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2863 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 192/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2853 - acc: 0.1292 - val_loss: 2.3025 - val_acc: 0.1091\n",
      "Epoch 193/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2882 - acc: 0.1417 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 194/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2869 - acc: 0.1083 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 195/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2880 - acc: 0.1167 - val_loss: 2.3023 - val_acc: 0.1000\n",
      "Epoch 196/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2881 - acc: 0.1208 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 197/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2912 - acc: 0.1208 - val_loss: 2.3027 - val_acc: 0.0909\n",
      "Epoch 198/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2903 - acc: 0.1542 - val_loss: 2.3011 - val_acc: 0.1000\n",
      "Epoch 199/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2959 - acc: 0.0833 - val_loss: 2.3022 - val_acc: 0.1091\n",
      "Epoch 200/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2856 - acc: 0.0875 - val_loss: 2.3023 - val_acc: 0.1091\n",
      "Epoch 201/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2859 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 202/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2936 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.0909\n",
      "Epoch 203/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2910 - acc: 0.1000 - val_loss: 2.3028 - val_acc: 0.1091\n",
      "Epoch 204/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2828 - acc: 0.1042 - val_loss: 2.3029 - val_acc: 0.1091\n",
      "Epoch 205/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2827 - acc: 0.1167 - val_loss: 2.3033 - val_acc: 0.1000\n",
      "Epoch 206/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2811 - acc: 0.0917 - val_loss: 2.3031 - val_acc: 0.0818\n",
      "Epoch 207/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2790 - acc: 0.1042 - val_loss: 2.3029 - val_acc: 0.0909\n",
      "Epoch 208/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2789 - acc: 0.1125 - val_loss: 2.3038 - val_acc: 0.1091\n",
      "Epoch 209/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2829 - acc: 0.1083 - val_loss: 2.3033 - val_acc: 0.1455\n",
      "Epoch 210/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.3016 - acc: 0.1167 - val_loss: 2.3012 - val_acc: 0.1000\n",
      "Epoch 211/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2973 - acc: 0.0917 - val_loss: 2.3012 - val_acc: 0.0818\n",
      "Epoch 212/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2925 - acc: 0.1000 - val_loss: 2.3000 - val_acc: 0.1000\n",
      "Epoch 213/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2845 - acc: 0.1000 - val_loss: 2.3001 - val_acc: 0.1273\n",
      "Epoch 214/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2928 - acc: 0.0833 - val_loss: 2.3016 - val_acc: 0.0909\n",
      "Epoch 215/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2853 - acc: 0.0917 - val_loss: 2.3020 - val_acc: 0.0818\n",
      "Epoch 216/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2851 - acc: 0.1375 - val_loss: 2.3017 - val_acc: 0.1091\n",
      "Epoch 217/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2850 - acc: 0.0958 - val_loss: 2.3011 - val_acc: 0.1182\n",
      "Epoch 218/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2866 - acc: 0.0958 - val_loss: 2.2999 - val_acc: 0.1364\n",
      "Epoch 219/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2856 - acc: 0.0792 - val_loss: 2.2991 - val_acc: 0.1000\n",
      "Epoch 220/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2853 - acc: 0.1042 - val_loss: 2.2985 - val_acc: 0.1000\n",
      "Epoch 221/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2870 - acc: 0.0958 - val_loss: 2.2977 - val_acc: 0.1091\n",
      "Epoch 222/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2910 - acc: 0.1125 - val_loss: 2.2988 - val_acc: 0.1182\n",
      "Epoch 223/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2900 - acc: 0.1250 - val_loss: 2.2995 - val_acc: 0.1000\n",
      "Epoch 224/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2810 - acc: 0.1208 - val_loss: 2.3006 - val_acc: 0.1000\n",
      "Epoch 225/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2843 - acc: 0.1000 - val_loss: 2.3005 - val_acc: 0.1000\n",
      "Epoch 226/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2832 - acc: 0.1000 - val_loss: 2.3017 - val_acc: 0.0818\n",
      "Epoch 227/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2859 - acc: 0.1333 - val_loss: 2.3018 - val_acc: 0.0727\n",
      "Epoch 228/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2786 - acc: 0.0958 - val_loss: 2.3018 - val_acc: 0.1000\n",
      "Epoch 229/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2761 - acc: 0.1250 - val_loss: 2.3018 - val_acc: 0.1091\n",
      "Epoch 230/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2875 - acc: 0.1292 - val_loss: 2.2994 - val_acc: 0.1091\n",
      "Epoch 231/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2822 - acc: 0.1292 - val_loss: 2.3006 - val_acc: 0.1000\n",
      "Epoch 232/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2780 - acc: 0.1000 - val_loss: 2.2995 - val_acc: 0.1000\n",
      "Epoch 233/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2797 - acc: 0.1250 - val_loss: 2.3009 - val_acc: 0.0909\n",
      "Epoch 234/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2787 - acc: 0.0958 - val_loss: 2.3007 - val_acc: 0.1182\n",
      "Epoch 235/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2773 - acc: 0.1083 - val_loss: 2.3014 - val_acc: 0.1000\n",
      "Epoch 236/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2737 - acc: 0.1292 - val_loss: 2.3014 - val_acc: 0.1091\n",
      "Epoch 237/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2766 - acc: 0.1292 - val_loss: 2.3016 - val_acc: 0.1091\n",
      "Epoch 238/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2791 - acc: 0.0917 - val_loss: 2.3011 - val_acc: 0.0818\n",
      "Epoch 239/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2811 - acc: 0.1542 - val_loss: 2.3013 - val_acc: 0.1091\n",
      "Epoch 240/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2781 - acc: 0.1458 - val_loss: 2.3025 - val_acc: 0.0909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2927 - acc: 0.1125 - val_loss: 2.3018 - val_acc: 0.0909\n",
      "Epoch 242/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2756 - acc: 0.1042 - val_loss: 2.3014 - val_acc: 0.0909\n",
      "Epoch 243/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2803 - acc: 0.1125 - val_loss: 2.3013 - val_acc: 0.1182\n",
      "Epoch 244/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2807 - acc: 0.1042 - val_loss: 2.3011 - val_acc: 0.1091\n",
      "Epoch 245/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2669 - acc: 0.1167 - val_loss: 2.2966 - val_acc: 0.0636\n",
      "Epoch 246/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2732 - acc: 0.1042 - val_loss: 2.2971 - val_acc: 0.1000\n",
      "Epoch 247/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2772 - acc: 0.1500 - val_loss: 2.2988 - val_acc: 0.0818\n",
      "Epoch 248/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.3140 - acc: 0.1375 - val_loss: 2.3264 - val_acc: 0.1091\n",
      "Epoch 249/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.3001 - acc: 0.0917 - val_loss: 2.2960 - val_acc: 0.1091\n",
      "Epoch 250/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2852 - acc: 0.0750 - val_loss: 2.2954 - val_acc: 0.1091\n",
      "Epoch 251/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2899 - acc: 0.1000 - val_loss: 2.2976 - val_acc: 0.1000\n",
      "Epoch 252/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2770 - acc: 0.0958 - val_loss: 2.2970 - val_acc: 0.1364\n",
      "Epoch 253/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2810 - acc: 0.1375 - val_loss: 2.2936 - val_acc: 0.1364\n",
      "Epoch 254/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2637 - acc: 0.1458 - val_loss: 2.3037 - val_acc: 0.1364\n",
      "Epoch 255/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2671 - acc: 0.1333 - val_loss: 2.2954 - val_acc: 0.1091\n",
      "Epoch 256/500\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 2.2581 - acc: 0.1500 - val_loss: 2.3092 - val_acc: 0.1000\n",
      "Epoch 257/500\n",
      "240/240 [==============================] - 13s 53ms/step - loss: 2.2892 - acc: 0.1083 - val_loss: 2.2959 - val_acc: 0.1636\n",
      "Epoch 258/500\n",
      "240/240 [==============================] - 15s 62ms/step - loss: 2.2819 - acc: 0.1500 - val_loss: 2.3111 - val_acc: 0.1000\n",
      "Epoch 259/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2584 - acc: 0.1542 - val_loss: 2.3102 - val_acc: 0.1455\n",
      "Epoch 260/500\n",
      "240/240 [==============================] - 12s 51ms/step - loss: 2.2724 - acc: 0.1250 - val_loss: 2.3020 - val_acc: 0.1000\n",
      "Epoch 261/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.2515 - acc: 0.1500 - val_loss: 2.3013 - val_acc: 0.1000\n",
      "Epoch 262/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2735 - acc: 0.1250 - val_loss: 2.3039 - val_acc: 0.1000\n",
      "Epoch 263/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2774 - acc: 0.1583 - val_loss: 2.2991 - val_acc: 0.1091\n",
      "Epoch 264/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2771 - acc: 0.1625 - val_loss: 2.2982 - val_acc: 0.1455\n",
      "Epoch 265/500\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 2.2181 - acc: 0.1875 - val_loss: 2.3194 - val_acc: 0.0818\n",
      "Epoch 266/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2432 - acc: 0.1083 - val_loss: 2.3032 - val_acc: 0.1182\n",
      "Epoch 267/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2421 - acc: 0.1792 - val_loss: 2.3147 - val_acc: 0.1364\n",
      "Epoch 268/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2029 - acc: 0.1708 - val_loss: 2.3138 - val_acc: 0.1455\n",
      "Epoch 269/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2260 - acc: 0.1625 - val_loss: 2.3344 - val_acc: 0.1273\n",
      "Epoch 270/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.1651 - acc: 0.2000 - val_loss: 2.3397 - val_acc: 0.1364\n",
      "Epoch 271/500\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 2.1948 - acc: 0.1917 - val_loss: 2.3211 - val_acc: 0.1000\n",
      "Epoch 272/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2406 - acc: 0.1542 - val_loss: 2.3530 - val_acc: 0.0818\n",
      "Epoch 273/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.2290 - acc: 0.1625 - val_loss: 2.3195 - val_acc: 0.0909\n",
      "Epoch 274/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.2327 - acc: 0.1458 - val_loss: 2.3105 - val_acc: 0.1000\n",
      "Epoch 275/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.1713 - acc: 0.1792 - val_loss: 2.3475 - val_acc: 0.0909\n",
      "Epoch 276/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.1953 - acc: 0.1792 - val_loss: 2.3104 - val_acc: 0.0636\n",
      "Epoch 277/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.1692 - acc: 0.2167 - val_loss: 2.3487 - val_acc: 0.1000\n",
      "Epoch 278/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.1591 - acc: 0.2083 - val_loss: 2.3337 - val_acc: 0.1000\n",
      "Epoch 279/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.1300 - acc: 0.2292 - val_loss: 2.3338 - val_acc: 0.1636\n",
      "Epoch 280/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.1314 - acc: 0.2458 - val_loss: 2.3864 - val_acc: 0.0909\n",
      "Epoch 281/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.1434 - acc: 0.2042 - val_loss: 2.3872 - val_acc: 0.0818\n",
      "Epoch 282/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.1267 - acc: 0.2333 - val_loss: 2.3757 - val_acc: 0.0727\n",
      "Epoch 283/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.0694 - acc: 0.2333 - val_loss: 2.3990 - val_acc: 0.1091\n",
      "Epoch 284/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.1009 - acc: 0.2625 - val_loss: 2.3919 - val_acc: 0.0727\n",
      "Epoch 285/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.1335 - acc: 0.2208 - val_loss: 2.3955 - val_acc: 0.1000\n",
      "Epoch 286/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.0523 - acc: 0.2875 - val_loss: 2.4179 - val_acc: 0.1455\n",
      "Epoch 287/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.1058 - acc: 0.2500 - val_loss: 2.3885 - val_acc: 0.0727\n",
      "Epoch 288/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.0661 - acc: 0.2125 - val_loss: 2.4034 - val_acc: 0.0909\n",
      "Epoch 289/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.9971 - acc: 0.2167 - val_loss: 2.4242 - val_acc: 0.0909\n",
      "Epoch 290/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.0513 - acc: 0.2375 - val_loss: 2.3935 - val_acc: 0.0909\n",
      "Epoch 291/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.0190 - acc: 0.2708 - val_loss: 2.4536 - val_acc: 0.1000\n",
      "Epoch 292/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 2.0746 - acc: 0.2417 - val_loss: 2.4583 - val_acc: 0.1273\n",
      "Epoch 293/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.9980 - acc: 0.3042 - val_loss: 2.3750 - val_acc: 0.1091\n",
      "Epoch 294/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.0373 - acc: 0.2833 - val_loss: 2.3846 - val_acc: 0.1091\n",
      "Epoch 295/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.9634 - acc: 0.2917 - val_loss: 2.4337 - val_acc: 0.0909\n",
      "Epoch 296/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 2.0359 - acc: 0.2083 - val_loss: 2.4116 - val_acc: 0.0909\n",
      "Epoch 297/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.0011 - acc: 0.2542 - val_loss: 2.4133 - val_acc: 0.0818\n",
      "Epoch 298/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.0803 - acc: 0.2833 - val_loss: 2.4091 - val_acc: 0.1273\n",
      "Epoch 299/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 2.0541 - acc: 0.2458 - val_loss: 2.3949 - val_acc: 0.1000\n",
      "Epoch 300/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.9950 - acc: 0.2500 - val_loss: 2.4053 - val_acc: 0.1091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.9299 - acc: 0.2833 - val_loss: 2.4380 - val_acc: 0.1000\n",
      "Epoch 302/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.9833 - acc: 0.2542 - val_loss: 2.4681 - val_acc: 0.1273\n",
      "Epoch 303/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 1.9717 - acc: 0.2875 - val_loss: 2.5168 - val_acc: 0.1273\n",
      "Epoch 304/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.9072 - acc: 0.2750 - val_loss: 2.4502 - val_acc: 0.0909\n",
      "Epoch 305/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.8722 - acc: 0.2917 - val_loss: 2.5139 - val_acc: 0.1000\n",
      "Epoch 306/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.9819 - acc: 0.2625 - val_loss: 2.5418 - val_acc: 0.0727\n",
      "Epoch 307/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.9131 - acc: 0.3000 - val_loss: 2.5757 - val_acc: 0.1091\n",
      "Epoch 308/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.9366 - acc: 0.2917 - val_loss: 2.5182 - val_acc: 0.0909\n",
      "Epoch 309/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.8668 - acc: 0.3292 - val_loss: 2.5366 - val_acc: 0.1000\n",
      "Epoch 310/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.8748 - acc: 0.3125 - val_loss: 2.5499 - val_acc: 0.0909\n",
      "Epoch 311/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.8448 - acc: 0.3125 - val_loss: 2.5641 - val_acc: 0.0909\n",
      "Epoch 312/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.8228 - acc: 0.3250 - val_loss: 2.5554 - val_acc: 0.0909\n",
      "Epoch 313/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 1.7809 - acc: 0.3292 - val_loss: 2.6391 - val_acc: 0.1000\n",
      "Epoch 314/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.7798 - acc: 0.3792 - val_loss: 2.7176 - val_acc: 0.0909\n",
      "Epoch 315/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.8072 - acc: 0.2875 - val_loss: 2.5968 - val_acc: 0.0727\n",
      "Epoch 316/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.7743 - acc: 0.3333 - val_loss: 2.6460 - val_acc: 0.0909\n",
      "Epoch 317/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.8313 - acc: 0.2875 - val_loss: 2.6358 - val_acc: 0.0636\n",
      "Epoch 318/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.7381 - acc: 0.3292 - val_loss: 2.6664 - val_acc: 0.0636\n",
      "Epoch 319/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.8228 - acc: 0.2792 - val_loss: 2.6531 - val_acc: 0.1091\n",
      "Epoch 320/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.7829 - acc: 0.3083 - val_loss: 2.5954 - val_acc: 0.0909\n",
      "Epoch 321/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.7991 - acc: 0.3125 - val_loss: 2.6687 - val_acc: 0.1091\n",
      "Epoch 322/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.7480 - acc: 0.3250 - val_loss: 2.7619 - val_acc: 0.1000\n",
      "Epoch 323/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.7565 - acc: 0.3500 - val_loss: 2.7054 - val_acc: 0.1091\n",
      "Epoch 324/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 1.7245 - acc: 0.3458 - val_loss: 2.6869 - val_acc: 0.0818\n",
      "Epoch 325/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.6475 - acc: 0.3917 - val_loss: 2.6889 - val_acc: 0.1000\n",
      "Epoch 326/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.7260 - acc: 0.3125 - val_loss: 2.7093 - val_acc: 0.1091\n",
      "Epoch 327/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.8495 - acc: 0.2958 - val_loss: 2.6773 - val_acc: 0.1091\n",
      "Epoch 328/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.7964 - acc: 0.3375 - val_loss: 2.6735 - val_acc: 0.0545\n",
      "Epoch 329/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.7249 - acc: 0.3208 - val_loss: 2.6832 - val_acc: 0.1091\n",
      "Epoch 330/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.6732 - acc: 0.3542 - val_loss: 2.6734 - val_acc: 0.1182\n",
      "Epoch 331/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.6573 - acc: 0.4167 - val_loss: 2.7013 - val_acc: 0.1091\n",
      "Epoch 332/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.7116 - acc: 0.4042 - val_loss: 2.7138 - val_acc: 0.1182\n",
      "Epoch 333/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.6489 - acc: 0.4125 - val_loss: 2.7354 - val_acc: 0.1364\n",
      "Epoch 334/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 1.7055 - acc: 0.3500 - val_loss: 2.7403 - val_acc: 0.1364\n",
      "Epoch 335/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.6912 - acc: 0.3500 - val_loss: 2.7827 - val_acc: 0.0909\n",
      "Epoch 336/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.6159 - acc: 0.3625 - val_loss: 2.8269 - val_acc: 0.0818\n",
      "Epoch 337/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.6043 - acc: 0.4000 - val_loss: 2.8620 - val_acc: 0.0727\n",
      "Epoch 338/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.6601 - acc: 0.3875 - val_loss: 2.8907 - val_acc: 0.0909\n",
      "Epoch 339/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.7353 - acc: 0.3250 - val_loss: 2.8146 - val_acc: 0.1000\n",
      "Epoch 340/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.6010 - acc: 0.3750 - val_loss: 2.8989 - val_acc: 0.0727\n",
      "Epoch 341/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.6021 - acc: 0.4042 - val_loss: 2.8391 - val_acc: 0.1273\n",
      "Epoch 342/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.5689 - acc: 0.4833 - val_loss: 2.9314 - val_acc: 0.1000\n",
      "Epoch 343/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.4944 - acc: 0.4292 - val_loss: 2.9271 - val_acc: 0.1182\n",
      "Epoch 344/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.6140 - acc: 0.3833 - val_loss: 2.8472 - val_acc: 0.1273\n",
      "Epoch 345/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 1.6695 - acc: 0.3458 - val_loss: 2.9438 - val_acc: 0.1273\n",
      "Epoch 346/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.6704 - acc: 0.3708 - val_loss: 2.9307 - val_acc: 0.1364\n",
      "Epoch 347/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.5853 - acc: 0.3917 - val_loss: 2.8603 - val_acc: 0.1364\n",
      "Epoch 348/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.6221 - acc: 0.3708 - val_loss: 2.8786 - val_acc: 0.1182\n",
      "Epoch 349/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.7920 - acc: 0.3375 - val_loss: 2.9181 - val_acc: 0.0818\n",
      "Epoch 350/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.6666 - acc: 0.3458 - val_loss: 2.9314 - val_acc: 0.1273\n",
      "Epoch 351/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.6079 - acc: 0.3542 - val_loss: 2.9893 - val_acc: 0.1364\n",
      "Epoch 352/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 1.5547 - acc: 0.4208 - val_loss: 3.0316 - val_acc: 0.1273\n",
      "Epoch 353/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.5248 - acc: 0.4375 - val_loss: 3.0488 - val_acc: 0.1182\n",
      "Epoch 354/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.5997 - acc: 0.4333 - val_loss: 2.9656 - val_acc: 0.1182\n",
      "Epoch 355/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 1.7683 - acc: 0.3292 - val_loss: 2.9187 - val_acc: 0.1364\n",
      "Epoch 356/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.6444 - acc: 0.3667 - val_loss: 2.8833 - val_acc: 0.1545\n",
      "Epoch 357/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.5815 - acc: 0.3542 - val_loss: 2.9421 - val_acc: 0.1273\n",
      "Epoch 358/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.8054 - acc: 0.2875 - val_loss: 2.8898 - val_acc: 0.1364\n",
      "Epoch 359/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.7026 - acc: 0.3792 - val_loss: 2.8079 - val_acc: 0.1273\n",
      "Epoch 360/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.6406 - acc: 0.3875 - val_loss: 2.8869 - val_acc: 0.1273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.5734 - acc: 0.4042 - val_loss: 2.9206 - val_acc: 0.1091\n",
      "Epoch 362/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.5608 - acc: 0.3917 - val_loss: 2.9435 - val_acc: 0.1636\n",
      "Epoch 363/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.4686 - acc: 0.4083 - val_loss: 2.9890 - val_acc: 0.1727\n",
      "Epoch 364/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.4882 - acc: 0.4708 - val_loss: 3.0268 - val_acc: 0.1455\n",
      "Epoch 365/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.5438 - acc: 0.4083 - val_loss: 3.1233 - val_acc: 0.1091\n",
      "Epoch 366/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 1.4923 - acc: 0.4000 - val_loss: 3.1130 - val_acc: 0.1182\n",
      "Epoch 367/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.4718 - acc: 0.4708 - val_loss: 3.1565 - val_acc: 0.1000\n",
      "Epoch 368/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.6751 - acc: 0.3417 - val_loss: 3.1822 - val_acc: 0.0909\n",
      "Epoch 369/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.4261 - acc: 0.4542 - val_loss: 3.1295 - val_acc: 0.1182\n",
      "Epoch 370/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.4348 - acc: 0.4000 - val_loss: 3.2060 - val_acc: 0.1000\n",
      "Epoch 371/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.4446 - acc: 0.4583 - val_loss: 3.1901 - val_acc: 0.1636\n",
      "Epoch 372/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.3872 - acc: 0.4583 - val_loss: 3.2330 - val_acc: 0.1455\n",
      "Epoch 373/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.3362 - acc: 0.4792 - val_loss: 3.3378 - val_acc: 0.1273\n",
      "Epoch 374/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.4438 - acc: 0.4500 - val_loss: 3.1758 - val_acc: 0.1364\n",
      "Epoch 375/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.4401 - acc: 0.5000 - val_loss: 3.2558 - val_acc: 0.1273\n",
      "Epoch 376/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 1.4212 - acc: 0.4250 - val_loss: 3.3694 - val_acc: 0.1545\n",
      "Epoch 377/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.4182 - acc: 0.4500 - val_loss: 3.3709 - val_acc: 0.1364\n",
      "Epoch 378/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.5010 - acc: 0.4000 - val_loss: 3.2465 - val_acc: 0.1909\n",
      "Epoch 379/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.4274 - acc: 0.4167 - val_loss: 3.2505 - val_acc: 0.1091\n",
      "Epoch 380/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.3963 - acc: 0.4958 - val_loss: 3.2132 - val_acc: 0.1273\n",
      "Epoch 381/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.4311 - acc: 0.4333 - val_loss: 3.3144 - val_acc: 0.1364\n",
      "Epoch 382/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.3332 - acc: 0.4917 - val_loss: 3.3011 - val_acc: 0.1182\n",
      "Epoch 383/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.3718 - acc: 0.4833 - val_loss: 3.3847 - val_acc: 0.1091\n",
      "Epoch 384/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.3612 - acc: 0.4833 - val_loss: 3.3824 - val_acc: 0.1182\n",
      "Epoch 385/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.4943 - acc: 0.4417 - val_loss: 3.3625 - val_acc: 0.1000\n",
      "Epoch 386/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.3919 - acc: 0.4583 - val_loss: 3.4113 - val_acc: 0.1000\n",
      "Epoch 387/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 1.3333 - acc: 0.5042 - val_loss: 3.5112 - val_acc: 0.1273\n",
      "Epoch 388/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.3947 - acc: 0.4458 - val_loss: 3.4036 - val_acc: 0.1273\n",
      "Epoch 389/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.3602 - acc: 0.4333 - val_loss: 3.3816 - val_acc: 0.1182\n",
      "Epoch 390/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.3518 - acc: 0.4917 - val_loss: 3.4165 - val_acc: 0.1455\n",
      "Epoch 391/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.2927 - acc: 0.4750 - val_loss: 3.5278 - val_acc: 0.1727\n",
      "Epoch 392/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.3558 - acc: 0.4792 - val_loss: 3.6541 - val_acc: 0.1000\n",
      "Epoch 393/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.2462 - acc: 0.5000 - val_loss: 3.6389 - val_acc: 0.1364\n",
      "Epoch 394/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.2391 - acc: 0.5625 - val_loss: 3.6502 - val_acc: 0.1455\n",
      "Epoch 395/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.2654 - acc: 0.5250 - val_loss: 3.7545 - val_acc: 0.1545\n",
      "Epoch 396/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.3340 - acc: 0.4667 - val_loss: 3.6454 - val_acc: 0.1000\n",
      "Epoch 397/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.2915 - acc: 0.4583 - val_loss: 3.5556 - val_acc: 0.1364\n",
      "Epoch 398/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.2852 - acc: 0.5458 - val_loss: 3.6663 - val_acc: 0.1818\n",
      "Epoch 399/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.2795 - acc: 0.4750 - val_loss: 3.7113 - val_acc: 0.1727\n",
      "Epoch 400/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.3328 - acc: 0.4167 - val_loss: 3.6757 - val_acc: 0.2182\n",
      "Epoch 401/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.3568 - acc: 0.4792 - val_loss: 3.6876 - val_acc: 0.1455\n",
      "Epoch 402/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.3029 - acc: 0.5417 - val_loss: 3.7217 - val_acc: 0.1636\n",
      "Epoch 403/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.3509 - acc: 0.4958 - val_loss: 3.7700 - val_acc: 0.1545\n",
      "Epoch 404/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.3473 - acc: 0.4625 - val_loss: 3.5242 - val_acc: 0.1091\n",
      "Epoch 405/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.3781 - acc: 0.4542 - val_loss: 3.7368 - val_acc: 0.1636\n",
      "Epoch 406/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.3425 - acc: 0.4833 - val_loss: 3.7245 - val_acc: 0.1545\n",
      "Epoch 407/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.3360 - acc: 0.4542 - val_loss: 3.7464 - val_acc: 0.1364\n",
      "Epoch 408/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 1.2735 - acc: 0.4875 - val_loss: 3.7676 - val_acc: 0.1545\n",
      "Epoch 409/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.2050 - acc: 0.5292 - val_loss: 3.7425 - val_acc: 0.1636\n",
      "Epoch 410/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.2515 - acc: 0.4917 - val_loss: 3.7516 - val_acc: 0.1364\n",
      "Epoch 411/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.2662 - acc: 0.5042 - val_loss: 3.8122 - val_acc: 0.1364\n",
      "Epoch 412/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.3317 - acc: 0.4583 - val_loss: 3.6714 - val_acc: 0.1364\n",
      "Epoch 413/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.2161 - acc: 0.5167 - val_loss: 3.6953 - val_acc: 0.1364\n",
      "Epoch 414/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.1847 - acc: 0.5125 - val_loss: 3.8845 - val_acc: 0.1273\n",
      "Epoch 415/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.2073 - acc: 0.5167 - val_loss: 3.8760 - val_acc: 0.1364\n",
      "Epoch 416/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.1175 - acc: 0.5750 - val_loss: 4.0227 - val_acc: 0.1182\n",
      "Epoch 417/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.1863 - acc: 0.5375 - val_loss: 3.9850 - val_acc: 0.1455\n",
      "Epoch 418/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.2038 - acc: 0.5708 - val_loss: 3.9118 - val_acc: 0.1182\n",
      "Epoch 419/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.0956 - acc: 0.5833 - val_loss: 4.0304 - val_acc: 0.1455\n",
      "Epoch 420/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.1523 - acc: 0.5333 - val_loss: 4.1624 - val_acc: 0.1182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.2107 - acc: 0.5125 - val_loss: 4.1469 - val_acc: 0.1091\n",
      "Epoch 422/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.1678 - acc: 0.5250 - val_loss: 4.0886 - val_acc: 0.1455\n",
      "Epoch 423/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.1937 - acc: 0.5458 - val_loss: 4.2088 - val_acc: 0.1273\n",
      "Epoch 424/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.2111 - acc: 0.5083 - val_loss: 4.2246 - val_acc: 0.1182\n",
      "Epoch 425/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.2017 - acc: 0.5250 - val_loss: 4.2516 - val_acc: 0.1455\n",
      "Epoch 426/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.2054 - acc: 0.5083 - val_loss: 4.1317 - val_acc: 0.1182\n",
      "Epoch 427/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.0880 - acc: 0.5625 - val_loss: 4.2997 - val_acc: 0.1273\n",
      "Epoch 428/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.1684 - acc: 0.5583 - val_loss: 4.2532 - val_acc: 0.1364\n",
      "Epoch 429/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 1.2381 - acc: 0.5417 - val_loss: 4.1273 - val_acc: 0.1545\n",
      "Epoch 430/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.2132 - acc: 0.5292 - val_loss: 3.9042 - val_acc: 0.1636\n",
      "Epoch 431/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.2694 - acc: 0.4833 - val_loss: 4.1975 - val_acc: 0.1455\n",
      "Epoch 432/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.1816 - acc: 0.5042 - val_loss: 4.1718 - val_acc: 0.1455\n",
      "Epoch 433/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.1842 - acc: 0.5625 - val_loss: 4.1744 - val_acc: 0.1273\n",
      "Epoch 434/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.1752 - acc: 0.5208 - val_loss: 4.2264 - val_acc: 0.1545\n",
      "Epoch 435/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.1470 - acc: 0.5375 - val_loss: 4.3326 - val_acc: 0.1455\n",
      "Epoch 436/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.2117 - acc: 0.5250 - val_loss: 4.2170 - val_acc: 0.1545\n",
      "Epoch 437/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.1703 - acc: 0.5375 - val_loss: 4.2837 - val_acc: 0.1364\n",
      "Epoch 438/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.1013 - acc: 0.5458 - val_loss: 4.4540 - val_acc: 0.1545\n",
      "Epoch 439/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 1.2136 - acc: 0.5333 - val_loss: 4.2712 - val_acc: 0.1727\n",
      "Epoch 440/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.1617 - acc: 0.5542 - val_loss: 4.3696 - val_acc: 0.1273\n",
      "Epoch 441/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.0988 - acc: 0.6083 - val_loss: 4.2828 - val_acc: 0.1364\n",
      "Epoch 442/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.1796 - acc: 0.5583 - val_loss: 4.1923 - val_acc: 0.1636\n",
      "Epoch 443/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.2255 - acc: 0.5167 - val_loss: 4.2821 - val_acc: 0.1273\n",
      "Epoch 444/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.1792 - acc: 0.5208 - val_loss: 4.3217 - val_acc: 0.2000\n",
      "Epoch 445/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.1687 - acc: 0.5750 - val_loss: 4.4050 - val_acc: 0.1545\n",
      "Epoch 446/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.1688 - acc: 0.5083 - val_loss: 4.3265 - val_acc: 0.1455\n",
      "Epoch 447/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.1122 - acc: 0.5667 - val_loss: 4.3945 - val_acc: 0.1545\n",
      "Epoch 448/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.1111 - acc: 0.5708 - val_loss: 4.4821 - val_acc: 0.1364\n",
      "Epoch 449/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.2119 - acc: 0.5333 - val_loss: 4.3582 - val_acc: 0.1364\n",
      "Epoch 450/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 1.1318 - acc: 0.5875 - val_loss: 4.5508 - val_acc: 0.1364\n",
      "Epoch 451/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.2280 - acc: 0.5458 - val_loss: 4.4486 - val_acc: 0.1636\n",
      "Epoch 452/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.1770 - acc: 0.5083 - val_loss: 4.3836 - val_acc: 0.1091\n",
      "Epoch 453/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.2322 - acc: 0.5167 - val_loss: 4.3843 - val_acc: 0.1455\n",
      "Epoch 454/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.1261 - acc: 0.5542 - val_loss: 4.4341 - val_acc: 0.1545\n",
      "Epoch 455/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.0966 - acc: 0.5708 - val_loss: 4.3805 - val_acc: 0.1636\n",
      "Epoch 456/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.1889 - acc: 0.5375 - val_loss: 4.3494 - val_acc: 0.1455\n",
      "Epoch 457/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.1385 - acc: 0.5542 - val_loss: 4.3989 - val_acc: 0.1273\n",
      "Epoch 458/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.1217 - acc: 0.5167 - val_loss: 4.4008 - val_acc: 0.1273\n",
      "Epoch 459/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.3005 - acc: 0.4917 - val_loss: 4.5195 - val_acc: 0.1273\n",
      "Epoch 460/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 1.2277 - acc: 0.4958 - val_loss: 4.3428 - val_acc: 0.1545\n",
      "Epoch 461/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.2190 - acc: 0.5208 - val_loss: 4.4198 - val_acc: 0.1182\n",
      "Epoch 462/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.1661 - acc: 0.5292 - val_loss: 4.4834 - val_acc: 0.1273\n",
      "Epoch 463/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.1825 - acc: 0.5500 - val_loss: 4.4148 - val_acc: 0.1273\n",
      "Epoch 464/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.0362 - acc: 0.5917 - val_loss: 4.3861 - val_acc: 0.1182\n",
      "Epoch 465/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.1613 - acc: 0.5583 - val_loss: 4.4750 - val_acc: 0.1455\n",
      "Epoch 466/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.0770 - acc: 0.5917 - val_loss: 4.5509 - val_acc: 0.1364\n",
      "Epoch 467/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.0412 - acc: 0.6292 - val_loss: 4.4820 - val_acc: 0.1273\n",
      "Epoch 468/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.1381 - acc: 0.5625 - val_loss: 4.3204 - val_acc: 0.1000\n",
      "Epoch 469/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.2342 - acc: 0.5208 - val_loss: 4.5719 - val_acc: 0.1364\n",
      "Epoch 470/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.1871 - acc: 0.5167 - val_loss: 4.5913 - val_acc: 0.1182\n",
      "Epoch 471/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 1.1065 - acc: 0.5500 - val_loss: 4.6787 - val_acc: 0.1273\n",
      "Epoch 472/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.0596 - acc: 0.5500 - val_loss: 4.6472 - val_acc: 0.1091\n",
      "Epoch 473/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.1492 - acc: 0.5458 - val_loss: 4.5540 - val_acc: 0.1455\n",
      "Epoch 474/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.9623 - acc: 0.6667 - val_loss: 4.7079 - val_acc: 0.1182\n",
      "Epoch 475/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.0179 - acc: 0.5833 - val_loss: 4.6625 - val_acc: 0.1364\n",
      "Epoch 476/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.0237 - acc: 0.6042 - val_loss: 4.6842 - val_acc: 0.1182\n",
      "Epoch 477/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.9911 - acc: 0.6042 - val_loss: 4.7146 - val_acc: 0.1455\n",
      "Epoch 478/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.1182 - acc: 0.5500 - val_loss: 4.6464 - val_acc: 0.1364\n",
      "Epoch 479/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.0769 - acc: 0.5625 - val_loss: 4.7572 - val_acc: 0.1273\n",
      "Epoch 480/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.0421 - acc: 0.5625 - val_loss: 4.7415 - val_acc: 0.1091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 1.1408 - acc: 0.6000 - val_loss: 4.5937 - val_acc: 0.1091\n",
      "Epoch 482/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.1149 - acc: 0.5375 - val_loss: 4.5408 - val_acc: 0.1545\n",
      "Epoch 483/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.2273 - acc: 0.5292 - val_loss: 4.7546 - val_acc: 0.1091\n",
      "Epoch 484/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.1140 - acc: 0.5542 - val_loss: 4.6849 - val_acc: 0.1273\n",
      "Epoch 485/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.0051 - acc: 0.5708 - val_loss: 4.8579 - val_acc: 0.1182\n",
      "Epoch 486/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.0274 - acc: 0.6042 - val_loss: 4.9194 - val_acc: 0.1182\n",
      "Epoch 487/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 0.9577 - acc: 0.6083 - val_loss: 4.8453 - val_acc: 0.1545\n",
      "Epoch 488/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.0093 - acc: 0.5750 - val_loss: 4.8887 - val_acc: 0.1273\n",
      "Epoch 489/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.0580 - acc: 0.5583 - val_loss: 4.8998 - val_acc: 0.1364\n",
      "Epoch 490/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.9736 - acc: 0.6083 - val_loss: 4.8789 - val_acc: 0.1545\n",
      "Epoch 491/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.0844 - acc: 0.5625 - val_loss: 4.8584 - val_acc: 0.1455\n",
      "Epoch 492/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 1.0605 - acc: 0.5708 - val_loss: 4.9570 - val_acc: 0.1364\n",
      "Epoch 493/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.0086 - acc: 0.5833 - val_loss: 4.9093 - val_acc: 0.1636\n",
      "Epoch 494/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.0749 - acc: 0.6000 - val_loss: 4.8311 - val_acc: 0.1455\n",
      "Epoch 495/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.2398 - acc: 0.5000 - val_loss: 4.7803 - val_acc: 0.1091\n",
      "Epoch 496/500\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 1.1865 - acc: 0.5125 - val_loss: 4.7664 - val_acc: 0.1545\n",
      "Epoch 497/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.2795 - acc: 0.4958 - val_loss: 4.7568 - val_acc: 0.1636\n",
      "Epoch 498/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.2454 - acc: 0.5208 - val_loss: 4.7264 - val_acc: 0.1727\n",
      "Epoch 499/500\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 1.1694 - acc: 0.5458 - val_loss: 4.7256 - val_acc: 0.1091\n",
      "Epoch 500/500\n",
      "240/240 [==============================] - 11s 48ms/step - loss: 1.2376 - acc: 0.5375 - val_loss: 4.7126 - val_acc: 0.1545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa414116c88>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_with_2layers_1D('LSTM_2Layer1DDelta8',dropout=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/1000\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 2.3052 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 2/1000\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 2.3037 - acc: 0.0583 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 3/1000\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 2.3029 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 4/1000\n",
      "240/240 [==============================] - 10s 42ms/step - loss: 2.4110 - acc: 0.1000 - val_loss: 2.3320 - val_acc: 0.1000\n",
      "Epoch 5/1000\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 2.3087 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 6/1000\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 7/1000\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 2.3025 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 8/1000\n",
      "240/240 [==============================] - 10s 43ms/step - loss: 2.3024 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 9/1000\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 2.3024 - acc: 0.0792 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 10/1000\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.3022 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 11/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3024 - acc: 0.0625 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 12/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3019 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 13/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3019 - acc: 0.0750 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 14/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3015 - acc: 0.0750 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 15/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3007 - acc: 0.1083 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 16/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3007 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 17/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2991 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 18/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2988 - acc: 0.0667 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 19/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2974 - acc: 0.0708 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 20/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2971 - acc: 0.0792 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 21/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2959 - acc: 0.1083 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 22/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2956 - acc: 0.1042 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 23/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2947 - acc: 0.0500 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 24/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2951 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 25/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2944 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 26/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2947 - acc: 0.0833 - val_loss: 2.3025 - val_acc: 0.1000\n",
      "Epoch 27/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2942 - acc: 0.0958 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 28/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2941 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 29/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2946 - acc: 0.1042 - val_loss: 2.3025 - val_acc: 0.1000\n",
      "Epoch 30/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2938 - acc: 0.1083 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 31/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2945 - acc: 0.0917 - val_loss: 2.3025 - val_acc: 0.0909\n",
      "Epoch 32/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2942 - acc: 0.0875 - val_loss: 2.3025 - val_acc: 0.0909\n",
      "Epoch 33/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2931 - acc: 0.0917 - val_loss: 2.3020 - val_acc: 0.0818\n",
      "Epoch 34/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2980 - acc: 0.0667 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 35/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2968 - acc: 0.1083 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 36/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2988 - acc: 0.1042 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 37/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2960 - acc: 0.1042 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 38/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2952 - acc: 0.1042 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 39/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2946 - acc: 0.1042 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 40/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2952 - acc: 0.1042 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 41/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2944 - acc: 0.0625 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 42/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2943 - acc: 0.0917 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 43/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2945 - acc: 0.0625 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 44/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2942 - acc: 0.0583 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 45/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2948 - acc: 0.0792 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 46/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2942 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 47/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2942 - acc: 0.0750 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 48/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2941 - acc: 0.0750 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 49/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2940 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 50/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2941 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 51/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2942 - acc: 0.0500 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 52/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2942 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 53/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2946 - acc: 0.0625 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 54/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2941 - acc: 0.0583 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 55/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2939 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 56/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2949 - acc: 0.0708 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 57/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2941 - acc: 0.0667 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 58/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2942 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 59/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2937 - acc: 0.0875 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 60/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2938 - acc: 0.0625 - val_loss: 2.3027 - val_acc: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2940 - acc: 0.0500 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 62/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2941 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 63/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2941 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 64/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2940 - acc: 0.0792 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 65/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2938 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 66/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2946 - acc: 0.0750 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 67/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2936 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 68/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2939 - acc: 0.0750 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 69/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2941 - acc: 0.0958 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 70/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2939 - acc: 0.0792 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 71/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2942 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 72/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2941 - acc: 0.0542 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 73/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2937 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 74/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2947 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 75/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2940 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 76/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2940 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 77/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2936 - acc: 0.0750 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 78/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2939 - acc: 0.0667 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 79/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2936 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 80/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2939 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 81/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2937 - acc: 0.0875 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 82/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2942 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 83/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2934 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 84/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2933 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 85/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2931 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 86/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2924 - acc: 0.0917 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 87/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2959 - acc: 0.0583 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 88/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3060 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 89/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3029 - acc: 0.0583 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 90/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2997 - acc: 0.0750 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 91/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2957 - acc: 0.0792 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 92/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2950 - acc: 0.0625 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 93/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2945 - acc: 0.0750 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 94/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2941 - acc: 0.0875 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 95/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2951 - acc: 0.0667 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 96/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2940 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 97/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2940 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 98/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2940 - acc: 0.0750 - val_loss: 2.3027 - val_acc: 0.0909\n",
      "Epoch 99/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2939 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 100/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2941 - acc: 0.0708 - val_loss: 2.3027 - val_acc: 0.1091\n",
      "Epoch 101/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2940 - acc: 0.0875 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 102/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2935 - acc: 0.0792 - val_loss: 2.3025 - val_acc: 0.1000\n",
      "Epoch 103/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2920 - acc: 0.0958 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 104/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2909 - acc: 0.0708 - val_loss: 2.3026 - val_acc: 0.0909\n",
      "Epoch 105/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2904 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 106/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2865 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 107/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3038 - acc: 0.1000 - val_loss: 2.3218 - val_acc: 0.1000\n",
      "Epoch 108/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2877 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.0909\n",
      "Epoch 109/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3009 - acc: 0.0625 - val_loss: 2.3027 - val_acc: 0.0909\n",
      "Epoch 110/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2944 - acc: 0.0792 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 111/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2972 - acc: 0.0792 - val_loss: 2.3024 - val_acc: 0.1000\n",
      "Epoch 112/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2870 - acc: 0.0958 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 113/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2865 - acc: 0.0542 - val_loss: 2.3023 - val_acc: 0.0909\n",
      "Epoch 114/1000\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.2829 - acc: 0.1000 - val_loss: 2.3028 - val_acc: 0.1091\n",
      "Epoch 115/1000\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 2.2944 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 116/1000\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.2932 - acc: 0.1042 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 117/1000\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.2918 - acc: 0.0875 - val_loss: 2.3024 - val_acc: 0.0909\n",
      "Epoch 118/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2900 - acc: 0.1167 - val_loss: 2.3034 - val_acc: 0.0909\n",
      "Epoch 119/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.2918 - acc: 0.0875 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 120/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2958 - acc: 0.0875 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2934 - acc: 0.0875 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 122/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2933 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 123/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2941 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 124/1000\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 2.2926 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 125/1000\n",
      "240/240 [==============================] - 10s 44ms/step - loss: 2.2916 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 126/1000\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 2.2902 - acc: 0.1042 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 127/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2866 - acc: 0.1125 - val_loss: 2.3059 - val_acc: 0.1091\n",
      "Epoch 128/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2907 - acc: 0.1083 - val_loss: 2.3050 - val_acc: 0.1182\n",
      "Epoch 129/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2884 - acc: 0.1000 - val_loss: 2.3020 - val_acc: 0.0909\n",
      "Epoch 130/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2751 - acc: 0.1333 - val_loss: 2.3074 - val_acc: 0.1000\n",
      "Epoch 131/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.3056 - acc: 0.1000 - val_loss: 2.3046 - val_acc: 0.1000\n",
      "Epoch 132/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2947 - acc: 0.1042 - val_loss: 2.3035 - val_acc: 0.1000\n",
      "Epoch 133/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2935 - acc: 0.1083 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 134/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2934 - acc: 0.1125 - val_loss: 2.3033 - val_acc: 0.1000\n",
      "Epoch 135/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2917 - acc: 0.1083 - val_loss: 2.3025 - val_acc: 0.1000\n",
      "Epoch 136/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2925 - acc: 0.0958 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 137/1000\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 2.3020 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 138/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2937 - acc: 0.0958 - val_loss: 2.3024 - val_acc: 0.1000\n",
      "Epoch 139/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2934 - acc: 0.0792 - val_loss: 2.3024 - val_acc: 0.1000\n",
      "Epoch 140/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2902 - acc: 0.1167 - val_loss: 2.2964 - val_acc: 0.1182\n",
      "Epoch 141/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2913 - acc: 0.1083 - val_loss: 2.3029 - val_acc: 0.0909\n",
      "Epoch 142/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2974 - acc: 0.0708 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 143/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2933 - acc: 0.0875 - val_loss: 2.3023 - val_acc: 0.1182\n",
      "Epoch 144/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2924 - acc: 0.0917 - val_loss: 2.3022 - val_acc: 0.1182\n",
      "Epoch 145/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2890 - acc: 0.0833 - val_loss: 2.3114 - val_acc: 0.0727\n",
      "Epoch 146/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2983 - acc: 0.0875 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 147/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2937 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 148/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2939 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 149/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2937 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 150/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2949 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 151/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2934 - acc: 0.0833 - val_loss: 2.3025 - val_acc: 0.1091\n",
      "Epoch 152/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2932 - acc: 0.1042 - val_loss: 2.3024 - val_acc: 0.1182\n",
      "Epoch 153/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2924 - acc: 0.1167 - val_loss: 2.3018 - val_acc: 0.1182\n",
      "Epoch 154/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2935 - acc: 0.0750 - val_loss: 2.2978 - val_acc: 0.1182\n",
      "Epoch 155/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2920 - acc: 0.0625 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 156/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2937 - acc: 0.1083 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 157/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2940 - acc: 0.1000 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 158/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2938 - acc: 0.0875 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 159/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2933 - acc: 0.1042 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 160/1000\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 2.2937 - acc: 0.0833 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 161/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2932 - acc: 0.0833 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 162/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2930 - acc: 0.0917 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 163/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2922 - acc: 0.0750 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 164/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2900 - acc: 0.1083 - val_loss: 2.3032 - val_acc: 0.1000\n",
      "Epoch 165/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2975 - acc: 0.0875 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 166/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2993 - acc: 0.0833 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 167/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2962 - acc: 0.1083 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 168/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2945 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 169/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2945 - acc: 0.0542 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 170/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2943 - acc: 0.0625 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 171/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2941 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 172/1000\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 2.2939 - acc: 0.0750 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 173/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2946 - acc: 0.0875 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 174/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2939 - acc: 0.0792 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 175/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2937 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 176/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2936 - acc: 0.0958 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 177/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2941 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 178/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2933 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 179/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2937 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 180/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2935 - acc: 0.0958 - val_loss: 2.3026 - val_acc: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2929 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 182/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2933 - acc: 0.1083 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 183/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2943 - acc: 0.1083 - val_loss: 2.3026 - val_acc: 0.1182\n",
      "Epoch 184/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2936 - acc: 0.0750 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 185/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2928 - acc: 0.0958 - val_loss: 2.3025 - val_acc: 0.1000\n",
      "Epoch 186/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2926 - acc: 0.0708 - val_loss: 2.3025 - val_acc: 0.1091\n",
      "Epoch 187/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2914 - acc: 0.1125 - val_loss: 2.3019 - val_acc: 0.1091\n",
      "Epoch 188/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2884 - acc: 0.1000 - val_loss: 2.3054 - val_acc: 0.0909\n",
      "Epoch 189/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2931 - acc: 0.0667 - val_loss: 2.3023 - val_acc: 0.1091\n",
      "Epoch 190/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2946 - acc: 0.1125 - val_loss: 2.3043 - val_acc: 0.1000\n",
      "Epoch 191/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2957 - acc: 0.1208 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 192/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2944 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 193/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2941 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 194/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2939 - acc: 0.0792 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 195/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2942 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 196/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2938 - acc: 0.0792 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 197/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2933 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 198/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2932 - acc: 0.0500 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 199/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2925 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 200/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2921 - acc: 0.0917 - val_loss: 2.3025 - val_acc: 0.1000\n",
      "Epoch 201/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2916 - acc: 0.0625 - val_loss: 2.3014 - val_acc: 0.1000\n",
      "Epoch 202/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2881 - acc: 0.1042 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 203/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2871 - acc: 0.1125 - val_loss: 2.3025 - val_acc: 0.1000\n",
      "Epoch 204/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2815 - acc: 0.0875 - val_loss: 2.3024 - val_acc: 0.1000\n",
      "Epoch 205/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2790 - acc: 0.0750 - val_loss: 2.3112 - val_acc: 0.1273\n",
      "Epoch 206/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2768 - acc: 0.0875 - val_loss: 2.3032 - val_acc: 0.0909\n",
      "Epoch 207/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2942 - acc: 0.0542 - val_loss: 2.3021 - val_acc: 0.0909\n",
      "Epoch 208/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2792 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 209/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2927 - acc: 0.0917 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 210/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2873 - acc: 0.0750 - val_loss: 2.3022 - val_acc: 0.1182\n",
      "Epoch 211/1000\n",
      "240/240 [==============================] - 11s 46ms/step - loss: 2.2826 - acc: 0.1083 - val_loss: 2.3024 - val_acc: 0.0818\n",
      "Epoch 212/1000\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 2.2830 - acc: 0.0958 - val_loss: 2.3026 - val_acc: 0.0727\n",
      "Epoch 213/1000\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 2.2876 - acc: 0.0917 - val_loss: 2.3016 - val_acc: 0.1091\n",
      "Epoch 214/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2761 - acc: 0.0917 - val_loss: 2.3025 - val_acc: 0.1000\n",
      "Epoch 215/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 2.2748 - acc: 0.1042 - val_loss: 2.3024 - val_acc: 0.1182\n",
      "Epoch 216/1000\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.2750 - acc: 0.0750 - val_loss: 2.3017 - val_acc: 0.1273\n",
      "Epoch 217/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 2.2752 - acc: 0.0750 - val_loss: 2.3034 - val_acc: 0.1000\n",
      "Epoch 218/1000\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 2.2760 - acc: 0.0958 - val_loss: 2.3173 - val_acc: 0.0545\n",
      "Epoch 219/1000\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 2.2828 - acc: 0.1042 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 220/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2759 - acc: 0.0833 - val_loss: 2.3040 - val_acc: 0.1000\n",
      "Epoch 221/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2756 - acc: 0.0917 - val_loss: 2.3221 - val_acc: 0.1182\n",
      "Epoch 222/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2759 - acc: 0.1125 - val_loss: 2.4742 - val_acc: 0.1000\n",
      "Epoch 223/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.3057 - acc: 0.0667 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 224/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2908 - acc: 0.0958 - val_loss: 2.3184 - val_acc: 0.1182\n",
      "Epoch 225/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2898 - acc: 0.0875 - val_loss: 2.3030 - val_acc: 0.0909\n",
      "Epoch 226/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2800 - acc: 0.0625 - val_loss: 2.3070 - val_acc: 0.0818\n",
      "Epoch 227/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2931 - acc: 0.0792 - val_loss: 2.3025 - val_acc: 0.1091\n",
      "Epoch 228/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2910 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.0727\n",
      "Epoch 229/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2878 - acc: 0.1167 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 230/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2823 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 231/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2777 - acc: 0.1000 - val_loss: 2.3062 - val_acc: 0.1091\n",
      "Epoch 232/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2771 - acc: 0.0917 - val_loss: 2.3073 - val_acc: 0.1091\n",
      "Epoch 233/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2747 - acc: 0.0500 - val_loss: 2.3155 - val_acc: 0.1091\n",
      "Epoch 234/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2739 - acc: 0.0750 - val_loss: 2.3028 - val_acc: 0.0909\n",
      "Epoch 235/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2751 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 236/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2749 - acc: 0.0833 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 237/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2747 - acc: 0.1125 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 238/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2747 - acc: 0.0750 - val_loss: 2.3029 - val_acc: 0.0909\n",
      "Epoch 239/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2748 - acc: 0.1000 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 240/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2744 - acc: 0.0667 - val_loss: 2.3028 - val_acc: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2746 - acc: 0.1042 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 242/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2746 - acc: 0.0958 - val_loss: 2.3028 - val_acc: 0.0909\n",
      "Epoch 243/1000\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 2.2745 - acc: 0.0792 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 244/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2747 - acc: 0.0750 - val_loss: 2.3029 - val_acc: 0.0727\n",
      "Epoch 245/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2751 - acc: 0.0875 - val_loss: 2.3032 - val_acc: 0.0909\n",
      "Epoch 246/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2745 - acc: 0.0542 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 247/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2739 - acc: 0.0833 - val_loss: 2.3031 - val_acc: 0.0818\n",
      "Epoch 248/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2737 - acc: 0.1333 - val_loss: 2.3026 - val_acc: 0.0818\n",
      "Epoch 249/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2694 - acc: 0.1667 - val_loss: 2.4794 - val_acc: 0.1364\n",
      "Epoch 250/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.3358 - acc: 0.0917 - val_loss: 2.3030 - val_acc: 0.1091\n",
      "Epoch 251/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2762 - acc: 0.0833 - val_loss: 2.3052 - val_acc: 0.1000\n",
      "Epoch 252/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2922 - acc: 0.1125 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 253/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2888 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1182\n",
      "Epoch 254/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2733 - acc: 0.0958 - val_loss: 2.4322 - val_acc: 0.1091\n",
      "Epoch 255/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2957 - acc: 0.0792 - val_loss: 2.3431 - val_acc: 0.1000\n",
      "Epoch 256/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2914 - acc: 0.1208 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 257/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2830 - acc: 0.0958 - val_loss: 2.3032 - val_acc: 0.1091\n",
      "Epoch 258/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2800 - acc: 0.0750 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 259/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2776 - acc: 0.0708 - val_loss: 2.3032 - val_acc: 0.1091\n",
      "Epoch 260/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2767 - acc: 0.0917 - val_loss: 2.3030 - val_acc: 0.0909\n",
      "Epoch 261/1000\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 2.2760 - acc: 0.0792 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 262/1000\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 2.2762 - acc: 0.0833 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 263/1000\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 2.2751 - acc: 0.0917 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 264/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2753 - acc: 0.0958 - val_loss: 2.3029 - val_acc: 0.0909\n",
      "Epoch 265/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2750 - acc: 0.0917 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 266/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2749 - acc: 0.1000 - val_loss: 2.3025 - val_acc: 0.1091\n",
      "Epoch 267/1000\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 2.2751 - acc: 0.1125 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 268/1000\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 2.2750 - acc: 0.0792 - val_loss: 2.3026 - val_acc: 0.1091\n",
      "Epoch 269/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2745 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 270/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2755 - acc: 0.0792 - val_loss: 2.3023 - val_acc: 0.1091\n",
      "Epoch 271/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2750 - acc: 0.0875 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 272/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2749 - acc: 0.0792 - val_loss: 2.3025 - val_acc: 0.1091\n",
      "Epoch 273/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2749 - acc: 0.0875 - val_loss: 2.3024 - val_acc: 0.1091\n",
      "Epoch 274/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2744 - acc: 0.1042 - val_loss: 2.3021 - val_acc: 0.1091\n",
      "Epoch 275/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2744 - acc: 0.0750 - val_loss: 2.3019 - val_acc: 0.1000\n",
      "Epoch 276/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2746 - acc: 0.1208 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 277/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2756 - acc: 0.0875 - val_loss: 2.3025 - val_acc: 0.0909\n",
      "Epoch 278/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2741 - acc: 0.1125 - val_loss: 2.3020 - val_acc: 0.1000\n",
      "Epoch 279/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2745 - acc: 0.1125 - val_loss: 2.3020 - val_acc: 0.1091\n",
      "Epoch 280/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2742 - acc: 0.1167 - val_loss: 2.3021 - val_acc: 0.1000\n",
      "Epoch 281/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2746 - acc: 0.1125 - val_loss: 2.3012 - val_acc: 0.1091\n",
      "Epoch 282/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2738 - acc: 0.1042 - val_loss: 2.3063 - val_acc: 0.0909\n",
      "Epoch 283/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 2.2736 - acc: 0.1167 - val_loss: 2.3011 - val_acc: 0.1273\n",
      "Epoch 284/1000\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 2.2819 - acc: 0.1042 - val_loss: 2.3399 - val_acc: 0.1000\n",
      "Epoch 285/1000\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 2.3183 - acc: 0.0875 - val_loss: 2.3042 - val_acc: 0.1000\n",
      "Epoch 286/1000\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 2.2821 - acc: 0.1083 - val_loss: 2.3071 - val_acc: 0.0818\n",
      "Epoch 287/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2746 - acc: 0.1208 - val_loss: 2.3139 - val_acc: 0.0909\n",
      "Epoch 288/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2621 - acc: 0.0917 - val_loss: 2.3344 - val_acc: 0.1000\n",
      "Epoch 289/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2565 - acc: 0.1292 - val_loss: 2.3104 - val_acc: 0.0727\n",
      "Epoch 290/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2717 - acc: 0.0958 - val_loss: 2.3119 - val_acc: 0.1000\n",
      "Epoch 291/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2559 - acc: 0.1167 - val_loss: 2.3048 - val_acc: 0.1000\n",
      "Epoch 292/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2712 - acc: 0.1208 - val_loss: 2.3133 - val_acc: 0.0818\n",
      "Epoch 293/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2652 - acc: 0.1167 - val_loss: 2.3050 - val_acc: 0.1000\n",
      "Epoch 294/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2840 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 295/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2707 - acc: 0.1125 - val_loss: 2.3202 - val_acc: 0.0727\n",
      "Epoch 296/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2502 - acc: 0.1042 - val_loss: 2.3115 - val_acc: 0.0909\n",
      "Epoch 297/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2352 - acc: 0.1167 - val_loss: 2.3072 - val_acc: 0.1000\n",
      "Epoch 298/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2334 - acc: 0.1208 - val_loss: 2.3058 - val_acc: 0.1000\n",
      "Epoch 299/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2232 - acc: 0.1250 - val_loss: 2.3561 - val_acc: 0.1000\n",
      "Epoch 300/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2163 - acc: 0.1083 - val_loss: 2.3305 - val_acc: 0.1091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2018 - acc: 0.1375 - val_loss: 2.3459 - val_acc: 0.0909\n",
      "Epoch 302/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2118 - acc: 0.1292 - val_loss: 2.3052 - val_acc: 0.1000\n",
      "Epoch 303/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2233 - acc: 0.1417 - val_loss: 2.3342 - val_acc: 0.1000\n",
      "Epoch 304/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2487 - acc: 0.1333 - val_loss: 2.3983 - val_acc: 0.1455\n",
      "Epoch 305/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2617 - acc: 0.1083 - val_loss: 2.3805 - val_acc: 0.0636\n",
      "Epoch 306/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2314 - acc: 0.1250 - val_loss: 2.3677 - val_acc: 0.1000\n",
      "Epoch 307/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2283 - acc: 0.1333 - val_loss: 2.3592 - val_acc: 0.1091\n",
      "Epoch 308/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2161 - acc: 0.1583 - val_loss: 2.4648 - val_acc: 0.1091\n",
      "Epoch 309/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2656 - acc: 0.1542 - val_loss: 2.3402 - val_acc: 0.1000\n",
      "Epoch 310/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2157 - acc: 0.1500 - val_loss: 2.4313 - val_acc: 0.1000\n",
      "Epoch 311/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2405 - acc: 0.1375 - val_loss: 2.3357 - val_acc: 0.1091\n",
      "Epoch 312/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2300 - acc: 0.1458 - val_loss: 2.3600 - val_acc: 0.1091\n",
      "Epoch 313/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2038 - acc: 0.1458 - val_loss: 2.4587 - val_acc: 0.0909\n",
      "Epoch 314/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.1937 - acc: 0.1625 - val_loss: 2.4667 - val_acc: 0.1000\n",
      "Epoch 315/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2174 - acc: 0.1583 - val_loss: 2.4256 - val_acc: 0.1091\n",
      "Epoch 316/1000\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 2.1703 - acc: 0.1667 - val_loss: 2.4071 - val_acc: 0.1091\n",
      "Epoch 317/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.1514 - acc: 0.1750 - val_loss: 2.4893 - val_acc: 0.1000\n",
      "Epoch 318/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.1284 - acc: 0.1917 - val_loss: 2.4002 - val_acc: 0.1000\n",
      "Epoch 319/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.1745 - acc: 0.1625 - val_loss: 2.4701 - val_acc: 0.1364\n",
      "Epoch 320/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2333 - acc: 0.1417 - val_loss: 2.4543 - val_acc: 0.1000\n",
      "Epoch 321/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.1865 - acc: 0.1625 - val_loss: 2.3733 - val_acc: 0.1091\n",
      "Epoch 322/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.1594 - acc: 0.1625 - val_loss: 2.4495 - val_acc: 0.1000\n",
      "Epoch 323/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.1166 - acc: 0.1875 - val_loss: 2.4216 - val_acc: 0.1091\n",
      "Epoch 324/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.1011 - acc: 0.2042 - val_loss: 2.5343 - val_acc: 0.1000\n",
      "Epoch 325/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.0749 - acc: 0.2083 - val_loss: 2.5474 - val_acc: 0.1000\n",
      "Epoch 326/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.0883 - acc: 0.1917 - val_loss: 2.5351 - val_acc: 0.0909\n",
      "Epoch 327/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.1498 - acc: 0.1750 - val_loss: 2.6617 - val_acc: 0.0909\n",
      "Epoch 328/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.1375 - acc: 0.1875 - val_loss: 2.5197 - val_acc: 0.0818\n",
      "Epoch 329/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.2639 - acc: 0.1667 - val_loss: 2.3225 - val_acc: 0.0909\n",
      "Epoch 330/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.2502 - acc: 0.1417 - val_loss: 2.3260 - val_acc: 0.1000\n",
      "Epoch 331/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.1936 - acc: 0.1625 - val_loss: 2.4327 - val_acc: 0.0909\n",
      "Epoch 332/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.1325 - acc: 0.1667 - val_loss: 2.3619 - val_acc: 0.0909\n",
      "Epoch 333/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.1420 - acc: 0.1625 - val_loss: 2.4720 - val_acc: 0.0818\n",
      "Epoch 334/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.0882 - acc: 0.2000 - val_loss: 2.5222 - val_acc: 0.0909\n",
      "Epoch 335/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.0818 - acc: 0.1958 - val_loss: 2.5026 - val_acc: 0.1091\n",
      "Epoch 336/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.0879 - acc: 0.1917 - val_loss: 2.4551 - val_acc: 0.1000\n",
      "Epoch 337/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.1117 - acc: 0.1958 - val_loss: 2.3494 - val_acc: 0.1091\n",
      "Epoch 338/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.1009 - acc: 0.1917 - val_loss: 2.4925 - val_acc: 0.0818\n",
      "Epoch 339/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.1535 - acc: 0.1875 - val_loss: 2.4272 - val_acc: 0.0909\n",
      "Epoch 340/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.0906 - acc: 0.1708 - val_loss: 2.4274 - val_acc: 0.0909\n",
      "Epoch 341/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.0668 - acc: 0.2042 - val_loss: 2.4170 - val_acc: 0.0818\n",
      "Epoch 342/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.0607 - acc: 0.2083 - val_loss: 2.4260 - val_acc: 0.0818\n",
      "Epoch 343/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.0297 - acc: 0.2417 - val_loss: 2.4472 - val_acc: 0.1000\n",
      "Epoch 344/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.0261 - acc: 0.2042 - val_loss: 2.4929 - val_acc: 0.0909\n",
      "Epoch 345/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.0393 - acc: 0.2083 - val_loss: 2.5165 - val_acc: 0.0818\n",
      "Epoch 346/1000\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 2.0428 - acc: 0.2042 - val_loss: 2.4387 - val_acc: 0.1091\n",
      "Epoch 347/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.0661 - acc: 0.1750 - val_loss: 2.6048 - val_acc: 0.1182\n",
      "Epoch 348/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.1116 - acc: 0.1625 - val_loss: 2.4781 - val_acc: 0.0818\n",
      "Epoch 349/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.0763 - acc: 0.1917 - val_loss: 2.5193 - val_acc: 0.0727\n",
      "Epoch 350/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.0497 - acc: 0.2042 - val_loss: 2.4912 - val_acc: 0.0909\n",
      "Epoch 351/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.0685 - acc: 0.2000 - val_loss: 2.4449 - val_acc: 0.0455\n",
      "Epoch 352/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.1077 - acc: 0.1792 - val_loss: 2.4676 - val_acc: 0.1091\n",
      "Epoch 353/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.1098 - acc: 0.1792 - val_loss: 2.4533 - val_acc: 0.0818\n",
      "Epoch 354/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.0683 - acc: 0.2000 - val_loss: 2.4938 - val_acc: 0.1000\n",
      "Epoch 355/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.0523 - acc: 0.1917 - val_loss: 2.4830 - val_acc: 0.1091\n",
      "Epoch 356/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.0444 - acc: 0.1958 - val_loss: 2.5619 - val_acc: 0.1182\n",
      "Epoch 357/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.0308 - acc: 0.1917 - val_loss: 2.5491 - val_acc: 0.1091\n",
      "Epoch 358/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.0327 - acc: 0.2000 - val_loss: 2.6232 - val_acc: 0.0909\n",
      "Epoch 359/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.0350 - acc: 0.1583 - val_loss: 2.5209 - val_acc: 0.0636\n",
      "Epoch 360/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.0365 - acc: 0.2208 - val_loss: 2.6134 - val_acc: 0.0818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.0221 - acc: 0.2042 - val_loss: 2.6748 - val_acc: 0.0818\n",
      "Epoch 362/1000\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 2.0238 - acc: 0.1958 - val_loss: 2.6088 - val_acc: 0.1000\n",
      "Epoch 363/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.0230 - acc: 0.1958 - val_loss: 2.6081 - val_acc: 0.1000\n",
      "Epoch 364/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.0168 - acc: 0.2042 - val_loss: 2.6250 - val_acc: 0.0727\n",
      "Epoch 365/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.0299 - acc: 0.2167 - val_loss: 2.5836 - val_acc: 0.0727\n",
      "Epoch 366/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.0127 - acc: 0.1958 - val_loss: 2.5966 - val_acc: 0.0727\n",
      "Epoch 367/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.0221 - acc: 0.2292 - val_loss: 2.5512 - val_acc: 0.0909\n",
      "Epoch 368/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.0136 - acc: 0.1958 - val_loss: 2.5526 - val_acc: 0.1182\n",
      "Epoch 369/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.0109 - acc: 0.2042 - val_loss: 2.6717 - val_acc: 0.0455\n",
      "Epoch 370/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.0113 - acc: 0.2083 - val_loss: 2.6846 - val_acc: 0.1000\n",
      "Epoch 371/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.0345 - acc: 0.1833 - val_loss: 2.6012 - val_acc: 0.1000\n",
      "Epoch 372/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.0527 - acc: 0.1958 - val_loss: 2.5555 - val_acc: 0.0818\n",
      "Epoch 373/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.0273 - acc: 0.2333 - val_loss: 2.6453 - val_acc: 0.0909\n",
      "Epoch 374/1000\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 2.0317 - acc: 0.2000 - val_loss: 2.6194 - val_acc: 0.0909\n",
      "Epoch 375/1000\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 2.0168 - acc: 0.2042 - val_loss: 2.6048 - val_acc: 0.0818\n",
      "Epoch 376/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.0168 - acc: 0.2250 - val_loss: 2.6750 - val_acc: 0.0818\n",
      "Epoch 377/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 1.9981 - acc: 0.2167 - val_loss: 2.7058 - val_acc: 0.0909\n",
      "Epoch 378/1000\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 1.9903 - acc: 0.2292 - val_loss: 2.7277 - val_acc: 0.0727\n",
      "Epoch 379/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 1.9890 - acc: 0.2000 - val_loss: 2.7232 - val_acc: 0.1091\n",
      "Epoch 380/1000\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 1.9871 - acc: 0.2083 - val_loss: 2.7568 - val_acc: 0.0818\n",
      "Epoch 381/1000\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.9854 - acc: 0.2000 - val_loss: 2.7608 - val_acc: 0.0909\n",
      "Epoch 382/1000\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.9879 - acc: 0.2083 - val_loss: 2.7724 - val_acc: 0.1091\n",
      "Epoch 383/1000\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.0710 - acc: 0.1875 - val_loss: 2.6342 - val_acc: 0.0909\n",
      "Epoch 384/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 2.0283 - acc: 0.2083 - val_loss: 2.6280 - val_acc: 0.1000\n",
      "Epoch 385/1000\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 2.0457 - acc: 0.2125 - val_loss: 2.5378 - val_acc: 0.1091\n",
      "Epoch 386/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.0738 - acc: 0.1708 - val_loss: 2.6298 - val_acc: 0.1273\n",
      "Epoch 387/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 2.0190 - acc: 0.2042 - val_loss: 2.6300 - val_acc: 0.1182\n",
      "Epoch 388/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.0131 - acc: 0.2042 - val_loss: 2.7012 - val_acc: 0.1182\n",
      "Epoch 389/1000\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.0092 - acc: 0.2167 - val_loss: 2.7275 - val_acc: 0.0909\n",
      "Epoch 390/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.0043 - acc: 0.2375 - val_loss: 2.7038 - val_acc: 0.1000\n",
      "Epoch 391/1000\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.9961 - acc: 0.2292 - val_loss: 2.6875 - val_acc: 0.1000\n",
      "Epoch 392/1000\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 1.9890 - acc: 0.2250 - val_loss: 2.7019 - val_acc: 0.1273\n",
      "Epoch 393/1000\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 1.9866 - acc: 0.2417 - val_loss: 2.7230 - val_acc: 0.0727\n",
      "Epoch 394/1000\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 1.9858 - acc: 0.2500 - val_loss: 2.7284 - val_acc: 0.0636\n",
      "Epoch 395/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.9830 - acc: 0.2500 - val_loss: 2.7766 - val_acc: 0.0909\n",
      "Epoch 396/1000\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.9944 - acc: 0.2042 - val_loss: 2.6337 - val_acc: 0.1091\n",
      "Epoch 397/1000\n",
      "240/240 [==============================] - 11s 45ms/step - loss: 1.9887 - acc: 0.2083 - val_loss: 2.6543 - val_acc: 0.0727\n",
      "Epoch 398/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.9854 - acc: 0.2000 - val_loss: 2.6931 - val_acc: 0.0909\n",
      "Epoch 399/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.9853 - acc: 0.2083 - val_loss: 2.7086 - val_acc: 0.0727\n",
      "Epoch 400/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 1.9825 - acc: 0.2167 - val_loss: 2.7282 - val_acc: 0.0909\n",
      "Epoch 401/1000\n",
      "240/240 [==============================] - 11s 45ms/step - loss: 1.9828 - acc: 0.2167 - val_loss: 2.7411 - val_acc: 0.0818\n",
      "Epoch 402/1000\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 1.9825 - acc: 0.2208 - val_loss: 2.7555 - val_acc: 0.0727\n",
      "Epoch 403/1000\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 1.9826 - acc: 0.2333 - val_loss: 2.7633 - val_acc: 0.0727\n",
      "Epoch 404/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 1.9822 - acc: 0.2250 - val_loss: 2.7685 - val_acc: 0.0727\n",
      "Epoch 405/1000\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 1.9828 - acc: 0.2042 - val_loss: 2.7712 - val_acc: 0.0909\n",
      "Epoch 406/1000\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 1.9826 - acc: 0.2083 - val_loss: 2.7776 - val_acc: 0.0727\n",
      "Epoch 407/1000\n",
      "240/240 [==============================] - 10s 42ms/step - loss: 1.9830 - acc: 0.2125 - val_loss: 2.7795 - val_acc: 0.0727\n",
      "Epoch 408/1000\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 1.9813 - acc: 0.2208 - val_loss: 2.7918 - val_acc: 0.1000\n",
      "Epoch 409/1000\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 1.9820 - acc: 0.2167 - val_loss: 2.7912 - val_acc: 0.0727\n",
      "Epoch 410/1000\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 1.9815 - acc: 0.2042 - val_loss: 2.8005 - val_acc: 0.1000\n",
      "Epoch 411/1000\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.9819 - acc: 0.2083 - val_loss: 2.8031 - val_acc: 0.1000\n",
      "Epoch 412/1000\n",
      "240/240 [==============================] - 11s 45ms/step - loss: 1.9813 - acc: 0.2042 - val_loss: 2.8078 - val_acc: 0.0818\n",
      "Epoch 413/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 1.9833 - acc: 0.2125 - val_loss: 2.8206 - val_acc: 0.0818\n",
      "Epoch 414/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.9813 - acc: 0.2125 - val_loss: 2.8164 - val_acc: 0.1000\n",
      "Epoch 415/1000\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 1.9809 - acc: 0.2333 - val_loss: 2.8168 - val_acc: 0.1000\n",
      "Epoch 416/1000\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.9811 - acc: 0.2333 - val_loss: 2.8261 - val_acc: 0.0818\n",
      "Epoch 417/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.9813 - acc: 0.2042 - val_loss: 2.8322 - val_acc: 0.0818\n",
      "Epoch 418/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.9821 - acc: 0.2167 - val_loss: 2.8244 - val_acc: 0.1000\n",
      "Epoch 419/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.9804 - acc: 0.2208 - val_loss: 2.8301 - val_acc: 0.0818\n",
      "Epoch 420/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.9814 - acc: 0.2292 - val_loss: 2.8430 - val_acc: 0.0818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.9816 - acc: 0.2250 - val_loss: 2.8379 - val_acc: 0.0818\n",
      "Epoch 422/1000\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 1.9810 - acc: 0.2167 - val_loss: 2.8488 - val_acc: 0.1000\n",
      "Epoch 423/1000\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.9808 - acc: 0.2125 - val_loss: 2.8538 - val_acc: 0.1091\n",
      "Epoch 424/1000\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 1.9809 - acc: 0.2167 - val_loss: 2.8563 - val_acc: 0.0818\n",
      "Epoch 425/1000\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 1.9809 - acc: 0.2125 - val_loss: 2.8721 - val_acc: 0.1182\n",
      "Epoch 426/1000\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.9801 - acc: 0.2250 - val_loss: 2.8701 - val_acc: 0.1091\n",
      "Epoch 427/1000\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.9805 - acc: 0.2292 - val_loss: 2.8600 - val_acc: 0.1000\n",
      "Epoch 428/1000\n",
      "240/240 [==============================] - 10s 42ms/step - loss: 2.0122 - acc: 0.2083 - val_loss: 2.7152 - val_acc: 0.0909\n",
      "Epoch 429/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.0304 - acc: 0.2083 - val_loss: 2.8701 - val_acc: 0.0818\n",
      "Epoch 430/1000\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.0730 - acc: 0.1792 - val_loss: 2.7065 - val_acc: 0.1273\n",
      "Epoch 431/1000\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.0511 - acc: 0.2000 - val_loss: 2.5375 - val_acc: 0.0818\n",
      "Epoch 432/1000\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 2.0526 - acc: 0.1958 - val_loss: 2.7070 - val_acc: 0.0909\n",
      "Epoch 433/1000\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 2.0445 - acc: 0.1833 - val_loss: 2.6867 - val_acc: 0.1182\n",
      "Epoch 434/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.0271 - acc: 0.2250 - val_loss: 2.5960 - val_acc: 0.1182\n",
      "Epoch 435/1000\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 2.0465 - acc: 0.2042 - val_loss: 2.4888 - val_acc: 0.1091\n",
      "Epoch 436/1000\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 2.1353 - acc: 0.1875 - val_loss: 2.3132 - val_acc: 0.1000\n",
      "Epoch 437/1000\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 2.2209 - acc: 0.1250 - val_loss: 2.3635 - val_acc: 0.1000\n",
      "Epoch 438/1000\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 2.1357 - acc: 0.1833 - val_loss: 2.3426 - val_acc: 0.1091\n",
      "Epoch 439/1000\n",
      "240/240 [==============================] - 9s 40ms/step - loss: 2.1149 - acc: 0.1958 - val_loss: 2.3386 - val_acc: 0.1000\n",
      "Epoch 440/1000\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 2.0818 - acc: 0.2000 - val_loss: 2.3334 - val_acc: 0.0909\n",
      "Epoch 441/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.0609 - acc: 0.1833 - val_loss: 2.3314 - val_acc: 0.1000\n",
      "Epoch 442/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.0505 - acc: 0.1958 - val_loss: 2.3334 - val_acc: 0.1000\n",
      "Epoch 443/1000\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 2.0428 - acc: 0.2125 - val_loss: 2.3446 - val_acc: 0.1000\n",
      "Epoch 444/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.0417 - acc: 0.1833 - val_loss: 2.3498 - val_acc: 0.0818\n",
      "Epoch 445/1000\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.0403 - acc: 0.2167 - val_loss: 2.3586 - val_acc: 0.0818\n",
      "Epoch 446/1000\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.0358 - acc: 0.2125 - val_loss: 2.3623 - val_acc: 0.0818\n",
      "Epoch 447/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2403 - acc: 0.1708 - val_loss: 2.3257 - val_acc: 0.0727\n",
      "Epoch 448/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.1880 - acc: 0.1708 - val_loss: 2.3374 - val_acc: 0.0909\n",
      "Epoch 449/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.1878 - acc: 0.1750 - val_loss: 2.3364 - val_acc: 0.1000\n",
      "Epoch 450/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.1624 - acc: 0.1667 - val_loss: 2.3418 - val_acc: 0.1000\n",
      "Epoch 451/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.1535 - acc: 0.1250 - val_loss: 2.3220 - val_acc: 0.1000\n",
      "Epoch 452/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.1569 - acc: 0.1333 - val_loss: 2.3428 - val_acc: 0.0909\n",
      "Epoch 453/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.1355 - acc: 0.1375 - val_loss: 2.3387 - val_acc: 0.0727\n",
      "Epoch 454/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.1302 - acc: 0.1458 - val_loss: 2.3276 - val_acc: 0.1000\n",
      "Epoch 455/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.1393 - acc: 0.1667 - val_loss: 2.3456 - val_acc: 0.1000\n",
      "Epoch 456/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.1342 - acc: 0.1750 - val_loss: 2.3490 - val_acc: 0.1000\n",
      "Epoch 457/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.1185 - acc: 0.1875 - val_loss: 2.3611 - val_acc: 0.1000\n",
      "Epoch 458/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.1186 - acc: 0.1833 - val_loss: 2.3526 - val_acc: 0.1091\n",
      "Epoch 459/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.1155 - acc: 0.1750 - val_loss: 2.3575 - val_acc: 0.0909\n",
      "Epoch 460/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.1134 - acc: 0.1833 - val_loss: 2.3661 - val_acc: 0.0909\n",
      "Epoch 461/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.1126 - acc: 0.1833 - val_loss: 2.3126 - val_acc: 0.1273\n",
      "Epoch 462/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.1130 - acc: 0.1458 - val_loss: 2.3380 - val_acc: 0.0909\n",
      "Epoch 463/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.1068 - acc: 0.1917 - val_loss: 2.3594 - val_acc: 0.1273\n",
      "Epoch 464/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.1090 - acc: 0.1917 - val_loss: 2.3391 - val_acc: 0.1182\n",
      "Epoch 465/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.0909 - acc: 0.1875 - val_loss: 2.3223 - val_acc: 0.1273\n",
      "Epoch 466/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.0844 - acc: 0.1792 - val_loss: 2.3036 - val_acc: 0.0818\n",
      "Epoch 467/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.1306 - acc: 0.1875 - val_loss: 2.3603 - val_acc: 0.1182\n",
      "Epoch 468/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.1057 - acc: 0.1792 - val_loss: 2.3557 - val_acc: 0.1182\n",
      "Epoch 469/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.0921 - acc: 0.1792 - val_loss: 2.3175 - val_acc: 0.1273\n",
      "Epoch 470/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.0751 - acc: 0.1667 - val_loss: 2.3344 - val_acc: 0.0818\n",
      "Epoch 471/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.1604 - acc: 0.1458 - val_loss: 2.3067 - val_acc: 0.0636\n",
      "Epoch 472/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.1330 - acc: 0.1542 - val_loss: 2.3006 - val_acc: 0.1091\n",
      "Epoch 473/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.1327 - acc: 0.1833 - val_loss: 2.3063 - val_acc: 0.1000\n",
      "Epoch 474/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.1271 - acc: 0.1833 - val_loss: 2.3058 - val_acc: 0.1000\n",
      "Epoch 475/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.1264 - acc: 0.1375 - val_loss: 2.3037 - val_acc: 0.1182\n",
      "Epoch 476/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.1230 - acc: 0.1875 - val_loss: 2.3081 - val_acc: 0.0909\n",
      "Epoch 477/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.1214 - acc: 0.1917 - val_loss: 2.3079 - val_acc: 0.1182\n",
      "Epoch 478/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.1287 - acc: 0.1792 - val_loss: 2.3098 - val_acc: 0.1091\n",
      "Epoch 479/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.1252 - acc: 0.1667 - val_loss: 2.2895 - val_acc: 0.1091\n",
      "Epoch 480/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.1544 - acc: 0.1875 - val_loss: 2.2986 - val_acc: 0.1182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.1188 - acc: 0.1458 - val_loss: 2.2970 - val_acc: 0.1455\n",
      "Epoch 482/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.1166 - acc: 0.2000 - val_loss: 2.3109 - val_acc: 0.0909\n",
      "Epoch 483/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.1290 - acc: 0.1833 - val_loss: 2.2996 - val_acc: 0.1091\n",
      "Epoch 484/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.1129 - acc: 0.1875 - val_loss: 2.2913 - val_acc: 0.1091\n",
      "Epoch 485/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.1263 - acc: 0.1875 - val_loss: 2.2991 - val_acc: 0.0818\n",
      "Epoch 486/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.0912 - acc: 0.1792 - val_loss: 2.2851 - val_acc: 0.1000\n",
      "Epoch 487/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.0919 - acc: 0.1875 - val_loss: 2.2903 - val_acc: 0.1364\n",
      "Epoch 488/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.0808 - acc: 0.1917 - val_loss: 2.2847 - val_acc: 0.1091\n",
      "Epoch 489/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.0811 - acc: 0.1875 - val_loss: 2.3001 - val_acc: 0.1091\n",
      "Epoch 490/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.0700 - acc: 0.2083 - val_loss: 2.3031 - val_acc: 0.0909\n",
      "Epoch 491/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.0938 - acc: 0.2125 - val_loss: 2.2811 - val_acc: 0.1182\n",
      "Epoch 492/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.0722 - acc: 0.2042 - val_loss: 2.2744 - val_acc: 0.1364\n",
      "Epoch 493/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.0689 - acc: 0.2083 - val_loss: 2.2718 - val_acc: 0.1636\n",
      "Epoch 494/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.0397 - acc: 0.2375 - val_loss: 2.2412 - val_acc: 0.1727\n",
      "Epoch 495/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.0197 - acc: 0.2417 - val_loss: 2.2045 - val_acc: 0.2000\n",
      "Epoch 496/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.9605 - acc: 0.2500 - val_loss: 2.2242 - val_acc: 0.1727\n",
      "Epoch 497/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.9326 - acc: 0.2500 - val_loss: 2.1932 - val_acc: 0.1818\n",
      "Epoch 498/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.9074 - acc: 0.2833 - val_loss: 2.1985 - val_acc: 0.1909\n",
      "Epoch 499/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.9231 - acc: 0.2542 - val_loss: 2.3898 - val_acc: 0.1636\n",
      "Epoch 500/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.0155 - acc: 0.2250 - val_loss: 2.2665 - val_acc: 0.1545\n",
      "Epoch 501/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.9448 - acc: 0.2500 - val_loss: 2.2414 - val_acc: 0.1909\n",
      "Epoch 502/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.8679 - acc: 0.2083 - val_loss: 2.2818 - val_acc: 0.2000\n",
      "Epoch 503/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.8616 - acc: 0.2292 - val_loss: 2.2764 - val_acc: 0.1909\n",
      "Epoch 504/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.7771 - acc: 0.2667 - val_loss: 2.2198 - val_acc: 0.1636\n",
      "Epoch 505/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7317 - acc: 0.2583 - val_loss: 2.2256 - val_acc: 0.2091\n",
      "Epoch 506/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.7923 - acc: 0.2792 - val_loss: 2.1138 - val_acc: 0.2000\n",
      "Epoch 507/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7242 - acc: 0.2708 - val_loss: 2.1417 - val_acc: 0.1909\n",
      "Epoch 508/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6635 - acc: 0.3208 - val_loss: 2.1807 - val_acc: 0.2000\n",
      "Epoch 509/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6517 - acc: 0.2917 - val_loss: 2.2256 - val_acc: 0.1909\n",
      "Epoch 510/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6817 - acc: 0.2917 - val_loss: 2.3287 - val_acc: 0.1636\n",
      "Epoch 511/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7324 - acc: 0.2250 - val_loss: 2.2408 - val_acc: 0.1818\n",
      "Epoch 512/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6920 - acc: 0.2958 - val_loss: 2.3187 - val_acc: 0.1545\n",
      "Epoch 513/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6837 - acc: 0.2792 - val_loss: 2.1654 - val_acc: 0.1636\n",
      "Epoch 514/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.6990 - acc: 0.2875 - val_loss: 2.1587 - val_acc: 0.1727\n",
      "Epoch 515/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.7811 - acc: 0.2833 - val_loss: 2.2300 - val_acc: 0.1909\n",
      "Epoch 516/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7464 - acc: 0.2583 - val_loss: 2.1755 - val_acc: 0.1818\n",
      "Epoch 517/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.7849 - acc: 0.2708 - val_loss: 2.2569 - val_acc: 0.1455\n",
      "Epoch 518/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.8050 - acc: 0.2792 - val_loss: 2.1900 - val_acc: 0.1636\n",
      "Epoch 519/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.8882 - acc: 0.2333 - val_loss: 2.1764 - val_acc: 0.1273\n",
      "Epoch 520/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.8199 - acc: 0.2542 - val_loss: 2.1685 - val_acc: 0.1636\n",
      "Epoch 521/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.8540 - acc: 0.2292 - val_loss: 2.1434 - val_acc: 0.1636\n",
      "Epoch 522/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.8155 - acc: 0.2083 - val_loss: 2.1265 - val_acc: 0.2091\n",
      "Epoch 523/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7329 - acc: 0.2667 - val_loss: 2.1370 - val_acc: 0.1364\n",
      "Epoch 524/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.7059 - acc: 0.2833 - val_loss: 2.1007 - val_acc: 0.1909\n",
      "Epoch 525/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6833 - acc: 0.2583 - val_loss: 2.0946 - val_acc: 0.2364\n",
      "Epoch 526/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6545 - acc: 0.2833 - val_loss: 2.1020 - val_acc: 0.2000\n",
      "Epoch 527/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6540 - acc: 0.2708 - val_loss: 2.1224 - val_acc: 0.1818\n",
      "Epoch 528/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6915 - acc: 0.2625 - val_loss: 2.1217 - val_acc: 0.1909\n",
      "Epoch 529/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6764 - acc: 0.2375 - val_loss: 2.1735 - val_acc: 0.1364\n",
      "Epoch 530/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.6670 - acc: 0.2417 - val_loss: 2.2618 - val_acc: 0.1636\n",
      "Epoch 531/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6604 - acc: 0.2583 - val_loss: 2.1482 - val_acc: 0.2091\n",
      "Epoch 532/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6502 - acc: 0.2583 - val_loss: 2.1343 - val_acc: 0.2000\n",
      "Epoch 533/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6395 - acc: 0.2917 - val_loss: 2.1355 - val_acc: 0.1909\n",
      "Epoch 534/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6439 - acc: 0.2792 - val_loss: 2.1926 - val_acc: 0.2091\n",
      "Epoch 535/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6254 - acc: 0.3208 - val_loss: 2.2019 - val_acc: 0.2182\n",
      "Epoch 536/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6311 - acc: 0.2958 - val_loss: 2.3115 - val_acc: 0.1545\n",
      "Epoch 537/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6529 - acc: 0.2917 - val_loss: 2.2583 - val_acc: 0.1818\n",
      "Epoch 538/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6256 - acc: 0.3042 - val_loss: 2.2242 - val_acc: 0.1818\n",
      "Epoch 539/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6445 - acc: 0.2917 - val_loss: 2.2641 - val_acc: 0.1364\n",
      "Epoch 540/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6266 - acc: 0.2917 - val_loss: 2.2804 - val_acc: 0.2273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6275 - acc: 0.3083 - val_loss: 2.1739 - val_acc: 0.1818\n",
      "Epoch 542/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6063 - acc: 0.2875 - val_loss: 2.1657 - val_acc: 0.2000\n",
      "Epoch 543/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6559 - acc: 0.2917 - val_loss: 2.1670 - val_acc: 0.1364\n",
      "Epoch 544/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6471 - acc: 0.2750 - val_loss: 2.1461 - val_acc: 0.1727\n",
      "Epoch 545/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6211 - acc: 0.2875 - val_loss: 2.1493 - val_acc: 0.1636\n",
      "Epoch 546/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6064 - acc: 0.3125 - val_loss: 2.1476 - val_acc: 0.1909\n",
      "Epoch 547/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6206 - acc: 0.3083 - val_loss: 2.1473 - val_acc: 0.1818\n",
      "Epoch 548/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.5975 - acc: 0.3208 - val_loss: 2.1158 - val_acc: 0.2091\n",
      "Epoch 549/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5847 - acc: 0.3542 - val_loss: 2.1527 - val_acc: 0.2182\n",
      "Epoch 550/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6036 - acc: 0.3000 - val_loss: 2.2587 - val_acc: 0.1818\n",
      "Epoch 551/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.7690 - acc: 0.2667 - val_loss: 2.2027 - val_acc: 0.1636\n",
      "Epoch 552/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.9405 - acc: 0.2125 - val_loss: 2.1644 - val_acc: 0.1909\n",
      "Epoch 553/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.8548 - acc: 0.2417 - val_loss: 2.2084 - val_acc: 0.1727\n",
      "Epoch 554/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.8233 - acc: 0.2500 - val_loss: 2.1120 - val_acc: 0.1364\n",
      "Epoch 555/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7575 - acc: 0.2375 - val_loss: 2.1308 - val_acc: 0.2091\n",
      "Epoch 556/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.7760 - acc: 0.2833 - val_loss: 2.1240 - val_acc: 0.1818\n",
      "Epoch 557/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.7919 - acc: 0.2625 - val_loss: 2.1903 - val_acc: 0.1909\n",
      "Epoch 558/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7380 - acc: 0.2458 - val_loss: 2.1691 - val_acc: 0.1818\n",
      "Epoch 559/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.7071 - acc: 0.2542 - val_loss: 2.2045 - val_acc: 0.1818\n",
      "Epoch 560/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.8780 - acc: 0.2333 - val_loss: 2.2845 - val_acc: 0.1818\n",
      "Epoch 561/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.8633 - acc: 0.2708 - val_loss: 2.0768 - val_acc: 0.1818\n",
      "Epoch 562/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.7306 - acc: 0.2417 - val_loss: 2.0859 - val_acc: 0.2000\n",
      "Epoch 563/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7068 - acc: 0.2833 - val_loss: 2.0972 - val_acc: 0.2091\n",
      "Epoch 564/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6774 - acc: 0.2792 - val_loss: 2.0894 - val_acc: 0.2273\n",
      "Epoch 565/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7137 - acc: 0.2875 - val_loss: 2.0996 - val_acc: 0.1909\n",
      "Epoch 566/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.7638 - acc: 0.2542 - val_loss: 2.2238 - val_acc: 0.1636\n",
      "Epoch 567/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6923 - acc: 0.2583 - val_loss: 2.2285 - val_acc: 0.1909\n",
      "Epoch 568/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6607 - acc: 0.3042 - val_loss: 2.1695 - val_acc: 0.1909\n",
      "Epoch 569/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6469 - acc: 0.3042 - val_loss: 2.2023 - val_acc: 0.1727\n",
      "Epoch 570/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6426 - acc: 0.3167 - val_loss: 2.1979 - val_acc: 0.2091\n",
      "Epoch 571/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6421 - acc: 0.2917 - val_loss: 2.3146 - val_acc: 0.2000\n",
      "Epoch 572/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6495 - acc: 0.2792 - val_loss: 2.3532 - val_acc: 0.1818\n",
      "Epoch 573/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6408 - acc: 0.2875 - val_loss: 2.2804 - val_acc: 0.2091\n",
      "Epoch 574/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6283 - acc: 0.3125 - val_loss: 2.2286 - val_acc: 0.2182\n",
      "Epoch 575/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6411 - acc: 0.3167 - val_loss: 2.3220 - val_acc: 0.1727\n",
      "Epoch 576/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6311 - acc: 0.2833 - val_loss: 2.2301 - val_acc: 0.2091\n",
      "Epoch 577/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6222 - acc: 0.3125 - val_loss: 2.2755 - val_acc: 0.1909\n",
      "Epoch 578/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6674 - acc: 0.3042 - val_loss: 2.2229 - val_acc: 0.2273\n",
      "Epoch 579/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6493 - acc: 0.3167 - val_loss: 2.2266 - val_acc: 0.2000\n",
      "Epoch 580/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6332 - acc: 0.3250 - val_loss: 2.2406 - val_acc: 0.2000\n",
      "Epoch 581/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6332 - acc: 0.3292 - val_loss: 2.2115 - val_acc: 0.1909\n",
      "Epoch 582/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6374 - acc: 0.2875 - val_loss: 2.3107 - val_acc: 0.2000\n",
      "Epoch 583/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6270 - acc: 0.3083 - val_loss: 2.1979 - val_acc: 0.2182\n",
      "Epoch 584/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6300 - acc: 0.2792 - val_loss: 2.2592 - val_acc: 0.1818\n",
      "Epoch 585/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6477 - acc: 0.2958 - val_loss: 2.3130 - val_acc: 0.1909\n",
      "Epoch 586/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.6333 - acc: 0.3167 - val_loss: 2.2836 - val_acc: 0.2000\n",
      "Epoch 587/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6190 - acc: 0.3167 - val_loss: 2.2855 - val_acc: 0.1636\n",
      "Epoch 588/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6574 - acc: 0.3000 - val_loss: 2.2908 - val_acc: 0.2182\n",
      "Epoch 589/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6478 - acc: 0.2833 - val_loss: 2.3300 - val_acc: 0.1636\n",
      "Epoch 590/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6378 - acc: 0.3000 - val_loss: 2.3402 - val_acc: 0.1818\n",
      "Epoch 591/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6264 - acc: 0.3208 - val_loss: 2.3249 - val_acc: 0.1636\n",
      "Epoch 592/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6253 - acc: 0.3250 - val_loss: 2.3658 - val_acc: 0.1909\n",
      "Epoch 593/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6237 - acc: 0.3042 - val_loss: 2.3639 - val_acc: 0.1727\n",
      "Epoch 594/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6203 - acc: 0.3000 - val_loss: 2.3303 - val_acc: 0.1909\n",
      "Epoch 595/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6129 - acc: 0.2958 - val_loss: 2.4116 - val_acc: 0.2000\n",
      "Epoch 596/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6497 - acc: 0.3125 - val_loss: 2.3770 - val_acc: 0.1727\n",
      "Epoch 597/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7742 - acc: 0.2375 - val_loss: 2.2393 - val_acc: 0.1727\n",
      "Epoch 598/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.7730 - acc: 0.2708 - val_loss: 2.2728 - val_acc: 0.1364\n",
      "Epoch 599/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7552 - acc: 0.2250 - val_loss: 2.1421 - val_acc: 0.1727\n",
      "Epoch 600/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7245 - acc: 0.2750 - val_loss: 2.2109 - val_acc: 0.1818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6831 - acc: 0.2792 - val_loss: 2.2143 - val_acc: 0.1909\n",
      "Epoch 602/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6640 - acc: 0.3125 - val_loss: 2.1808 - val_acc: 0.2273\n",
      "Epoch 603/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6948 - acc: 0.2750 - val_loss: 2.2980 - val_acc: 0.2273\n",
      "Epoch 604/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.7413 - acc: 0.2792 - val_loss: 2.2058 - val_acc: 0.1545\n",
      "Epoch 605/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6728 - acc: 0.2875 - val_loss: 2.2148 - val_acc: 0.2000\n",
      "Epoch 606/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6529 - acc: 0.3125 - val_loss: 2.3070 - val_acc: 0.1818\n",
      "Epoch 607/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.6474 - acc: 0.3083 - val_loss: 2.2411 - val_acc: 0.2091\n",
      "Epoch 608/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6225 - acc: 0.3250 - val_loss: 2.2722 - val_acc: 0.2273\n",
      "Epoch 609/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5911 - acc: 0.3333 - val_loss: 2.2945 - val_acc: 0.1636\n",
      "Epoch 610/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.6265 - acc: 0.3542 - val_loss: 2.2623 - val_acc: 0.1909\n",
      "Epoch 611/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5937 - acc: 0.3667 - val_loss: 2.1881 - val_acc: 0.2091\n",
      "Epoch 612/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5454 - acc: 0.3625 - val_loss: 2.2163 - val_acc: 0.1909\n",
      "Epoch 613/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5109 - acc: 0.3792 - val_loss: 2.2173 - val_acc: 0.2455\n",
      "Epoch 614/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.5147 - acc: 0.3667 - val_loss: 2.2001 - val_acc: 0.2000\n",
      "Epoch 615/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5424 - acc: 0.3708 - val_loss: 2.2745 - val_acc: 0.1455\n",
      "Epoch 616/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5597 - acc: 0.3750 - val_loss: 2.3098 - val_acc: 0.2000\n",
      "Epoch 617/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.5235 - acc: 0.3833 - val_loss: 2.3109 - val_acc: 0.2091\n",
      "Epoch 618/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.5156 - acc: 0.3750 - val_loss: 2.2832 - val_acc: 0.2182\n",
      "Epoch 619/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4953 - acc: 0.4125 - val_loss: 2.2968 - val_acc: 0.2182\n",
      "Epoch 620/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.8468 - acc: 0.4333 - val_loss: 2.5906 - val_acc: 0.1909\n",
      "Epoch 621/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.9245 - acc: 0.3042 - val_loss: 2.1975 - val_acc: 0.2091\n",
      "Epoch 622/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7065 - acc: 0.3042 - val_loss: 2.1708 - val_acc: 0.2000\n",
      "Epoch 623/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7785 - acc: 0.3167 - val_loss: 2.8746 - val_acc: 0.1727\n",
      "Epoch 624/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.9995 - acc: 0.2583 - val_loss: 2.2504 - val_acc: 0.1455\n",
      "Epoch 625/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.8804 - acc: 0.2625 - val_loss: 2.0948 - val_acc: 0.1818\n",
      "Epoch 626/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.8847 - acc: 0.2542 - val_loss: 2.1178 - val_acc: 0.1818\n",
      "Epoch 627/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.7787 - acc: 0.2708 - val_loss: 2.0129 - val_acc: 0.2000\n",
      "Epoch 628/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.7070 - acc: 0.3167 - val_loss: 2.1325 - val_acc: 0.1818\n",
      "Epoch 629/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6435 - acc: 0.3333 - val_loss: 2.0132 - val_acc: 0.2091\n",
      "Epoch 630/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6464 - acc: 0.3375 - val_loss: 2.2385 - val_acc: 0.1818\n",
      "Epoch 631/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6585 - acc: 0.3208 - val_loss: 2.0639 - val_acc: 0.2273\n",
      "Epoch 632/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.6186 - acc: 0.3250 - val_loss: 2.0462 - val_acc: 0.2000\n",
      "Epoch 633/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.5805 - acc: 0.3583 - val_loss: 2.1090 - val_acc: 0.1909\n",
      "Epoch 634/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6489 - acc: 0.3500 - val_loss: 2.1542 - val_acc: 0.2182\n",
      "Epoch 635/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6942 - acc: 0.2708 - val_loss: 2.1607 - val_acc: 0.1727\n",
      "Epoch 636/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7167 - acc: 0.3000 - val_loss: 2.1161 - val_acc: 0.2364\n",
      "Epoch 637/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6098 - acc: 0.3500 - val_loss: 2.0908 - val_acc: 0.1909\n",
      "Epoch 638/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6643 - acc: 0.3500 - val_loss: 2.0127 - val_acc: 0.2364\n",
      "Epoch 639/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6264 - acc: 0.3417 - val_loss: 2.0412 - val_acc: 0.2273\n",
      "Epoch 640/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5588 - acc: 0.3833 - val_loss: 2.0588 - val_acc: 0.2273\n",
      "Epoch 641/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5436 - acc: 0.3708 - val_loss: 2.0738 - val_acc: 0.2273\n",
      "Epoch 642/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5176 - acc: 0.4083 - val_loss: 2.1742 - val_acc: 0.2091\n",
      "Epoch 643/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.5077 - acc: 0.3708 - val_loss: 2.0740 - val_acc: 0.2000\n",
      "Epoch 644/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4786 - acc: 0.3833 - val_loss: 2.0400 - val_acc: 0.2273\n",
      "Epoch 645/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4794 - acc: 0.3708 - val_loss: 2.0530 - val_acc: 0.2182\n",
      "Epoch 646/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5526 - acc: 0.3833 - val_loss: 2.1165 - val_acc: 0.2091\n",
      "Epoch 647/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.5263 - acc: 0.3375 - val_loss: 2.0800 - val_acc: 0.1909\n",
      "Epoch 648/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5001 - acc: 0.3333 - val_loss: 2.0473 - val_acc: 0.2273\n",
      "Epoch 649/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5545 - acc: 0.3583 - val_loss: 2.0169 - val_acc: 0.2545\n",
      "Epoch 650/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.5123 - acc: 0.3417 - val_loss: 1.9990 - val_acc: 0.2545\n",
      "Epoch 651/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4545 - acc: 0.3875 - val_loss: 1.9807 - val_acc: 0.2545\n",
      "Epoch 652/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4224 - acc: 0.4167 - val_loss: 1.9989 - val_acc: 0.2545\n",
      "Epoch 653/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4440 - acc: 0.4250 - val_loss: 2.0692 - val_acc: 0.2273\n",
      "Epoch 654/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3973 - acc: 0.3958 - val_loss: 2.0591 - val_acc: 0.2182\n",
      "Epoch 655/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4031 - acc: 0.4208 - val_loss: 2.0488 - val_acc: 0.2455\n",
      "Epoch 656/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4424 - acc: 0.4083 - val_loss: 2.2654 - val_acc: 0.2273\n",
      "Epoch 657/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.4400 - acc: 0.4250 - val_loss: 2.1029 - val_acc: 0.2455\n",
      "Epoch 658/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.4417 - acc: 0.4250 - val_loss: 2.1576 - val_acc: 0.2182\n",
      "Epoch 659/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3971 - acc: 0.4458 - val_loss: 2.1792 - val_acc: 0.2273\n",
      "Epoch 660/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3713 - acc: 0.4167 - val_loss: 2.3679 - val_acc: 0.2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 661/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3719 - acc: 0.4375 - val_loss: 2.1148 - val_acc: 0.2000\n",
      "Epoch 662/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3643 - acc: 0.4250 - val_loss: 2.3375 - val_acc: 0.2091\n",
      "Epoch 663/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3754 - acc: 0.4292 - val_loss: 2.2545 - val_acc: 0.2364\n",
      "Epoch 664/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3569 - acc: 0.4458 - val_loss: 2.7266 - val_acc: 0.2000\n",
      "Epoch 665/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.5915 - acc: 0.3750 - val_loss: 2.2844 - val_acc: 0.2818\n",
      "Epoch 666/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.5925 - acc: 0.4208 - val_loss: 2.1420 - val_acc: 0.2545\n",
      "Epoch 667/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4709 - acc: 0.4167 - val_loss: 2.0404 - val_acc: 0.2455\n",
      "Epoch 668/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4479 - acc: 0.4500 - val_loss: 2.0677 - val_acc: 0.2455\n",
      "Epoch 669/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4362 - acc: 0.4042 - val_loss: 1.9726 - val_acc: 0.2545\n",
      "Epoch 670/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4151 - acc: 0.4500 - val_loss: 2.0674 - val_acc: 0.2909\n",
      "Epoch 671/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4094 - acc: 0.4458 - val_loss: 2.2385 - val_acc: 0.2636\n",
      "Epoch 672/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3597 - acc: 0.4667 - val_loss: 2.1718 - val_acc: 0.2909\n",
      "Epoch 673/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3832 - acc: 0.4792 - val_loss: 2.1748 - val_acc: 0.2818\n",
      "Epoch 674/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3903 - acc: 0.4542 - val_loss: 2.0777 - val_acc: 0.2545\n",
      "Epoch 675/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3558 - acc: 0.4833 - val_loss: 2.0566 - val_acc: 0.2455\n",
      "Epoch 676/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3287 - acc: 0.4792 - val_loss: 2.2203 - val_acc: 0.2364\n",
      "Epoch 677/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3028 - acc: 0.4875 - val_loss: 2.2015 - val_acc: 0.2545\n",
      "Epoch 678/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2940 - acc: 0.4875 - val_loss: 2.2279 - val_acc: 0.2636\n",
      "Epoch 679/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2802 - acc: 0.4875 - val_loss: 2.2637 - val_acc: 0.2455\n",
      "Epoch 680/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2874 - acc: 0.4917 - val_loss: 2.2417 - val_acc: 0.2455\n",
      "Epoch 681/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2765 - acc: 0.4792 - val_loss: 2.2603 - val_acc: 0.2636\n",
      "Epoch 682/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2631 - acc: 0.4917 - val_loss: 2.3257 - val_acc: 0.2545\n",
      "Epoch 683/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2650 - acc: 0.4792 - val_loss: 2.2613 - val_acc: 0.2636\n",
      "Epoch 684/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2592 - acc: 0.5042 - val_loss: 2.2907 - val_acc: 0.2636\n",
      "Epoch 685/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2563 - acc: 0.5083 - val_loss: 2.3830 - val_acc: 0.2545\n",
      "Epoch 686/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2512 - acc: 0.5083 - val_loss: 2.4189 - val_acc: 0.2455\n",
      "Epoch 687/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2575 - acc: 0.4958 - val_loss: 2.1797 - val_acc: 0.2636\n",
      "Epoch 688/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2688 - acc: 0.4875 - val_loss: 2.2945 - val_acc: 0.2818\n",
      "Epoch 689/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3119 - acc: 0.4792 - val_loss: 2.4013 - val_acc: 0.2909\n",
      "Epoch 690/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.4469 - acc: 0.4458 - val_loss: 2.2089 - val_acc: 0.2364\n",
      "Epoch 691/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4805 - acc: 0.4125 - val_loss: 2.5240 - val_acc: 0.2818\n",
      "Epoch 692/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4624 - acc: 0.4292 - val_loss: 2.2757 - val_acc: 0.2455\n",
      "Epoch 693/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5249 - acc: 0.4083 - val_loss: 2.3042 - val_acc: 0.2364\n",
      "Epoch 694/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5624 - acc: 0.3792 - val_loss: 2.2673 - val_acc: 0.2182\n",
      "Epoch 695/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4922 - acc: 0.4167 - val_loss: 2.2409 - val_acc: 0.2364\n",
      "Epoch 696/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.5144 - acc: 0.4458 - val_loss: 2.2299 - val_acc: 0.2364\n",
      "Epoch 697/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6497 - acc: 0.3792 - val_loss: 2.2314 - val_acc: 0.2545\n",
      "Epoch 698/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.7032 - acc: 0.3708 - val_loss: 2.1220 - val_acc: 0.1818\n",
      "Epoch 699/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6739 - acc: 0.3792 - val_loss: 2.1804 - val_acc: 0.2455\n",
      "Epoch 700/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.5987 - acc: 0.3875 - val_loss: 2.0865 - val_acc: 0.2727\n",
      "Epoch 701/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5889 - acc: 0.4292 - val_loss: 2.0363 - val_acc: 0.3182\n",
      "Epoch 702/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5080 - acc: 0.4417 - val_loss: 2.2468 - val_acc: 0.2727\n",
      "Epoch 703/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4762 - acc: 0.4542 - val_loss: 2.1664 - val_acc: 0.2545\n",
      "Epoch 704/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4636 - acc: 0.4542 - val_loss: 2.2909 - val_acc: 0.2273\n",
      "Epoch 705/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4523 - acc: 0.4583 - val_loss: 2.2448 - val_acc: 0.2545\n",
      "Epoch 706/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4522 - acc: 0.4625 - val_loss: 2.2206 - val_acc: 0.2818\n",
      "Epoch 707/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4299 - acc: 0.4667 - val_loss: 2.1747 - val_acc: 0.2455\n",
      "Epoch 708/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4078 - acc: 0.4708 - val_loss: 2.0383 - val_acc: 0.2545\n",
      "Epoch 709/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4165 - acc: 0.4667 - val_loss: 2.1267 - val_acc: 0.2364\n",
      "Epoch 710/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3757 - acc: 0.4708 - val_loss: 2.0660 - val_acc: 0.2545\n",
      "Epoch 711/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3543 - acc: 0.4833 - val_loss: 2.0587 - val_acc: 0.2909\n",
      "Epoch 712/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3366 - acc: 0.5042 - val_loss: 2.0622 - val_acc: 0.2636\n",
      "Epoch 713/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3056 - acc: 0.5167 - val_loss: 2.0684 - val_acc: 0.2545\n",
      "Epoch 714/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3044 - acc: 0.5083 - val_loss: 2.1168 - val_acc: 0.2455\n",
      "Epoch 715/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3184 - acc: 0.5125 - val_loss: 2.0974 - val_acc: 0.2455\n",
      "Epoch 716/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2789 - acc: 0.5250 - val_loss: 2.1587 - val_acc: 0.2364\n",
      "Epoch 717/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2928 - acc: 0.5333 - val_loss: 2.3020 - val_acc: 0.2091\n",
      "Epoch 718/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2595 - acc: 0.5042 - val_loss: 2.2581 - val_acc: 0.2455\n",
      "Epoch 719/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3230 - acc: 0.5083 - val_loss: 2.1962 - val_acc: 0.2364\n",
      "Epoch 720/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3971 - acc: 0.4833 - val_loss: 2.3066 - val_acc: 0.2364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4095 - acc: 0.4750 - val_loss: 2.2498 - val_acc: 0.2455\n",
      "Epoch 722/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3092 - acc: 0.5000 - val_loss: 2.2597 - val_acc: 0.2636\n",
      "Epoch 723/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3074 - acc: 0.4917 - val_loss: 2.2692 - val_acc: 0.2545\n",
      "Epoch 724/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3484 - acc: 0.4917 - val_loss: 2.3874 - val_acc: 0.2182\n",
      "Epoch 725/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2840 - acc: 0.5042 - val_loss: 2.3616 - val_acc: 0.2455\n",
      "Epoch 726/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2791 - acc: 0.5083 - val_loss: 2.2303 - val_acc: 0.2818\n",
      "Epoch 727/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2581 - acc: 0.4958 - val_loss: 2.4251 - val_acc: 0.2273\n",
      "Epoch 728/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2478 - acc: 0.5042 - val_loss: 2.3723 - val_acc: 0.2364\n",
      "Epoch 729/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2475 - acc: 0.5167 - val_loss: 2.4231 - val_acc: 0.2545\n",
      "Epoch 730/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2625 - acc: 0.5292 - val_loss: 2.2946 - val_acc: 0.2545\n",
      "Epoch 731/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3775 - acc: 0.4917 - val_loss: 2.1399 - val_acc: 0.2545\n",
      "Epoch 732/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3720 - acc: 0.4750 - val_loss: 2.4954 - val_acc: 0.2818\n",
      "Epoch 733/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3237 - acc: 0.5083 - val_loss: 2.3631 - val_acc: 0.2182\n",
      "Epoch 734/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2921 - acc: 0.5208 - val_loss: 2.5147 - val_acc: 0.2182\n",
      "Epoch 735/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2668 - acc: 0.5292 - val_loss: 2.4419 - val_acc: 0.2182\n",
      "Epoch 736/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2313 - acc: 0.5208 - val_loss: 2.4430 - val_acc: 0.2545\n",
      "Epoch 737/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2264 - acc: 0.5250 - val_loss: 2.5738 - val_acc: 0.2727\n",
      "Epoch 738/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3195 - acc: 0.4833 - val_loss: 2.5812 - val_acc: 0.2364\n",
      "Epoch 739/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4636 - acc: 0.4542 - val_loss: 2.5094 - val_acc: 0.2455\n",
      "Epoch 740/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3986 - acc: 0.4500 - val_loss: 2.2997 - val_acc: 0.2727\n",
      "Epoch 741/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3347 - acc: 0.4750 - val_loss: 2.4436 - val_acc: 0.2364\n",
      "Epoch 742/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2953 - acc: 0.4333 - val_loss: 2.4933 - val_acc: 0.2273\n",
      "Epoch 743/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2615 - acc: 0.5333 - val_loss: 2.5352 - val_acc: 0.2727\n",
      "Epoch 744/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2457 - acc: 0.5125 - val_loss: 2.5043 - val_acc: 0.2636\n",
      "Epoch 745/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2259 - acc: 0.5333 - val_loss: 2.5334 - val_acc: 0.2364\n",
      "Epoch 746/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2101 - acc: 0.5417 - val_loss: 2.5783 - val_acc: 0.2636\n",
      "Epoch 747/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2149 - acc: 0.5500 - val_loss: 2.6913 - val_acc: 0.2727\n",
      "Epoch 748/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2362 - acc: 0.5292 - val_loss: 2.6539 - val_acc: 0.2455\n",
      "Epoch 749/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2154 - acc: 0.5500 - val_loss: 2.5845 - val_acc: 0.2364\n",
      "Epoch 750/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.2156 - acc: 0.5458 - val_loss: 2.6027 - val_acc: 0.2273\n",
      "Epoch 751/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2191 - acc: 0.5417 - val_loss: 2.6183 - val_acc: 0.2364\n",
      "Epoch 752/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2501 - acc: 0.5333 - val_loss: 2.6432 - val_acc: 0.2818\n",
      "Epoch 753/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2928 - acc: 0.5250 - val_loss: 2.4927 - val_acc: 0.2364\n",
      "Epoch 754/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2406 - acc: 0.5417 - val_loss: 2.6982 - val_acc: 0.2455\n",
      "Epoch 755/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.5448 - acc: 0.4625 - val_loss: 2.6015 - val_acc: 0.2818\n",
      "Epoch 756/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3513 - acc: 0.4792 - val_loss: 2.5176 - val_acc: 0.2636\n",
      "Epoch 757/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2788 - acc: 0.5208 - val_loss: 2.5564 - val_acc: 0.2545\n",
      "Epoch 758/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3284 - acc: 0.5000 - val_loss: 2.6077 - val_acc: 0.2182\n",
      "Epoch 759/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2901 - acc: 0.5208 - val_loss: 2.7214 - val_acc: 0.2364\n",
      "Epoch 760/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2277 - acc: 0.5542 - val_loss: 2.7704 - val_acc: 0.2182\n",
      "Epoch 761/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2684 - acc: 0.5333 - val_loss: 2.6354 - val_acc: 0.2364\n",
      "Epoch 762/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2335 - acc: 0.5250 - val_loss: 2.7107 - val_acc: 0.2000\n",
      "Epoch 763/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3125 - acc: 0.5125 - val_loss: 2.4708 - val_acc: 0.2182\n",
      "Epoch 764/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.8214 - acc: 0.4458 - val_loss: 3.7633 - val_acc: 0.1545\n",
      "Epoch 765/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.9329 - acc: 0.1333 - val_loss: 2.5801 - val_acc: 0.1000\n",
      "Epoch 766/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3975 - acc: 0.1042 - val_loss: 2.3866 - val_acc: 0.1091\n",
      "Epoch 767/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2913 - acc: 0.1208 - val_loss: 2.4690 - val_acc: 0.0818\n",
      "Epoch 768/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2751 - acc: 0.1250 - val_loss: 2.3852 - val_acc: 0.1182\n",
      "Epoch 769/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2382 - acc: 0.1208 - val_loss: 2.4025 - val_acc: 0.1273\n",
      "Epoch 770/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.4070 - acc: 0.1167 - val_loss: 2.3250 - val_acc: 0.1364\n",
      "Epoch 771/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2503 - acc: 0.1292 - val_loss: 2.2957 - val_acc: 0.1364\n",
      "Epoch 772/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2599 - acc: 0.1458 - val_loss: 2.3245 - val_acc: 0.1273\n",
      "Epoch 773/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2194 - acc: 0.1750 - val_loss: 2.2859 - val_acc: 0.1182\n",
      "Epoch 774/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.3401 - acc: 0.1167 - val_loss: 2.3104 - val_acc: 0.0818\n",
      "Epoch 775/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3414 - acc: 0.0667 - val_loss: 2.2999 - val_acc: 0.0909\n",
      "Epoch 776/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3468 - acc: 0.0875 - val_loss: 2.3045 - val_acc: 0.1091\n",
      "Epoch 777/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3427 - acc: 0.0792 - val_loss: 2.3042 - val_acc: 0.0909\n",
      "Epoch 778/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3415 - acc: 0.0958 - val_loss: 2.3011 - val_acc: 0.1273\n",
      "Epoch 779/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3312 - acc: 0.0792 - val_loss: 2.2946 - val_acc: 0.1000\n",
      "Epoch 780/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3249 - acc: 0.0625 - val_loss: 2.2965 - val_acc: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 781/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3159 - acc: 0.0750 - val_loss: 2.2931 - val_acc: 0.1818\n",
      "Epoch 782/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3095 - acc: 0.1167 - val_loss: 2.2912 - val_acc: 0.1364\n",
      "Epoch 783/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3010 - acc: 0.0917 - val_loss: 2.2865 - val_acc: 0.1182\n",
      "Epoch 784/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2995 - acc: 0.1083 - val_loss: 2.2864 - val_acc: 0.1727\n",
      "Epoch 785/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2962 - acc: 0.1375 - val_loss: 2.2821 - val_acc: 0.1182\n",
      "Epoch 786/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2904 - acc: 0.0958 - val_loss: 2.2791 - val_acc: 0.1273\n",
      "Epoch 787/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2772 - acc: 0.1375 - val_loss: 2.2725 - val_acc: 0.1182\n",
      "Epoch 788/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2708 - acc: 0.1375 - val_loss: 2.2639 - val_acc: 0.1000\n",
      "Epoch 789/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2632 - acc: 0.1125 - val_loss: 2.2523 - val_acc: 0.1455\n",
      "Epoch 790/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2480 - acc: 0.1542 - val_loss: 2.2389 - val_acc: 0.2182\n",
      "Epoch 791/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.2193 - acc: 0.1750 - val_loss: 2.2275 - val_acc: 0.2182\n",
      "Epoch 792/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.1969 - acc: 0.1958 - val_loss: 2.2066 - val_acc: 0.1636\n",
      "Epoch 793/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.1870 - acc: 0.1625 - val_loss: 2.2048 - val_acc: 0.1727\n",
      "Epoch 794/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.1687 - acc: 0.1792 - val_loss: 2.2127 - val_acc: 0.1727\n",
      "Epoch 795/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.1318 - acc: 0.1875 - val_loss: 2.1614 - val_acc: 0.2273\n",
      "Epoch 796/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.1343 - acc: 0.1417 - val_loss: 2.1409 - val_acc: 0.2091\n",
      "Epoch 797/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.0725 - acc: 0.1833 - val_loss: 2.0992 - val_acc: 0.2273\n",
      "Epoch 798/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.0419 - acc: 0.2083 - val_loss: 2.1218 - val_acc: 0.2364\n",
      "Epoch 799/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.0614 - acc: 0.2042 - val_loss: 2.1683 - val_acc: 0.2091\n",
      "Epoch 800/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.0748 - acc: 0.1875 - val_loss: 2.1110 - val_acc: 0.2091\n",
      "Epoch 801/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.1387 - acc: 0.1750 - val_loss: 2.2209 - val_acc: 0.1818\n",
      "Epoch 802/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.1334 - acc: 0.1500 - val_loss: 2.1247 - val_acc: 0.2636\n",
      "Epoch 803/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.0449 - acc: 0.2250 - val_loss: 2.0997 - val_acc: 0.2182\n",
      "Epoch 804/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.0006 - acc: 0.1917 - val_loss: 2.0978 - val_acc: 0.2091\n",
      "Epoch 805/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.9538 - acc: 0.2375 - val_loss: 2.0652 - val_acc: 0.2182\n",
      "Epoch 806/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.9592 - acc: 0.2250 - val_loss: 2.0567 - val_acc: 0.2273\n",
      "Epoch 807/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.9022 - acc: 0.2417 - val_loss: 2.0290 - val_acc: 0.2273\n",
      "Epoch 808/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.9121 - acc: 0.1708 - val_loss: 2.0567 - val_acc: 0.2364\n",
      "Epoch 809/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.8835 - acc: 0.2042 - val_loss: 2.0781 - val_acc: 0.2455\n",
      "Epoch 810/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.9110 - acc: 0.2542 - val_loss: 2.0720 - val_acc: 0.2364\n",
      "Epoch 811/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.8765 - acc: 0.2167 - val_loss: 2.0679 - val_acc: 0.2273\n",
      "Epoch 812/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.8704 - acc: 0.2542 - val_loss: 2.0930 - val_acc: 0.2182\n",
      "Epoch 813/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.9088 - acc: 0.2500 - val_loss: 2.0351 - val_acc: 0.2273\n",
      "Epoch 814/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.8651 - acc: 0.2083 - val_loss: 2.0264 - val_acc: 0.2455\n",
      "Epoch 815/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.8208 - acc: 0.2167 - val_loss: 2.0728 - val_acc: 0.2273\n",
      "Epoch 816/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.7801 - acc: 0.3000 - val_loss: 2.0482 - val_acc: 0.2545\n",
      "Epoch 817/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7974 - acc: 0.2625 - val_loss: 2.0877 - val_acc: 0.2182\n",
      "Epoch 818/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7710 - acc: 0.2583 - val_loss: 2.0422 - val_acc: 0.1636\n",
      "Epoch 819/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7630 - acc: 0.2667 - val_loss: 2.0386 - val_acc: 0.2000\n",
      "Epoch 820/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7388 - acc: 0.2792 - val_loss: 2.1353 - val_acc: 0.2091\n",
      "Epoch 821/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7538 - acc: 0.2583 - val_loss: 2.1278 - val_acc: 0.2182\n",
      "Epoch 822/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.0817 - acc: 0.1750 - val_loss: 2.3158 - val_acc: 0.0909\n",
      "Epoch 823/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2449 - acc: 0.1375 - val_loss: 2.2448 - val_acc: 0.1545\n",
      "Epoch 824/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.1410 - acc: 0.1750 - val_loss: 2.2027 - val_acc: 0.2091\n",
      "Epoch 825/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.0721 - acc: 0.2208 - val_loss: 2.2001 - val_acc: 0.1909\n",
      "Epoch 826/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.1402 - acc: 0.2000 - val_loss: 2.2192 - val_acc: 0.1455\n",
      "Epoch 827/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.1311 - acc: 0.2125 - val_loss: 2.2708 - val_acc: 0.1273\n",
      "Epoch 828/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.0889 - acc: 0.1917 - val_loss: 2.2059 - val_acc: 0.1818\n",
      "Epoch 829/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.0214 - acc: 0.2625 - val_loss: 2.1813 - val_acc: 0.2091\n",
      "Epoch 830/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.9786 - acc: 0.2333 - val_loss: 2.1520 - val_acc: 0.2273\n",
      "Epoch 831/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.9353 - acc: 0.3000 - val_loss: 2.1325 - val_acc: 0.2364\n",
      "Epoch 832/1000\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.8842 - acc: 0.2833 - val_loss: 2.0913 - val_acc: 0.2727\n",
      "Epoch 833/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.8694 - acc: 0.2333 - val_loss: 2.0958 - val_acc: 0.2182\n",
      "Epoch 834/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.8000 - acc: 0.3208 - val_loss: 2.1903 - val_acc: 0.2364\n",
      "Epoch 835/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.7430 - acc: 0.3458 - val_loss: 2.0171 - val_acc: 0.2909\n",
      "Epoch 836/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6672 - acc: 0.3417 - val_loss: 2.0473 - val_acc: 0.3091\n",
      "Epoch 837/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6414 - acc: 0.3500 - val_loss: 2.0289 - val_acc: 0.2818\n",
      "Epoch 838/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.8057 - acc: 0.3250 - val_loss: 2.1304 - val_acc: 0.2182\n",
      "Epoch 839/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.7954 - acc: 0.3042 - val_loss: 2.1930 - val_acc: 0.2545\n",
      "Epoch 840/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6959 - acc: 0.3458 - val_loss: 2.0874 - val_acc: 0.3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6092 - acc: 0.3875 - val_loss: 1.9617 - val_acc: 0.2909\n",
      "Epoch 842/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.5591 - acc: 0.3917 - val_loss: 2.0832 - val_acc: 0.2727\n",
      "Epoch 843/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.5232 - acc: 0.4500 - val_loss: 1.9619 - val_acc: 0.2818\n",
      "Epoch 844/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4473 - acc: 0.4375 - val_loss: 1.9902 - val_acc: 0.2727\n",
      "Epoch 845/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4638 - acc: 0.4458 - val_loss: 2.1233 - val_acc: 0.2273\n",
      "Epoch 846/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4207 - acc: 0.4917 - val_loss: 2.0538 - val_acc: 0.2636\n",
      "Epoch 847/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3327 - acc: 0.4917 - val_loss: 2.1075 - val_acc: 0.2364\n",
      "Epoch 848/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3405 - acc: 0.4667 - val_loss: 2.0209 - val_acc: 0.2818\n",
      "Epoch 849/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3248 - acc: 0.5208 - val_loss: 2.0365 - val_acc: 0.2364\n",
      "Epoch 850/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2792 - acc: 0.5125 - val_loss: 2.1032 - val_acc: 0.3000\n",
      "Epoch 851/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4213 - acc: 0.4750 - val_loss: 1.9873 - val_acc: 0.2909\n",
      "Epoch 852/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.5359 - acc: 0.4292 - val_loss: 1.9958 - val_acc: 0.2455\n",
      "Epoch 853/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3307 - acc: 0.5250 - val_loss: 1.9560 - val_acc: 0.3364\n",
      "Epoch 854/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3640 - acc: 0.4667 - val_loss: 1.9649 - val_acc: 0.3182\n",
      "Epoch 855/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3536 - acc: 0.4792 - val_loss: 1.9821 - val_acc: 0.2727\n",
      "Epoch 856/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2500 - acc: 0.5125 - val_loss: 1.9347 - val_acc: 0.3000\n",
      "Epoch 857/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.1521 - acc: 0.5875 - val_loss: 2.1027 - val_acc: 0.2727\n",
      "Epoch 858/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.1074 - acc: 0.5958 - val_loss: 1.8979 - val_acc: 0.3818\n",
      "Epoch 859/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0702 - acc: 0.5958 - val_loss: 2.0494 - val_acc: 0.3182\n",
      "Epoch 860/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0494 - acc: 0.6417 - val_loss: 1.8708 - val_acc: 0.3545\n",
      "Epoch 861/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.9679 - acc: 0.6500 - val_loss: 1.9341 - val_acc: 0.3364\n",
      "Epoch 862/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.9641 - acc: 0.6417 - val_loss: 1.8072 - val_acc: 0.3636\n",
      "Epoch 863/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.9658 - acc: 0.6292 - val_loss: 1.7403 - val_acc: 0.4182\n",
      "Epoch 864/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8831 - acc: 0.6542 - val_loss: 1.8237 - val_acc: 0.3909\n",
      "Epoch 865/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8782 - acc: 0.6917 - val_loss: 1.8597 - val_acc: 0.4091\n",
      "Epoch 866/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0160 - acc: 0.6375 - val_loss: 1.9057 - val_acc: 0.4364\n",
      "Epoch 867/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.1810 - acc: 0.5625 - val_loss: 1.8862 - val_acc: 0.4000\n",
      "Epoch 868/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.9694 - acc: 0.6625 - val_loss: 1.7752 - val_acc: 0.4818\n",
      "Epoch 869/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8753 - acc: 0.7292 - val_loss: 2.0675 - val_acc: 0.3727\n",
      "Epoch 870/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.1987 - acc: 0.5750 - val_loss: 1.8241 - val_acc: 0.4364\n",
      "Epoch 871/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8325 - acc: 0.7083 - val_loss: 1.7894 - val_acc: 0.4545\n",
      "Epoch 872/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7557 - acc: 0.7333 - val_loss: 1.8210 - val_acc: 0.4727\n",
      "Epoch 873/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7065 - acc: 0.7542 - val_loss: 1.8198 - val_acc: 0.4636\n",
      "Epoch 874/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7261 - acc: 0.7292 - val_loss: 1.7404 - val_acc: 0.4909\n",
      "Epoch 875/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6861 - acc: 0.7458 - val_loss: 1.6867 - val_acc: 0.5273\n",
      "Epoch 876/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6701 - acc: 0.7625 - val_loss: 1.6292 - val_acc: 0.5455\n",
      "Epoch 877/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5852 - acc: 0.8083 - val_loss: 1.6723 - val_acc: 0.5455\n",
      "Epoch 878/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5792 - acc: 0.7917 - val_loss: 1.8679 - val_acc: 0.4727\n",
      "Epoch 879/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6607 - acc: 0.7708 - val_loss: 1.7691 - val_acc: 0.4727\n",
      "Epoch 880/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6709 - acc: 0.7417 - val_loss: 1.8354 - val_acc: 0.4636\n",
      "Epoch 881/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6508 - acc: 0.7958 - val_loss: 1.8382 - val_acc: 0.4909\n",
      "Epoch 882/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5423 - acc: 0.8000 - val_loss: 1.8285 - val_acc: 0.5000\n",
      "Epoch 883/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5079 - acc: 0.8292 - val_loss: 1.7602 - val_acc: 0.5000\n",
      "Epoch 884/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4431 - acc: 0.8583 - val_loss: 1.7275 - val_acc: 0.5636\n",
      "Epoch 885/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5332 - acc: 0.8083 - val_loss: 1.8471 - val_acc: 0.4364\n",
      "Epoch 886/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.5521 - acc: 0.8375 - val_loss: 1.6923 - val_acc: 0.4727\n",
      "Epoch 887/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5268 - acc: 0.8125 - val_loss: 1.9772 - val_acc: 0.4727\n",
      "Epoch 888/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6124 - acc: 0.7833 - val_loss: 2.3339 - val_acc: 0.3818\n",
      "Epoch 889/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7256 - acc: 0.7458 - val_loss: 1.8280 - val_acc: 0.5000\n",
      "Epoch 890/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6036 - acc: 0.8000 - val_loss: 1.7524 - val_acc: 0.5000\n",
      "Epoch 891/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4450 - acc: 0.8750 - val_loss: 1.7366 - val_acc: 0.5273\n",
      "Epoch 892/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.3888 - acc: 0.8833 - val_loss: 1.8130 - val_acc: 0.4909\n",
      "Epoch 893/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.3749 - acc: 0.9042 - val_loss: 1.8477 - val_acc: 0.5091\n",
      "Epoch 894/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5233 - acc: 0.8375 - val_loss: 1.9580 - val_acc: 0.4364\n",
      "Epoch 895/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4082 - acc: 0.8833 - val_loss: 1.7588 - val_acc: 0.4818\n",
      "Epoch 896/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4047 - acc: 0.9000 - val_loss: 2.2273 - val_acc: 0.4909\n",
      "Epoch 897/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5918 - acc: 0.7958 - val_loss: 1.8902 - val_acc: 0.4818\n",
      "Epoch 898/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5039 - acc: 0.8500 - val_loss: 2.0633 - val_acc: 0.4182\n",
      "Epoch 899/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4826 - acc: 0.8500 - val_loss: 1.7410 - val_acc: 0.4909\n",
      "Epoch 900/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.3850 - acc: 0.9000 - val_loss: 1.7884 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 901/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.3429 - acc: 0.9083 - val_loss: 1.8705 - val_acc: 0.5182\n",
      "Epoch 902/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.2902 - acc: 0.9375 - val_loss: 1.9672 - val_acc: 0.4636\n",
      "Epoch 903/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.2609 - acc: 0.9583 - val_loss: 2.1657 - val_acc: 0.4909\n",
      "Epoch 904/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.2422 - acc: 0.9292 - val_loss: 2.0291 - val_acc: 0.4909\n",
      "Epoch 905/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.2362 - acc: 0.9417 - val_loss: 1.9413 - val_acc: 0.5364\n",
      "Epoch 906/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.2034 - acc: 0.9625 - val_loss: 2.0722 - val_acc: 0.5182\n",
      "Epoch 907/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1845 - acc: 0.9625 - val_loss: 2.0322 - val_acc: 0.5182\n",
      "Epoch 908/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1718 - acc: 0.9625 - val_loss: 2.1995 - val_acc: 0.4818\n",
      "Epoch 909/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1602 - acc: 0.9667 - val_loss: 2.2455 - val_acc: 0.4818\n",
      "Epoch 910/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1464 - acc: 0.9667 - val_loss: 2.2877 - val_acc: 0.4909\n",
      "Epoch 911/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1431 - acc: 0.9667 - val_loss: 2.2545 - val_acc: 0.4909\n",
      "Epoch 912/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1293 - acc: 0.9708 - val_loss: 2.3041 - val_acc: 0.4727\n",
      "Epoch 913/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1963 - acc: 0.9417 - val_loss: 2.4606 - val_acc: 0.4545\n",
      "Epoch 914/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5074 - acc: 0.8500 - val_loss: 2.2680 - val_acc: 0.4727\n",
      "Epoch 915/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.9038 - acc: 0.7000 - val_loss: 1.7928 - val_acc: 0.4273\n",
      "Epoch 916/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6265 - acc: 0.7917 - val_loss: 1.6078 - val_acc: 0.5091\n",
      "Epoch 917/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4235 - acc: 0.8833 - val_loss: 1.9010 - val_acc: 0.5455\n",
      "Epoch 918/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.2855 - acc: 0.9292 - val_loss: 1.9305 - val_acc: 0.5091\n",
      "Epoch 919/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.2768 - acc: 0.9250 - val_loss: 2.1628 - val_acc: 0.5182\n",
      "Epoch 920/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.2674 - acc: 0.9083 - val_loss: 2.1838 - val_acc: 0.5273\n",
      "Epoch 921/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.3683 - acc: 0.8875 - val_loss: 2.1175 - val_acc: 0.5273\n",
      "Epoch 922/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4642 - acc: 0.8500 - val_loss: 2.2077 - val_acc: 0.4545\n",
      "Epoch 923/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4178 - acc: 0.8583 - val_loss: 1.9872 - val_acc: 0.5273\n",
      "Epoch 924/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.2228 - acc: 0.9458 - val_loss: 2.0306 - val_acc: 0.5455\n",
      "Epoch 925/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.2724 - acc: 0.9125 - val_loss: 2.1683 - val_acc: 0.4909\n",
      "Epoch 926/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.3685 - acc: 0.8750 - val_loss: 2.0905 - val_acc: 0.4909\n",
      "Epoch 927/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.2893 - acc: 0.9042 - val_loss: 2.0771 - val_acc: 0.5273\n",
      "Epoch 928/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1929 - acc: 0.9625 - val_loss: 2.1733 - val_acc: 0.4818\n",
      "Epoch 929/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1332 - acc: 0.9667 - val_loss: 2.2073 - val_acc: 0.5182\n",
      "Epoch 930/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1101 - acc: 0.9792 - val_loss: 2.3207 - val_acc: 0.5182\n",
      "Epoch 931/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1325 - acc: 0.9667 - val_loss: 2.2442 - val_acc: 0.5091\n",
      "Epoch 932/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5784 - acc: 0.8417 - val_loss: 2.4598 - val_acc: 0.4364\n",
      "Epoch 933/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8815 - acc: 0.7292 - val_loss: 2.1049 - val_acc: 0.4727\n",
      "Epoch 934/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.3687 - acc: 0.9042 - val_loss: 1.9190 - val_acc: 0.5182\n",
      "Epoch 935/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.2631 - acc: 0.9417 - val_loss: 1.9797 - val_acc: 0.5273\n",
      "Epoch 936/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.2203 - acc: 0.9458 - val_loss: 2.1479 - val_acc: 0.5545\n",
      "Epoch 937/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1746 - acc: 0.9625 - val_loss: 2.1023 - val_acc: 0.5364\n",
      "Epoch 938/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1774 - acc: 0.9542 - val_loss: 2.0836 - val_acc: 0.5364\n",
      "Epoch 939/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1724 - acc: 0.9542 - val_loss: 2.1791 - val_acc: 0.5273\n",
      "Epoch 940/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1593 - acc: 0.9500 - val_loss: 2.1837 - val_acc: 0.5364\n",
      "Epoch 941/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1547 - acc: 0.9667 - val_loss: 2.1373 - val_acc: 0.5182\n",
      "Epoch 942/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1214 - acc: 0.9625 - val_loss: 2.0999 - val_acc: 0.5364\n",
      "Epoch 943/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1261 - acc: 0.9750 - val_loss: 2.1382 - val_acc: 0.5273\n",
      "Epoch 944/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1137 - acc: 0.9708 - val_loss: 2.2055 - val_acc: 0.5636\n",
      "Epoch 945/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1929 - acc: 0.9208 - val_loss: 2.2440 - val_acc: 0.4909\n",
      "Epoch 946/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1962 - acc: 0.9333 - val_loss: 2.5016 - val_acc: 0.4727\n",
      "Epoch 947/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1904 - acc: 0.9333 - val_loss: 2.1437 - val_acc: 0.5364\n",
      "Epoch 948/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1508 - acc: 0.9625 - val_loss: 2.2589 - val_acc: 0.5000\n",
      "Epoch 949/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1707 - acc: 0.9417 - val_loss: 2.3301 - val_acc: 0.4727\n",
      "Epoch 950/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.1780 - acc: 0.9500 - val_loss: 2.4233 - val_acc: 0.4909\n",
      "Epoch 951/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.5627 - acc: 0.8375 - val_loss: 2.2110 - val_acc: 0.5182\n",
      "Epoch 952/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.2765 - acc: 0.9125 - val_loss: 2.1572 - val_acc: 0.5545\n",
      "Epoch 953/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1485 - acc: 0.9583 - val_loss: 2.2894 - val_acc: 0.5727\n",
      "Epoch 954/1000\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.1056 - acc: 0.9750 - val_loss: 2.3642 - val_acc: 0.5636\n",
      "Epoch 955/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0857 - acc: 0.9792 - val_loss: 2.4471 - val_acc: 0.5364\n",
      "Epoch 956/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0961 - acc: 0.9750 - val_loss: 2.5081 - val_acc: 0.5455\n",
      "Epoch 957/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0846 - acc: 0.9875 - val_loss: 2.4437 - val_acc: 0.5455\n",
      "Epoch 958/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0797 - acc: 0.9833 - val_loss: 2.5212 - val_acc: 0.5545\n",
      "Epoch 959/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1090 - acc: 0.9792 - val_loss: 2.5343 - val_acc: 0.5636\n",
      "Epoch 960/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0745 - acc: 0.9792 - val_loss: 2.4733 - val_acc: 0.5636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 961/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0767 - acc: 0.9833 - val_loss: 2.4907 - val_acc: 0.5455\n",
      "Epoch 962/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0973 - acc: 0.9750 - val_loss: 2.5189 - val_acc: 0.5273\n",
      "Epoch 963/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0596 - acc: 0.9917 - val_loss: 2.4452 - val_acc: 0.5818\n",
      "Epoch 964/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0533 - acc: 0.9917 - val_loss: 2.4469 - val_acc: 0.6000\n",
      "Epoch 965/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0561 - acc: 0.9875 - val_loss: 2.4644 - val_acc: 0.6000\n",
      "Epoch 966/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0512 - acc: 0.9917 - val_loss: 2.6837 - val_acc: 0.5455\n",
      "Epoch 967/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0170 - acc: 0.7375 - val_loss: 2.5948 - val_acc: 0.3909\n",
      "Epoch 968/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2562 - acc: 0.6500 - val_loss: 3.7559 - val_acc: 0.2364\n",
      "Epoch 969/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.4842 - acc: 0.3208 - val_loss: 2.3995 - val_acc: 0.3273\n",
      "Epoch 970/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2917 - acc: 0.5625 - val_loss: 1.9103 - val_acc: 0.4545\n",
      "Epoch 971/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.9123 - acc: 0.6875 - val_loss: 1.8337 - val_acc: 0.5000\n",
      "Epoch 972/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7138 - acc: 0.7375 - val_loss: 1.8236 - val_acc: 0.5091\n",
      "Epoch 973/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5526 - acc: 0.8250 - val_loss: 1.8760 - val_acc: 0.5091\n",
      "Epoch 974/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4653 - acc: 0.8417 - val_loss: 1.7566 - val_acc: 0.5818\n",
      "Epoch 975/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4315 - acc: 0.8833 - val_loss: 1.8320 - val_acc: 0.6091\n",
      "Epoch 976/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.3701 - acc: 0.9042 - val_loss: 1.7280 - val_acc: 0.5909\n",
      "Epoch 977/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.3354 - acc: 0.9042 - val_loss: 1.7435 - val_acc: 0.5545\n",
      "Epoch 978/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4452 - acc: 0.8375 - val_loss: 1.7876 - val_acc: 0.5091\n",
      "Epoch 979/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.3461 - acc: 0.8917 - val_loss: 1.6386 - val_acc: 0.5636\n",
      "Epoch 980/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.3527 - acc: 0.9125 - val_loss: 2.2300 - val_acc: 0.4273\n",
      "Epoch 981/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4518 - acc: 0.8625 - val_loss: 1.7794 - val_acc: 0.5545\n",
      "Epoch 982/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.2792 - acc: 0.9208 - val_loss: 1.7594 - val_acc: 0.5727\n",
      "Epoch 983/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1864 - acc: 0.9625 - val_loss: 1.7209 - val_acc: 0.5909\n",
      "Epoch 984/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1378 - acc: 0.9750 - val_loss: 1.7623 - val_acc: 0.6000\n",
      "Epoch 985/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1200 - acc: 0.9750 - val_loss: 1.7835 - val_acc: 0.6182\n",
      "Epoch 986/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1066 - acc: 0.9792 - val_loss: 1.7602 - val_acc: 0.6364\n",
      "Epoch 987/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1073 - acc: 0.9833 - val_loss: 1.8005 - val_acc: 0.6455\n",
      "Epoch 988/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0937 - acc: 0.9792 - val_loss: 1.8731 - val_acc: 0.6455\n",
      "Epoch 989/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1321 - acc: 0.9750 - val_loss: 1.9189 - val_acc: 0.6455\n",
      "Epoch 990/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0911 - acc: 0.9833 - val_loss: 1.9312 - val_acc: 0.6545\n",
      "Epoch 991/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0965 - acc: 0.9833 - val_loss: 1.9605 - val_acc: 0.6364\n",
      "Epoch 992/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0756 - acc: 0.9833 - val_loss: 1.9801 - val_acc: 0.6273\n",
      "Epoch 993/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0647 - acc: 0.9875 - val_loss: 1.9853 - val_acc: 0.6273\n",
      "Epoch 994/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0605 - acc: 0.9875 - val_loss: 1.9826 - val_acc: 0.6364\n",
      "Epoch 995/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0522 - acc: 0.9917 - val_loss: 1.9721 - val_acc: 0.6455\n",
      "Epoch 996/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0481 - acc: 0.9917 - val_loss: 1.9867 - val_acc: 0.6455\n",
      "Epoch 997/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0456 - acc: 0.9917 - val_loss: 2.0131 - val_acc: 0.6636\n",
      "Epoch 998/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0419 - acc: 0.9917 - val_loss: 2.0266 - val_acc: 0.6455\n",
      "Epoch 999/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0435 - acc: 0.9917 - val_loss: 2.0553 - val_acc: 0.6455\n",
      "Epoch 1000/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0407 - acc: 0.9875 - val_loss: 2.0441 - val_acc: 0.6364\n"
     ]
    }
   ],
   "source": [
    "LSTMDD5=LSTM_with_Dropout('LSTM_Dropoutdelta5',dropout=0.5,n_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/1000\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 2.3051 - acc: 0.0875 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 2/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3038 - acc: 0.0667 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 3/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3032 - acc: 0.0667 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 4/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3008 - acc: 0.0542 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 5/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3042 - acc: 0.0667 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 6/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2999 - acc: 0.0667 - val_loss: 2.3031 - val_acc: 0.1091\n",
      "Epoch 7/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3019 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 8/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2969 - acc: 0.0750 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 9/1000\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.2949 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.0727\n",
      "Epoch 10/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2941 - acc: 0.1083 - val_loss: 2.3024 - val_acc: 0.1091\n",
      "Epoch 11/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2935 - acc: 0.0833 - val_loss: 2.3023 - val_acc: 0.1091\n",
      "Epoch 12/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2937 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 13/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2944 - acc: 0.0750 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 14/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2943 - acc: 0.0792 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 15/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2940 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 16/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2938 - acc: 0.0792 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 17/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2940 - acc: 0.0625 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 18/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2938 - acc: 0.0708 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 19/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2939 - acc: 0.0958 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 20/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2943 - acc: 0.0833 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 21/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2939 - acc: 0.0958 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 22/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2938 - acc: 0.0875 - val_loss: 2.3026 - val_acc: 0.0909\n",
      "Epoch 23/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2938 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 24/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2935 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 25/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2937 - acc: 0.0750 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 26/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2937 - acc: 0.0708 - val_loss: 2.3026 - val_acc: 0.0909\n",
      "Epoch 27/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2939 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 28/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2936 - acc: 0.1042 - val_loss: 2.3025 - val_acc: 0.1000\n",
      "Epoch 29/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2935 - acc: 0.0917 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 30/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2943 - acc: 0.0583 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 31/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2942 - acc: 0.0500 - val_loss: 2.3028 - val_acc: 0.0909\n",
      "Epoch 32/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2939 - acc: 0.0708 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 33/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2935 - acc: 0.1000 - val_loss: 2.3006 - val_acc: 0.1000\n",
      "Epoch 34/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2869 - acc: 0.0792 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 35/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3008 - acc: 0.0917 - val_loss: 2.3012 - val_acc: 0.1091\n",
      "Epoch 36/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3006 - acc: 0.0667 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 37/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3042 - acc: 0.0875 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 38/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3024 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 39/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2996 - acc: 0.0708 - val_loss: 2.3025 - val_acc: 0.1000\n",
      "Epoch 40/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2973 - acc: 0.0875 - val_loss: 2.3031 - val_acc: 0.0909\n",
      "Epoch 41/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3088 - acc: 0.0875 - val_loss: 2.3049 - val_acc: 0.1273\n",
      "Epoch 42/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2957 - acc: 0.1000 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 43/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3053 - acc: 0.0958 - val_loss: 2.3038 - val_acc: 0.1000\n",
      "Epoch 44/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.8207 - acc: 0.1042 - val_loss: 2.5145 - val_acc: 0.0909\n",
      "Epoch 45/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.4235 - acc: 0.0792 - val_loss: 2.3201 - val_acc: 0.1000\n",
      "Epoch 46/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3612 - acc: 0.0792 - val_loss: 2.3267 - val_acc: 0.1000\n",
      "Epoch 47/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3417 - acc: 0.1042 - val_loss: 2.3129 - val_acc: 0.1000\n",
      "Epoch 48/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3415 - acc: 0.0667 - val_loss: 2.3102 - val_acc: 0.1091\n",
      "Epoch 49/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3409 - acc: 0.1000 - val_loss: 2.3120 - val_acc: 0.1000\n",
      "Epoch 50/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3372 - acc: 0.1042 - val_loss: 2.3056 - val_acc: 0.1091\n",
      "Epoch 51/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3325 - acc: 0.0833 - val_loss: 2.3035 - val_acc: 0.1091\n",
      "Epoch 52/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3130 - acc: 0.1000 - val_loss: 2.3016 - val_acc: 0.1000\n",
      "Epoch 53/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3201 - acc: 0.0875 - val_loss: 2.2954 - val_acc: 0.1545\n",
      "Epoch 54/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3217 - acc: 0.0750 - val_loss: 2.2917 - val_acc: 0.1455\n",
      "Epoch 55/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3083 - acc: 0.0625 - val_loss: 2.2854 - val_acc: 0.1273\n",
      "Epoch 56/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2950 - acc: 0.1208 - val_loss: 2.2985 - val_acc: 0.1273\n",
      "Epoch 57/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2853 - acc: 0.1000 - val_loss: 2.2574 - val_acc: 0.1364\n",
      "Epoch 58/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2678 - acc: 0.1417 - val_loss: 2.2535 - val_acc: 0.1455\n",
      "Epoch 59/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2303 - acc: 0.1125 - val_loss: 2.2148 - val_acc: 0.1636\n",
      "Epoch 60/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2047 - acc: 0.1625 - val_loss: 2.1707 - val_acc: 0.1727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2987 - acc: 0.0750 - val_loss: 2.3082 - val_acc: 0.1091\n",
      "Epoch 62/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3096 - acc: 0.0917 - val_loss: 2.3140 - val_acc: 0.1000\n",
      "Epoch 63/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3160 - acc: 0.0792 - val_loss: 2.3147 - val_acc: 0.1000\n",
      "Epoch 64/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3129 - acc: 0.0542 - val_loss: 2.3131 - val_acc: 0.0818\n",
      "Epoch 65/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3141 - acc: 0.0708 - val_loss: 2.3143 - val_acc: 0.1000\n",
      "Epoch 66/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3038 - acc: 0.1125 - val_loss: 2.3147 - val_acc: 0.1091\n",
      "Epoch 67/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3059 - acc: 0.0583 - val_loss: 2.3126 - val_acc: 0.1000\n",
      "Epoch 68/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3026 - acc: 0.0667 - val_loss: 2.3116 - val_acc: 0.1091\n",
      "Epoch 69/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3070 - acc: 0.1042 - val_loss: 2.3134 - val_acc: 0.1000\n",
      "Epoch 70/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3003 - acc: 0.0750 - val_loss: 2.3121 - val_acc: 0.1000\n",
      "Epoch 71/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2939 - acc: 0.1167 - val_loss: 2.3104 - val_acc: 0.0909\n",
      "Epoch 72/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3016 - acc: 0.0958 - val_loss: 2.3109 - val_acc: 0.1091\n",
      "Epoch 73/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3087 - acc: 0.0667 - val_loss: 2.3095 - val_acc: 0.1091\n",
      "Epoch 74/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2977 - acc: 0.0833 - val_loss: 2.3085 - val_acc: 0.1000\n",
      "Epoch 75/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2995 - acc: 0.0792 - val_loss: 2.3065 - val_acc: 0.1000\n",
      "Epoch 76/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2938 - acc: 0.1042 - val_loss: 2.3062 - val_acc: 0.1091\n",
      "Epoch 77/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2967 - acc: 0.0917 - val_loss: 2.3050 - val_acc: 0.1000\n",
      "Epoch 78/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2936 - acc: 0.0917 - val_loss: 2.3049 - val_acc: 0.0909\n",
      "Epoch 79/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2956 - acc: 0.0917 - val_loss: 2.3058 - val_acc: 0.1182\n",
      "Epoch 80/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2939 - acc: 0.0750 - val_loss: 2.3055 - val_acc: 0.0909\n",
      "Epoch 81/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2927 - acc: 0.0917 - val_loss: 2.3053 - val_acc: 0.1000\n",
      "Epoch 82/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2886 - acc: 0.1042 - val_loss: 2.2987 - val_acc: 0.1182\n",
      "Epoch 83/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2945 - acc: 0.0708 - val_loss: 2.3094 - val_acc: 0.0909\n",
      "Epoch 84/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2923 - acc: 0.0958 - val_loss: 2.3033 - val_acc: 0.1091\n",
      "Epoch 85/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2941 - acc: 0.1083 - val_loss: 2.3083 - val_acc: 0.1000\n",
      "Epoch 86/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2953 - acc: 0.0958 - val_loss: 2.3181 - val_acc: 0.1091\n",
      "Epoch 87/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2885 - acc: 0.1000 - val_loss: 2.3145 - val_acc: 0.1091\n",
      "Epoch 88/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2872 - acc: 0.1083 - val_loss: 2.3082 - val_acc: 0.1182\n",
      "Epoch 89/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2870 - acc: 0.0875 - val_loss: 2.2991 - val_acc: 0.0636\n",
      "Epoch 90/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2578 - acc: 0.1250 - val_loss: 2.2639 - val_acc: 0.1545\n",
      "Epoch 91/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.1763 - acc: 0.1167 - val_loss: 2.1753 - val_acc: 0.1636\n",
      "Epoch 92/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.1975 - acc: 0.1417 - val_loss: 2.4244 - val_acc: 0.1000\n",
      "Epoch 93/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3633 - acc: 0.0750 - val_loss: 2.3050 - val_acc: 0.1000\n",
      "Epoch 94/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3228 - acc: 0.0875 - val_loss: 2.3056 - val_acc: 0.1000\n",
      "Epoch 95/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3181 - acc: 0.1000 - val_loss: 2.3052 - val_acc: 0.1000\n",
      "Epoch 96/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3147 - acc: 0.0750 - val_loss: 2.3038 - val_acc: 0.1000\n",
      "Epoch 97/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3185 - acc: 0.0792 - val_loss: 2.3047 - val_acc: 0.1000\n",
      "Epoch 98/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3102 - acc: 0.0958 - val_loss: 2.3033 - val_acc: 0.1000\n",
      "Epoch 99/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3126 - acc: 0.0667 - val_loss: 2.3034 - val_acc: 0.1000\n",
      "Epoch 100/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3178 - acc: 0.0708 - val_loss: 2.3051 - val_acc: 0.1000\n",
      "Epoch 101/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3156 - acc: 0.0625 - val_loss: 2.3040 - val_acc: 0.1000\n",
      "Epoch 102/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3212 - acc: 0.0542 - val_loss: 2.3040 - val_acc: 0.1000\n",
      "Epoch 103/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3127 - acc: 0.0833 - val_loss: 2.3044 - val_acc: 0.1000\n",
      "Epoch 104/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3222 - acc: 0.0792 - val_loss: 2.3044 - val_acc: 0.1000\n",
      "Epoch 105/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3117 - acc: 0.1000 - val_loss: 2.3049 - val_acc: 0.1000\n",
      "Epoch 106/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3155 - acc: 0.0708 - val_loss: 2.3035 - val_acc: 0.1000\n",
      "Epoch 107/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3168 - acc: 0.0667 - val_loss: 2.3045 - val_acc: 0.1000\n",
      "Epoch 108/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3220 - acc: 0.0750 - val_loss: 2.3041 - val_acc: 0.1000\n",
      "Epoch 109/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3125 - acc: 0.0792 - val_loss: 2.3033 - val_acc: 0.1000\n",
      "Epoch 110/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3193 - acc: 0.0750 - val_loss: 2.3034 - val_acc: 0.1000\n",
      "Epoch 111/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3165 - acc: 0.0667 - val_loss: 2.3039 - val_acc: 0.1000\n",
      "Epoch 112/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3176 - acc: 0.0750 - val_loss: 2.3032 - val_acc: 0.1000\n",
      "Epoch 113/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3143 - acc: 0.0958 - val_loss: 2.3051 - val_acc: 0.1000\n",
      "Epoch 114/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3152 - acc: 0.0917 - val_loss: 2.3045 - val_acc: 0.1000\n",
      "Epoch 115/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3183 - acc: 0.0792 - val_loss: 2.3051 - val_acc: 0.1000\n",
      "Epoch 116/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3259 - acc: 0.0708 - val_loss: 2.3048 - val_acc: 0.1000\n",
      "Epoch 117/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3145 - acc: 0.0917 - val_loss: 2.3061 - val_acc: 0.1000\n",
      "Epoch 118/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3195 - acc: 0.0500 - val_loss: 2.3038 - val_acc: 0.1000\n",
      "Epoch 119/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3138 - acc: 0.0750 - val_loss: 2.3040 - val_acc: 0.1000\n",
      "Epoch 120/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3146 - acc: 0.0875 - val_loss: 2.3038 - val_acc: 0.1000\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3141 - acc: 0.0583 - val_loss: 2.3033 - val_acc: 0.1000\n",
      "Epoch 122/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3103 - acc: 0.0875 - val_loss: 2.3034 - val_acc: 0.1000\n",
      "Epoch 123/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3174 - acc: 0.0875 - val_loss: 2.3045 - val_acc: 0.1000\n",
      "Epoch 124/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3157 - acc: 0.0792 - val_loss: 2.3040 - val_acc: 0.1000\n",
      "Epoch 125/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3176 - acc: 0.0708 - val_loss: 2.3037 - val_acc: 0.1000\n",
      "Epoch 126/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3161 - acc: 0.0875 - val_loss: 2.3038 - val_acc: 0.1000\n",
      "Epoch 127/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3093 - acc: 0.0958 - val_loss: 2.3035 - val_acc: 0.1000\n",
      "Epoch 128/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3214 - acc: 0.0500 - val_loss: 2.3052 - val_acc: 0.1000\n",
      "Epoch 129/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3126 - acc: 0.0917 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 130/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3121 - acc: 0.1083 - val_loss: 2.3032 - val_acc: 0.1000\n",
      "Epoch 131/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3127 - acc: 0.0792 - val_loss: 2.3034 - val_acc: 0.1000\n",
      "Epoch 132/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3121 - acc: 0.0833 - val_loss: 2.3035 - val_acc: 0.1000\n",
      "Epoch 133/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3197 - acc: 0.0708 - val_loss: 2.3039 - val_acc: 0.1000\n",
      "Epoch 134/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3187 - acc: 0.0667 - val_loss: 2.3047 - val_acc: 0.1000\n",
      "Epoch 135/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3155 - acc: 0.0792 - val_loss: 2.3040 - val_acc: 0.1000\n",
      "Epoch 136/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3136 - acc: 0.0625 - val_loss: 2.3032 - val_acc: 0.1000\n",
      "Epoch 137/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3180 - acc: 0.0542 - val_loss: 2.3046 - val_acc: 0.1000\n",
      "Epoch 138/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3098 - acc: 0.0792 - val_loss: 2.3032 - val_acc: 0.1000\n",
      "Epoch 139/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3135 - acc: 0.1083 - val_loss: 2.3038 - val_acc: 0.1000\n",
      "Epoch 140/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3159 - acc: 0.0625 - val_loss: 2.3034 - val_acc: 0.1000\n",
      "Epoch 141/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3140 - acc: 0.0792 - val_loss: 2.3046 - val_acc: 0.1000\n",
      "Epoch 142/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3127 - acc: 0.0625 - val_loss: 2.3033 - val_acc: 0.1000\n",
      "Epoch 143/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3099 - acc: 0.0958 - val_loss: 2.3038 - val_acc: 0.1000\n",
      "Epoch 144/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3129 - acc: 0.0833 - val_loss: 2.3037 - val_acc: 0.1000\n",
      "Epoch 145/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3144 - acc: 0.1000 - val_loss: 2.3039 - val_acc: 0.1000\n",
      "Epoch 146/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3102 - acc: 0.0875 - val_loss: 2.3032 - val_acc: 0.1000\n",
      "Epoch 147/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3142 - acc: 0.0583 - val_loss: 2.3033 - val_acc: 0.1000\n",
      "Epoch 148/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3113 - acc: 0.0958 - val_loss: 2.3033 - val_acc: 0.1000\n",
      "Epoch 149/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3139 - acc: 0.0542 - val_loss: 2.3034 - val_acc: 0.1000\n",
      "Epoch 150/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3110 - acc: 0.0833 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 151/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3194 - acc: 0.0667 - val_loss: 2.3041 - val_acc: 0.1000\n",
      "Epoch 152/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3109 - acc: 0.0583 - val_loss: 2.3036 - val_acc: 0.1000\n",
      "Epoch 153/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3118 - acc: 0.0750 - val_loss: 2.3042 - val_acc: 0.1000\n",
      "Epoch 154/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3181 - acc: 0.0833 - val_loss: 2.3040 - val_acc: 0.1000\n",
      "Epoch 155/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3097 - acc: 0.0792 - val_loss: 2.3036 - val_acc: 0.1000\n",
      "Epoch 156/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3086 - acc: 0.0917 - val_loss: 2.3039 - val_acc: 0.1000\n",
      "Epoch 157/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3150 - acc: 0.1000 - val_loss: 2.3036 - val_acc: 0.1000\n",
      "Epoch 158/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3155 - acc: 0.0958 - val_loss: 2.3047 - val_acc: 0.1000\n",
      "Epoch 159/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3089 - acc: 0.0917 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 160/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3165 - acc: 0.0792 - val_loss: 2.3035 - val_acc: 0.1000\n",
      "Epoch 161/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3082 - acc: 0.1000 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 162/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.3097 - acc: 0.0750 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 163/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3118 - acc: 0.1042 - val_loss: 2.3038 - val_acc: 0.1000\n",
      "Epoch 164/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3120 - acc: 0.0708 - val_loss: 2.3035 - val_acc: 0.1000\n",
      "Epoch 165/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3123 - acc: 0.0833 - val_loss: 2.3038 - val_acc: 0.1000\n",
      "Epoch 166/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3098 - acc: 0.0917 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 167/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3112 - acc: 0.0625 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 168/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.3141 - acc: 0.0875 - val_loss: 2.2978 - val_acc: 0.1091\n",
      "Epoch 169/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2972 - acc: 0.1083 - val_loss: 2.2683 - val_acc: 0.1818\n",
      "Epoch 170/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2413 - acc: 0.1500 - val_loss: 2.1981 - val_acc: 0.1727\n",
      "Epoch 171/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2206 - acc: 0.1667 - val_loss: 2.2119 - val_acc: 0.1636\n",
      "Epoch 172/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2372 - acc: 0.1667 - val_loss: 2.3287 - val_acc: 0.1091\n",
      "Epoch 173/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.3113 - acc: 0.1083 - val_loss: 2.2466 - val_acc: 0.1545\n",
      "Epoch 174/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2165 - acc: 0.1708 - val_loss: 2.1793 - val_acc: 0.1727\n",
      "Epoch 175/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.1649 - acc: 0.1542 - val_loss: 2.1507 - val_acc: 0.1727\n",
      "Epoch 176/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.2441 - acc: 0.1042 - val_loss: 2.2225 - val_acc: 0.1182\n",
      "Epoch 177/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.1659 - acc: 0.1375 - val_loss: 2.1376 - val_acc: 0.1909\n",
      "Epoch 178/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.1190 - acc: 0.1750 - val_loss: 2.1506 - val_acc: 0.1545\n",
      "Epoch 179/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.0632 - acc: 0.1750 - val_loss: 2.0825 - val_acc: 0.2182\n",
      "Epoch 180/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.0309 - acc: 0.1875 - val_loss: 2.0588 - val_acc: 0.2182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.9645 - acc: 0.2125 - val_loss: 2.0042 - val_acc: 0.2182\n",
      "Epoch 182/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.9327 - acc: 0.2292 - val_loss: 1.9970 - val_acc: 0.2091\n",
      "Epoch 183/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.9057 - acc: 0.2042 - val_loss: 2.0361 - val_acc: 0.1818\n",
      "Epoch 184/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.9129 - acc: 0.2292 - val_loss: 1.9954 - val_acc: 0.1818\n",
      "Epoch 185/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.8754 - acc: 0.2458 - val_loss: 2.0088 - val_acc: 0.2091\n",
      "Epoch 186/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.8418 - acc: 0.2375 - val_loss: 1.9083 - val_acc: 0.2455\n",
      "Epoch 187/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.8721 - acc: 0.2375 - val_loss: 1.9664 - val_acc: 0.2000\n",
      "Epoch 188/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.9817 - acc: 0.1792 - val_loss: 2.0231 - val_acc: 0.2182\n",
      "Epoch 189/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.1805 - acc: 0.1375 - val_loss: 2.1684 - val_acc: 0.1818\n",
      "Epoch 190/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.0372 - acc: 0.1958 - val_loss: 2.0883 - val_acc: 0.1455\n",
      "Epoch 191/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.9618 - acc: 0.2083 - val_loss: 2.0231 - val_acc: 0.2000\n",
      "Epoch 192/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.9330 - acc: 0.2542 - val_loss: 2.0460 - val_acc: 0.1818\n",
      "Epoch 193/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.9134 - acc: 0.2167 - val_loss: 2.0209 - val_acc: 0.1636\n",
      "Epoch 194/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.8867 - acc: 0.2083 - val_loss: 1.9723 - val_acc: 0.2364\n",
      "Epoch 195/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.8794 - acc: 0.2458 - val_loss: 1.9975 - val_acc: 0.1818\n",
      "Epoch 196/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.8460 - acc: 0.2625 - val_loss: 1.9715 - val_acc: 0.1909\n",
      "Epoch 197/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7707 - acc: 0.2833 - val_loss: 1.9331 - val_acc: 0.2000\n",
      "Epoch 198/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.8074 - acc: 0.2625 - val_loss: 2.0112 - val_acc: 0.1818\n",
      "Epoch 199/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.8388 - acc: 0.2708 - val_loss: 1.9875 - val_acc: 0.2091\n",
      "Epoch 200/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.8181 - acc: 0.2792 - val_loss: 1.9987 - val_acc: 0.2182\n",
      "Epoch 201/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7638 - acc: 0.2958 - val_loss: 1.9461 - val_acc: 0.2000\n",
      "Epoch 202/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.7443 - acc: 0.2917 - val_loss: 1.9274 - val_acc: 0.2091\n",
      "Epoch 203/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.7353 - acc: 0.3083 - val_loss: 1.9223 - val_acc: 0.2091\n",
      "Epoch 204/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.8185 - acc: 0.3083 - val_loss: 2.3215 - val_acc: 0.1818\n",
      "Epoch 205/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.9464 - acc: 0.2125 - val_loss: 1.9154 - val_acc: 0.2000\n",
      "Epoch 206/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.9061 - acc: 0.2167 - val_loss: 1.9369 - val_acc: 0.2636\n",
      "Epoch 207/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.8056 - acc: 0.2708 - val_loss: 1.8669 - val_acc: 0.2273\n",
      "Epoch 208/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.8033 - acc: 0.3042 - val_loss: 1.9376 - val_acc: 0.2091\n",
      "Epoch 209/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7622 - acc: 0.3000 - val_loss: 1.9616 - val_acc: 0.2182\n",
      "Epoch 210/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7331 - acc: 0.2667 - val_loss: 1.9831 - val_acc: 0.2000\n",
      "Epoch 211/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7117 - acc: 0.2875 - val_loss: 1.9633 - val_acc: 0.2182\n",
      "Epoch 212/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6940 - acc: 0.3042 - val_loss: 2.1856 - val_acc: 0.1818\n",
      "Epoch 213/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.7965 - acc: 0.2625 - val_loss: 1.9884 - val_acc: 0.1909\n",
      "Epoch 214/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7232 - acc: 0.2792 - val_loss: 1.9847 - val_acc: 0.2273\n",
      "Epoch 215/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7061 - acc: 0.2917 - val_loss: 1.9668 - val_acc: 0.2182\n",
      "Epoch 216/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6712 - acc: 0.2917 - val_loss: 1.9481 - val_acc: 0.2273\n",
      "Epoch 217/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6446 - acc: 0.3125 - val_loss: 1.9598 - val_acc: 0.2091\n",
      "Epoch 218/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6347 - acc: 0.2875 - val_loss: 1.9641 - val_acc: 0.2091\n",
      "Epoch 219/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6191 - acc: 0.3333 - val_loss: 1.9859 - val_acc: 0.2091\n",
      "Epoch 220/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5983 - acc: 0.3542 - val_loss: 1.9634 - val_acc: 0.2545\n",
      "Epoch 221/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.5728 - acc: 0.3708 - val_loss: 1.9778 - val_acc: 0.2364\n",
      "Epoch 222/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.5640 - acc: 0.3750 - val_loss: 2.0038 - val_acc: 0.2545\n",
      "Epoch 223/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.5397 - acc: 0.4000 - val_loss: 1.9987 - val_acc: 0.2182\n",
      "Epoch 224/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.7907 - acc: 0.3333 - val_loss: 1.9977 - val_acc: 0.2364\n",
      "Epoch 225/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6857 - acc: 0.2792 - val_loss: 2.0040 - val_acc: 0.1909\n",
      "Epoch 226/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.6842 - acc: 0.2833 - val_loss: 1.9497 - val_acc: 0.2182\n",
      "Epoch 227/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6768 - acc: 0.2833 - val_loss: 1.9542 - val_acc: 0.2091\n",
      "Epoch 228/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6026 - acc: 0.3458 - val_loss: 1.8923 - val_acc: 0.2364\n",
      "Epoch 229/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6154 - acc: 0.3167 - val_loss: 1.9833 - val_acc: 0.2273\n",
      "Epoch 230/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6114 - acc: 0.3417 - val_loss: 2.0072 - val_acc: 0.2091\n",
      "Epoch 231/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.5778 - acc: 0.3792 - val_loss: 2.0324 - val_acc: 0.2273\n",
      "Epoch 232/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.5687 - acc: 0.3792 - val_loss: 1.8944 - val_acc: 0.2636\n",
      "Epoch 233/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.5356 - acc: 0.3667 - val_loss: 1.9520 - val_acc: 0.2364\n",
      "Epoch 234/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4956 - acc: 0.4167 - val_loss: 1.9822 - val_acc: 0.2545\n",
      "Epoch 235/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4890 - acc: 0.4083 - val_loss: 1.9579 - val_acc: 0.2818\n",
      "Epoch 236/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4711 - acc: 0.4333 - val_loss: 2.0153 - val_acc: 0.2182\n",
      "Epoch 237/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.5008 - acc: 0.4042 - val_loss: 2.0466 - val_acc: 0.2091\n",
      "Epoch 238/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6113 - acc: 0.3833 - val_loss: 1.9414 - val_acc: 0.3364\n",
      "Epoch 239/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.5140 - acc: 0.4125 - val_loss: 1.9374 - val_acc: 0.3182\n",
      "Epoch 240/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4509 - acc: 0.4208 - val_loss: 1.8521 - val_acc: 0.3091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.8884 - acc: 0.3625 - val_loss: 2.3635 - val_acc: 0.1818\n",
      "Epoch 242/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6043 - acc: 0.3542 - val_loss: 1.8597 - val_acc: 0.2727\n",
      "Epoch 243/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4537 - acc: 0.3958 - val_loss: 1.7899 - val_acc: 0.2455\n",
      "Epoch 244/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3995 - acc: 0.4333 - val_loss: 1.8112 - val_acc: 0.3000\n",
      "Epoch 245/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3583 - acc: 0.4625 - val_loss: 1.7952 - val_acc: 0.2727\n",
      "Epoch 246/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3441 - acc: 0.4875 - val_loss: 1.8313 - val_acc: 0.3091\n",
      "Epoch 247/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3312 - acc: 0.4833 - val_loss: 1.7856 - val_acc: 0.2909\n",
      "Epoch 248/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3309 - acc: 0.4917 - val_loss: 1.8613 - val_acc: 0.3000\n",
      "Epoch 249/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3084 - acc: 0.4792 - val_loss: 1.8116 - val_acc: 0.3273\n",
      "Epoch 250/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2953 - acc: 0.5292 - val_loss: 1.8952 - val_acc: 0.2909\n",
      "Epoch 251/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2866 - acc: 0.5083 - val_loss: 1.9254 - val_acc: 0.3091\n",
      "Epoch 252/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2714 - acc: 0.4958 - val_loss: 1.8865 - val_acc: 0.3000\n",
      "Epoch 253/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2369 - acc: 0.5250 - val_loss: 1.8942 - val_acc: 0.3273\n",
      "Epoch 254/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.1972 - acc: 0.5375 - val_loss: 1.8890 - val_acc: 0.3273\n",
      "Epoch 255/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2506 - acc: 0.5208 - val_loss: 1.7891 - val_acc: 0.3182\n",
      "Epoch 256/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.1974 - acc: 0.5500 - val_loss: 1.8313 - val_acc: 0.3545\n",
      "Epoch 257/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.1461 - acc: 0.5583 - val_loss: 1.8461 - val_acc: 0.3636\n",
      "Epoch 258/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.1343 - acc: 0.5417 - val_loss: 1.8316 - val_acc: 0.3545\n",
      "Epoch 259/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0928 - acc: 0.5792 - val_loss: 1.7770 - val_acc: 0.3727\n",
      "Epoch 260/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0796 - acc: 0.5833 - val_loss: 1.8125 - val_acc: 0.3364\n",
      "Epoch 261/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0705 - acc: 0.5875 - val_loss: 1.7544 - val_acc: 0.4000\n",
      "Epoch 262/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0515 - acc: 0.6000 - val_loss: 1.8356 - val_acc: 0.3818\n",
      "Epoch 263/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0081 - acc: 0.6542 - val_loss: 1.7854 - val_acc: 0.3636\n",
      "Epoch 264/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0012 - acc: 0.6333 - val_loss: 1.7416 - val_acc: 0.3818\n",
      "Epoch 265/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0078 - acc: 0.6333 - val_loss: 1.8908 - val_acc: 0.3455\n",
      "Epoch 266/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0086 - acc: 0.6083 - val_loss: 1.8663 - val_acc: 0.3909\n",
      "Epoch 267/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0640 - acc: 0.6292 - val_loss: 1.8150 - val_acc: 0.3455\n",
      "Epoch 268/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0815 - acc: 0.5917 - val_loss: 1.7566 - val_acc: 0.3727\n",
      "Epoch 269/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0333 - acc: 0.6250 - val_loss: 1.6543 - val_acc: 0.4273\n",
      "Epoch 270/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.9490 - acc: 0.6708 - val_loss: 1.7030 - val_acc: 0.4091\n",
      "Epoch 271/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.9298 - acc: 0.6500 - val_loss: 1.6489 - val_acc: 0.4727\n",
      "Epoch 272/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0075 - acc: 0.6083 - val_loss: 1.7033 - val_acc: 0.4000\n",
      "Epoch 273/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.9742 - acc: 0.6583 - val_loss: 1.6942 - val_acc: 0.4545\n",
      "Epoch 274/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0499 - acc: 0.6292 - val_loss: 1.6630 - val_acc: 0.4545\n",
      "Epoch 275/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.9455 - acc: 0.6833 - val_loss: 1.7493 - val_acc: 0.4091\n",
      "Epoch 276/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0374 - acc: 0.6000 - val_loss: 1.8224 - val_acc: 0.3909\n",
      "Epoch 277/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8843 - acc: 0.7083 - val_loss: 1.6936 - val_acc: 0.4091\n",
      "Epoch 278/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8796 - acc: 0.7000 - val_loss: 1.6758 - val_acc: 0.4182\n",
      "Epoch 279/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8340 - acc: 0.7000 - val_loss: 1.6180 - val_acc: 0.4364\n",
      "Epoch 280/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8452 - acc: 0.6917 - val_loss: 1.6779 - val_acc: 0.3727\n",
      "Epoch 281/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.9012 - acc: 0.6542 - val_loss: 1.6476 - val_acc: 0.4455\n",
      "Epoch 282/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8557 - acc: 0.7083 - val_loss: 1.6862 - val_acc: 0.4545\n",
      "Epoch 283/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.8482 - acc: 0.7083 - val_loss: 1.6719 - val_acc: 0.4727\n",
      "Epoch 284/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0637 - acc: 0.6042 - val_loss: 1.7905 - val_acc: 0.4091\n",
      "Epoch 285/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0626 - acc: 0.5833 - val_loss: 1.7507 - val_acc: 0.3909\n",
      "Epoch 286/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0156 - acc: 0.6417 - val_loss: 1.7164 - val_acc: 0.4182\n",
      "Epoch 287/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8881 - acc: 0.6875 - val_loss: 1.6698 - val_acc: 0.4545\n",
      "Epoch 288/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8275 - acc: 0.6917 - val_loss: 1.6898 - val_acc: 0.4545\n",
      "Epoch 289/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8729 - acc: 0.6625 - val_loss: 1.7386 - val_acc: 0.4455\n",
      "Epoch 290/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0075 - acc: 0.6083 - val_loss: 1.9454 - val_acc: 0.3182\n",
      "Epoch 291/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0510 - acc: 0.5625 - val_loss: 1.7619 - val_acc: 0.3455\n",
      "Epoch 292/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.9245 - acc: 0.6792 - val_loss: 1.6880 - val_acc: 0.4364\n",
      "Epoch 293/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8199 - acc: 0.7000 - val_loss: 1.6126 - val_acc: 0.4545\n",
      "Epoch 294/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7761 - acc: 0.7417 - val_loss: 1.5971 - val_acc: 0.4727\n",
      "Epoch 295/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.9396 - acc: 0.6583 - val_loss: 1.5883 - val_acc: 0.4182\n",
      "Epoch 296/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.9544 - acc: 0.6417 - val_loss: 1.6068 - val_acc: 0.4455\n",
      "Epoch 297/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8689 - acc: 0.7042 - val_loss: 1.5027 - val_acc: 0.4636\n",
      "Epoch 298/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8214 - acc: 0.7083 - val_loss: 1.5376 - val_acc: 0.5091\n",
      "Epoch 299/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7736 - acc: 0.7458 - val_loss: 1.5357 - val_acc: 0.4727\n",
      "Epoch 300/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7369 - acc: 0.7625 - val_loss: 1.5125 - val_acc: 0.4909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7083 - acc: 0.7375 - val_loss: 1.5519 - val_acc: 0.4727\n",
      "Epoch 302/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7017 - acc: 0.7500 - val_loss: 1.5308 - val_acc: 0.4636\n",
      "Epoch 303/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7159 - acc: 0.7542 - val_loss: 1.5349 - val_acc: 0.4909\n",
      "Epoch 304/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7087 - acc: 0.7458 - val_loss: 1.5807 - val_acc: 0.4818\n",
      "Epoch 305/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6877 - acc: 0.7708 - val_loss: 1.5648 - val_acc: 0.4818\n",
      "Epoch 306/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7028 - acc: 0.7500 - val_loss: 1.5541 - val_acc: 0.4909\n",
      "Epoch 307/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6860 - acc: 0.7375 - val_loss: 1.5692 - val_acc: 0.4636\n",
      "Epoch 308/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6642 - acc: 0.7625 - val_loss: 1.5367 - val_acc: 0.5091\n",
      "Epoch 309/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6543 - acc: 0.7667 - val_loss: 1.5648 - val_acc: 0.5091\n",
      "Epoch 310/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6838 - acc: 0.7500 - val_loss: 1.6220 - val_acc: 0.4909\n",
      "Epoch 311/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6943 - acc: 0.7375 - val_loss: 1.7118 - val_acc: 0.4545\n",
      "Epoch 312/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6998 - acc: 0.7625 - val_loss: 1.7206 - val_acc: 0.4455\n",
      "Epoch 313/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6685 - acc: 0.7667 - val_loss: 1.5926 - val_acc: 0.5000\n",
      "Epoch 314/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6408 - acc: 0.7792 - val_loss: 1.6048 - val_acc: 0.4727\n",
      "Epoch 315/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6279 - acc: 0.7917 - val_loss: 1.6222 - val_acc: 0.4545\n",
      "Epoch 316/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6212 - acc: 0.7875 - val_loss: 1.6495 - val_acc: 0.4636\n",
      "Epoch 317/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6170 - acc: 0.7917 - val_loss: 1.5806 - val_acc: 0.5182\n",
      "Epoch 318/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6143 - acc: 0.7958 - val_loss: 1.6698 - val_acc: 0.4455\n",
      "Epoch 319/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6018 - acc: 0.7875 - val_loss: 1.6090 - val_acc: 0.4818\n",
      "Epoch 320/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5966 - acc: 0.8000 - val_loss: 1.6902 - val_acc: 0.4364\n",
      "Epoch 321/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5949 - acc: 0.7875 - val_loss: 1.6467 - val_acc: 0.5000\n",
      "Epoch 322/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5921 - acc: 0.7833 - val_loss: 1.7022 - val_acc: 0.4636\n",
      "Epoch 323/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5872 - acc: 0.7958 - val_loss: 1.6298 - val_acc: 0.4909\n",
      "Epoch 324/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5824 - acc: 0.7917 - val_loss: 1.7073 - val_acc: 0.4545\n",
      "Epoch 325/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6359 - acc: 0.7708 - val_loss: 1.6739 - val_acc: 0.4909\n",
      "Epoch 326/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5991 - acc: 0.7833 - val_loss: 1.6049 - val_acc: 0.4727\n",
      "Epoch 327/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5871 - acc: 0.7917 - val_loss: 1.7288 - val_acc: 0.4364\n",
      "Epoch 328/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6343 - acc: 0.7708 - val_loss: 1.6959 - val_acc: 0.4636\n",
      "Epoch 329/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6275 - acc: 0.7667 - val_loss: 1.8801 - val_acc: 0.4455\n",
      "Epoch 330/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6170 - acc: 0.7792 - val_loss: 1.8331 - val_acc: 0.4636\n",
      "Epoch 331/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6183 - acc: 0.7708 - val_loss: 1.8032 - val_acc: 0.4455\n",
      "Epoch 332/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5891 - acc: 0.7833 - val_loss: 1.7611 - val_acc: 0.4636\n",
      "Epoch 333/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5873 - acc: 0.7833 - val_loss: 1.8303 - val_acc: 0.4636\n",
      "Epoch 334/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.6035 - acc: 0.7833 - val_loss: 1.9318 - val_acc: 0.4364\n",
      "Epoch 335/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6242 - acc: 0.7792 - val_loss: 1.7993 - val_acc: 0.5000\n",
      "Epoch 336/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6108 - acc: 0.7917 - val_loss: 1.8217 - val_acc: 0.5000\n",
      "Epoch 337/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7405 - acc: 0.7292 - val_loss: 1.7467 - val_acc: 0.4727\n",
      "Epoch 338/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7138 - acc: 0.7417 - val_loss: 1.7841 - val_acc: 0.5091\n",
      "Epoch 339/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6239 - acc: 0.7750 - val_loss: 1.7346 - val_acc: 0.4545\n",
      "Epoch 340/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6006 - acc: 0.7792 - val_loss: 1.7102 - val_acc: 0.4455\n",
      "Epoch 341/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5713 - acc: 0.8000 - val_loss: 1.7381 - val_acc: 0.4727\n",
      "Epoch 342/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5911 - acc: 0.7792 - val_loss: 1.7399 - val_acc: 0.4364\n",
      "Epoch 343/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6411 - acc: 0.7583 - val_loss: 1.6585 - val_acc: 0.5000\n",
      "Epoch 344/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5836 - acc: 0.8000 - val_loss: 1.7068 - val_acc: 0.4818\n",
      "Epoch 345/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5621 - acc: 0.7875 - val_loss: 1.7475 - val_acc: 0.4727\n",
      "Epoch 346/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5777 - acc: 0.7958 - val_loss: 1.7940 - val_acc: 0.4909\n",
      "Epoch 347/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5556 - acc: 0.8042 - val_loss: 1.7664 - val_acc: 0.4727\n",
      "Epoch 348/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5421 - acc: 0.7792 - val_loss: 1.7828 - val_acc: 0.4636\n",
      "Epoch 349/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5368 - acc: 0.8042 - val_loss: 1.7828 - val_acc: 0.4545\n",
      "Epoch 350/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5313 - acc: 0.7958 - val_loss: 1.7228 - val_acc: 0.5000\n",
      "Epoch 351/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5263 - acc: 0.8000 - val_loss: 1.7711 - val_acc: 0.4909\n",
      "Epoch 352/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5255 - acc: 0.7917 - val_loss: 1.8095 - val_acc: 0.4636\n",
      "Epoch 353/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5197 - acc: 0.8042 - val_loss: 1.7901 - val_acc: 0.4818\n",
      "Epoch 354/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5338 - acc: 0.7958 - val_loss: 1.8820 - val_acc: 0.4545\n",
      "Epoch 355/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5220 - acc: 0.7833 - val_loss: 1.7842 - val_acc: 0.4727\n",
      "Epoch 356/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5208 - acc: 0.7958 - val_loss: 1.8036 - val_acc: 0.4727\n",
      "Epoch 357/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5191 - acc: 0.7958 - val_loss: 1.8402 - val_acc: 0.4545\n",
      "Epoch 358/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5150 - acc: 0.7917 - val_loss: 1.7849 - val_acc: 0.4727\n",
      "Epoch 359/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5136 - acc: 0.7958 - val_loss: 1.7782 - val_acc: 0.4818\n",
      "Epoch 360/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5273 - acc: 0.7833 - val_loss: 1.8346 - val_acc: 0.4818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5364 - acc: 0.7917 - val_loss: 1.9489 - val_acc: 0.4727\n",
      "Epoch 362/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7553 - acc: 0.7292 - val_loss: 1.7924 - val_acc: 0.5000\n",
      "Epoch 363/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2040 - acc: 0.5833 - val_loss: 2.0393 - val_acc: 0.3818\n",
      "Epoch 364/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0361 - acc: 0.6000 - val_loss: 1.9381 - val_acc: 0.4545\n",
      "Epoch 365/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8496 - acc: 0.7042 - val_loss: 1.8501 - val_acc: 0.4636\n",
      "Epoch 366/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7763 - acc: 0.7375 - val_loss: 1.7737 - val_acc: 0.4273\n",
      "Epoch 367/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8135 - acc: 0.7333 - val_loss: 1.6639 - val_acc: 0.4818\n",
      "Epoch 368/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7217 - acc: 0.7583 - val_loss: 1.5913 - val_acc: 0.4909\n",
      "Epoch 369/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6634 - acc: 0.7708 - val_loss: 1.5734 - val_acc: 0.5182\n",
      "Epoch 370/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6192 - acc: 0.7750 - val_loss: 1.6338 - val_acc: 0.5091\n",
      "Epoch 371/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5878 - acc: 0.7917 - val_loss: 1.6252 - val_acc: 0.5364\n",
      "Epoch 372/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5782 - acc: 0.7708 - val_loss: 1.5926 - val_acc: 0.5273\n",
      "Epoch 373/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5719 - acc: 0.7833 - val_loss: 1.5952 - val_acc: 0.5273\n",
      "Epoch 374/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5756 - acc: 0.7792 - val_loss: 1.5629 - val_acc: 0.5455\n",
      "Epoch 375/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5648 - acc: 0.7875 - val_loss: 1.5746 - val_acc: 0.5455\n",
      "Epoch 376/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5600 - acc: 0.8000 - val_loss: 1.5659 - val_acc: 0.5545\n",
      "Epoch 377/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5483 - acc: 0.7958 - val_loss: 1.5182 - val_acc: 0.5636\n",
      "Epoch 378/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5339 - acc: 0.7958 - val_loss: 1.4999 - val_acc: 0.5727\n",
      "Epoch 379/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.5264 - acc: 0.7958 - val_loss: 1.5412 - val_acc: 0.5545\n",
      "Epoch 380/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5250 - acc: 0.7917 - val_loss: 1.5333 - val_acc: 0.5545\n",
      "Epoch 381/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5241 - acc: 0.8083 - val_loss: 1.5374 - val_acc: 0.5636\n",
      "Epoch 382/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5207 - acc: 0.7917 - val_loss: 1.5469 - val_acc: 0.5818\n",
      "Epoch 383/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5204 - acc: 0.8042 - val_loss: 1.5394 - val_acc: 0.5727\n",
      "Epoch 384/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5173 - acc: 0.8083 - val_loss: 1.5134 - val_acc: 0.5727\n",
      "Epoch 385/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5200 - acc: 0.8000 - val_loss: 1.7598 - val_acc: 0.5091\n",
      "Epoch 386/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5521 - acc: 0.7875 - val_loss: 1.7000 - val_acc: 0.4909\n",
      "Epoch 387/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.5538 - acc: 0.7958 - val_loss: 1.6339 - val_acc: 0.5182\n",
      "Epoch 388/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5526 - acc: 0.7917 - val_loss: 1.6077 - val_acc: 0.5182\n",
      "Epoch 389/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8005 - acc: 0.7083 - val_loss: 1.8477 - val_acc: 0.4545\n",
      "Epoch 390/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7944 - acc: 0.7167 - val_loss: 1.8271 - val_acc: 0.4182\n",
      "Epoch 391/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.9912 - acc: 0.3083 - val_loss: 2.5189 - val_acc: 0.2273\n",
      "Epoch 392/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.1150 - acc: 0.2583 - val_loss: 2.1030 - val_acc: 0.2364\n",
      "Epoch 393/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6652 - acc: 0.3833 - val_loss: 1.9455 - val_acc: 0.3091\n",
      "Epoch 394/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5146 - acc: 0.4333 - val_loss: 1.8246 - val_acc: 0.3364\n",
      "Epoch 395/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5964 - acc: 0.3750 - val_loss: 2.2384 - val_acc: 0.2182\n",
      "Epoch 396/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6821 - acc: 0.4000 - val_loss: 1.8219 - val_acc: 0.3273\n",
      "Epoch 397/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.9614 - acc: 0.3458 - val_loss: 2.4316 - val_acc: 0.2091\n",
      "Epoch 398/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.9386 - acc: 0.3292 - val_loss: 2.1040 - val_acc: 0.2455\n",
      "Epoch 399/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.9018 - acc: 0.2708 - val_loss: 2.0293 - val_acc: 0.2818\n",
      "Epoch 400/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.8450 - acc: 0.3083 - val_loss: 2.0602 - val_acc: 0.1727\n",
      "Epoch 401/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.1094 - acc: 0.2958 - val_loss: 2.3350 - val_acc: 0.1727\n",
      "Epoch 402/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.1155 - acc: 0.2250 - val_loss: 2.1604 - val_acc: 0.1909\n",
      "Epoch 403/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.9679 - acc: 0.2792 - val_loss: 2.1017 - val_acc: 0.2091\n",
      "Epoch 404/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.8972 - acc: 0.3083 - val_loss: 2.0382 - val_acc: 0.2545\n",
      "Epoch 405/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.8223 - acc: 0.3458 - val_loss: 1.9688 - val_acc: 0.2636\n",
      "Epoch 406/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7611 - acc: 0.3750 - val_loss: 1.9234 - val_acc: 0.3364\n",
      "Epoch 407/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.7155 - acc: 0.3958 - val_loss: 1.9118 - val_acc: 0.3000\n",
      "Epoch 408/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6952 - acc: 0.3708 - val_loss: 1.9540 - val_acc: 0.3000\n",
      "Epoch 409/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6155 - acc: 0.4292 - val_loss: 1.8897 - val_acc: 0.3818\n",
      "Epoch 410/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.5715 - acc: 0.4500 - val_loss: 1.8483 - val_acc: 0.3636\n",
      "Epoch 411/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5616 - acc: 0.4292 - val_loss: 1.8206 - val_acc: 0.3455\n",
      "Epoch 412/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.5499 - acc: 0.4667 - val_loss: 1.7757 - val_acc: 0.3455\n",
      "Epoch 413/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.4767 - acc: 0.4958 - val_loss: 1.7727 - val_acc: 0.3455\n",
      "Epoch 414/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4651 - acc: 0.4792 - val_loss: 1.7528 - val_acc: 0.3545\n",
      "Epoch 415/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.4206 - acc: 0.5000 - val_loss: 1.7475 - val_acc: 0.3545\n",
      "Epoch 416/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3240 - acc: 0.5500 - val_loss: 1.8201 - val_acc: 0.2818\n",
      "Epoch 417/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3899 - acc: 0.5125 - val_loss: 1.8134 - val_acc: 0.3182\n",
      "Epoch 418/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3419 - acc: 0.4958 - val_loss: 1.7458 - val_acc: 0.3727\n",
      "Epoch 419/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2581 - acc: 0.5792 - val_loss: 1.6935 - val_acc: 0.4091\n",
      "Epoch 420/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2190 - acc: 0.6042 - val_loss: 1.7954 - val_acc: 0.3909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3047 - acc: 0.5792 - val_loss: 1.6761 - val_acc: 0.4273\n",
      "Epoch 422/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.1823 - acc: 0.6042 - val_loss: 1.6571 - val_acc: 0.4091\n",
      "Epoch 423/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.1460 - acc: 0.6083 - val_loss: 1.6255 - val_acc: 0.4182\n",
      "Epoch 424/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.1483 - acc: 0.5917 - val_loss: 1.8097 - val_acc: 0.3545\n",
      "Epoch 425/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2672 - acc: 0.5167 - val_loss: 1.5283 - val_acc: 0.4273\n",
      "Epoch 426/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2421 - acc: 0.5375 - val_loss: 1.7206 - val_acc: 0.3727\n",
      "Epoch 427/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2216 - acc: 0.5750 - val_loss: 1.7585 - val_acc: 0.3636\n",
      "Epoch 428/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2622 - acc: 0.5542 - val_loss: 1.7684 - val_acc: 0.3909\n",
      "Epoch 429/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2135 - acc: 0.5500 - val_loss: 1.7207 - val_acc: 0.3818\n",
      "Epoch 430/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.1021 - acc: 0.6292 - val_loss: 1.6168 - val_acc: 0.4091\n",
      "Epoch 431/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0161 - acc: 0.6625 - val_loss: 1.5208 - val_acc: 0.4545\n",
      "Epoch 432/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.9807 - acc: 0.7125 - val_loss: 1.5049 - val_acc: 0.4182\n",
      "Epoch 433/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.9630 - acc: 0.6708 - val_loss: 1.6450 - val_acc: 0.3727\n",
      "Epoch 434/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.9697 - acc: 0.6625 - val_loss: 1.6960 - val_acc: 0.4182\n",
      "Epoch 435/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.9603 - acc: 0.6542 - val_loss: 1.5272 - val_acc: 0.4545\n",
      "Epoch 436/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8733 - acc: 0.7042 - val_loss: 1.4617 - val_acc: 0.4909\n",
      "Epoch 437/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8356 - acc: 0.7375 - val_loss: 1.4925 - val_acc: 0.4455\n",
      "Epoch 438/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8062 - acc: 0.7542 - val_loss: 1.4257 - val_acc: 0.4727\n",
      "Epoch 439/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.7855 - acc: 0.7208 - val_loss: 1.5282 - val_acc: 0.4636\n",
      "Epoch 440/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8657 - acc: 0.6875 - val_loss: 1.5409 - val_acc: 0.4545\n",
      "Epoch 441/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0153 - acc: 0.6792 - val_loss: 2.4856 - val_acc: 0.2636\n",
      "Epoch 442/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.9913 - acc: 0.3292 - val_loss: 2.2644 - val_acc: 0.2636\n",
      "Epoch 443/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.7369 - acc: 0.3542 - val_loss: 1.8682 - val_acc: 0.3455\n",
      "Epoch 444/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.4883 - acc: 0.4667 - val_loss: 1.7478 - val_acc: 0.3545\n",
      "Epoch 445/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3648 - acc: 0.5125 - val_loss: 1.7513 - val_acc: 0.3455\n",
      "Epoch 446/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2489 - acc: 0.5417 - val_loss: 1.6652 - val_acc: 0.4000\n",
      "Epoch 447/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.1919 - acc: 0.5500 - val_loss: 1.7069 - val_acc: 0.3909\n",
      "Epoch 448/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.1586 - acc: 0.5542 - val_loss: 1.6360 - val_acc: 0.3909\n",
      "Epoch 449/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.1351 - acc: 0.5750 - val_loss: 1.6627 - val_acc: 0.4000\n",
      "Epoch 450/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0982 - acc: 0.5750 - val_loss: 1.6670 - val_acc: 0.3818\n",
      "Epoch 451/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0488 - acc: 0.6375 - val_loss: 1.5969 - val_acc: 0.3727\n",
      "Epoch 452/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0363 - acc: 0.6292 - val_loss: 1.5736 - val_acc: 0.4091\n",
      "Epoch 453/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0333 - acc: 0.6208 - val_loss: 1.5836 - val_acc: 0.4000\n",
      "Epoch 454/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.9636 - acc: 0.6667 - val_loss: 1.5896 - val_acc: 0.4182\n",
      "Epoch 455/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.9249 - acc: 0.6792 - val_loss: 1.5528 - val_acc: 0.3909\n",
      "Epoch 456/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.9265 - acc: 0.7000 - val_loss: 1.5984 - val_acc: 0.4364\n",
      "Epoch 457/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8943 - acc: 0.7125 - val_loss: 1.5846 - val_acc: 0.4364\n",
      "Epoch 458/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8666 - acc: 0.7042 - val_loss: 1.5281 - val_acc: 0.4545\n",
      "Epoch 459/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8650 - acc: 0.6958 - val_loss: 1.5860 - val_acc: 0.4455\n",
      "Epoch 460/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8809 - acc: 0.6750 - val_loss: 1.4482 - val_acc: 0.4818\n",
      "Epoch 461/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8730 - acc: 0.6875 - val_loss: 1.5386 - val_acc: 0.4636\n",
      "Epoch 462/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8215 - acc: 0.6958 - val_loss: 1.5145 - val_acc: 0.4364\n",
      "Epoch 463/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8689 - acc: 0.7083 - val_loss: 1.6110 - val_acc: 0.4273\n",
      "Epoch 464/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7970 - acc: 0.7500 - val_loss: 1.6623 - val_acc: 0.4364\n",
      "Epoch 465/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.7735 - acc: 0.7458 - val_loss: 1.5275 - val_acc: 0.4818\n",
      "Epoch 466/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7373 - acc: 0.7667 - val_loss: 1.5861 - val_acc: 0.4909\n",
      "Epoch 467/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7655 - acc: 0.7500 - val_loss: 1.6199 - val_acc: 0.4000\n",
      "Epoch 468/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.9822 - acc: 0.6458 - val_loss: 1.5849 - val_acc: 0.4636\n",
      "Epoch 469/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.9084 - acc: 0.6667 - val_loss: 1.4760 - val_acc: 0.4455\n",
      "Epoch 470/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8473 - acc: 0.7000 - val_loss: 1.6505 - val_acc: 0.4182\n",
      "Epoch 471/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.1883 - acc: 0.5542 - val_loss: 1.7470 - val_acc: 0.3909\n",
      "Epoch 472/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0309 - acc: 0.5958 - val_loss: 1.5169 - val_acc: 0.4273\n",
      "Epoch 473/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.9344 - acc: 0.6708 - val_loss: 1.7939 - val_acc: 0.4091\n",
      "Epoch 474/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.1480 - acc: 0.5708 - val_loss: 1.3790 - val_acc: 0.5000\n",
      "Epoch 475/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0312 - acc: 0.6542 - val_loss: 1.3979 - val_acc: 0.4273\n",
      "Epoch 476/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8612 - acc: 0.7083 - val_loss: 1.5745 - val_acc: 0.4455\n",
      "Epoch 477/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8121 - acc: 0.7333 - val_loss: 1.4869 - val_acc: 0.4636\n",
      "Epoch 478/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7255 - acc: 0.7333 - val_loss: 1.4985 - val_acc: 0.4545\n",
      "Epoch 479/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6821 - acc: 0.7500 - val_loss: 1.6072 - val_acc: 0.4727\n",
      "Epoch 480/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6560 - acc: 0.7625 - val_loss: 1.5839 - val_acc: 0.4727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6418 - acc: 0.7708 - val_loss: 1.7594 - val_acc: 0.4545\n",
      "Epoch 482/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6647 - acc: 0.7625 - val_loss: 1.7984 - val_acc: 0.4545\n",
      "Epoch 483/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.6664 - acc: 0.7417 - val_loss: 1.4748 - val_acc: 0.5000\n",
      "Epoch 484/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6159 - acc: 0.7667 - val_loss: 1.4507 - val_acc: 0.5091\n",
      "Epoch 485/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5957 - acc: 0.8000 - val_loss: 1.6227 - val_acc: 0.5091\n",
      "Epoch 486/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5879 - acc: 0.7833 - val_loss: 1.6294 - val_acc: 0.5000\n",
      "Epoch 487/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5716 - acc: 0.8083 - val_loss: 1.5040 - val_acc: 0.4818\n",
      "Epoch 488/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.9399 - acc: 0.7292 - val_loss: 2.3380 - val_acc: 0.3818\n",
      "Epoch 489/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.6961 - acc: 0.4917 - val_loss: 1.8297 - val_acc: 0.3909\n",
      "Epoch 490/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2454 - acc: 0.5792 - val_loss: 1.6372 - val_acc: 0.4727\n",
      "Epoch 491/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.5565 - acc: 0.4667 - val_loss: 2.2046 - val_acc: 0.2818\n",
      "Epoch 492/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.3296 - acc: 0.5458 - val_loss: 1.5777 - val_acc: 0.4909\n",
      "Epoch 493/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0799 - acc: 0.6125 - val_loss: 1.4966 - val_acc: 0.5091\n",
      "Epoch 494/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.0220 - acc: 0.6542 - val_loss: 1.4567 - val_acc: 0.4909\n",
      "Epoch 495/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.9354 - acc: 0.6875 - val_loss: 1.4098 - val_acc: 0.5182\n",
      "Epoch 496/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8831 - acc: 0.7000 - val_loss: 1.3796 - val_acc: 0.5364\n",
      "Epoch 497/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.8414 - acc: 0.7208 - val_loss: 1.3977 - val_acc: 0.5091\n",
      "Epoch 498/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8149 - acc: 0.7125 - val_loss: 1.3909 - val_acc: 0.5182\n",
      "Epoch 499/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7752 - acc: 0.7333 - val_loss: 1.3894 - val_acc: 0.5273\n",
      "Epoch 500/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7460 - acc: 0.7417 - val_loss: 1.3712 - val_acc: 0.5364\n",
      "Epoch 501/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7367 - acc: 0.7458 - val_loss: 1.3899 - val_acc: 0.5091\n",
      "Epoch 502/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.7144 - acc: 0.7667 - val_loss: 1.3900 - val_acc: 0.5273\n",
      "Epoch 503/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7028 - acc: 0.7667 - val_loss: 1.4001 - val_acc: 0.5091\n",
      "Epoch 504/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6904 - acc: 0.7667 - val_loss: 1.4011 - val_acc: 0.5182\n",
      "Epoch 505/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.6799 - acc: 0.7792 - val_loss: 1.3906 - val_acc: 0.5091\n",
      "Epoch 506/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6741 - acc: 0.7667 - val_loss: 1.4059 - val_acc: 0.5091\n",
      "Epoch 507/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6592 - acc: 0.7833 - val_loss: 1.4222 - val_acc: 0.5091\n",
      "Epoch 508/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6477 - acc: 0.7708 - val_loss: 1.3860 - val_acc: 0.5273\n",
      "Epoch 509/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6412 - acc: 0.7833 - val_loss: 1.4155 - val_acc: 0.5273\n",
      "Epoch 510/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6340 - acc: 0.7833 - val_loss: 1.4181 - val_acc: 0.5091\n",
      "Epoch 511/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6224 - acc: 0.7917 - val_loss: 1.4099 - val_acc: 0.5273\n",
      "Epoch 512/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6124 - acc: 0.7750 - val_loss: 1.4100 - val_acc: 0.5364\n",
      "Epoch 513/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6081 - acc: 0.7875 - val_loss: 1.4236 - val_acc: 0.5455\n",
      "Epoch 514/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6073 - acc: 0.7917 - val_loss: 1.4171 - val_acc: 0.5364\n",
      "Epoch 515/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5922 - acc: 0.7875 - val_loss: 1.3872 - val_acc: 0.5636\n",
      "Epoch 516/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5956 - acc: 0.8000 - val_loss: 1.3749 - val_acc: 0.5273\n",
      "Epoch 517/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6905 - acc: 0.7708 - val_loss: 1.3354 - val_acc: 0.5364\n",
      "Epoch 518/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6209 - acc: 0.7917 - val_loss: 1.3516 - val_acc: 0.5364\n",
      "Epoch 519/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5908 - acc: 0.7917 - val_loss: 1.3410 - val_acc: 0.5182\n",
      "Epoch 520/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5769 - acc: 0.8042 - val_loss: 1.3307 - val_acc: 0.5455\n",
      "Epoch 521/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5671 - acc: 0.8083 - val_loss: 1.3346 - val_acc: 0.5455\n",
      "Epoch 522/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5584 - acc: 0.8042 - val_loss: 1.3452 - val_acc: 0.5545\n",
      "Epoch 523/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.5497 - acc: 0.8083 - val_loss: 1.3604 - val_acc: 0.5364\n",
      "Epoch 524/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5456 - acc: 0.8083 - val_loss: 1.3863 - val_acc: 0.5182\n",
      "Epoch 525/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5436 - acc: 0.8000 - val_loss: 1.4089 - val_acc: 0.5364\n",
      "Epoch 526/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5362 - acc: 0.8083 - val_loss: 1.4299 - val_acc: 0.5273\n",
      "Epoch 527/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5334 - acc: 0.8125 - val_loss: 1.4399 - val_acc: 0.5455\n",
      "Epoch 528/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.5284 - acc: 0.8167 - val_loss: 1.4552 - val_acc: 0.5273\n",
      "Epoch 529/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5256 - acc: 0.8125 - val_loss: 1.4540 - val_acc: 0.5455\n",
      "Epoch 530/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5223 - acc: 0.8167 - val_loss: 1.4590 - val_acc: 0.5455\n",
      "Epoch 531/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5179 - acc: 0.8042 - val_loss: 1.4838 - val_acc: 0.5455\n",
      "Epoch 532/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5140 - acc: 0.8000 - val_loss: 1.4656 - val_acc: 0.5273\n",
      "Epoch 533/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5099 - acc: 0.8208 - val_loss: 1.4854 - val_acc: 0.5364\n",
      "Epoch 534/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5079 - acc: 0.8000 - val_loss: 1.4862 - val_acc: 0.5545\n",
      "Epoch 535/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5059 - acc: 0.8125 - val_loss: 1.4902 - val_acc: 0.5545\n",
      "Epoch 536/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5090 - acc: 0.8125 - val_loss: 1.4559 - val_acc: 0.5636\n",
      "Epoch 537/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5289 - acc: 0.7917 - val_loss: 1.5161 - val_acc: 0.5636\n",
      "Epoch 538/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5248 - acc: 0.8167 - val_loss: 1.5101 - val_acc: 0.5364\n",
      "Epoch 539/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5094 - acc: 0.8125 - val_loss: 1.5130 - val_acc: 0.5364\n",
      "Epoch 540/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5161 - acc: 0.8000 - val_loss: 1.5015 - val_acc: 0.5545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5034 - acc: 0.8167 - val_loss: 1.5340 - val_acc: 0.5273\n",
      "Epoch 542/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4978 - acc: 0.8167 - val_loss: 1.5424 - val_acc: 0.5455\n",
      "Epoch 543/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4897 - acc: 0.8250 - val_loss: 1.5923 - val_acc: 0.5455\n",
      "Epoch 544/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4905 - acc: 0.8083 - val_loss: 1.5935 - val_acc: 0.5455\n",
      "Epoch 545/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4862 - acc: 0.8250 - val_loss: 1.5958 - val_acc: 0.5545\n",
      "Epoch 546/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4824 - acc: 0.8208 - val_loss: 1.5896 - val_acc: 0.5545\n",
      "Epoch 547/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4804 - acc: 0.8167 - val_loss: 1.6012 - val_acc: 0.5545\n",
      "Epoch 548/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4783 - acc: 0.8208 - val_loss: 1.6004 - val_acc: 0.5364\n",
      "Epoch 549/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4780 - acc: 0.8250 - val_loss: 1.6075 - val_acc: 0.5364\n",
      "Epoch 550/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4766 - acc: 0.8083 - val_loss: 1.6119 - val_acc: 0.5545\n",
      "Epoch 551/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4760 - acc: 0.8250 - val_loss: 1.5805 - val_acc: 0.5636\n",
      "Epoch 552/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4765 - acc: 0.8125 - val_loss: 1.6075 - val_acc: 0.5636\n",
      "Epoch 553/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4751 - acc: 0.8208 - val_loss: 1.6436 - val_acc: 0.5364\n",
      "Epoch 554/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4712 - acc: 0.8083 - val_loss: 1.6009 - val_acc: 0.5455\n",
      "Epoch 555/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4713 - acc: 0.8208 - val_loss: 1.6232 - val_acc: 0.5455\n",
      "Epoch 556/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4695 - acc: 0.8167 - val_loss: 1.6436 - val_acc: 0.5636\n",
      "Epoch 557/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4680 - acc: 0.8167 - val_loss: 1.6629 - val_acc: 0.5545\n",
      "Epoch 558/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4690 - acc: 0.8250 - val_loss: 1.6393 - val_acc: 0.5636\n",
      "Epoch 559/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4667 - acc: 0.8167 - val_loss: 1.6594 - val_acc: 0.5455\n",
      "Epoch 560/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4644 - acc: 0.8292 - val_loss: 1.6681 - val_acc: 0.5364\n",
      "Epoch 561/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4653 - acc: 0.8083 - val_loss: 1.6893 - val_acc: 0.5273\n",
      "Epoch 562/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4631 - acc: 0.8292 - val_loss: 1.6925 - val_acc: 0.5455\n",
      "Epoch 563/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4650 - acc: 0.8167 - val_loss: 1.6885 - val_acc: 0.5273\n",
      "Epoch 564/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4640 - acc: 0.8292 - val_loss: 1.6881 - val_acc: 0.5364\n",
      "Epoch 565/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4617 - acc: 0.8125 - val_loss: 1.6979 - val_acc: 0.5545\n",
      "Epoch 566/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4616 - acc: 0.8292 - val_loss: 1.6966 - val_acc: 0.5545\n",
      "Epoch 567/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4877 - acc: 0.8125 - val_loss: 1.7092 - val_acc: 0.5091\n",
      "Epoch 568/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5150 - acc: 0.7917 - val_loss: 1.6956 - val_acc: 0.5455\n",
      "Epoch 569/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.6671 - acc: 0.7583 - val_loss: 1.4677 - val_acc: 0.5273\n",
      "Epoch 570/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6098 - acc: 0.7958 - val_loss: 1.4769 - val_acc: 0.5545\n",
      "Epoch 571/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6402 - acc: 0.7542 - val_loss: 1.5647 - val_acc: 0.5455\n",
      "Epoch 572/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6208 - acc: 0.7625 - val_loss: 1.6215 - val_acc: 0.5636\n",
      "Epoch 573/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5732 - acc: 0.8042 - val_loss: 1.6239 - val_acc: 0.5545\n",
      "Epoch 574/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5332 - acc: 0.8000 - val_loss: 1.5898 - val_acc: 0.5727\n",
      "Epoch 575/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5420 - acc: 0.8083 - val_loss: 1.6159 - val_acc: 0.5545\n",
      "Epoch 576/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5261 - acc: 0.8125 - val_loss: 1.5997 - val_acc: 0.5727\n",
      "Epoch 577/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5127 - acc: 0.8167 - val_loss: 1.6009 - val_acc: 0.5364\n",
      "Epoch 578/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5050 - acc: 0.8208 - val_loss: 1.5383 - val_acc: 0.5545\n",
      "Epoch 579/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4982 - acc: 0.8208 - val_loss: 1.6034 - val_acc: 0.5455\n",
      "Epoch 580/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4981 - acc: 0.8167 - val_loss: 1.5561 - val_acc: 0.5636\n",
      "Epoch 581/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4912 - acc: 0.8208 - val_loss: 1.5564 - val_acc: 0.5727\n",
      "Epoch 582/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4893 - acc: 0.8083 - val_loss: 1.5672 - val_acc: 0.5273\n",
      "Epoch 583/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4842 - acc: 0.8125 - val_loss: 1.5482 - val_acc: 0.5545\n",
      "Epoch 584/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4826 - acc: 0.8208 - val_loss: 1.5567 - val_acc: 0.5636\n",
      "Epoch 585/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4809 - acc: 0.8208 - val_loss: 1.5633 - val_acc: 0.5545\n",
      "Epoch 586/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4809 - acc: 0.8125 - val_loss: 1.5434 - val_acc: 0.5364\n",
      "Epoch 587/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4793 - acc: 0.8167 - val_loss: 1.5435 - val_acc: 0.5636\n",
      "Epoch 588/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4770 - acc: 0.8208 - val_loss: 1.5440 - val_acc: 0.5636\n",
      "Epoch 589/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4765 - acc: 0.8250 - val_loss: 1.5530 - val_acc: 0.5636\n",
      "Epoch 590/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4758 - acc: 0.8208 - val_loss: 1.5741 - val_acc: 0.5545\n",
      "Epoch 591/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.4724 - acc: 0.8208 - val_loss: 1.5793 - val_acc: 0.5364\n",
      "Epoch 592/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4727 - acc: 0.8167 - val_loss: 1.6147 - val_acc: 0.5545\n",
      "Epoch 593/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.4735 - acc: 0.8042 - val_loss: 1.6110 - val_acc: 0.5364\n",
      "Epoch 594/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.4719 - acc: 0.8208 - val_loss: 1.6525 - val_acc: 0.5545\n",
      "Epoch 595/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.4740 - acc: 0.8042 - val_loss: 1.6534 - val_acc: 0.5455\n",
      "Epoch 596/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4686 - acc: 0.8167 - val_loss: 1.6593 - val_acc: 0.5364\n",
      "Epoch 597/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4699 - acc: 0.8167 - val_loss: 1.6679 - val_acc: 0.5545\n",
      "Epoch 598/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4710 - acc: 0.8083 - val_loss: 1.6767 - val_acc: 0.5273\n",
      "Epoch 599/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4702 - acc: 0.8125 - val_loss: 1.6728 - val_acc: 0.5545\n",
      "Epoch 600/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4690 - acc: 0.8167 - val_loss: 1.6888 - val_acc: 0.5455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4661 - acc: 0.8125 - val_loss: 1.6836 - val_acc: 0.5455\n",
      "Epoch 602/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4672 - acc: 0.8208 - val_loss: 1.6585 - val_acc: 0.5636\n",
      "Epoch 603/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4669 - acc: 0.8208 - val_loss: 1.6569 - val_acc: 0.5455\n",
      "Epoch 604/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4664 - acc: 0.8125 - val_loss: 1.7070 - val_acc: 0.5455\n",
      "Epoch 605/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4660 - acc: 0.8125 - val_loss: 1.6949 - val_acc: 0.5545\n",
      "Epoch 606/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.4663 - acc: 0.8083 - val_loss: 1.7271 - val_acc: 0.5273\n",
      "Epoch 607/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4656 - acc: 0.8083 - val_loss: 1.7030 - val_acc: 0.5636\n",
      "Epoch 608/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4625 - acc: 0.8208 - val_loss: 1.7217 - val_acc: 0.5636\n",
      "Epoch 609/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.4654 - acc: 0.8125 - val_loss: 1.7277 - val_acc: 0.5455\n",
      "Epoch 610/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4637 - acc: 0.8083 - val_loss: 1.7214 - val_acc: 0.5636\n",
      "Epoch 611/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4616 - acc: 0.7958 - val_loss: 1.7560 - val_acc: 0.5182\n",
      "Epoch 612/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4615 - acc: 0.8167 - val_loss: 1.7812 - val_acc: 0.5455\n",
      "Epoch 613/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.4602 - acc: 0.8125 - val_loss: 1.7577 - val_acc: 0.5545\n",
      "Epoch 614/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.4606 - acc: 0.8208 - val_loss: 1.7811 - val_acc: 0.5273\n",
      "Epoch 615/1000\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.4576 - acc: 0.8250 - val_loss: 1.7808 - val_acc: 0.5364\n",
      "Epoch 616/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.4579 - acc: 0.8208 - val_loss: 1.7961 - val_acc: 0.5364\n",
      "Epoch 617/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.4582 - acc: 0.8083 - val_loss: 1.7874 - val_acc: 0.5455\n",
      "Epoch 618/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.4591 - acc: 0.8208 - val_loss: 1.8411 - val_acc: 0.5455\n",
      "Epoch 619/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4556 - acc: 0.8167 - val_loss: 1.8371 - val_acc: 0.5455\n",
      "Epoch 620/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4553 - acc: 0.8167 - val_loss: 1.8207 - val_acc: 0.5545\n",
      "Epoch 621/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4551 - acc: 0.8208 - val_loss: 1.8353 - val_acc: 0.5545\n",
      "Epoch 622/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4557 - acc: 0.8167 - val_loss: 1.8241 - val_acc: 0.5545\n",
      "Epoch 623/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4534 - acc: 0.8208 - val_loss: 1.8600 - val_acc: 0.5364\n",
      "Epoch 624/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4609 - acc: 0.8167 - val_loss: 1.8756 - val_acc: 0.5273\n",
      "Epoch 625/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4821 - acc: 0.8167 - val_loss: 1.8575 - val_acc: 0.5545\n",
      "Epoch 626/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.4632 - acc: 0.8167 - val_loss: 1.8279 - val_acc: 0.5455\n",
      "Epoch 627/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6349 - acc: 0.7583 - val_loss: 1.8797 - val_acc: 0.4818\n",
      "Epoch 628/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8297 - acc: 0.7208 - val_loss: 1.6047 - val_acc: 0.5182\n",
      "Epoch 629/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7818 - acc: 0.7208 - val_loss: 1.5335 - val_acc: 0.5091\n",
      "Epoch 630/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.6662 - acc: 0.7458 - val_loss: 1.4555 - val_acc: 0.5273\n",
      "Epoch 631/1000\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.6861 - acc: 0.7583 - val_loss: 1.3180 - val_acc: 0.5636\n",
      "Epoch 632/1000\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.5797 - acc: 0.8042 - val_loss: 1.2587 - val_acc: 0.6091\n",
      "Epoch 633/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.5250 - acc: 0.8125 - val_loss: 1.2631 - val_acc: 0.5727\n",
      "Epoch 634/1000\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.5085 - acc: 0.8000 - val_loss: 1.2644 - val_acc: 0.5909\n",
      "Epoch 635/1000\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.4907 - acc: 0.8167 - val_loss: 1.3028 - val_acc: 0.5727\n",
      "Epoch 636/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.4981 - acc: 0.8125 - val_loss: 1.3818 - val_acc: 0.5727\n",
      "Epoch 637/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.4780 - acc: 0.8167 - val_loss: 1.4480 - val_acc: 0.5455\n",
      "Epoch 638/1000\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.4794 - acc: 0.8208 - val_loss: 1.4444 - val_acc: 0.5727\n",
      "Epoch 639/1000\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.5358 - acc: 0.8083 - val_loss: 1.7302 - val_acc: 0.5636\n",
      "Epoch 640/1000\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.5632 - acc: 0.8625 - val_loss: 1.5811 - val_acc: 0.6364\n",
      "Epoch 641/1000\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.6960 - acc: 0.8083 - val_loss: 1.4765 - val_acc: 0.6364\n",
      "Epoch 642/1000\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.3378 - acc: 0.8958 - val_loss: 1.2665 - val_acc: 0.6091\n",
      "Epoch 643/1000\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.3415 - acc: 0.9042 - val_loss: 1.3541 - val_acc: 0.6000\n",
      "Epoch 644/1000\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.2892 - acc: 0.9458 - val_loss: 1.3106 - val_acc: 0.6364\n",
      "Epoch 645/1000\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.1832 - acc: 0.9583 - val_loss: 1.2529 - val_acc: 0.6636\n",
      "Epoch 646/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.1470 - acc: 0.9667 - val_loss: 1.2376 - val_acc: 0.6545\n",
      "Epoch 647/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1292 - acc: 0.9833 - val_loss: 1.2721 - val_acc: 0.6455\n",
      "Epoch 648/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.1216 - acc: 0.9792 - val_loss: 1.3096 - val_acc: 0.6455\n",
      "Epoch 649/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.2149 - acc: 0.9583 - val_loss: 1.1789 - val_acc: 0.6727\n",
      "Epoch 650/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1871 - acc: 0.9625 - val_loss: 1.0985 - val_acc: 0.7000\n",
      "Epoch 651/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.2900 - acc: 0.9500 - val_loss: 1.1206 - val_acc: 0.7000\n",
      "Epoch 652/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.2116 - acc: 0.9542 - val_loss: 1.3202 - val_acc: 0.6727\n",
      "Epoch 653/1000\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.1435 - acc: 0.9667 - val_loss: 1.1092 - val_acc: 0.6909\n",
      "Epoch 654/1000\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.1302 - acc: 0.9750 - val_loss: 1.1925 - val_acc: 0.6818\n",
      "Epoch 655/1000\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.1343 - acc: 0.9667 - val_loss: 1.2530 - val_acc: 0.6909\n",
      "Epoch 656/1000\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0903 - acc: 0.9833 - val_loss: 1.1923 - val_acc: 0.7091\n",
      "Epoch 657/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0808 - acc: 0.9875 - val_loss: 1.1841 - val_acc: 0.6909\n",
      "Epoch 658/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0736 - acc: 0.9833 - val_loss: 1.1998 - val_acc: 0.7000\n",
      "Epoch 659/1000\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0691 - acc: 0.9833 - val_loss: 1.1878 - val_acc: 0.7091\n",
      "Epoch 660/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0645 - acc: 0.9833 - val_loss: 1.1876 - val_acc: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 661/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0610 - acc: 0.9833 - val_loss: 1.1996 - val_acc: 0.7000\n",
      "Epoch 662/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0579 - acc: 0.9833 - val_loss: 1.2168 - val_acc: 0.7091\n",
      "Epoch 663/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0552 - acc: 0.9875 - val_loss: 1.2183 - val_acc: 0.7182\n",
      "Epoch 664/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0524 - acc: 0.9833 - val_loss: 1.2398 - val_acc: 0.7000\n",
      "Epoch 665/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0762 - acc: 0.9792 - val_loss: 1.2896 - val_acc: 0.7091\n",
      "Epoch 666/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0841 - acc: 0.9792 - val_loss: 1.1804 - val_acc: 0.6818\n",
      "Epoch 667/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0615 - acc: 0.9875 - val_loss: 1.2272 - val_acc: 0.6818\n",
      "Epoch 668/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0583 - acc: 0.9875 - val_loss: 1.2217 - val_acc: 0.7000\n",
      "Epoch 669/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0554 - acc: 0.9875 - val_loss: 1.1793 - val_acc: 0.7182\n",
      "Epoch 670/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0507 - acc: 0.9875 - val_loss: 1.1963 - val_acc: 0.7182\n",
      "Epoch 671/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0473 - acc: 0.9833 - val_loss: 1.2409 - val_acc: 0.7091\n",
      "Epoch 672/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0446 - acc: 0.9875 - val_loss: 1.2606 - val_acc: 0.7091\n",
      "Epoch 673/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0455 - acc: 0.9833 - val_loss: 1.2687 - val_acc: 0.6909\n",
      "Epoch 674/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0405 - acc: 0.9875 - val_loss: 1.2197 - val_acc: 0.7000\n",
      "Epoch 675/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0357 - acc: 0.9875 - val_loss: 1.1929 - val_acc: 0.7000\n",
      "Epoch 676/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0332 - acc: 0.9875 - val_loss: 1.2005 - val_acc: 0.7182\n",
      "Epoch 677/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0308 - acc: 0.9917 - val_loss: 1.2218 - val_acc: 0.7182\n",
      "Epoch 678/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0300 - acc: 0.9917 - val_loss: 1.2569 - val_acc: 0.7091\n",
      "Epoch 679/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0272 - acc: 0.9917 - val_loss: 1.2608 - val_acc: 0.7091\n",
      "Epoch 680/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0402 - acc: 0.9875 - val_loss: 1.1140 - val_acc: 0.7455\n",
      "Epoch 681/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0317 - acc: 0.9917 - val_loss: 1.1754 - val_acc: 0.7364\n",
      "Epoch 682/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0268 - acc: 0.9917 - val_loss: 1.2382 - val_acc: 0.6909\n",
      "Epoch 683/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0283 - acc: 0.9875 - val_loss: 1.1870 - val_acc: 0.7182\n",
      "Epoch 684/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0250 - acc: 0.9875 - val_loss: 1.1740 - val_acc: 0.7273\n",
      "Epoch 685/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0183 - acc: 0.9958 - val_loss: 1.1997 - val_acc: 0.7182\n",
      "Epoch 686/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0166 - acc: 0.9917 - val_loss: 1.1980 - val_acc: 0.7182\n",
      "Epoch 687/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0157 - acc: 0.9958 - val_loss: 1.1930 - val_acc: 0.7182\n",
      "Epoch 688/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0148 - acc: 0.9958 - val_loss: 1.1980 - val_acc: 0.7182\n",
      "Epoch 689/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0156 - acc: 0.9917 - val_loss: 1.1914 - val_acc: 0.7182\n",
      "Epoch 690/1000\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0137 - acc: 0.9958 - val_loss: 1.1979 - val_acc: 0.7182\n",
      "Epoch 691/1000\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0134 - acc: 0.9958 - val_loss: 1.2109 - val_acc: 0.7273\n",
      "Epoch 692/1000\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0130 - acc: 0.9958 - val_loss: 1.2098 - val_acc: 0.7182\n",
      "Epoch 693/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0126 - acc: 0.9958 - val_loss: 1.2210 - val_acc: 0.7182\n",
      "Epoch 694/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0128 - acc: 0.9917 - val_loss: 1.2209 - val_acc: 0.7182\n",
      "Epoch 695/1000\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0132 - acc: 0.9958 - val_loss: 1.2355 - val_acc: 0.7091\n",
      "Epoch 696/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0123 - acc: 0.9958 - val_loss: 1.2366 - val_acc: 0.7091\n",
      "Epoch 697/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0120 - acc: 0.9917 - val_loss: 1.2423 - val_acc: 0.7091\n",
      "Epoch 698/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0122 - acc: 0.9958 - val_loss: 1.2478 - val_acc: 0.7091\n",
      "Epoch 699/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0114 - acc: 0.9958 - val_loss: 1.2599 - val_acc: 0.7000\n",
      "Epoch 700/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0119 - acc: 0.9958 - val_loss: 1.2722 - val_acc: 0.7000\n",
      "Epoch 701/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0109 - acc: 0.9958 - val_loss: 1.2803 - val_acc: 0.7000\n",
      "Epoch 702/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0109 - acc: 0.9958 - val_loss: 1.2855 - val_acc: 0.7000\n",
      "Epoch 703/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0105 - acc: 0.9958 - val_loss: 1.2886 - val_acc: 0.7000\n",
      "Epoch 704/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0109 - acc: 0.9917 - val_loss: 1.2982 - val_acc: 0.7000\n",
      "Epoch 705/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0104 - acc: 0.9917 - val_loss: 1.3047 - val_acc: 0.7000\n",
      "Epoch 706/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0101 - acc: 0.9958 - val_loss: 1.3112 - val_acc: 0.7000\n",
      "Epoch 707/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0104 - acc: 0.9917 - val_loss: 1.3177 - val_acc: 0.7000\n",
      "Epoch 708/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0103 - acc: 0.9958 - val_loss: 1.3229 - val_acc: 0.6909\n",
      "Epoch 709/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0102 - acc: 0.9917 - val_loss: 1.3300 - val_acc: 0.6909\n",
      "Epoch 710/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0098 - acc: 0.9958 - val_loss: 1.3322 - val_acc: 0.6909\n",
      "Epoch 711/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0096 - acc: 0.9958 - val_loss: 1.3379 - val_acc: 0.7000\n",
      "Epoch 712/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0099 - acc: 0.9917 - val_loss: 1.3442 - val_acc: 0.7000\n",
      "Epoch 713/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0102 - acc: 0.9917 - val_loss: 1.3495 - val_acc: 0.6909\n",
      "Epoch 714/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0105 - acc: 0.9917 - val_loss: 1.3437 - val_acc: 0.7000\n",
      "Epoch 715/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0093 - acc: 0.9958 - val_loss: 1.3559 - val_acc: 0.6909\n",
      "Epoch 716/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0091 - acc: 0.9958 - val_loss: 1.3601 - val_acc: 0.6909\n",
      "Epoch 717/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0094 - acc: 0.9917 - val_loss: 1.3637 - val_acc: 0.6909\n",
      "Epoch 718/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0100 - acc: 0.9917 - val_loss: 1.3678 - val_acc: 0.6818\n",
      "Epoch 719/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0089 - acc: 0.9958 - val_loss: 1.3568 - val_acc: 0.6909\n",
      "Epoch 720/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0096 - acc: 0.9958 - val_loss: 1.3720 - val_acc: 0.6909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0089 - acc: 0.9958 - val_loss: 1.3766 - val_acc: 0.6909\n",
      "Epoch 722/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0091 - acc: 0.9917 - val_loss: 1.3746 - val_acc: 0.6909\n",
      "Epoch 723/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0094 - acc: 0.9917 - val_loss: 1.3799 - val_acc: 0.7000\n",
      "Epoch 724/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0091 - acc: 0.9917 - val_loss: 1.3819 - val_acc: 0.6909\n",
      "Epoch 725/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0093 - acc: 0.9917 - val_loss: 1.3869 - val_acc: 0.7000\n",
      "Epoch 726/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0092 - acc: 0.9917 - val_loss: 1.3938 - val_acc: 0.6909\n",
      "Epoch 727/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0090 - acc: 0.9958 - val_loss: 1.4013 - val_acc: 0.6909\n",
      "Epoch 728/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0089 - acc: 0.9958 - val_loss: 1.4055 - val_acc: 0.6909\n",
      "Epoch 729/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0088 - acc: 0.9958 - val_loss: 1.4116 - val_acc: 0.6909\n",
      "Epoch 730/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0091 - acc: 0.9958 - val_loss: 1.4245 - val_acc: 0.7000\n",
      "Epoch 731/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0094 - acc: 0.9917 - val_loss: 1.4276 - val_acc: 0.7000\n",
      "Epoch 732/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0094 - acc: 0.9917 - val_loss: 1.4238 - val_acc: 0.7091\n",
      "Epoch 733/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0088 - acc: 0.9958 - val_loss: 1.4253 - val_acc: 0.7091\n",
      "Epoch 734/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0084 - acc: 0.9958 - val_loss: 1.4188 - val_acc: 0.7000\n",
      "Epoch 735/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0085 - acc: 0.9917 - val_loss: 1.4213 - val_acc: 0.7000\n",
      "Epoch 736/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0091 - acc: 0.9958 - val_loss: 1.4286 - val_acc: 0.7000\n",
      "Epoch 737/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0092 - acc: 0.9917 - val_loss: 1.4378 - val_acc: 0.7091\n",
      "Epoch 738/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 1.4369 - val_acc: 0.7000\n",
      "Epoch 739/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0083 - acc: 0.9958 - val_loss: 1.4347 - val_acc: 0.7091\n",
      "Epoch 740/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 1.4377 - val_acc: 0.7091\n",
      "Epoch 741/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0085 - acc: 0.9917 - val_loss: 1.4373 - val_acc: 0.7000\n",
      "Epoch 742/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0081 - acc: 0.9958 - val_loss: 1.4393 - val_acc: 0.7091\n",
      "Epoch 743/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0079 - acc: 0.9917 - val_loss: 1.4376 - val_acc: 0.7000\n",
      "Epoch 744/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 1.4400 - val_acc: 0.7000\n",
      "Epoch 745/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0085 - acc: 0.9917 - val_loss: 1.4377 - val_acc: 0.7000\n",
      "Epoch 746/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0077 - acc: 0.9958 - val_loss: 1.4541 - val_acc: 0.7091\n",
      "Epoch 747/1000\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.0087 - acc: 0.9917 - val_loss: 1.4357 - val_acc: 0.7000\n",
      "Epoch 748/1000\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0086 - acc: 0.9958 - val_loss: 1.4574 - val_acc: 0.7091\n",
      "Epoch 749/1000\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0081 - acc: 0.9958 - val_loss: 1.4550 - val_acc: 0.7000\n",
      "Epoch 750/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0086 - acc: 0.9958 - val_loss: 1.4434 - val_acc: 0.7000\n",
      "Epoch 751/1000\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.0086 - acc: 0.9917 - val_loss: 1.4660 - val_acc: 0.7091\n",
      "Epoch 752/1000\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0082 - acc: 0.9958 - val_loss: 1.4617 - val_acc: 0.7091\n",
      "Epoch 753/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0081 - acc: 0.9958 - val_loss: 1.4689 - val_acc: 0.7091\n",
      "Epoch 754/1000\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0090 - acc: 0.9917 - val_loss: 1.4493 - val_acc: 0.7000\n",
      "Epoch 755/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0077 - acc: 0.9958 - val_loss: 1.4676 - val_acc: 0.7000\n",
      "Epoch 756/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0076 - acc: 0.9917 - val_loss: 1.4741 - val_acc: 0.7091\n",
      "Epoch 757/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0076 - acc: 0.9917 - val_loss: 1.4779 - val_acc: 0.7091\n",
      "Epoch 758/1000\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0073 - acc: 0.9958 - val_loss: 1.4769 - val_acc: 0.7091\n",
      "Epoch 759/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0080 - acc: 0.9917 - val_loss: 1.4802 - val_acc: 0.7091\n",
      "Epoch 760/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 1.4794 - val_acc: 0.7091\n",
      "Epoch 761/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0077 - acc: 0.9958 - val_loss: 1.4918 - val_acc: 0.7091\n",
      "Epoch 762/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0079 - acc: 0.9958 - val_loss: 1.4878 - val_acc: 0.7091\n",
      "Epoch 763/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0077 - acc: 0.9958 - val_loss: 1.4802 - val_acc: 0.7000\n",
      "Epoch 764/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0079 - acc: 0.9958 - val_loss: 1.4843 - val_acc: 0.7000\n",
      "Epoch 765/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0080 - acc: 0.9958 - val_loss: 1.5044 - val_acc: 0.7091\n",
      "Epoch 766/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0079 - acc: 0.9917 - val_loss: 1.4897 - val_acc: 0.7000\n",
      "Epoch 767/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 1.4977 - val_acc: 0.7091\n",
      "Epoch 768/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0073 - acc: 0.9958 - val_loss: 1.4912 - val_acc: 0.7000\n",
      "Epoch 769/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0077 - acc: 0.9958 - val_loss: 1.5006 - val_acc: 0.7000\n",
      "Epoch 770/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0071 - acc: 0.9958 - val_loss: 1.5320 - val_acc: 0.7091\n",
      "Epoch 771/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 1.5090 - val_acc: 0.7091\n",
      "Epoch 772/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0072 - acc: 0.9958 - val_loss: 1.5250 - val_acc: 0.7091\n",
      "Epoch 773/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0071 - acc: 0.9958 - val_loss: 1.5251 - val_acc: 0.7091\n",
      "Epoch 774/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0080 - acc: 0.9917 - val_loss: 1.5238 - val_acc: 0.7091\n",
      "Epoch 775/1000\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0071 - acc: 0.9958 - val_loss: 1.5285 - val_acc: 0.7091\n",
      "Epoch 776/1000\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.0075 - acc: 0.9958 - val_loss: 1.5319 - val_acc: 0.7091\n",
      "Epoch 777/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0078 - acc: 0.9917 - val_loss: 1.5260 - val_acc: 0.7000\n",
      "Epoch 778/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0074 - acc: 0.9917 - val_loss: 1.5313 - val_acc: 0.7091\n",
      "Epoch 779/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0074 - acc: 0.9958 - val_loss: 1.5292 - val_acc: 0.7000\n",
      "Epoch 780/1000\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.0076 - acc: 0.9958 - val_loss: 1.5152 - val_acc: 0.6909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 781/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0073 - acc: 0.9958 - val_loss: 1.5343 - val_acc: 0.7000\n",
      "Epoch 782/1000\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.0072 - acc: 0.9917 - val_loss: 1.5402 - val_acc: 0.7091\n",
      "Epoch 783/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0077 - acc: 0.9917 - val_loss: 1.5340 - val_acc: 0.7091\n",
      "Epoch 784/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0078 - acc: 0.9958 - val_loss: 1.5431 - val_acc: 0.7091\n",
      "Epoch 785/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0071 - acc: 0.9958 - val_loss: 1.5224 - val_acc: 0.6909\n",
      "Epoch 786/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0070 - acc: 0.9958 - val_loss: 1.5118 - val_acc: 0.7000\n",
      "Epoch 787/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0078 - acc: 0.9917 - val_loss: 1.5204 - val_acc: 0.6909\n",
      "Epoch 788/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0084 - acc: 0.9958 - val_loss: 1.5211 - val_acc: 0.6909\n",
      "Epoch 789/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0070 - acc: 0.9958 - val_loss: 1.5370 - val_acc: 0.7091\n",
      "Epoch 790/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0081 - acc: 0.9958 - val_loss: 1.5487 - val_acc: 0.7091\n",
      "Epoch 791/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0078 - acc: 0.9917 - val_loss: 1.5203 - val_acc: 0.6909\n",
      "Epoch 792/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0087 - acc: 0.9917 - val_loss: 1.5499 - val_acc: 0.7091\n",
      "Epoch 793/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0068 - acc: 0.9958 - val_loss: 1.5196 - val_acc: 0.6909\n",
      "Epoch 794/1000\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0072 - acc: 0.9917 - val_loss: 1.5241 - val_acc: 0.7000\n",
      "Epoch 795/1000\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0077 - acc: 0.9917 - val_loss: 1.5322 - val_acc: 0.6909\n",
      "Epoch 796/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0074 - acc: 0.9917 - val_loss: 1.5363 - val_acc: 0.6909\n",
      "Epoch 797/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0078 - acc: 0.9917 - val_loss: 1.5326 - val_acc: 0.6909\n",
      "Epoch 798/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0070 - acc: 0.9958 - val_loss: 1.5364 - val_acc: 0.6909\n",
      "Epoch 799/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0069 - acc: 0.9958 - val_loss: 1.5370 - val_acc: 0.6909\n",
      "Epoch 800/1000\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0072 - acc: 0.9958 - val_loss: 1.5456 - val_acc: 0.6909\n",
      "Epoch 801/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0075 - acc: 0.9958 - val_loss: 1.5445 - val_acc: 0.6909\n",
      "Epoch 802/1000\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0086 - acc: 0.9917 - val_loss: 1.5692 - val_acc: 0.6909\n",
      "Epoch 803/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0171 - acc: 0.9917 - val_loss: 1.6529 - val_acc: 0.6909\n",
      "Epoch 804/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.9898 - acc: 0.8000 - val_loss: 2.5355 - val_acc: 0.4091\n",
      "Epoch 805/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.6935 - acc: 0.4917 - val_loss: 1.9096 - val_acc: 0.3545\n",
      "Epoch 806/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.1698 - acc: 0.6042 - val_loss: 1.6006 - val_acc: 0.4909\n",
      "Epoch 807/1000\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.7865 - acc: 0.7625 - val_loss: 1.2575 - val_acc: 0.6091\n",
      "Epoch 808/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.6844 - acc: 0.7500 - val_loss: 1.2216 - val_acc: 0.6364\n",
      "Epoch 809/1000\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.5752 - acc: 0.8000 - val_loss: 0.9521 - val_acc: 0.6909\n",
      "Epoch 810/1000\n",
      "240/240 [==============================] - 10s 42ms/step - loss: 0.3917 - acc: 0.8708 - val_loss: 0.9254 - val_acc: 0.7182\n",
      "Epoch 811/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.3458 - acc: 0.8917 - val_loss: 0.9171 - val_acc: 0.7182\n",
      "Epoch 812/1000\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.3135 - acc: 0.8917 - val_loss: 0.8582 - val_acc: 0.7545\n",
      "Epoch 813/1000\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.2373 - acc: 0.9208 - val_loss: 0.9435 - val_acc: 0.7273\n",
      "Epoch 814/1000\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.1699 - acc: 0.9500 - val_loss: 0.7931 - val_acc: 0.7273\n",
      "Epoch 815/1000\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.1226 - acc: 0.9750 - val_loss: 0.7796 - val_acc: 0.7545\n",
      "Epoch 816/1000\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.1242 - acc: 0.9750 - val_loss: 0.8804 - val_acc: 0.7273\n",
      "Epoch 817/1000\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0806 - acc: 0.9792 - val_loss: 0.8207 - val_acc: 0.7636\n",
      "Epoch 818/1000\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0686 - acc: 0.9917 - val_loss: 0.8057 - val_acc: 0.7727\n",
      "Epoch 819/1000\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0557 - acc: 0.9917 - val_loss: 0.8721 - val_acc: 0.7727\n",
      "Epoch 820/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0582 - acc: 0.9875 - val_loss: 0.9091 - val_acc: 0.7273\n",
      "Epoch 821/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0535 - acc: 0.9875 - val_loss: 0.8624 - val_acc: 0.7545\n",
      "Epoch 822/1000\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0459 - acc: 0.9917 - val_loss: 0.8477 - val_acc: 0.7818\n",
      "Epoch 823/1000\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0400 - acc: 0.9875 - val_loss: 0.7735 - val_acc: 0.7909\n",
      "Epoch 824/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0830 - acc: 0.9792 - val_loss: 0.8601 - val_acc: 0.7364\n",
      "Epoch 825/1000\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.1247 - acc: 0.9667 - val_loss: 0.8460 - val_acc: 0.7818\n",
      "Epoch 826/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.2041 - acc: 0.9208 - val_loss: 1.0739 - val_acc: 0.7727\n",
      "Epoch 827/1000\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.1767 - acc: 0.9333 - val_loss: 0.8477 - val_acc: 0.7727\n",
      "Epoch 828/1000\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.1634 - acc: 0.9500 - val_loss: 0.9748 - val_acc: 0.7364\n",
      "Epoch 829/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1241 - acc: 0.9625 - val_loss: 0.6792 - val_acc: 0.8091\n",
      "Epoch 830/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0729 - acc: 0.9833 - val_loss: 0.7663 - val_acc: 0.7818\n",
      "Epoch 831/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.1374 - acc: 0.9625 - val_loss: 0.8983 - val_acc: 0.7273\n",
      "Epoch 832/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0857 - acc: 0.9667 - val_loss: 0.7136 - val_acc: 0.7909\n",
      "Epoch 833/1000\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0695 - acc: 0.9875 - val_loss: 0.8554 - val_acc: 0.7909\n",
      "Epoch 834/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0660 - acc: 0.9833 - val_loss: 0.9137 - val_acc: 0.7273\n",
      "Epoch 835/1000\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0338 - acc: 0.9958 - val_loss: 0.9137 - val_acc: 0.7727\n",
      "Epoch 836/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0306 - acc: 0.9875 - val_loss: 0.8766 - val_acc: 0.7727\n",
      "Epoch 837/1000\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0236 - acc: 0.9958 - val_loss: 0.8604 - val_acc: 0.7818\n",
      "Epoch 838/1000\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.0207 - acc: 0.9958 - val_loss: 0.8764 - val_acc: 0.7909\n",
      "Epoch 839/1000\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0183 - acc: 0.9917 - val_loss: 0.8704 - val_acc: 0.8000\n",
      "Epoch 840/1000\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0166 - acc: 0.9958 - val_loss: 0.8716 - val_acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841/1000\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0163 - acc: 0.9917 - val_loss: 0.8729 - val_acc: 0.8000\n",
      "Epoch 842/1000\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0150 - acc: 0.9917 - val_loss: 0.8771 - val_acc: 0.8000\n",
      "Epoch 843/1000\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0143 - acc: 0.9917 - val_loss: 0.8795 - val_acc: 0.7909\n",
      "Epoch 844/1000\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0145 - acc: 0.9958 - val_loss: 0.8723 - val_acc: 0.8000\n",
      "Epoch 845/1000\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0138 - acc: 0.9958 - val_loss: 0.8350 - val_acc: 0.8091\n",
      "Epoch 846/1000\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0138 - acc: 0.9917 - val_loss: 0.8448 - val_acc: 0.8000\n",
      "Epoch 847/1000\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0137 - acc: 0.9917 - val_loss: 0.8453 - val_acc: 0.8091\n",
      "Epoch 848/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0126 - acc: 0.9917 - val_loss: 0.8548 - val_acc: 0.8091\n",
      "Epoch 849/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0119 - acc: 0.9958 - val_loss: 0.8518 - val_acc: 0.8091\n",
      "Epoch 850/1000\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0127 - acc: 0.9917 - val_loss: 0.8578 - val_acc: 0.8091\n",
      "Epoch 851/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0112 - acc: 0.9958 - val_loss: 0.8750 - val_acc: 0.8091\n",
      "Epoch 852/1000\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0113 - acc: 0.9917 - val_loss: 0.8703 - val_acc: 0.8091\n",
      "Epoch 853/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0110 - acc: 0.9958 - val_loss: 0.8771 - val_acc: 0.8091\n",
      "Epoch 854/1000\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0115 - acc: 0.9917 - val_loss: 0.8749 - val_acc: 0.8091\n",
      "Epoch 855/1000\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0106 - acc: 0.9958 - val_loss: 0.8764 - val_acc: 0.8091\n",
      "Epoch 856/1000\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0107 - acc: 0.9958 - val_loss: 0.8787 - val_acc: 0.8091\n",
      "Epoch 857/1000\n",
      "240/240 [==============================] - 10s 42ms/step - loss: 0.0111 - acc: 0.9917 - val_loss: 0.8742 - val_acc: 0.8182\n",
      "Epoch 858/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0099 - acc: 0.9958 - val_loss: 0.8766 - val_acc: 0.8091\n",
      "Epoch 859/1000\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0104 - acc: 0.9958 - val_loss: 0.8828 - val_acc: 0.8091\n",
      "Epoch 860/1000\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0105 - acc: 0.9917 - val_loss: 0.8629 - val_acc: 0.8182\n",
      "Epoch 861/1000\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0101 - acc: 0.9917 - val_loss: 0.8768 - val_acc: 0.8182\n",
      "Epoch 862/1000\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0104 - acc: 0.9958 - val_loss: 0.8795 - val_acc: 0.8091\n",
      "Epoch 863/1000\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0120 - acc: 0.9917 - val_loss: 0.8317 - val_acc: 0.8273\n",
      "Epoch 864/1000\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0095 - acc: 0.9958 - val_loss: 0.8491 - val_acc: 0.8273\n",
      "Epoch 865/1000\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0094 - acc: 0.9917 - val_loss: 0.8558 - val_acc: 0.8182\n",
      "Epoch 866/1000\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0093 - acc: 0.9917 - val_loss: 0.8631 - val_acc: 0.8182\n",
      "Epoch 867/1000\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0093 - acc: 0.9917 - val_loss: 0.8655 - val_acc: 0.8182\n",
      "Epoch 868/1000\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0096 - acc: 0.9958 - val_loss: 0.8747 - val_acc: 0.8182\n",
      "Epoch 869/1000\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0093 - acc: 0.9917 - val_loss: 0.8704 - val_acc: 0.8182\n",
      "Epoch 870/1000\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0088 - acc: 0.9958 - val_loss: 0.8783 - val_acc: 0.8182\n",
      "Epoch 871/1000\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.0091 - acc: 0.9917 - val_loss: 0.8787 - val_acc: 0.8182\n",
      "Epoch 872/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0093 - acc: 0.9917 - val_loss: 0.8741 - val_acc: 0.8091\n",
      "Epoch 873/1000\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0086 - acc: 0.9917 - val_loss: 0.8825 - val_acc: 0.8182\n",
      "Epoch 874/1000\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.0085 - acc: 0.9958 - val_loss: 0.8839 - val_acc: 0.8182\n",
      "Epoch 875/1000\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.0090 - acc: 0.9958 - val_loss: 0.8833 - val_acc: 0.8182\n",
      "Epoch 876/1000\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.0087 - acc: 0.9958 - val_loss: 0.8632 - val_acc: 0.8091\n",
      "Epoch 877/1000\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0085 - acc: 0.9917 - val_loss: 0.8778 - val_acc: 0.8091\n",
      "Epoch 878/1000\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0091 - acc: 0.9917 - val_loss: 0.8700 - val_acc: 0.8091\n",
      "Epoch 879/1000\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0083 - acc: 0.9958 - val_loss: 0.8829 - val_acc: 0.8091\n",
      "Epoch 880/1000\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.0086 - acc: 0.9917 - val_loss: 0.8955 - val_acc: 0.8091\n",
      "Epoch 881/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0084 - acc: 0.9958 - val_loss: 0.8905 - val_acc: 0.8091\n",
      "Epoch 882/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0087 - acc: 0.9958 - val_loss: 0.8981 - val_acc: 0.8000\n",
      "Epoch 883/1000\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.8891 - val_acc: 0.8000\n",
      "Epoch 884/1000\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.0081 - acc: 0.9958 - val_loss: 0.8967 - val_acc: 0.8000\n",
      "Epoch 885/1000\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.0088 - acc: 0.9917 - val_loss: 0.8966 - val_acc: 0.8000\n",
      "Epoch 886/1000\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0079 - acc: 0.9958 - val_loss: 0.9097 - val_acc: 0.8000\n",
      "Epoch 887/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0088 - acc: 0.9958 - val_loss: 0.8971 - val_acc: 0.8000\n",
      "Epoch 888/1000\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.8868 - val_acc: 0.8000\n",
      "Epoch 889/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0086 - acc: 0.9917 - val_loss: 0.8938 - val_acc: 0.8000\n",
      "Epoch 890/1000\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.0079 - acc: 0.9958 - val_loss: 0.8705 - val_acc: 0.8091\n",
      "Epoch 891/1000\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0080 - acc: 0.9958 - val_loss: 0.8772 - val_acc: 0.8091\n",
      "Epoch 892/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0078 - acc: 0.9958 - val_loss: 0.8878 - val_acc: 0.8091\n",
      "Epoch 893/1000\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0083 - acc: 0.9958 - val_loss: 0.8949 - val_acc: 0.8091\n",
      "Epoch 894/1000\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0075 - acc: 0.9958 - val_loss: 0.9135 - val_acc: 0.8000\n",
      "Epoch 895/1000\n",
      "240/240 [==============================] - 10s 42ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.9514 - val_acc: 0.7909\n",
      "Epoch 896/1000\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 0.0081 - acc: 0.9958 - val_loss: 0.9240 - val_acc: 0.8000\n",
      "Epoch 897/1000\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0077 - acc: 0.9917 - val_loss: 0.9148 - val_acc: 0.7909\n",
      "Epoch 898/1000\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.9081 - val_acc: 0.8000\n",
      "Epoch 899/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0076 - acc: 0.9958 - val_loss: 0.9249 - val_acc: 0.7909\n",
      "Epoch 900/1000\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.0075 - acc: 0.9958 - val_loss: 0.9265 - val_acc: 0.7909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 901/1000\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0081 - acc: 0.9958 - val_loss: 0.9245 - val_acc: 0.7909\n",
      "Epoch 902/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0076 - acc: 0.9958 - val_loss: 0.9175 - val_acc: 0.7909\n",
      "Epoch 903/1000\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0082 - acc: 0.9917 - val_loss: 0.9354 - val_acc: 0.7909\n",
      "Epoch 904/1000\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0078 - acc: 0.9917 - val_loss: 0.9371 - val_acc: 0.7909\n",
      "Epoch 905/1000\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0075 - acc: 0.9958 - val_loss: 0.9244 - val_acc: 0.8000\n",
      "Epoch 906/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0072 - acc: 0.9958 - val_loss: 0.9393 - val_acc: 0.8000\n",
      "Epoch 907/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0077 - acc: 0.9958 - val_loss: 0.9537 - val_acc: 0.8000\n",
      "Epoch 908/1000\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0073 - acc: 0.9958 - val_loss: 0.9576 - val_acc: 0.8000\n",
      "Epoch 909/1000\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0080 - acc: 0.9917 - val_loss: 0.9474 - val_acc: 0.8000\n",
      "Epoch 910/1000\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0080 - acc: 0.9917 - val_loss: 0.9383 - val_acc: 0.8000\n",
      "Epoch 911/1000\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.0077 - acc: 0.9958 - val_loss: 0.9578 - val_acc: 0.8000\n",
      "Epoch 912/1000\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0073 - acc: 0.9958 - val_loss: 0.9521 - val_acc: 0.8000\n",
      "Epoch 913/1000\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0079 - acc: 0.9917 - val_loss: 0.9532 - val_acc: 0.8000\n",
      "Epoch 914/1000\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0078 - acc: 0.9958 - val_loss: 0.9581 - val_acc: 0.8091\n",
      "Epoch 915/1000\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0071 - acc: 0.9958 - val_loss: 0.9481 - val_acc: 0.8091\n",
      "Epoch 916/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0082 - acc: 0.9958 - val_loss: 0.9413 - val_acc: 0.8000\n",
      "Epoch 917/1000\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0086 - acc: 0.9917 - val_loss: 0.9688 - val_acc: 0.7909\n",
      "Epoch 918/1000\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0074 - acc: 0.9958 - val_loss: 0.9744 - val_acc: 0.7909\n",
      "Epoch 919/1000\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0070 - acc: 0.9958 - val_loss: 0.9540 - val_acc: 0.8000\n",
      "Epoch 920/1000\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0071 - acc: 0.9958 - val_loss: 0.9519 - val_acc: 0.7909\n",
      "Epoch 921/1000\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0078 - acc: 0.9958 - val_loss: 0.9442 - val_acc: 0.8091\n",
      "Epoch 922/1000\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0071 - acc: 0.9958 - val_loss: 0.9655 - val_acc: 0.8091\n",
      "Epoch 923/1000\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0077 - acc: 0.9917 - val_loss: 0.9631 - val_acc: 0.8000\n",
      "Epoch 924/1000\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0068 - acc: 0.9958 - val_loss: 0.9676 - val_acc: 0.8091\n",
      "Epoch 925/1000\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0070 - acc: 0.9958 - val_loss: 0.9650 - val_acc: 0.8091\n",
      "Epoch 926/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0076 - acc: 0.9958 - val_loss: 0.9664 - val_acc: 0.8000\n",
      "Epoch 927/1000\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0073 - acc: 0.9917 - val_loss: 0.9647 - val_acc: 0.8000\n",
      "Epoch 928/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0068 - acc: 0.9958 - val_loss: 0.9610 - val_acc: 0.8091\n",
      "Epoch 929/1000\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0068 - acc: 0.9958 - val_loss: 0.9626 - val_acc: 0.8091\n",
      "Epoch 930/1000\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.0077 - acc: 0.9917 - val_loss: 0.9680 - val_acc: 0.8000\n",
      "Epoch 931/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0072 - acc: 0.9917 - val_loss: 0.9634 - val_acc: 0.8000\n",
      "Epoch 932/1000\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.0074 - acc: 0.9917 - val_loss: 0.9653 - val_acc: 0.8000\n",
      "Epoch 933/1000\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0069 - acc: 0.9958 - val_loss: 0.9584 - val_acc: 0.8000\n",
      "Epoch 934/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0072 - acc: 0.9917 - val_loss: 0.9640 - val_acc: 0.8000\n",
      "Epoch 935/1000\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0071 - acc: 0.9917 - val_loss: 0.9609 - val_acc: 0.8000\n",
      "Epoch 936/1000\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.0072 - acc: 0.9917 - val_loss: 0.9653 - val_acc: 0.8000\n",
      "Epoch 937/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0075 - acc: 0.9958 - val_loss: 0.9569 - val_acc: 0.8182\n",
      "Epoch 938/1000\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0074 - acc: 0.9917 - val_loss: 0.9685 - val_acc: 0.8182\n",
      "Epoch 939/1000\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0071 - acc: 0.9958 - val_loss: 0.9657 - val_acc: 0.8091\n",
      "Epoch 940/1000\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0079 - acc: 0.9958 - val_loss: 0.9016 - val_acc: 0.8091\n",
      "Epoch 941/1000\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0087 - acc: 0.9917 - val_loss: 0.9236 - val_acc: 0.8091\n",
      "Epoch 942/1000\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0080 - acc: 0.9958 - val_loss: 0.9497 - val_acc: 0.7909\n",
      "Epoch 943/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0088 - acc: 0.9917 - val_loss: 0.9579 - val_acc: 0.8000\n",
      "Epoch 944/1000\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0336 - acc: 0.9875 - val_loss: 1.3334 - val_acc: 0.7455\n",
      "Epoch 945/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.5150 - acc: 0.9000 - val_loss: 1.9915 - val_acc: 0.5545\n",
      "Epoch 946/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.6449 - acc: 0.8167 - val_loss: 1.4394 - val_acc: 0.6818\n",
      "Epoch 947/1000\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.4929 - acc: 0.8458 - val_loss: 1.3130 - val_acc: 0.6636\n",
      "Epoch 948/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.3247 - acc: 0.9042 - val_loss: 1.2032 - val_acc: 0.6727\n",
      "Epoch 949/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.1774 - acc: 0.9500 - val_loss: 1.0345 - val_acc: 0.7455\n",
      "Epoch 950/1000\n",
      "240/240 [==============================] - 11s 46ms/step - loss: 0.0711 - acc: 0.9833 - val_loss: 1.1807 - val_acc: 0.7091\n",
      "Epoch 951/1000\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.0756 - acc: 0.9708 - val_loss: 1.0163 - val_acc: 0.7545\n",
      "Epoch 952/1000\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.2763 - acc: 0.9125 - val_loss: 1.1237 - val_acc: 0.7273\n",
      "Epoch 953/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.7010 - acc: 0.8083 - val_loss: 1.1264 - val_acc: 0.6818\n",
      "Epoch 954/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.2751 - acc: 0.9125 - val_loss: 0.9310 - val_acc: 0.7636\n",
      "Epoch 955/1000\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.1082 - acc: 0.9708 - val_loss: 0.9333 - val_acc: 0.7636\n",
      "Epoch 956/1000\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0600 - acc: 0.9875 - val_loss: 0.9591 - val_acc: 0.7636\n",
      "Epoch 957/1000\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.0491 - acc: 0.9833 - val_loss: 0.9750 - val_acc: 0.7545\n",
      "Epoch 958/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0355 - acc: 0.9875 - val_loss: 1.0029 - val_acc: 0.7455\n",
      "Epoch 959/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0282 - acc: 0.9958 - val_loss: 1.0083 - val_acc: 0.7636\n",
      "Epoch 960/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.1953 - acc: 0.9583 - val_loss: 1.3010 - val_acc: 0.7182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 961/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.4382 - acc: 0.8833 - val_loss: 1.2931 - val_acc: 0.6727\n",
      "Epoch 962/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.2471 - acc: 0.9292 - val_loss: 1.0977 - val_acc: 0.7273\n",
      "Epoch 963/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.1006 - acc: 0.9667 - val_loss: 1.0965 - val_acc: 0.7545\n",
      "Epoch 964/1000\n",
      "240/240 [==============================] - 10s 42ms/step - loss: 0.0773 - acc: 0.9792 - val_loss: 1.0528 - val_acc: 0.7727\n",
      "Epoch 965/1000\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.0332 - acc: 0.9958 - val_loss: 1.0462 - val_acc: 0.7455\n",
      "Epoch 966/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0274 - acc: 0.9958 - val_loss: 0.9895 - val_acc: 0.7455\n",
      "Epoch 967/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0246 - acc: 0.9958 - val_loss: 1.0022 - val_acc: 0.7455\n",
      "Epoch 968/1000\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.0224 - acc: 0.9958 - val_loss: 0.9998 - val_acc: 0.7545\n",
      "Epoch 969/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0206 - acc: 0.9958 - val_loss: 1.0083 - val_acc: 0.7545\n",
      "Epoch 970/1000\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0199 - acc: 0.9958 - val_loss: 1.0074 - val_acc: 0.7455\n",
      "Epoch 971/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0191 - acc: 0.9958 - val_loss: 1.0186 - val_acc: 0.7455\n",
      "Epoch 972/1000\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.0190 - acc: 0.9958 - val_loss: 1.0029 - val_acc: 0.7545\n",
      "Epoch 973/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0167 - acc: 0.9958 - val_loss: 1.0288 - val_acc: 0.7364\n",
      "Epoch 974/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0161 - acc: 0.9958 - val_loss: 1.0154 - val_acc: 0.7364\n",
      "Epoch 975/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0161 - acc: 0.9958 - val_loss: 1.0155 - val_acc: 0.7455\n",
      "Epoch 976/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0153 - acc: 0.9958 - val_loss: 1.0119 - val_acc: 0.7364\n",
      "Epoch 977/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0141 - acc: 0.9958 - val_loss: 1.0131 - val_acc: 0.7545\n",
      "Epoch 978/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0136 - acc: 0.9958 - val_loss: 1.0158 - val_acc: 0.7545\n",
      "Epoch 979/1000\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0136 - acc: 0.9958 - val_loss: 1.0183 - val_acc: 0.7545\n",
      "Epoch 980/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0140 - acc: 0.9958 - val_loss: 1.0226 - val_acc: 0.7545\n",
      "Epoch 981/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0125 - acc: 0.9958 - val_loss: 1.0319 - val_acc: 0.7545\n",
      "Epoch 982/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0120 - acc: 0.9958 - val_loss: 1.0216 - val_acc: 0.7545\n",
      "Epoch 983/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0118 - acc: 0.9917 - val_loss: 1.0121 - val_acc: 0.7545\n",
      "Epoch 984/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0129 - acc: 0.9958 - val_loss: 1.0129 - val_acc: 0.7545\n",
      "Epoch 985/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0114 - acc: 0.9958 - val_loss: 1.0384 - val_acc: 0.7455\n",
      "Epoch 986/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0127 - acc: 0.9917 - val_loss: 1.0218 - val_acc: 0.7545\n",
      "Epoch 987/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0117 - acc: 0.9917 - val_loss: 1.0250 - val_acc: 0.7545\n",
      "Epoch 988/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0115 - acc: 0.9958 - val_loss: 1.0253 - val_acc: 0.7636\n",
      "Epoch 989/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0110 - acc: 0.9958 - val_loss: 1.0355 - val_acc: 0.7545\n",
      "Epoch 990/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0108 - acc: 0.9917 - val_loss: 1.0441 - val_acc: 0.7545\n",
      "Epoch 991/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0106 - acc: 0.9958 - val_loss: 1.0496 - val_acc: 0.7455\n",
      "Epoch 992/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0110 - acc: 0.9917 - val_loss: 1.0452 - val_acc: 0.7545\n",
      "Epoch 993/1000\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0109 - acc: 0.9958 - val_loss: 1.0487 - val_acc: 0.7545\n",
      "Epoch 994/1000\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0107 - acc: 0.9958 - val_loss: 1.0534 - val_acc: 0.7545\n",
      "Epoch 995/1000\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0097 - acc: 0.9958 - val_loss: 1.0698 - val_acc: 0.7455\n",
      "Epoch 996/1000\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0112 - acc: 0.9958 - val_loss: 1.0598 - val_acc: 0.7545\n",
      "Epoch 997/1000\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0103 - acc: 0.9958 - val_loss: 1.0970 - val_acc: 0.7455\n",
      "Epoch 998/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0101 - acc: 0.9958 - val_loss: 1.0994 - val_acc: 0.7455\n",
      "Epoch 999/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0099 - acc: 0.9958 - val_loss: 1.1007 - val_acc: 0.7545\n",
      "Epoch 1000/1000\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0111 - acc: 0.9917 - val_loss: 1.1062 - val_acc: 0.7545\n"
     ]
    }
   ],
   "source": [
    "LSTMDD8=LSTM_with_Dropout('LSTM_Dropoutdelta8',dropout=0.8,n_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/1000\n",
      "240/240 [==============================] - 16s 65ms/step - loss: 2.3038 - acc: 0.0833 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 2/1000\n",
      "240/240 [==============================] - 12s 51ms/step - loss: 2.3041 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 3/1000\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 2.3031 - acc: 0.1208 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 4/1000\n",
      "240/240 [==============================] - 12s 51ms/step - loss: 2.3036 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 5/1000\n",
      "240/240 [==============================] - 12s 51ms/step - loss: 2.3025 - acc: 0.0917 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 6/1000\n",
      "240/240 [==============================] - 12s 51ms/step - loss: 2.3037 - acc: 0.0917 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 7/1000\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 2.3028 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 8/1000\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 2.3034 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 9/1000\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 2.3013 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 10/1000\n",
      "240/240 [==============================] - 12s 51ms/step - loss: 2.3023 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 11/1000\n",
      "240/240 [==============================] - 12s 51ms/step - loss: 2.2995 - acc: 0.1125 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 12/1000\n",
      "240/240 [==============================] - 19s 79ms/step - loss: 2.2959 - acc: 0.1417 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 13/1000\n",
      "240/240 [==============================] - 14s 60ms/step - loss: 2.3021 - acc: 0.0792 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 14/1000\n",
      "240/240 [==============================] - 14s 56ms/step - loss: 2.2985 - acc: 0.1042 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 15/1000\n",
      "240/240 [==============================] - 14s 60ms/step - loss: 2.3050 - acc: 0.0833 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 16/1000\n",
      "240/240 [==============================] - 14s 58ms/step - loss: 2.2980 - acc: 0.1333 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 17/1000\n",
      "240/240 [==============================] - 14s 60ms/step - loss: 2.2970 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 18/1000\n",
      "240/240 [==============================] - 13s 56ms/step - loss: 2.2992 - acc: 0.0875 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 19/1000\n",
      "240/240 [==============================] - 14s 57ms/step - loss: 2.2959 - acc: 0.1167 - val_loss: 2.3024 - val_acc: 0.1000\n",
      "Epoch 20/1000\n",
      "240/240 [==============================] - 18s 74ms/step - loss: 2.2951 - acc: 0.1250 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 21/1000\n",
      "240/240 [==============================] - 15s 62ms/step - loss: 2.2968 - acc: 0.0958 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 22/1000\n",
      "240/240 [==============================] - 15s 63ms/step - loss: 2.2934 - acc: 0.1042 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 23/1000\n",
      "240/240 [==============================] - 15s 62ms/step - loss: 2.2967 - acc: 0.0667 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 24/1000\n",
      "240/240 [==============================] - 15s 63ms/step - loss: 2.2925 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.1091\n",
      "Epoch 25/1000\n",
      "240/240 [==============================] - 13s 56ms/step - loss: 2.2949 - acc: 0.0875 - val_loss: 2.3024 - val_acc: 0.1091\n",
      "Epoch 26/1000\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 2.2917 - acc: 0.1042 - val_loss: 2.3021 - val_acc: 0.1000\n",
      "Epoch 27/1000\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 2.2924 - acc: 0.0917 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 28/1000\n",
      "240/240 [==============================] - 13s 52ms/step - loss: 2.2934 - acc: 0.1125 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 29/1000\n",
      "240/240 [==============================] - 12s 52ms/step - loss: 2.2917 - acc: 0.1167 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 30/1000\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 2.2937 - acc: 0.0875 - val_loss: 2.3027 - val_acc: 0.0909\n",
      "Epoch 31/1000\n",
      "240/240 [==============================] - 20s 84ms/step - loss: 2.2904 - acc: 0.1000 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 32/1000\n",
      "240/240 [==============================] - 17s 70ms/step - loss: 2.2937 - acc: 0.1000 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 33/1000\n",
      "240/240 [==============================] - 13s 53ms/step - loss: 2.2927 - acc: 0.1000 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 34/1000\n",
      "240/240 [==============================] - 13s 56ms/step - loss: 2.2868 - acc: 0.1042 - val_loss: 2.3003 - val_acc: 0.1091\n",
      "Epoch 35/1000\n",
      "240/240 [==============================] - 14s 57ms/step - loss: 2.2927 - acc: 0.0958 - val_loss: 2.3020 - val_acc: 0.1000\n",
      "Epoch 36/1000\n",
      "240/240 [==============================] - 14s 59ms/step - loss: 2.2856 - acc: 0.1250 - val_loss: 2.3019 - val_acc: 0.1000\n",
      "Epoch 37/1000\n",
      "240/240 [==============================] - 14s 58ms/step - loss: 2.2888 - acc: 0.1042 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 38/1000\n",
      "240/240 [==============================] - 14s 58ms/step - loss: 2.2894 - acc: 0.0750 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 39/1000\n",
      "240/240 [==============================] - 19s 77ms/step - loss: 2.2841 - acc: 0.1250 - val_loss: 2.3009 - val_acc: 0.1091\n",
      "Epoch 40/1000\n",
      "240/240 [==============================] - 15s 60ms/step - loss: 2.2848 - acc: 0.1167 - val_loss: 2.2991 - val_acc: 0.1000\n",
      "Epoch 41/1000\n",
      "240/240 [==============================] - 15s 64ms/step - loss: 2.2844 - acc: 0.1333 - val_loss: 2.3032 - val_acc: 0.1000\n",
      "Epoch 42/1000\n",
      "240/240 [==============================] - 13s 53ms/step - loss: 2.2875 - acc: 0.1292 - val_loss: 2.3009 - val_acc: 0.1000\n",
      "Epoch 43/1000\n",
      "240/240 [==============================] - 14s 57ms/step - loss: 2.2850 - acc: 0.0833 - val_loss: 2.2998 - val_acc: 0.1091\n",
      "Epoch 44/1000\n",
      "240/240 [==============================] - 16s 65ms/step - loss: 2.2835 - acc: 0.1083 - val_loss: 2.3019 - val_acc: 0.1000\n",
      "Epoch 45/1000\n",
      "240/240 [==============================] - 16s 65ms/step - loss: 2.2977 - acc: 0.1083 - val_loss: 2.3015 - val_acc: 0.0909\n",
      "Epoch 46/1000\n",
      "240/240 [==============================] - 15s 63ms/step - loss: 2.2775 - acc: 0.1250 - val_loss: 2.3020 - val_acc: 0.0909\n",
      "Epoch 47/1000\n",
      "240/240 [==============================] - 15s 62ms/step - loss: 2.2857 - acc: 0.0750 - val_loss: 2.3017 - val_acc: 0.1000\n",
      "Epoch 48/1000\n",
      "240/240 [==============================] - 15s 61ms/step - loss: 2.2811 - acc: 0.1042 - val_loss: 2.2917 - val_acc: 0.1182\n",
      "Epoch 49/1000\n",
      "240/240 [==============================] - 12s 51ms/step - loss: 2.2853 - acc: 0.0958 - val_loss: 2.3038 - val_acc: 0.1182\n",
      "Epoch 50/1000\n",
      "240/240 [==============================] - 14s 60ms/step - loss: 2.2783 - acc: 0.1167 - val_loss: 2.2937 - val_acc: 0.1091\n",
      "Epoch 51/1000\n",
      "240/240 [==============================] - 15s 64ms/step - loss: 2.2816 - acc: 0.1167 - val_loss: 2.3045 - val_acc: 0.1000\n",
      "Epoch 52/1000\n",
      "240/240 [==============================] - 16s 68ms/step - loss: 2.2791 - acc: 0.1042 - val_loss: 2.3039 - val_acc: 0.0909\n",
      "Epoch 53/1000\n",
      "240/240 [==============================] - 16s 68ms/step - loss: 2.2747 - acc: 0.1167 - val_loss: 2.3048 - val_acc: 0.0818\n",
      "Epoch 54/1000\n",
      "240/240 [==============================] - 12s 51ms/step - loss: 2.2799 - acc: 0.1333 - val_loss: 2.3021 - val_acc: 0.0909\n",
      "Epoch 55/1000\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 2.2792 - acc: 0.1042 - val_loss: 2.3042 - val_acc: 0.1000\n",
      "Epoch 56/1000\n",
      "240/240 [==============================] - 12s 52ms/step - loss: 2.2783 - acc: 0.1542 - val_loss: 2.3048 - val_acc: 0.1091\n",
      "Epoch 57/1000\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 2.2778 - acc: 0.1000 - val_loss: 2.3035 - val_acc: 0.0818\n",
      "Epoch 58/1000\n",
      "240/240 [==============================] - 13s 53ms/step - loss: 2.2617 - acc: 0.1292 - val_loss: 2.3189 - val_acc: 0.0909\n",
      "Epoch 59/1000\n",
      "240/240 [==============================] - 13s 56ms/step - loss: 2.2984 - acc: 0.0917 - val_loss: 2.3029 - val_acc: 0.1000\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 16s 65ms/step - loss: 2.2750 - acc: 0.1250 - val_loss: 2.3075 - val_acc: 0.1000\n",
      "Epoch 61/1000\n",
      "240/240 [==============================] - 13s 53ms/step - loss: 2.2731 - acc: 0.1292 - val_loss: 2.3094 - val_acc: 0.1273\n",
      "Epoch 62/1000\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 2.2730 - acc: 0.1042 - val_loss: 2.3113 - val_acc: 0.1000\n",
      "Epoch 63/1000\n",
      "240/240 [==============================] - 14s 58ms/step - loss: 2.2589 - acc: 0.1167 - val_loss: 2.3083 - val_acc: 0.1182\n",
      "Epoch 64/1000\n",
      "240/240 [==============================] - 13s 53ms/step - loss: 2.2532 - acc: 0.1375 - val_loss: 2.3404 - val_acc: 0.0636\n",
      "Epoch 65/1000\n",
      "240/240 [==============================] - 15s 64ms/step - loss: 2.2602 - acc: 0.1375 - val_loss: 2.3150 - val_acc: 0.1364\n",
      "Epoch 66/1000\n",
      "240/240 [==============================] - 14s 58ms/step - loss: 2.2558 - acc: 0.1292 - val_loss: 2.3216 - val_acc: 0.0727\n",
      "Epoch 67/1000\n",
      "240/240 [==============================] - 13s 56ms/step - loss: 2.2220 - acc: 0.1833 - val_loss: 2.3453 - val_acc: 0.0818\n",
      "Epoch 68/1000\n",
      "240/240 [==============================] - 14s 57ms/step - loss: 2.2290 - acc: 0.2042 - val_loss: 2.3221 - val_acc: 0.0909\n",
      "Epoch 69/1000\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 2.2305 - acc: 0.1833 - val_loss: 2.2879 - val_acc: 0.1636\n",
      "Epoch 70/1000\n",
      "240/240 [==============================] - 13s 52ms/step - loss: 2.2297 - acc: 0.1625 - val_loss: 2.3000 - val_acc: 0.1182\n",
      "Epoch 71/1000\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 2.1895 - acc: 0.1958 - val_loss: 2.3193 - val_acc: 0.1000\n",
      "Epoch 72/1000\n",
      "240/240 [==============================] - 14s 56ms/step - loss: 2.1672 - acc: 0.1958 - val_loss: 2.4574 - val_acc: 0.0455\n",
      "Epoch 73/1000\n",
      "240/240 [==============================] - 16s 68ms/step - loss: 2.1297 - acc: 0.2250 - val_loss: 2.3976 - val_acc: 0.1091\n",
      "Epoch 74/1000\n",
      "240/240 [==============================] - 15s 63ms/step - loss: 2.1021 - acc: 0.2333 - val_loss: 2.4145 - val_acc: 0.0909\n",
      "Epoch 75/1000\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 2.1056 - acc: 0.2458 - val_loss: 2.5195 - val_acc: 0.0727\n",
      "Epoch 76/1000\n",
      "240/240 [==============================] - 14s 58ms/step - loss: 2.0989 - acc: 0.2375 - val_loss: 2.4381 - val_acc: 0.0909\n",
      "Epoch 77/1000\n",
      "240/240 [==============================] - 16s 65ms/step - loss: 1.9785 - acc: 0.2708 - val_loss: 2.5303 - val_acc: 0.0909\n",
      "Epoch 78/1000\n",
      "240/240 [==============================] - 15s 60ms/step - loss: 1.9671 - acc: 0.2750 - val_loss: 2.5454 - val_acc: 0.0818\n",
      "Epoch 79/1000\n",
      "240/240 [==============================] - 18s 73ms/step - loss: 1.9803 - acc: 0.2583 - val_loss: 2.5918 - val_acc: 0.0909\n",
      "Epoch 80/1000\n",
      "240/240 [==============================] - 16s 69ms/step - loss: 1.9359 - acc: 0.3125 - val_loss: 2.6501 - val_acc: 0.0727\n",
      "Epoch 81/1000\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 1.8833 - acc: 0.3375 - val_loss: 2.7099 - val_acc: 0.0364\n",
      "Epoch 82/1000\n",
      "240/240 [==============================] - 17s 69ms/step - loss: 1.8273 - acc: 0.3333 - val_loss: 2.8535 - val_acc: 0.0818\n",
      "Epoch 83/1000\n",
      "240/240 [==============================] - 14s 56ms/step - loss: 1.9138 - acc: 0.2917 - val_loss: 2.8233 - val_acc: 0.0727\n",
      "Epoch 84/1000\n",
      "240/240 [==============================] - 13s 53ms/step - loss: 1.8780 - acc: 0.2833 - val_loss: 2.7680 - val_acc: 0.0818\n",
      "Epoch 85/1000\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 1.8811 - acc: 0.2792 - val_loss: 2.8389 - val_acc: 0.1000\n",
      "Epoch 86/1000\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 1.8850 - acc: 0.2958 - val_loss: 2.7304 - val_acc: 0.0727\n",
      "Epoch 87/1000\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 1.8217 - acc: 0.3375 - val_loss: 2.8234 - val_acc: 0.0818\n",
      "Epoch 88/1000\n",
      "240/240 [==============================] - 14s 59ms/step - loss: 1.7920 - acc: 0.2917 - val_loss: 2.8832 - val_acc: 0.0727\n",
      "Epoch 89/1000\n",
      "240/240 [==============================] - 16s 65ms/step - loss: 1.7358 - acc: 0.3417 - val_loss: 2.8658 - val_acc: 0.0909\n",
      "Epoch 90/1000\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 1.6820 - acc: 0.3750 - val_loss: 3.1540 - val_acc: 0.0909\n",
      "Epoch 91/1000\n",
      "240/240 [==============================] - 14s 60ms/step - loss: 1.6615 - acc: 0.3708 - val_loss: 3.0644 - val_acc: 0.0727\n",
      "Epoch 92/1000\n",
      "240/240 [==============================] - 16s 68ms/step - loss: 1.6145 - acc: 0.3792 - val_loss: 2.9963 - val_acc: 0.0818\n",
      "Epoch 93/1000\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 1.5681 - acc: 0.4042 - val_loss: 3.1189 - val_acc: 0.0636\n",
      "Epoch 94/1000\n",
      "240/240 [==============================] - 16s 68ms/step - loss: 1.5664 - acc: 0.4042 - val_loss: 3.2152 - val_acc: 0.0818\n",
      "Epoch 95/1000\n",
      "240/240 [==============================] - 16s 69ms/step - loss: 1.5156 - acc: 0.4083 - val_loss: 3.3151 - val_acc: 0.1091\n",
      "Epoch 96/1000\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 1.5446 - acc: 0.4083 - val_loss: 3.2233 - val_acc: 0.0818\n",
      "Epoch 97/1000\n",
      "240/240 [==============================] - 17s 71ms/step - loss: 1.6390 - acc: 0.3667 - val_loss: 3.1899 - val_acc: 0.0818\n",
      "Epoch 98/1000\n",
      "240/240 [==============================] - 17s 73ms/step - loss: 1.6044 - acc: 0.3417 - val_loss: 3.1774 - val_acc: 0.1455\n",
      "Epoch 99/1000\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 1.5299 - acc: 0.3667 - val_loss: 3.2239 - val_acc: 0.0818\n",
      "Epoch 100/1000\n",
      "240/240 [==============================] - 16s 68ms/step - loss: 1.4671 - acc: 0.4708 - val_loss: 3.4122 - val_acc: 0.0545\n",
      "Epoch 101/1000\n",
      "240/240 [==============================] - 15s 62ms/step - loss: 1.4864 - acc: 0.3958 - val_loss: 3.4520 - val_acc: 0.0636\n",
      "Epoch 102/1000\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 1.4603 - acc: 0.4083 - val_loss: 3.4540 - val_acc: 0.0636\n",
      "Epoch 103/1000\n",
      "240/240 [==============================] - 15s 61ms/step - loss: 1.4769 - acc: 0.3750 - val_loss: 3.4944 - val_acc: 0.1091\n",
      "Epoch 104/1000\n",
      "240/240 [==============================] - 14s 56ms/step - loss: 1.4251 - acc: 0.4167 - val_loss: 3.3876 - val_acc: 0.1000\n",
      "Epoch 105/1000\n",
      "240/240 [==============================] - 19s 80ms/step - loss: 1.5044 - acc: 0.3958 - val_loss: 3.5639 - val_acc: 0.0818\n",
      "Epoch 106/1000\n",
      "240/240 [==============================] - 13s 52ms/step - loss: 1.5381 - acc: 0.3625 - val_loss: 3.6204 - val_acc: 0.1000\n",
      "Epoch 107/1000\n",
      "240/240 [==============================] - 12s 51ms/step - loss: 1.4172 - acc: 0.4208 - val_loss: 3.5125 - val_acc: 0.0727\n",
      "Epoch 108/1000\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 1.4135 - acc: 0.4208 - val_loss: 3.6535 - val_acc: 0.0727\n",
      "Epoch 109/1000\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 1.3796 - acc: 0.4625 - val_loss: 3.6316 - val_acc: 0.0545\n",
      "Epoch 110/1000\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 1.3309 - acc: 0.4375 - val_loss: 3.7494 - val_acc: 0.0636\n",
      "Epoch 111/1000\n",
      "240/240 [==============================] - 12s 52ms/step - loss: 1.3039 - acc: 0.5000 - val_loss: 3.7889 - val_acc: 0.0727\n",
      "Epoch 112/1000\n",
      "240/240 [==============================] - 15s 60ms/step - loss: 1.2708 - acc: 0.5000 - val_loss: 3.8567 - val_acc: 0.1091\n",
      "Epoch 113/1000\n",
      "240/240 [==============================] - 14s 59ms/step - loss: 1.3324 - acc: 0.4333 - val_loss: 3.8764 - val_acc: 0.0909\n",
      "Epoch 114/1000\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 1.3880 - acc: 0.4125 - val_loss: 3.7641 - val_acc: 0.0909\n",
      "Epoch 115/1000\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 1.3358 - acc: 0.4708 - val_loss: 3.8639 - val_acc: 0.0818\n",
      "Epoch 116/1000\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 1.3386 - acc: 0.4833 - val_loss: 3.8541 - val_acc: 0.0818\n",
      "Epoch 117/1000\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 1.2800 - acc: 0.4417 - val_loss: 3.9172 - val_acc: 0.0636\n",
      "Epoch 118/1000\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 1.2778 - acc: 0.4958 - val_loss: 3.9245 - val_acc: 0.1273\n",
      "Epoch 119/1000\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 1.2625 - acc: 0.4875 - val_loss: 3.8791 - val_acc: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "240/240 [==============================] - 12s 51ms/step - loss: 1.2617 - acc: 0.4792 - val_loss: 3.8725 - val_acc: 0.1091\n",
      "Epoch 121/1000\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 1.1916 - acc: 0.4917 - val_loss: 3.9111 - val_acc: 0.1182\n",
      "Epoch 122/1000\n",
      "240/240 [==============================] - 12s 51ms/step - loss: 1.1687 - acc: 0.5667 - val_loss: 4.0066 - val_acc: 0.0727\n",
      "Epoch 123/1000\n",
      "240/240 [==============================] - 12s 51ms/step - loss: 1.1255 - acc: 0.5625 - val_loss: 4.1110 - val_acc: 0.1091\n",
      "Epoch 124/1000\n",
      "240/240 [==============================] - 14s 57ms/step - loss: 1.1203 - acc: 0.5458 - val_loss: 4.2149 - val_acc: 0.0818\n",
      "Epoch 125/1000\n",
      "240/240 [==============================] - 15s 61ms/step - loss: 1.1696 - acc: 0.5167 - val_loss: 4.2432 - val_acc: 0.1364\n",
      "Epoch 126/1000\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 1.1039 - acc: 0.5667 - val_loss: 4.1696 - val_acc: 0.0818\n",
      "Epoch 127/1000\n",
      "240/240 [==============================] - 15s 63ms/step - loss: 1.0975 - acc: 0.5667 - val_loss: 4.2596 - val_acc: 0.0727\n",
      "Epoch 128/1000\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 1.0769 - acc: 0.6333 - val_loss: 4.3187 - val_acc: 0.0727\n",
      "Epoch 129/1000\n",
      "240/240 [==============================] - 13s 53ms/step - loss: 1.0349 - acc: 0.6333 - val_loss: 4.3431 - val_acc: 0.0727\n",
      "Epoch 130/1000\n",
      "240/240 [==============================] - 13s 52ms/step - loss: 1.0488 - acc: 0.6000 - val_loss: 4.3548 - val_acc: 0.0818\n",
      "Epoch 131/1000\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 1.1245 - acc: 0.5333 - val_loss: 4.2991 - val_acc: 0.0818\n",
      "Epoch 132/1000\n",
      "240/240 [==============================] - 16s 68ms/step - loss: 1.2128 - acc: 0.5083 - val_loss: 4.3398 - val_acc: 0.1182\n",
      "Epoch 133/1000\n",
      "240/240 [==============================] - 14s 60ms/step - loss: 1.1737 - acc: 0.5167 - val_loss: 4.3882 - val_acc: 0.1000\n",
      "Epoch 134/1000\n",
      "240/240 [==============================] - 13s 52ms/step - loss: 1.2169 - acc: 0.5167 - val_loss: 4.3839 - val_acc: 0.1000\n",
      "Epoch 135/1000\n",
      "240/240 [==============================] - 14s 57ms/step - loss: 1.2073 - acc: 0.4458 - val_loss: 4.2201 - val_acc: 0.1000\n",
      "Epoch 136/1000\n",
      "240/240 [==============================] - 15s 64ms/step - loss: 1.3715 - acc: 0.4792 - val_loss: 4.1439 - val_acc: 0.1273\n",
      "Epoch 137/1000\n",
      "240/240 [==============================] - 14s 58ms/step - loss: 1.3446 - acc: 0.4792 - val_loss: 4.3836 - val_acc: 0.0727\n",
      "Epoch 138/1000\n",
      "240/240 [==============================] - 14s 59ms/step - loss: 1.1851 - acc: 0.5042 - val_loss: 4.2262 - val_acc: 0.1000\n",
      "Epoch 139/1000\n",
      "240/240 [==============================] - 13s 56ms/step - loss: 1.2268 - acc: 0.4750 - val_loss: 4.3328 - val_acc: 0.1091\n",
      "Epoch 140/1000\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 1.0685 - acc: 0.5625 - val_loss: 4.3488 - val_acc: 0.1091\n",
      "Epoch 141/1000\n",
      "240/240 [==============================] - 14s 56ms/step - loss: 1.0365 - acc: 0.5917 - val_loss: 4.2835 - val_acc: 0.0909\n",
      "Epoch 142/1000\n",
      "240/240 [==============================] - 15s 61ms/step - loss: 1.0135 - acc: 0.6542 - val_loss: 4.4128 - val_acc: 0.1182\n",
      "Epoch 143/1000\n",
      "240/240 [==============================] - 14s 58ms/step - loss: 1.0168 - acc: 0.6042 - val_loss: 4.4340 - val_acc: 0.1182\n",
      "Epoch 144/1000\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 1.0319 - acc: 0.6208 - val_loss: 4.4813 - val_acc: 0.1273\n",
      "Epoch 145/1000\n",
      "240/240 [==============================] - 15s 62ms/step - loss: 0.9805 - acc: 0.6500 - val_loss: 4.5576 - val_acc: 0.1182\n",
      "Epoch 146/1000\n",
      "240/240 [==============================] - 15s 61ms/step - loss: 0.9387 - acc: 0.6792 - val_loss: 4.5808 - val_acc: 0.1182\n",
      "Epoch 147/1000\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 0.9934 - acc: 0.6125 - val_loss: 4.5029 - val_acc: 0.1091\n",
      "Epoch 148/1000\n",
      "240/240 [==============================] - 15s 61ms/step - loss: 0.9994 - acc: 0.6292 - val_loss: 4.6012 - val_acc: 0.1182\n",
      "Epoch 149/1000\n",
      "240/240 [==============================] - 15s 63ms/step - loss: 0.9656 - acc: 0.6583 - val_loss: 4.6683 - val_acc: 0.1091\n",
      "Epoch 150/1000\n",
      "240/240 [==============================] - 15s 61ms/step - loss: 0.9778 - acc: 0.6208 - val_loss: 4.6860 - val_acc: 0.1091\n",
      "Epoch 151/1000\n",
      "240/240 [==============================] - 13s 52ms/step - loss: 0.9704 - acc: 0.6458 - val_loss: 4.7485 - val_acc: 0.0818\n",
      "Epoch 152/1000\n",
      "240/240 [==============================] - 13s 53ms/step - loss: 1.0993 - acc: 0.5375 - val_loss: 4.6439 - val_acc: 0.1000\n",
      "Epoch 153/1000\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 1.3009 - acc: 0.4208 - val_loss: 4.5219 - val_acc: 0.1182\n",
      "Epoch 154/1000\n",
      "240/240 [==============================] - 12s 52ms/step - loss: 1.7071 - acc: 0.3208 - val_loss: 4.3673 - val_acc: 0.0909\n",
      "Epoch 155/1000\n",
      "240/240 [==============================] - 13s 52ms/step - loss: 1.1235 - acc: 0.5667 - val_loss: 4.7169 - val_acc: 0.0909\n",
      "Epoch 156/1000\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 1.0808 - acc: 0.5375 - val_loss: 4.5861 - val_acc: 0.0545\n",
      "Epoch 157/1000\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 1.0411 - acc: 0.5917 - val_loss: 4.6658 - val_acc: 0.0727\n",
      "Epoch 158/1000\n",
      "240/240 [==============================] - 14s 58ms/step - loss: 1.0506 - acc: 0.6083 - val_loss: 4.5731 - val_acc: 0.1182\n",
      "Epoch 159/1000\n",
      "240/240 [==============================] - 15s 64ms/step - loss: 1.0482 - acc: 0.5958 - val_loss: 4.6011 - val_acc: 0.1273\n",
      "Epoch 160/1000\n",
      "240/240 [==============================] - 15s 64ms/step - loss: 0.9670 - acc: 0.6250 - val_loss: 4.6719 - val_acc: 0.1364\n",
      "Epoch 161/1000\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.9106 - acc: 0.6333 - val_loss: 4.5694 - val_acc: 0.1091\n",
      "Epoch 162/1000\n",
      "240/240 [==============================] - 13s 53ms/step - loss: 0.8901 - acc: 0.6750 - val_loss: 4.7240 - val_acc: 0.1364\n",
      "Epoch 163/1000\n",
      "240/240 [==============================] - 13s 52ms/step - loss: 0.9266 - acc: 0.6667 - val_loss: 4.7320 - val_acc: 0.0909\n",
      "Epoch 164/1000\n",
      "240/240 [==============================] - 12s 51ms/step - loss: 0.8983 - acc: 0.6458 - val_loss: 4.7177 - val_acc: 0.1091\n",
      "Epoch 165/1000\n",
      "240/240 [==============================] - 12s 52ms/step - loss: 0.8409 - acc: 0.7458 - val_loss: 4.8004 - val_acc: 0.0909\n",
      "Epoch 166/1000\n",
      "240/240 [==============================] - 16s 68ms/step - loss: 0.8485 - acc: 0.7292 - val_loss: 4.8174 - val_acc: 0.1182\n",
      "Epoch 167/1000\n",
      "240/240 [==============================] - 13s 52ms/step - loss: 0.8096 - acc: 0.7375 - val_loss: 4.8417 - val_acc: 0.1000\n",
      "Epoch 168/1000\n",
      "240/240 [==============================] - 13s 53ms/step - loss: 0.8167 - acc: 0.6875 - val_loss: 4.9056 - val_acc: 0.1000\n",
      "Epoch 169/1000\n",
      "240/240 [==============================] - 12s 52ms/step - loss: 0.8334 - acc: 0.7167 - val_loss: 4.8702 - val_acc: 0.1091\n",
      "Epoch 170/1000\n",
      "240/240 [==============================] - 12s 52ms/step - loss: 0.8895 - acc: 0.7333 - val_loss: 4.8950 - val_acc: 0.1000\n",
      "Epoch 171/1000\n",
      "240/240 [==============================] - 13s 56ms/step - loss: 1.0244 - acc: 0.6333 - val_loss: 4.9184 - val_acc: 0.1091\n",
      "Epoch 172/1000\n",
      "240/240 [==============================] - 12s 52ms/step - loss: 1.0662 - acc: 0.5583 - val_loss: 4.7743 - val_acc: 0.1091\n",
      "Epoch 173/1000\n",
      "240/240 [==============================] - 15s 64ms/step - loss: 0.9522 - acc: 0.6583 - val_loss: 4.7835 - val_acc: 0.0818\n",
      "Epoch 174/1000\n",
      "240/240 [==============================] - 14s 58ms/step - loss: 1.0539 - acc: 0.5500 - val_loss: 4.6962 - val_acc: 0.1273\n",
      "Epoch 175/1000\n",
      "240/240 [==============================] - 15s 61ms/step - loss: 0.8727 - acc: 0.6875 - val_loss: 4.8817 - val_acc: 0.1000\n",
      "Epoch 176/1000\n",
      "240/240 [==============================] - 12s 51ms/step - loss: 0.8632 - acc: 0.6875 - val_loss: 4.8301 - val_acc: 0.1000\n",
      "Epoch 177/1000\n",
      "240/240 [==============================] - 13s 56ms/step - loss: 0.8637 - acc: 0.6958 - val_loss: 4.8625 - val_acc: 0.1273\n",
      "Epoch 178/1000\n",
      "240/240 [==============================] - 14s 56ms/step - loss: 0.7898 - acc: 0.7583 - val_loss: 4.9728 - val_acc: 0.1182\n",
      "Epoch 179/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 13s 55ms/step - loss: 0.8007 - acc: 0.7500 - val_loss: 5.0208 - val_acc: 0.0909\n",
      "Epoch 180/1000\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 0.8793 - acc: 0.6792 - val_loss: 5.1310 - val_acc: 0.0909\n",
      "Epoch 181/1000\n",
      "240/240 [==============================] - 15s 62ms/step - loss: 0.8562 - acc: 0.6750 - val_loss: 5.0591 - val_acc: 0.1091\n",
      "Epoch 182/1000\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 0.7875 - acc: 0.7083 - val_loss: 5.0320 - val_acc: 0.0818\n",
      "Epoch 183/1000\n",
      "240/240 [==============================] - 14s 60ms/step - loss: 0.8325 - acc: 0.6750 - val_loss: 5.2046 - val_acc: 0.1000\n",
      "Epoch 184/1000\n",
      "240/240 [==============================] - 14s 60ms/step - loss: 0.7789 - acc: 0.7083 - val_loss: 5.1967 - val_acc: 0.0909\n",
      "Epoch 185/1000\n",
      "240/240 [==============================] - 14s 59ms/step - loss: 0.8515 - acc: 0.6875 - val_loss: 5.0979 - val_acc: 0.1000\n",
      "Epoch 186/1000\n",
      "240/240 [==============================] - 14s 58ms/step - loss: 0.8678 - acc: 0.6625 - val_loss: 5.2508 - val_acc: 0.0818\n",
      "Epoch 187/1000\n",
      "240/240 [==============================] - 14s 59ms/step - loss: 0.8089 - acc: 0.6875 - val_loss: 5.1888 - val_acc: 0.1091\n",
      "Epoch 188/1000\n",
      "240/240 [==============================] - 14s 57ms/step - loss: 0.7754 - acc: 0.7167 - val_loss: 5.1150 - val_acc: 0.1091\n",
      "Epoch 189/1000\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 0.7574 - acc: 0.7375 - val_loss: 5.2424 - val_acc: 0.1000\n",
      "Epoch 190/1000\n",
      "240/240 [==============================] - 14s 57ms/step - loss: 0.7260 - acc: 0.7542 - val_loss: 5.2303 - val_acc: 0.1000\n",
      "Epoch 191/1000\n",
      "240/240 [==============================] - 15s 61ms/step - loss: 0.7041 - acc: 0.7917 - val_loss: 5.2602 - val_acc: 0.1273\n",
      "Epoch 192/1000\n",
      "240/240 [==============================] - 15s 64ms/step - loss: 0.6710 - acc: 0.7792 - val_loss: 5.4180 - val_acc: 0.1000\n",
      "Epoch 193/1000\n",
      "240/240 [==============================] - 13s 56ms/step - loss: 0.7110 - acc: 0.7708 - val_loss: 5.2225 - val_acc: 0.1273\n",
      "Epoch 194/1000\n",
      "240/240 [==============================] - 18s 74ms/step - loss: 0.7305 - acc: 0.7750 - val_loss: 5.3526 - val_acc: 0.1000\n",
      "Epoch 195/1000\n",
      "240/240 [==============================] - 22s 94ms/step - loss: 0.6301 - acc: 0.8208 - val_loss: 5.3194 - val_acc: 0.1091\n",
      "Epoch 196/1000\n",
      "240/240 [==============================] - 15s 64ms/step - loss: 0.6383 - acc: 0.8542 - val_loss: 5.4959 - val_acc: 0.0818\n",
      "Epoch 197/1000\n",
      "240/240 [==============================] - 15s 61ms/step - loss: 0.6382 - acc: 0.7958 - val_loss: 5.4461 - val_acc: 0.1091\n",
      "Epoch 198/1000\n",
      "240/240 [==============================] - 16s 65ms/step - loss: 0.6349 - acc: 0.8000 - val_loss: 5.5636 - val_acc: 0.0727\n",
      "Epoch 199/1000\n",
      "240/240 [==============================] - 18s 76ms/step - loss: 0.6622 - acc: 0.8000 - val_loss: 5.4140 - val_acc: 0.1364\n",
      "Epoch 200/1000\n",
      "240/240 [==============================] - 14s 60ms/step - loss: 0.6656 - acc: 0.7958 - val_loss: 5.5382 - val_acc: 0.1273\n",
      "Epoch 201/1000\n",
      "240/240 [==============================] - 14s 58ms/step - loss: 0.5848 - acc: 0.8333 - val_loss: 5.5901 - val_acc: 0.1000\n",
      "Epoch 202/1000\n",
      "240/240 [==============================] - 20s 84ms/step - loss: 0.6529 - acc: 0.7792 - val_loss: 5.5535 - val_acc: 0.1273\n",
      "Epoch 203/1000\n",
      "240/240 [==============================] - 21s 87ms/step - loss: 0.7286 - acc: 0.7708 - val_loss: 5.5655 - val_acc: 0.1182\n",
      "Epoch 204/1000\n",
      "240/240 [==============================] - 14s 57ms/step - loss: 0.6766 - acc: 0.7875 - val_loss: 5.6229 - val_acc: 0.1273\n",
      "Epoch 205/1000\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 0.7015 - acc: 0.7708 - val_loss: 5.6929 - val_acc: 0.1000\n",
      "Epoch 206/1000\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 0.7693 - acc: 0.7208 - val_loss: 5.5432 - val_acc: 0.1182\n",
      "Epoch 207/1000\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 0.6762 - acc: 0.7875 - val_loss: 5.6674 - val_acc: 0.1091\n",
      "Epoch 208/1000\n",
      "240/240 [==============================] - 15s 63ms/step - loss: 0.6443 - acc: 0.8333 - val_loss: 5.6425 - val_acc: 0.1364\n",
      "Epoch 209/1000\n",
      "240/240 [==============================] - 18s 74ms/step - loss: 0.5996 - acc: 0.8375 - val_loss: 5.7106 - val_acc: 0.1091\n",
      "Epoch 210/1000\n",
      "240/240 [==============================] - 27s 113ms/step - loss: 0.6461 - acc: 0.8042 - val_loss: 5.5485 - val_acc: 0.1182\n",
      "Epoch 211/1000\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 0.7544 - acc: 0.7500 - val_loss: 5.5906 - val_acc: 0.1364\n",
      "Epoch 212/1000\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 0.7219 - acc: 0.7375 - val_loss: 5.7212 - val_acc: 0.1182\n",
      "Epoch 213/1000\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 0.8155 - acc: 0.7042 - val_loss: 5.5849 - val_acc: 0.1273\n",
      "Epoch 214/1000\n",
      "240/240 [==============================] - 12s 52ms/step - loss: 0.7430 - acc: 0.7792 - val_loss: 5.7774 - val_acc: 0.1273\n",
      "Epoch 215/1000\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 0.7559 - acc: 0.7333 - val_loss: 5.8531 - val_acc: 0.1182\n",
      "Epoch 216/1000\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 0.7049 - acc: 0.7292 - val_loss: 5.7109 - val_acc: 0.1182\n",
      "Epoch 217/1000\n",
      "240/240 [==============================] - 14s 57ms/step - loss: 0.6268 - acc: 0.7792 - val_loss: 5.7379 - val_acc: 0.1364\n",
      "Epoch 218/1000\n",
      "240/240 [==============================] - 14s 58ms/step - loss: 0.5740 - acc: 0.8167 - val_loss: 5.8408 - val_acc: 0.1273\n",
      "Epoch 219/1000\n",
      "240/240 [==============================] - 25s 104ms/step - loss: 0.6106 - acc: 0.8167 - val_loss: 5.8770 - val_acc: 0.1091\n",
      "Epoch 220/1000\n",
      "240/240 [==============================] - 18s 73ms/step - loss: 0.6199 - acc: 0.8125 - val_loss: 5.8516 - val_acc: 0.1091\n",
      "Epoch 221/1000\n",
      "240/240 [==============================] - 14s 58ms/step - loss: 0.6342 - acc: 0.7875 - val_loss: 6.0047 - val_acc: 0.1364\n",
      "Epoch 222/1000\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 0.6173 - acc: 0.8333 - val_loss: 5.9126 - val_acc: 0.1000\n",
      "Epoch 223/1000\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 0.5814 - acc: 0.8500 - val_loss: 5.7774 - val_acc: 0.1364\n",
      "Epoch 224/1000\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 0.5992 - acc: 0.8375 - val_loss: 6.1244 - val_acc: 0.1000\n",
      "Epoch 225/1000\n",
      "240/240 [==============================] - 15s 62ms/step - loss: 0.5737 - acc: 0.8125 - val_loss: 6.0459 - val_acc: 0.0727\n",
      "Epoch 226/1000\n",
      "240/240 [==============================] - 23s 94ms/step - loss: 0.6013 - acc: 0.8167 - val_loss: 6.0584 - val_acc: 0.0909\n",
      "Epoch 227/1000\n",
      "240/240 [==============================] - 15s 63ms/step - loss: 0.5341 - acc: 0.8625 - val_loss: 6.0313 - val_acc: 0.0909\n",
      "Epoch 228/1000\n",
      "240/240 [==============================] - 29s 123ms/step - loss: 0.5386 - acc: 0.8583 - val_loss: 6.0413 - val_acc: 0.0818\n",
      "Epoch 229/1000\n",
      "240/240 [==============================] - 21s 88ms/step - loss: 0.5263 - acc: 0.8333 - val_loss: 5.9642 - val_acc: 0.1273\n",
      "Epoch 230/1000\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.5351 - acc: 0.8708 - val_loss: 6.1748 - val_acc: 0.1091\n",
      "Epoch 231/1000\n",
      "240/240 [==============================] - 15s 61ms/step - loss: 0.5985 - acc: 0.8083 - val_loss: 6.0864 - val_acc: 0.1273\n",
      "Epoch 232/1000\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.6823 - acc: 0.7708 - val_loss: 6.2042 - val_acc: 0.1182\n",
      "Epoch 233/1000\n",
      "240/240 [==============================] - 14s 60ms/step - loss: 0.6027 - acc: 0.7833 - val_loss: 6.1267 - val_acc: 0.1364\n",
      "Epoch 234/1000\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 0.6066 - acc: 0.8000 - val_loss: 6.1359 - val_acc: 0.1000\n",
      "Epoch 235/1000\n",
      "240/240 [==============================] - 15s 64ms/step - loss: 0.7139 - acc: 0.7333 - val_loss: 6.1765 - val_acc: 0.1000\n",
      "Epoch 236/1000\n",
      "240/240 [==============================] - 14s 59ms/step - loss: 0.7339 - acc: 0.7333 - val_loss: 6.1729 - val_acc: 0.1182\n",
      "Epoch 237/1000\n",
      "240/240 [==============================] - 13s 56ms/step - loss: 0.9406 - acc: 0.6667 - val_loss: 6.1615 - val_acc: 0.1545\n",
      "Epoch 238/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 20s 82ms/step - loss: 0.8405 - acc: 0.6708 - val_loss: 6.1054 - val_acc: 0.1182\n",
      "Epoch 239/1000\n",
      "240/240 [==============================] - 24s 101ms/step - loss: 0.7212 - acc: 0.7083 - val_loss: 6.1174 - val_acc: 0.0818\n",
      "Epoch 240/1000\n",
      "240/240 [==============================] - 15s 63ms/step - loss: 0.8936 - acc: 0.6750 - val_loss: 5.9156 - val_acc: 0.1091\n",
      "Epoch 241/1000\n",
      "240/240 [==============================] - 15s 63ms/step - loss: 0.8028 - acc: 0.6917 - val_loss: 6.1551 - val_acc: 0.0818\n",
      "Epoch 242/1000\n",
      "240/240 [==============================] - 12s 51ms/step - loss: 0.7094 - acc: 0.7375 - val_loss: 6.1778 - val_acc: 0.1000\n",
      "Epoch 243/1000\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 0.6571 - acc: 0.7583 - val_loss: 6.1447 - val_acc: 0.1182\n",
      "Epoch 244/1000\n",
      "240/240 [==============================] - 14s 60ms/step - loss: 0.7388 - acc: 0.7250 - val_loss: 6.1217 - val_acc: 0.1000\n",
      "Epoch 245/1000\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 0.5394 - acc: 0.8375 - val_loss: 6.1425 - val_acc: 0.0545\n",
      "Epoch 246/1000\n",
      "240/240 [==============================] - 31s 129ms/step - loss: 0.5408 - acc: 0.8333 - val_loss: 6.1684 - val_acc: 0.0727\n",
      "Epoch 247/1000\n",
      "240/240 [==============================] - 18s 76ms/step - loss: 0.4964 - acc: 0.8708 - val_loss: 6.2031 - val_acc: 0.0818\n",
      "Epoch 248/1000\n",
      "240/240 [==============================] - 14s 58ms/step - loss: 0.5454 - acc: 0.8542 - val_loss: 6.3478 - val_acc: 0.1000\n",
      "Epoch 249/1000\n",
      "240/240 [==============================] - 15s 62ms/step - loss: 0.7983 - acc: 0.6792 - val_loss: 6.2569 - val_acc: 0.0818\n",
      "Epoch 250/1000\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 1.0209 - acc: 0.5625 - val_loss: 6.2485 - val_acc: 0.1091\n",
      "Epoch 251/1000\n",
      "240/240 [==============================] - 14s 58ms/step - loss: 1.5856 - acc: 0.5000 - val_loss: 6.0986 - val_acc: 0.1182\n",
      "Epoch 252/1000\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 1.1790 - acc: 0.6208 - val_loss: 6.0367 - val_acc: 0.0727\n",
      "Epoch 253/1000\n",
      "240/240 [==============================] - 19s 81ms/step - loss: 0.7703 - acc: 0.6958 - val_loss: 6.0715 - val_acc: 0.1091\n",
      "Epoch 254/1000\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 0.7561 - acc: 0.7208 - val_loss: 6.0995 - val_acc: 0.0909\n",
      "Epoch 255/1000\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 0.6189 - acc: 0.8083 - val_loss: 6.0675 - val_acc: 0.0909\n",
      "Epoch 256/1000\n",
      "240/240 [==============================] - 12s 51ms/step - loss: 0.5855 - acc: 0.8708 - val_loss: 6.0620 - val_acc: 0.1091\n",
      "Epoch 257/1000\n",
      "240/240 [==============================] - 12s 51ms/step - loss: 0.5885 - acc: 0.8333 - val_loss: 6.0955 - val_acc: 0.0818\n",
      "Epoch 258/1000\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 0.5859 - acc: 0.8167 - val_loss: 6.1986 - val_acc: 0.0909\n",
      "Epoch 259/1000\n",
      "240/240 [==============================] - 12s 51ms/step - loss: 0.5568 - acc: 0.8250 - val_loss: 6.2134 - val_acc: 0.0636\n",
      "Epoch 260/1000\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 0.5273 - acc: 0.8292 - val_loss: 6.1233 - val_acc: 0.0818\n",
      "Epoch 261/1000\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 0.5044 - acc: 0.8625 - val_loss: 6.2475 - val_acc: 0.1091\n",
      "Epoch 262/1000\n",
      "240/240 [==============================] - 15s 62ms/step - loss: 0.5158 - acc: 0.8917 - val_loss: 6.2151 - val_acc: 0.1000\n",
      "Epoch 263/1000\n",
      "240/240 [==============================] - 14s 57ms/step - loss: 0.4870 - acc: 0.8708 - val_loss: 6.2496 - val_acc: 0.1000\n",
      "Epoch 264/1000\n",
      "240/240 [==============================] - 15s 61ms/step - loss: 0.4611 - acc: 0.8750 - val_loss: 6.2164 - val_acc: 0.1091\n",
      "Epoch 265/1000\n",
      "240/240 [==============================] - 15s 62ms/step - loss: 0.5359 - acc: 0.8417 - val_loss: 6.2451 - val_acc: 0.0909\n",
      "Epoch 266/1000\n",
      "240/240 [==============================] - 15s 64ms/step - loss: 0.4407 - acc: 0.9125 - val_loss: 6.2868 - val_acc: 0.1182\n",
      "Epoch 267/1000\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 0.4458 - acc: 0.9083 - val_loss: 6.3616 - val_acc: 0.0909\n",
      "Epoch 268/1000\n",
      "240/240 [==============================] - 13s 56ms/step - loss: 0.4575 - acc: 0.8958 - val_loss: 6.3855 - val_acc: 0.0909\n",
      "Epoch 269/1000\n",
      "240/240 [==============================] - 15s 64ms/step - loss: 0.4532 - acc: 0.9042 - val_loss: 6.4559 - val_acc: 0.0909\n",
      "Epoch 270/1000\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 0.4476 - acc: 0.8667 - val_loss: 6.3268 - val_acc: 0.0818\n",
      "Epoch 271/1000\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 0.4180 - acc: 0.8917 - val_loss: 6.5364 - val_acc: 0.1000\n",
      "Epoch 272/1000\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 0.4081 - acc: 0.9333 - val_loss: 6.5465 - val_acc: 0.0909\n",
      "Epoch 273/1000\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 0.4336 - acc: 0.9042 - val_loss: 6.5974 - val_acc: 0.1182\n",
      "Epoch 274/1000\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 0.4482 - acc: 0.8917 - val_loss: 6.6163 - val_acc: 0.0909\n",
      "Epoch 275/1000\n",
      "240/240 [==============================] - 14s 58ms/step - loss: 0.4290 - acc: 0.8833 - val_loss: 6.5750 - val_acc: 0.1091\n",
      "Epoch 276/1000\n",
      "240/240 [==============================] - 13s 53ms/step - loss: 0.4361 - acc: 0.9042 - val_loss: 6.6628 - val_acc: 0.0909\n",
      "Epoch 277/1000\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 0.4194 - acc: 0.9042 - val_loss: 6.6795 - val_acc: 0.1000\n",
      "Epoch 278/1000\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 0.3645 - acc: 0.9417 - val_loss: 6.7327 - val_acc: 0.0909\n",
      "Epoch 279/1000\n",
      "240/240 [==============================] - 13s 53ms/step - loss: 0.3610 - acc: 0.9417 - val_loss: 6.7642 - val_acc: 0.0909\n",
      "Epoch 280/1000\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 0.3970 - acc: 0.9000 - val_loss: 6.7419 - val_acc: 0.0909\n",
      "Epoch 281/1000\n",
      "240/240 [==============================] - 13s 56ms/step - loss: 0.3682 - acc: 0.9333 - val_loss: 6.7390 - val_acc: 0.0909\n",
      "Epoch 282/1000\n",
      "240/240 [==============================] - 13s 53ms/step - loss: 0.3935 - acc: 0.9042 - val_loss: 6.8648 - val_acc: 0.0909\n",
      "Epoch 283/1000\n",
      "240/240 [==============================] - 13s 56ms/step - loss: 0.3836 - acc: 0.9125 - val_loss: 6.8370 - val_acc: 0.1000\n",
      "Epoch 284/1000\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 0.3536 - acc: 0.9458 - val_loss: 6.8713 - val_acc: 0.1000\n",
      "Epoch 285/1000\n",
      "240/240 [==============================] - 14s 59ms/step - loss: 0.3975 - acc: 0.8792 - val_loss: 6.9187 - val_acc: 0.0909\n",
      "Epoch 286/1000\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 0.3601 - acc: 0.9292 - val_loss: 7.0114 - val_acc: 0.0909\n",
      "Epoch 287/1000\n",
      "240/240 [==============================] - 14s 58ms/step - loss: 0.3685 - acc: 0.9083 - val_loss: 6.9946 - val_acc: 0.1091\n",
      "Epoch 288/1000\n",
      "220/240 [==========================>...] - ETA: 1s - loss: 0.3620 - acc: 0.8955"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-355843850991>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLSTM_with_2layers_1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM_2Layer1DDelta5epochs1000'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-43210c223a22>\u001b[0m in \u001b[0;36mLSTM_with_2layers_1D\u001b[0;34m(name, dropout, n_units, time_steps, n_inputs, batch_size, n_epochs)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtimei\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtimef\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LSTM_with_2layers_1D('LSTM_2Layer1DDelta5epochs1000',dropout=0.5,n_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_with_2layers_1D('LSTM_2Layer1DDelta8',dropout=0.8,n_epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(dir):\n",
    "    m=tf.keras.models.load_model(dir)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recording audios and predict them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8e68eb1c774a59a8b114ebe183cd9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Record', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "button1 = widgets.Button(description=\"Record\",)\n",
    "button2 = widgets.Button(description='Test')\n",
    "display(button)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    print(\"Button clicked.\")\n",
    "\n",
    "button1.on_click(on_button_clicked)\n",
    "button2.on_click(on_button_clicked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording...\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    " \n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 48000#44100\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 2\n",
    "WAVE_OUTPUT_FILENAME = \"file.wav\"\n",
    " \n",
    "audio = pyaudio.PyAudio()\n",
    " \n",
    "# start Recording\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                rate=RATE, input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "print (\"recording...\")\n",
    "frames = []\n",
    " \n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "print (\"finished recording\")\n",
    " \n",
    " \n",
    "# stop Recording\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    " \n",
    "waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "waveFile.setnchannels(CHANNELS)\n",
    "waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "waveFile.setframerate(RATE)\n",
    "waveFile.writeframes(b''.join(frames))\n",
    "waveFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'wave' from '/home/visoc/anaconda3/envs/tf/lib/python3.6/wave.py'>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "wave, sr = librosa.load('file.wav', mono=True)\n",
    "features= librosa.feature.mfcc(wave, sr,n_mfcc=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00155109, -0.00390198, -0.00120344, ...,  0.00196864,\n",
       "        0.00147835,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = sklearn.preprocessing.scale(features, axis=1)\n",
    "features=np.pad(features,((0,0),(0,160-len(features[0]))),mode='constant', constant_values=0)\n",
    "f=np.matrix.transpose(np.array([features]),[0,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=model.predict_classes(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Sequential.get_config of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f4076c35128>>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['cuatro']], dtype='<U6')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(np.eye(10)[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=class_to_integer_encoded(label[0]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['seis'], dtype='<U6')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.inverse_transform(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
