{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importanción de librerías "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.externals import joblib as joblib\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de ficheros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función se encarga de generar un archivo txt de manera que este contenga 2 elementos por fila ('name_file','etiqueta') de esta manera permitirá poder entrenar la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "def generate_file_data(dir,name):\n",
    "    directory=dir\n",
    "    #el nombre de los archivos posee el primer dígito en el nombre de esta forma permitirá etiquetarlos.\n",
    "    a={'0':'cero','1':'uno','2':'dos','3':'tres','4':'cuatro','5':'cinco','6':'seis','7':'siete','8':'ocho','9':'nueve'}\n",
    "    da=os.listdir(directory)\n",
    "    # ordena los archivos\n",
    "    da.sort()\n",
    "    file = open(dir+name+'.txt',\"w\")\n",
    "    for filename in da:\n",
    "        if '.wav' in filename:\n",
    "            file.write(filename+','+a[filename[0]]+'\\n')\n",
    "    file.close() \n",
    "    # genera el fichero\n",
    "    with open(directory+'/'+name+'.txt') as f:\n",
    "        read_data = f.read()\n",
    "        f.closed\n",
    "    read_data=read_data.split('\\n')\n",
    "    read_data=read_data[0:len(read_data)-1]\n",
    "    return read_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding words with One Hot Encoding\n",
    "En esta sección se usará one hot encoding para representar las palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot=joblib.load('OneHotEncoding/onehot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se muestran las funciones para codificar y decodificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x):# tomará un array de string y lo transformada a encode\n",
    "    return onehot.transform(x.reshape(-1,1)).toarray()\n",
    "def decode(x):\n",
    "    return onehot.inverse_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_features(DIR,list_dir):\n",
    "    mfcc_audios=[]\n",
    "    for dir in list_dir:\n",
    "        wave, sr = librosa.load(DIR+dir, mono=True,sr=16000)\n",
    "        features= librosa.feature.mfcc(wave, sr,n_mfcc=13)\n",
    "        try:\n",
    "            features=np.pad(features,((0,0),(0,110-len(features[0]))),mode='constant', constant_values=0)\n",
    "        except OSError as err:\n",
    "            print(dir)\n",
    "        mfcc_audios.append(features)\n",
    "    mfcc_audios=np.array(mfcc_audios)\n",
    "    return mfcc_audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(dir,name):\n",
    "    file = open(dir+name)\n",
    "    f=file.read()\n",
    "    file.close()\n",
    "    f=f.split('\\n')\n",
    "    f=f[0:len(f)-1]\n",
    "    labels=[]\n",
    "    names_audios=[]\n",
    "    for i in f:\n",
    "        j=i.split(',')\n",
    "        names_audios.append(j[0])\n",
    "        labels.append(j[1])\n",
    "    labels=np.array(labels)\n",
    "    onehot= encode(labels)\n",
    "    mfcc=mfcc_features(dir,names_audios)\n",
    "    print(name+' OK')\n",
    "    return mfcc,onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se definen los distintos modelos a aplicar en este seminario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se cargará el modelo propuesto para realizar las pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(dir):\n",
    "    m=tf.keras.models.load_model(dir)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('Models/Model_LSTM_2Layer2D6006/LSTM_2Layer2D6006')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recording audios and predict them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import pyaudio\n",
    "import wave\n",
    "import sklearn.externals.joblib as joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(name='prueba'):\n",
    "    generate_file_data('data/pruebas/',name)\n",
    "    data=prepare_data('data/pruebas/',name+'.txt')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_audio():\n",
    "\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "    RATE = 16000#44100\n",
    "    CHUNK = 1024\n",
    "    RECORD_SECONDS = 2\n",
    "    WAVE_OUTPUT_FILENAME = \"file.wav\"\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                rate=RATE, input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "    frames = []\n",
    " \n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data) \n",
    "    # stop Recording\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "    waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    waveFile.setnchannels(CHANNELS)\n",
    "    waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    waveFile.setframerate(RATE)\n",
    "    waveFile.writeframes(b''.join(frames))\n",
    "    waveFile.close()\n",
    "    onda, sr = librosa.load('file.wav', mono=True)\n",
    "    features= librosa.feature.mfcc(onda, sr,n_mfcc=13)\n",
    "    features=np.pad(features,((0,0),(0,110-len(features[0]))),mode='constant', constant_values=0)\n",
    "    f=np.matrix.transpose(np.array([features]),[0,2,1])\n",
    "    label=model.predict_classes(f)\n",
    "    texto=decode(np.eye(10)[label])\n",
    "    print(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prec(n):\n",
    "    data=prepare()\n",
    "    testx, testy = data[0],data[1]\n",
    "    testx=np.matrix.transpose(testx,[0,2,1])\n",
    "    print(model.evaluate(testx,testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e58f1378e6d42168af2532258e8fec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Test Model', style=ButtonStyle()), Button(description='Run Example', style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prueba.txt OK\n",
      "2/2 [==============================] - 0s 101ms/step\n",
      "[0.5292925238609314, 0.5]\n"
     ]
    }
   ],
   "source": [
    "button1 = widgets.Button(description = 'Test Model')\n",
    "button2 = widgets.Button(description = 'Run Example')\n",
    "display(widgets.HBox((button1, button2)))   \n",
    "\n",
    "def testear(n):\n",
    "    save_audio()\n",
    "\n",
    "button1.on_click(testear)\n",
    "button2.on_click(test_prec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['cuatro']]\n"
     ]
    }
   ],
   "source": [
    "onda, sr = librosa.load('data/pruebas/9_prueba_b.wav', mono=True)\n",
    "features= librosa.feature.mfcc(onda, sr,n_mfcc=13)\n",
    "features=np.pad(features,((0,0),(0,110-len(features[0]))),mode='constant', constant_values=0)\n",
    "f=np.matrix.transpose(np.array([features]),[0,2,1])\n",
    "label=model.predict_classes(f)\n",
    "texto=decode(np.eye(10)[label])\n",
    "print(texto)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
