{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importanción de librerías "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import librosa\n",
    "from python_speech_features import mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de ficheros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función se encarga de generar un archivo txt de manera que este contenga 2 elementos por fila ('name_file','etiqueta') de esta manera permitirá poder entrenar la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "def generate_file_data(dir,name):\n",
    "    directory=dir\n",
    "    #el nombre de los archivos posee el primer dígito en el nombre de esta forma permitirá etiquetarlos.\n",
    "    a={'0':'cero','1':'uno','2':'dos','3':'tres','4':'cuatro','5':'cinco','6':'seis','7':'siete','8':'ocho','9':'nueve'}\n",
    "    da=os.listdir(directory)\n",
    "    # ordena los archivos\n",
    "    da.sort()\n",
    "    file = open(dir+name+'.txt',\"w\")\n",
    "    for filename in da:\n",
    "        if '.wav' in filename:\n",
    "            file.write(filename+','+a[filename[0]]+'\\n')\n",
    "    file.close() \n",
    "    # genera el fichero\n",
    "    with open(directory+'/'+name+'.txt') as f:\n",
    "        read_data = f.read()\n",
    "        f.closed\n",
    "    read_data=read_data.split('\\n')\n",
    "    read_data=read_data[0:len(read_data)-1]\n",
    "    return read_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding words with One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "vocabulary_words=np.array(['cero','uno','dos','tres','cuatro','cinco','seis','siete','ocho','nueve'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore',categories='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories='auto',\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "       n_values=None, sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['cero'],\n",
       "       ['uno'],\n",
       "       ['dos'],\n",
       "       ['tres'],\n",
       "       ['cuatro'],\n",
       "       ['cinco'],\n",
       "       ['seis'],\n",
       "       ['siete'],\n",
       "       ['ocho'],\n",
       "       ['nueve']], dtype='<U6')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_words.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories='auto',\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "       n_values=None, sparse=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder.fit(X=vocabulary_words.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['cero', 'cinco', 'cuatro', 'dos', 'nueve', 'ocho', 'seis', 'siete',\n",
       "        'tres', 'uno'], dtype='<U6')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=onehot_encoder.transform(vocabulary_words.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['cero'],\n",
       "       ['uno'],\n",
       "       ['dos'],\n",
       "       ['tres'],\n",
       "       ['cuatro'],\n",
       "       ['cinco'],\n",
       "       ['seis'],\n",
       "       ['siete'],\n",
       "       ['ocho'],\n",
       "       ['nueve']], dtype='<U6')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder.inverse_transform(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_to_integer_encoded(n):# no srive\n",
    "    return integer_encoded[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x):# tomará un array de string y lo transformada a encode\n",
    "    return onehot_encoder.transform(x.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=encode(np.array(['uno','dos']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(x):\n",
    "    return onehot_encoder.inverse_transform(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['uno'],\n",
       "       ['dos']], dtype='<U6')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_text(m,mfcc):\n",
    "    label=m.predict_classes(mfcc)\n",
    "    text=label_encoder.inverse_transform(label)\n",
    "    text=text[0]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_features(DIR,list_dir):\n",
    "    mfcc_audios=[]\n",
    "    for dir in list_dir:\n",
    "        wave, sr = librosa.load(DIR+dir, mono=True)\n",
    "        features= librosa.feature.mfcc(wave, sr,n_mfcc=20)\n",
    "        #features = sklearn.preprocessing.scale(features, axis=1)\n",
    "        #features=sklearn.preprocessing.normalize(features,axis=1)\n",
    "        try:\n",
    "            features=np.pad(features,((0,0),(0,160-len(features[0]))),mode='constant', constant_values=0)\n",
    "        except OSError as err:\n",
    "            print(dir)\n",
    "        mfcc_audios.append(features)\n",
    "    mfcc_audios=np.array(mfcc_audios)\n",
    "    return mfcc_audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(dir,name):\n",
    "    file = open(dir+name)\n",
    "    f=file.read()\n",
    "    file.close()\n",
    "    f=f.split('\\n')\n",
    "    f=f[0:len(f)-1]\n",
    "    labels=[]\n",
    "    names_audios=[]\n",
    "    for i in f:\n",
    "        j=i.split(',')\n",
    "        names_audios.append(j[0])\n",
    "        labels.append(j[1])\n",
    "    labels=np.array(labels)\n",
    "    onehot= encode(labels)\n",
    "    mfcc=mfcc_features(dir,names_audios)\n",
    "    print(name+' OK')\n",
    "    return mfcc,onehot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    def __init__(self,data):\n",
    "        self.i=0#para el shuffle\n",
    "        self.data_dir=data\n",
    "        self.shuffle=None\n",
    "        self.dir_training=data+'/training/'\n",
    "        self.dir_test=data+'/test/'\n",
    "        self.training_set=None\n",
    "        self.test_set=None\n",
    "    def split_dataset(self):\n",
    "        generate_file_data(self.dir_training,name='training')\n",
    "        generate_file_data(self.dir_test,name='test')\n",
    "        self.training_set=prepare_data(self.dir_training,'training.txt')\n",
    "        self.test_set=prepare_data(self.dir_test,'test.txt')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training.txt OK\n",
      "test.txt OK\n"
     ]
    }
   ],
   "source": [
    "d=dataset('data')\n",
    "d.split_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/test/'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.dir_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[-5.64680866e+02, -5.29639572e+02, -5.03711243e+02, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 1.31315456e+00,  3.83504027e+01,  5.91761157e+01, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 9.67559702e-01,  1.58076723e+01,  1.61406856e+01, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         ...,\n",
       "         [-2.26318818e-01,  8.51022362e-01,  1.20597587e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [-8.17593134e-02,  3.73614388e+00, -2.09463672e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [-1.73113489e-01,  3.40531451e+00,  8.65122496e-01, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "        [[-5.19092302e+02, -5.08130382e+02, -4.93961628e+02, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  1.31851391e+01,  2.85274192e+01, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  7.17792662e+00,  1.40888544e+01, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         ...,\n",
       "         [ 0.00000000e+00, -2.96481487e+00, -3.20175894e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00, -2.42184993e+00, -2.22600717e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00, -1.08814320e+00,  4.25423065e-02, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "        [[-6.29261049e+02, -6.10069041e+02, -6.09615559e+02, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 1.04480096e+02,  9.60035227e+01,  7.89167544e+01, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 5.15493304e+01,  3.37623996e+01,  1.28544967e+01, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         ...,\n",
       "         [ 5.75014309e+00,  5.61006518e+00, -2.26959334e-01, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [-2.15469150e+00, -1.45374697e+00, -2.37645754e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 1.34756607e+00,  3.13367230e+00, -3.46365896e-01, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-3.86915408e+02, -2.47648257e+02, -1.66865266e+02, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 1.47978561e+02,  1.65742735e+02,  1.53301202e+02, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 3.60010383e+01,  7.83900010e+00, -1.38968520e+01, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         ...,\n",
       "         [-1.81583083e+01, -1.81952384e+01, -1.64987463e+01, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [-6.55758499e+00, -5.43138908e+00, -5.72493017e-02, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 3.61670221e+00,  1.11321391e+00, -4.59573251e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "        [[-4.79848078e+02, -3.42123029e+02, -2.35516891e+02, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 1.07321439e+02,  1.42589094e+02,  1.46480996e+02, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 5.26972946e+01,  2.70015151e+01,  4.51661460e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         ...,\n",
       "         [-1.30181318e+01, -1.11503085e+01, -1.23723922e+01, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [-7.51490328e+00, -5.79684475e+00,  5.13929444e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [-1.62499952e+00, -3.69430352e+00, -8.45864345e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "        [[-7.28333401e+02, -7.28333401e+02, -7.28333401e+02, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         ...,\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]]),\n",
       " array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d.training_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[d.training_set[0][i].shape for i in range(len(d.training_set[0]))] #will display numofcep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(d.training_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-5.13639854e+02, -5.10511934e+02, -5.00494016e+02, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  4.37834542e+00,  1.78571824e+01, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  4.24387386e+00,  1.59164626e+01, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        ...,\n",
       "        [ 0.00000000e+00, -2.63404490e+00, -3.65825454e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00, -2.90678541e+00, -3.80509903e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00, -3.10796143e+00, -3.31458643e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "       [[-6.28216153e+02, -6.02791031e+02, -5.98293685e+02, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 1.11749813e+02,  1.02410410e+02,  8.27195833e+01, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 4.78110068e+01,  2.46125923e+01,  4.21841183e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        ...,\n",
       "        [ 3.12890952e+00,  3.49803786e+00,  4.12006358e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [-2.02561476e-01, -3.10840482e-01,  4.16586152e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 5.20885623e+00,  6.24703543e+00,  7.77290448e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "       [[-7.61195833e+02, -7.61195833e+02, -7.61195833e+02, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-4.60982260e+02, -3.95170324e+02, -3.53051016e+02, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 1.17328426e+02,  1.33143094e+02,  1.36252103e+02, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 1.51620876e+01, -7.59963452e+00, -1.90609421e+01, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        ...,\n",
       "        [ 9.38875081e+00,  2.49717038e+00, -8.38468121e-01, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 1.35307872e+00, -1.08383638e+00, -5.50485404e-01, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 8.53050782e-01, -1.64744921e+00, -3.54321319e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "       [[-7.31556535e+02, -6.27686729e+02, -5.91997381e+02, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 6.03974806e+01,  1.29829033e+02,  1.48089981e+02, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 3.18527697e+01,  3.23428164e+01,  2.38291235e+01, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        ...,\n",
       "        [ 4.39290534e+00, -3.14358927e+00, -1.06738352e+01, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 2.67596518e+00, -6.71530112e+00, -1.00056812e+01, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 8.09766680e-01, -6.48806755e+00, -4.89440075e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "       [[-5.24272826e+02, -4.42483992e+02, -4.10771027e+02, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 5.85691905e+01,  8.99507133e+01,  8.32239064e+01, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 3.10505715e+01,  1.73415913e+01,  9.66849295e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        ...,\n",
       "        [-3.81882109e+00, -8.94896265e-01,  6.81840658e-01, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [-1.97879005e+00,  2.49845088e+00,  3.52927193e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 7.45096257e-01,  2.87864018e+00,  4.98669847e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.test_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.test_set[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red neuronal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY = d.training_set[0],d.training_set[1]\n",
    "testX, testY = d.test_set[0],d.test_set[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX=np.matrix.transpose(trainX,[0,2,1])\n",
    "testX=np.matrix.transpose(testX,[0,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-5.64680866e+02,  1.31315456e+00,  9.67559702e-01, ...,\n",
       "         -2.26318818e-01, -8.17593134e-02, -1.73113489e-01],\n",
       "        [-5.29639572e+02,  3.83504027e+01,  1.58076723e+01, ...,\n",
       "          8.51022362e-01,  3.73614388e+00,  3.40531451e+00],\n",
       "        [-5.03711243e+02,  5.91761157e+01,  1.61406856e+01, ...,\n",
       "          1.20597587e+00, -2.09463672e+00,  8.65122496e-01],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "       [[-5.19092302e+02,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [-5.08130382e+02,  1.31851391e+01,  7.17792662e+00, ...,\n",
       "         -2.96481487e+00, -2.42184993e+00, -1.08814320e+00],\n",
       "        [-4.93961628e+02,  2.85274192e+01,  1.40888544e+01, ...,\n",
       "         -3.20175894e+00, -2.22600717e+00,  4.25423065e-02],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "       [[-6.29261049e+02,  1.04480096e+02,  5.15493304e+01, ...,\n",
       "          5.75014309e+00, -2.15469150e+00,  1.34756607e+00],\n",
       "        [-6.10069041e+02,  9.60035227e+01,  3.37623996e+01, ...,\n",
       "          5.61006518e+00, -1.45374697e+00,  3.13367230e+00],\n",
       "        [-6.09615559e+02,  7.89167544e+01,  1.28544967e+01, ...,\n",
       "         -2.26959334e-01, -2.37645754e+00, -3.46365896e-01],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-3.86915408e+02,  1.47978561e+02,  3.60010383e+01, ...,\n",
       "         -1.81583083e+01, -6.55758499e+00,  3.61670221e+00],\n",
       "        [-2.47648257e+02,  1.65742735e+02,  7.83900010e+00, ...,\n",
       "         -1.81952384e+01, -5.43138908e+00,  1.11321391e+00],\n",
       "        [-1.66865266e+02,  1.53301202e+02, -1.38968520e+01, ...,\n",
       "         -1.64987463e+01, -5.72493017e-02, -4.59573251e+00],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "       [[-4.79848078e+02,  1.07321439e+02,  5.26972946e+01, ...,\n",
       "         -1.30181318e+01, -7.51490328e+00, -1.62499952e+00],\n",
       "        [-3.42123029e+02,  1.42589094e+02,  2.70015151e+01, ...,\n",
       "         -1.11503085e+01, -5.79684475e+00, -3.69430352e+00],\n",
       "        [-2.35516891e+02,  1.46480996e+02,  4.51661460e+00, ...,\n",
       "         -1.23723922e+01,  5.13929444e+00, -8.45864345e+00],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "       [[-7.28333401e+02,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [-7.28333401e+02,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [-7.28333401e+02,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-5.13639854e+02,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [-5.10511934e+02,  4.37834542e+00,  4.24387386e+00, ...,\n",
       "         -2.63404490e+00, -2.90678541e+00, -3.10796143e+00],\n",
       "        [-5.00494016e+02,  1.78571824e+01,  1.59164626e+01, ...,\n",
       "         -3.65825454e+00, -3.80509903e+00, -3.31458643e+00],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "       [[-6.28216153e+02,  1.11749813e+02,  4.78110068e+01, ...,\n",
       "          3.12890952e+00, -2.02561476e-01,  5.20885623e+00],\n",
       "        [-6.02791031e+02,  1.02410410e+02,  2.46125923e+01, ...,\n",
       "          3.49803786e+00, -3.10840482e-01,  6.24703543e+00],\n",
       "        [-5.98293685e+02,  8.27195833e+01,  4.21841183e+00, ...,\n",
       "          4.12006358e+00,  4.16586152e+00,  7.77290448e+00],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "       [[-7.61195833e+02,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [-7.61195833e+02,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [-7.61195833e+02,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-4.60982260e+02,  1.17328426e+02,  1.51620876e+01, ...,\n",
       "          9.38875081e+00,  1.35307872e+00,  8.53050782e-01],\n",
       "        [-3.95170324e+02,  1.33143094e+02, -7.59963452e+00, ...,\n",
       "          2.49717038e+00, -1.08383638e+00, -1.64744921e+00],\n",
       "        [-3.53051016e+02,  1.36252103e+02, -1.90609421e+01, ...,\n",
       "         -8.38468121e-01, -5.50485404e-01, -3.54321319e+00],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "       [[-7.31556535e+02,  6.03974806e+01,  3.18527697e+01, ...,\n",
       "          4.39290534e+00,  2.67596518e+00,  8.09766680e-01],\n",
       "        [-6.27686729e+02,  1.29829033e+02,  3.23428164e+01, ...,\n",
       "         -3.14358927e+00, -6.71530112e+00, -6.48806755e+00],\n",
       "        [-5.91997381e+02,  1.48089981e+02,  2.38291235e+01, ...,\n",
       "         -1.06738352e+01, -1.00056812e+01, -4.89440075e+00],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "       [[-5.24272826e+02,  5.85691905e+01,  3.10505715e+01, ...,\n",
       "         -3.81882109e+00, -1.97879005e+00,  7.45096257e-01],\n",
       "        [-4.42483992e+02,  8.99507133e+01,  1.73415913e+01, ...,\n",
       "         -8.94896265e-01,  2.49845088e+00,  2.87864018e+00],\n",
       "        [-4.10771027e+02,  8.32239064e+01,  9.66849295e+00, ...,\n",
       "          6.81840658e-01,  3.52927193e+00,  4.98669847e+00],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time \n",
    "n_units=128\n",
    "time_steps=160\n",
    "n_inputs=20\n",
    "batch_size=20\n",
    "n_epochs=10\n",
    "n_class=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(n_units, input_shape=(time_steps,n_inputs),return_sequences=True))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "#model.add(tf.keras)\n",
    "model.add(tf.keras.layers.LSTM(n_units))#,return_sequences=True))\n",
    "model.add(tf.layers.Dense(n_class, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 2.3059 - acc: 0.0667 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2983 - acc: 0.0917 - val_loss: 2.3028 - val_acc: 0.1091\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.2956 - acc: 0.0708 - val_loss: 2.3029 - val_acc: 0.0909\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.2886 - acc: 0.1125 - val_loss: 2.3041 - val_acc: 0.1000\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 2.2880 - acc: 0.1208 - val_loss: 2.3036 - val_acc: 0.1091\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.2831 - acc: 0.1125 - val_loss: 2.3050 - val_acc: 0.1000\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 2.2811 - acc: 0.1125 - val_loss: 2.3056 - val_acc: 0.0909\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 2.2895 - acc: 0.1000 - val_loss: 2.3036 - val_acc: 0.0909\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.2809 - acc: 0.1208 - val_loss: 2.3040 - val_acc: 0.1091\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.2874 - acc: 0.1042 - val_loss: 2.3061 - val_acc: 0.1000\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.2974 - acc: 0.1292 - val_loss: 2.3062 - val_acc: 0.1091\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.2840 - acc: 0.1042 - val_loss: 2.3063 - val_acc: 0.1000\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 2.2829 - acc: 0.0875 - val_loss: 2.3057 - val_acc: 0.1091\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 2.2622 - acc: 0.1000 - val_loss: 2.2956 - val_acc: 0.1091\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.2637 - acc: 0.1167 - val_loss: 2.3051 - val_acc: 0.0909\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.2496 - acc: 0.1250 - val_loss: 2.2925 - val_acc: 0.1182\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.2431 - acc: 0.1042 - val_loss: 2.2913 - val_acc: 0.1273\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.2321 - acc: 0.1375 - val_loss: 2.2969 - val_acc: 0.1091\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.2371 - acc: 0.1375 - val_loss: 2.2817 - val_acc: 0.1091\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 2.2168 - acc: 0.1542 - val_loss: 2.2825 - val_acc: 0.1182\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.2009 - acc: 0.1417 - val_loss: 2.2811 - val_acc: 0.1273\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.1789 - acc: 0.1625 - val_loss: 2.2910 - val_acc: 0.1364\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.1354 - acc: 0.1958 - val_loss: 2.3583 - val_acc: 0.1818\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 2.1139 - acc: 0.1917 - val_loss: 2.0973 - val_acc: 0.1636\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 2.2277 - acc: 0.1500 - val_loss: 2.2524 - val_acc: 0.1636\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 2.2613 - acc: 0.1500 - val_loss: 2.2933 - val_acc: 0.1000\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.1918 - acc: 0.1500 - val_loss: 2.2372 - val_acc: 0.1182\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 2.1810 - acc: 0.1500 - val_loss: 2.2662 - val_acc: 0.1000\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 2.1274 - acc: 0.2250 - val_loss: 2.0635 - val_acc: 0.1909\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.8879 - acc: 0.2250 - val_loss: 1.8671 - val_acc: 0.2091\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.8376 - acc: 0.2208 - val_loss: 1.9186 - val_acc: 0.2545\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 1.9471 - acc: 0.2333 - val_loss: 2.2934 - val_acc: 0.1818\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 2.1392 - acc: 0.2292 - val_loss: 2.0831 - val_acc: 0.2455\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 2.0555 - acc: 0.2167 - val_loss: 1.9329 - val_acc: 0.2545\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.9234 - acc: 0.2000 - val_loss: 1.8829 - val_acc: 0.2818\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.8695 - acc: 0.2833 - val_loss: 1.8482 - val_acc: 0.3273\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.8439 - acc: 0.2375 - val_loss: 1.8116 - val_acc: 0.2455\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.8217 - acc: 0.2542 - val_loss: 1.8529 - val_acc: 0.2818\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.8161 - acc: 0.2667 - val_loss: 1.9480 - val_acc: 0.2727\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.7906 - acc: 0.2917 - val_loss: 1.9650 - val_acc: 0.2364\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 1.7673 - acc: 0.2833 - val_loss: 1.8334 - val_acc: 0.2727\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.7333 - acc: 0.3292 - val_loss: 1.8129 - val_acc: 0.2818\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 1.6753 - acc: 0.3125 - val_loss: 2.0018 - val_acc: 0.2636\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.0589 - acc: 0.2708 - val_loss: 2.0597 - val_acc: 0.1818\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 2.0436 - acc: 0.2083 - val_loss: 2.0290 - val_acc: 0.2091\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.8609 - acc: 0.2542 - val_loss: 1.8302 - val_acc: 0.2818\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.7530 - acc: 0.3083 - val_loss: 1.7955 - val_acc: 0.2636\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.7411 - acc: 0.2708 - val_loss: 1.8788 - val_acc: 0.2182\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.6903 - acc: 0.3083 - val_loss: 1.7848 - val_acc: 0.3182\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.6238 - acc: 0.3125 - val_loss: 1.8917 - val_acc: 0.2545\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.6552 - acc: 0.3042 - val_loss: 1.8119 - val_acc: 0.2727\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.7050 - acc: 0.2500 - val_loss: 1.7855 - val_acc: 0.2727\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.6558 - acc: 0.3000 - val_loss: 1.9524 - val_acc: 0.2727\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.7072 - acc: 0.3042 - val_loss: 1.6739 - val_acc: 0.3091\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.6382 - acc: 0.2875 - val_loss: 1.6014 - val_acc: 0.3455\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.6419 - acc: 0.3208 - val_loss: 1.7400 - val_acc: 0.3273\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.5398 - acc: 0.3542 - val_loss: 1.5340 - val_acc: 0.3091\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.4317 - acc: 0.3375 - val_loss: 1.5640 - val_acc: 0.3909\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.3999 - acc: 0.4000 - val_loss: 1.3428 - val_acc: 0.3636\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 7s 30ms/step - loss: 1.3564 - acc: 0.3833 - val_loss: 1.3492 - val_acc: 0.4455\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.4463 - acc: 0.3458 - val_loss: 1.3835 - val_acc: 0.3818\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.3781 - acc: 0.3833 - val_loss: 1.4182 - val_acc: 0.4091\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.2966 - acc: 0.4125 - val_loss: 1.4327 - val_acc: 0.3727\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.3101 - acc: 0.4167 - val_loss: 1.4521 - val_acc: 0.3727\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.3298 - acc: 0.4125 - val_loss: 1.7368 - val_acc: 0.3182\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.5786 - acc: 0.2792 - val_loss: 1.6290 - val_acc: 0.3182\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.3868 - acc: 0.3833 - val_loss: 1.4331 - val_acc: 0.3909\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.3451 - acc: 0.4083 - val_loss: 1.3669 - val_acc: 0.4273\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.3151 - acc: 0.4208 - val_loss: 1.3564 - val_acc: 0.4182\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.3199 - acc: 0.4000 - val_loss: 1.4301 - val_acc: 0.3727\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 1.3440 - acc: 0.4292 - val_loss: 1.3697 - val_acc: 0.4000\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.2800 - acc: 0.4083 - val_loss: 1.4189 - val_acc: 0.4091\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.6871 - acc: 0.3167 - val_loss: 1.8810 - val_acc: 0.2545\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.6212 - acc: 0.2917 - val_loss: 1.6011 - val_acc: 0.3636\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.5115 - acc: 0.3333 - val_loss: 1.5088 - val_acc: 0.3909\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.4350 - acc: 0.3875 - val_loss: 1.5949 - val_acc: 0.3455\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.3429 - acc: 0.4250 - val_loss: 1.3719 - val_acc: 0.4091\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 1.2689 - acc: 0.4667 - val_loss: 1.3046 - val_acc: 0.4636\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.2008 - acc: 0.5083 - val_loss: 1.2916 - val_acc: 0.5091\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.2211 - acc: 0.4625 - val_loss: 1.3388 - val_acc: 0.4364\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.2006 - acc: 0.4958 - val_loss: 1.3192 - val_acc: 0.4273\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.1663 - acc: 0.5000 - val_loss: 1.3179 - val_acc: 0.4818\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.0971 - acc: 0.5375 - val_loss: 1.3654 - val_acc: 0.4545\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.0677 - acc: 0.4875 - val_loss: 1.3553 - val_acc: 0.4545\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.1365 - acc: 0.5333 - val_loss: 1.3073 - val_acc: 0.4455\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.1333 - acc: 0.5000 - val_loss: 1.2653 - val_acc: 0.4818\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.1460 - acc: 0.4958 - val_loss: 1.6219 - val_acc: 0.4364\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.4908 - acc: 0.3667 - val_loss: 1.4161 - val_acc: 0.4000\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.2534 - acc: 0.4292 - val_loss: 1.4938 - val_acc: 0.3909\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.2319 - acc: 0.4083 - val_loss: 1.3053 - val_acc: 0.4727\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.1154 - acc: 0.5292 - val_loss: 1.3047 - val_acc: 0.4818\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.0859 - acc: 0.5208 - val_loss: 1.3286 - val_acc: 0.4364\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0723 - acc: 0.4792 - val_loss: 1.2946 - val_acc: 0.4545\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.0348 - acc: 0.5000 - val_loss: 1.4361 - val_acc: 0.4455\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.2558 - acc: 0.4417 - val_loss: 1.5651 - val_acc: 0.3818\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.5462 - acc: 0.3875 - val_loss: 1.7484 - val_acc: 0.4091\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.2323 - acc: 0.4833 - val_loss: 1.5243 - val_acc: 0.4455\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.2477 - acc: 0.5000 - val_loss: 1.4789 - val_acc: 0.4818\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.2044 - acc: 0.5167 - val_loss: 1.4080 - val_acc: 0.4727\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.1360 - acc: 0.5208 - val_loss: 1.4890 - val_acc: 0.4455\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.1017 - acc: 0.5250 - val_loss: 1.4776 - val_acc: 0.4818\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.0607 - acc: 0.5083 - val_loss: 1.2641 - val_acc: 0.4909\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2095 - acc: 0.4875 - val_loss: 1.5145 - val_acc: 0.4364\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3237 - acc: 0.4375 - val_loss: 1.4389 - val_acc: 0.4091\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.2897 - acc: 0.4042 - val_loss: 1.3791 - val_acc: 0.4364\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.2949 - acc: 0.4333 - val_loss: 1.3751 - val_acc: 0.4273\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.2483 - acc: 0.4417 - val_loss: 1.3953 - val_acc: 0.4273\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.2475 - acc: 0.4792 - val_loss: 1.3186 - val_acc: 0.5000\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.2228 - acc: 0.4625 - val_loss: 1.2590 - val_acc: 0.4636\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 1.2466 - acc: 0.4500 - val_loss: 1.2835 - val_acc: 0.4545\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.2246 - acc: 0.4333 - val_loss: 1.3622 - val_acc: 0.5182\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.2466 - acc: 0.4208 - val_loss: 1.3637 - val_acc: 0.4455\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.3738 - acc: 0.4417 - val_loss: 1.6641 - val_acc: 0.4364\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.1839 - acc: 0.4708 - val_loss: 1.4698 - val_acc: 0.4000\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.1616 - acc: 0.5042 - val_loss: 1.4157 - val_acc: 0.4545\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.0567 - acc: 0.5708 - val_loss: 1.3035 - val_acc: 0.4455\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.0290 - acc: 0.5500 - val_loss: 1.2497 - val_acc: 0.4636\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.9755 - acc: 0.5625 - val_loss: 1.2225 - val_acc: 0.5273\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 6s 27ms/step - loss: 1.0616 - acc: 0.5458 - val_loss: 1.2784 - val_acc: 0.4909\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 1.0622 - acc: 0.4958 - val_loss: 1.3122 - val_acc: 0.4909\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.9594 - acc: 0.5375 - val_loss: 1.4157 - val_acc: 0.5182\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0601 - acc: 0.5583 - val_loss: 1.3910 - val_acc: 0.4727\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.3695 - acc: 0.4833 - val_loss: 1.8170 - val_acc: 0.3727\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.3659 - acc: 0.4792 - val_loss: 1.6443 - val_acc: 0.3455\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 10s 43ms/step - loss: 1.2925 - acc: 0.4417 - val_loss: 1.3032 - val_acc: 0.5545\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.9945 - acc: 0.5458 - val_loss: 1.3208 - val_acc: 0.4818\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.0413 - acc: 0.5500 - val_loss: 1.2977 - val_acc: 0.4818\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.9034 - acc: 0.5958 - val_loss: 1.2312 - val_acc: 0.4455\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.9568 - acc: 0.5750 - val_loss: 1.3279 - val_acc: 0.4636\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.9062 - acc: 0.5917 - val_loss: 1.1946 - val_acc: 0.5182\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.8687 - acc: 0.6250 - val_loss: 1.1752 - val_acc: 0.5455\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.9240 - acc: 0.5958 - val_loss: 1.1921 - val_acc: 0.5091\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8431 - acc: 0.6042 - val_loss: 1.1843 - val_acc: 0.5636\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8508 - acc: 0.5917 - val_loss: 1.3240 - val_acc: 0.4636\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8938 - acc: 0.5917 - val_loss: 1.3310 - val_acc: 0.4818\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.8374 - acc: 0.6042 - val_loss: 1.3328 - val_acc: 0.4909\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8212 - acc: 0.6250 - val_loss: 1.3293 - val_acc: 0.5182\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.8350 - acc: 0.6458 - val_loss: 1.1758 - val_acc: 0.5000\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8683 - acc: 0.5917 - val_loss: 1.3283 - val_acc: 0.4818\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.9038 - acc: 0.5917 - val_loss: 1.2602 - val_acc: 0.5545\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8876 - acc: 0.6000 - val_loss: 1.2934 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8612 - acc: 0.6542 - val_loss: 1.1657 - val_acc: 0.5455\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7813 - acc: 0.6625 - val_loss: 1.2239 - val_acc: 0.5455\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8562 - acc: 0.6417 - val_loss: 1.0836 - val_acc: 0.5727\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.8083 - acc: 0.6458 - val_loss: 1.1475 - val_acc: 0.5727\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.7797 - acc: 0.6542 - val_loss: 1.1398 - val_acc: 0.5727\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.7467 - acc: 0.6667 - val_loss: 1.1470 - val_acc: 0.6182\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7791 - acc: 0.6708 - val_loss: 1.1782 - val_acc: 0.6091\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 1.0815 - acc: 0.5958 - val_loss: 1.3324 - val_acc: 0.4909\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.9765 - acc: 0.5500 - val_loss: 1.1243 - val_acc: 0.5182\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.8848 - acc: 0.6125 - val_loss: 1.0354 - val_acc: 0.6182\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.9272 - acc: 0.5833 - val_loss: 1.0905 - val_acc: 0.5727\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.8301 - acc: 0.6417 - val_loss: 1.0079 - val_acc: 0.6273\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7733 - acc: 0.6458 - val_loss: 1.0122 - val_acc: 0.5455\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.7175 - acc: 0.6542 - val_loss: 1.0828 - val_acc: 0.5636\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.7441 - acc: 0.6542 - val_loss: 1.1198 - val_acc: 0.6182\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.9173 - acc: 0.6125 - val_loss: 1.2630 - val_acc: 0.5364\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 1.3721 - acc: 0.5042 - val_loss: 1.4486 - val_acc: 0.5182\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.0822 - acc: 0.5417 - val_loss: 1.2968 - val_acc: 0.4909\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.9977 - acc: 0.5833 - val_loss: 1.1753 - val_acc: 0.5636\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.9097 - acc: 0.6125 - val_loss: 1.1955 - val_acc: 0.5727\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.8470 - acc: 0.6625 - val_loss: 1.1289 - val_acc: 0.6182\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 0.7427 - acc: 0.7042 - val_loss: 1.0529 - val_acc: 0.6000\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.0047 - acc: 0.5792 - val_loss: 1.3441 - val_acc: 0.5455\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 1.3126 - acc: 0.4458 - val_loss: 1.9177 - val_acc: 0.3545\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 1.5332 - acc: 0.3458 - val_loss: 1.9334 - val_acc: 0.3273\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 1.6631 - acc: 0.3458 - val_loss: 1.5635 - val_acc: 0.4091\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 1.3592 - acc: 0.4458 - val_loss: 1.7276 - val_acc: 0.3455\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.2669 - acc: 0.4542 - val_loss: 1.5775 - val_acc: 0.3545\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.4996 - acc: 0.4292 - val_loss: 1.4572 - val_acc: 0.4000\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 1.2302 - acc: 0.4958 - val_loss: 1.4065 - val_acc: 0.4545\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.0938 - acc: 0.5917 - val_loss: 1.3835 - val_acc: 0.4364\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.1029 - acc: 0.5833 - val_loss: 1.3933 - val_acc: 0.4636\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 1.2462 - acc: 0.5458 - val_loss: 1.3300 - val_acc: 0.4727\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.1832 - acc: 0.5333 - val_loss: 1.3286 - val_acc: 0.5455\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 1.1324 - acc: 0.5583 - val_loss: 1.3785 - val_acc: 0.5091\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.1822 - acc: 0.5542 - val_loss: 1.3936 - val_acc: 0.4364\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 6s 24ms/step - loss: 1.1203 - acc: 0.5542 - val_loss: 1.2715 - val_acc: 0.4909\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.0479 - acc: 0.5875 - val_loss: 1.2075 - val_acc: 0.5273\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.0026 - acc: 0.6417 - val_loss: 1.1944 - val_acc: 0.5091\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.9751 - acc: 0.6125 - val_loss: 1.1928 - val_acc: 0.5273\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.9650 - acc: 0.6458 - val_loss: 1.1879 - val_acc: 0.5727\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.9099 - acc: 0.6667 - val_loss: 1.1842 - val_acc: 0.6091\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.9013 - acc: 0.6917 - val_loss: 1.3084 - val_acc: 0.5364\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.8924 - acc: 0.6625 - val_loss: 1.1397 - val_acc: 0.5818\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.8293 - acc: 0.7208 - val_loss: 1.1110 - val_acc: 0.6545\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.8503 - acc: 0.6667 - val_loss: 1.2179 - val_acc: 0.5636\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.8806 - acc: 0.6375 - val_loss: 1.1357 - val_acc: 0.6000\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.8242 - acc: 0.6667 - val_loss: 1.2349 - val_acc: 0.5364\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.9524 - acc: 0.6042 - val_loss: 1.1719 - val_acc: 0.5727\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.8431 - acc: 0.7000 - val_loss: 1.1998 - val_acc: 0.5727\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.7690 - acc: 0.7500 - val_loss: 1.1248 - val_acc: 0.6091\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.8201 - acc: 0.7167 - val_loss: 1.1299 - val_acc: 0.6000\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.8645 - acc: 0.7042 - val_loss: 1.1726 - val_acc: 0.6273\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.8406 - acc: 0.7042 - val_loss: 1.1334 - val_acc: 0.6000\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.7722 - acc: 0.7125 - val_loss: 0.9786 - val_acc: 0.5818\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.7407 - acc: 0.7667 - val_loss: 0.9368 - val_acc: 0.6364\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.9032 - acc: 0.6875 - val_loss: 1.2922 - val_acc: 0.5727\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.1650 - acc: 0.5958 - val_loss: 1.3604 - val_acc: 0.5727\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.0484 - acc: 0.5875 - val_loss: 1.1883 - val_acc: 0.6455\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.0229 - acc: 0.5958 - val_loss: 1.2543 - val_acc: 0.5636\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.9374 - acc: 0.6292 - val_loss: 1.1558 - val_acc: 0.5636\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.9997 - acc: 0.6083 - val_loss: 1.2956 - val_acc: 0.5636\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 2.0795 - acc: 0.5167 - val_loss: 2.3052 - val_acc: 0.3545\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 1.8716 - acc: 0.4167 - val_loss: 1.7779 - val_acc: 0.3091\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 1.5110 - acc: 0.3958 - val_loss: 1.4485 - val_acc: 0.4545\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 1.3233 - acc: 0.4375 - val_loss: 1.3677 - val_acc: 0.4091\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.2858 - acc: 0.4042 - val_loss: 1.4307 - val_acc: 0.3909\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 1.2748 - acc: 0.4667 - val_loss: 1.4669 - val_acc: 0.4636\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 1.1875 - acc: 0.5083 - val_loss: 1.5895 - val_acc: 0.3818\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.3003 - acc: 0.4667 - val_loss: 1.3436 - val_acc: 0.5273\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 1.1884 - acc: 0.5125 - val_loss: 1.3594 - val_acc: 0.4818\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 1.1249 - acc: 0.5583 - val_loss: 1.2595 - val_acc: 0.4818\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 1.1072 - acc: 0.5542 - val_loss: 1.2377 - val_acc: 0.5364\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 1.1171 - acc: 0.5542 - val_loss: 1.3435 - val_acc: 0.5091\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 1.0737 - acc: 0.5833 - val_loss: 1.1789 - val_acc: 0.5091\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.9910 - acc: 0.5667 - val_loss: 1.1126 - val_acc: 0.5545\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.9498 - acc: 0.6042 - val_loss: 1.1276 - val_acc: 0.5455\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.9944 - acc: 0.5917 - val_loss: 1.1314 - val_acc: 0.5909\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.9589 - acc: 0.6250 - val_loss: 1.0816 - val_acc: 0.6000\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.9046 - acc: 0.6375 - val_loss: 1.1485 - val_acc: 0.5636\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.8704 - acc: 0.6542 - val_loss: 1.0596 - val_acc: 0.6545\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.7778 - acc: 0.6958 - val_loss: 1.0553 - val_acc: 0.5818\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.7764 - acc: 0.7042 - val_loss: 1.0769 - val_acc: 0.6182\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.7222 - acc: 0.7417 - val_loss: 1.0233 - val_acc: 0.5818\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.7089 - acc: 0.7333 - val_loss: 1.0121 - val_acc: 0.6273\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.6816 - acc: 0.7750 - val_loss: 1.0351 - val_acc: 0.6182\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.6623 - acc: 0.7708 - val_loss: 1.0405 - val_acc: 0.6000\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.6473 - acc: 0.7542 - val_loss: 1.0396 - val_acc: 0.6273\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.6768 - acc: 0.7292 - val_loss: 0.9493 - val_acc: 0.6273\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.6272 - acc: 0.7875 - val_loss: 0.9694 - val_acc: 0.6273\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.6089 - acc: 0.7875 - val_loss: 0.9569 - val_acc: 0.6818\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.6060 - acc: 0.8042 - val_loss: 0.9927 - val_acc: 0.6091\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.6088 - acc: 0.7667 - val_loss: 0.9820 - val_acc: 0.6818\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.6008 - acc: 0.7958 - val_loss: 0.9278 - val_acc: 0.7364\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 12s 51ms/step - loss: 0.5722 - acc: 0.8250 - val_loss: 0.9686 - val_acc: 0.6636\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 8s 32ms/step - loss: 0.5356 - acc: 0.8167 - val_loss: 0.9205 - val_acc: 0.7000\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.4996 - acc: 0.8292 - val_loss: 0.9446 - val_acc: 0.7000\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.5215 - acc: 0.8125 - val_loss: 0.9616 - val_acc: 0.7000\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.5137 - acc: 0.8208 - val_loss: 0.9240 - val_acc: 0.7545\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.6382 - acc: 0.7875 - val_loss: 0.9228 - val_acc: 0.7091\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.6170 - acc: 0.7792 - val_loss: 0.9237 - val_acc: 0.7455\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.5198 - acc: 0.8458 - val_loss: 0.8744 - val_acc: 0.7455\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.5013 - acc: 0.8292 - val_loss: 0.9916 - val_acc: 0.6818\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.7388 - acc: 0.7625 - val_loss: 1.0747 - val_acc: 0.6455\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.6120 - acc: 0.7750 - val_loss: 0.9804 - val_acc: 0.6727\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.6109 - acc: 0.7708 - val_loss: 0.8663 - val_acc: 0.7091\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.6419 - acc: 0.7917 - val_loss: 0.8688 - val_acc: 0.7545\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.5452 - acc: 0.8333 - val_loss: 0.8197 - val_acc: 0.7727\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.5250 - acc: 0.8417 - val_loss: 0.8047 - val_acc: 0.7455\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4826 - acc: 0.8667 - val_loss: 0.8187 - val_acc: 0.7545\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.5441 - acc: 0.8500 - val_loss: 0.7660 - val_acc: 0.7909\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.5180 - acc: 0.8542 - val_loss: 0.7357 - val_acc: 0.7818\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.4810 - acc: 0.8583 - val_loss: 0.8148 - val_acc: 0.7636\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.4592 - acc: 0.8625 - val_loss: 0.8740 - val_acc: 0.7182\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.4408 - acc: 0.8500 - val_loss: 0.8086 - val_acc: 0.7273\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.3849 - acc: 0.8833 - val_loss: 0.7049 - val_acc: 0.8091\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.3903 - acc: 0.8708 - val_loss: 0.7202 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.3385 - acc: 0.9125 - val_loss: 0.7575 - val_acc: 0.7455\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.3317 - acc: 0.9042 - val_loss: 0.7060 - val_acc: 0.8091\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.3104 - acc: 0.9125 - val_loss: 0.8510 - val_acc: 0.7818\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.4168 - acc: 0.8750 - val_loss: 0.7477 - val_acc: 0.8273\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.3803 - acc: 0.8958 - val_loss: 0.7909 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.3049 - acc: 0.9083 - val_loss: 0.7391 - val_acc: 0.8091\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.3135 - acc: 0.8917 - val_loss: 0.6318 - val_acc: 0.8364\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.3625 - acc: 0.8917 - val_loss: 0.6786 - val_acc: 0.7909\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.3514 - acc: 0.8875 - val_loss: 0.8118 - val_acc: 0.8182\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.3742 - acc: 0.8625 - val_loss: 0.7850 - val_acc: 0.7273\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.3742 - acc: 0.8500 - val_loss: 0.7444 - val_acc: 0.7545\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.3747 - acc: 0.8625 - val_loss: 0.7213 - val_acc: 0.7636\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.3007 - acc: 0.8958 - val_loss: 0.6933 - val_acc: 0.7909\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.2429 - acc: 0.9250 - val_loss: 0.7857 - val_acc: 0.8091\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.2645 - acc: 0.9083 - val_loss: 0.7476 - val_acc: 0.7909\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.2918 - acc: 0.8917 - val_loss: 0.7519 - val_acc: 0.7818\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.2579 - acc: 0.9375 - val_loss: 0.7327 - val_acc: 0.7909\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.2723 - acc: 0.9208 - val_loss: 0.8968 - val_acc: 0.7182\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.3620 - acc: 0.8875 - val_loss: 0.7741 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.3076 - acc: 0.9167 - val_loss: 0.8543 - val_acc: 0.7727\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.2762 - acc: 0.9333 - val_loss: 0.8834 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.3443 - acc: 0.8833 - val_loss: 0.8222 - val_acc: 0.8091\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.4033 - acc: 0.8625 - val_loss: 0.9249 - val_acc: 0.7364\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.4593 - acc: 0.8208 - val_loss: 0.8132 - val_acc: 0.7182\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.4231 - acc: 0.8583 - val_loss: 0.8926 - val_acc: 0.7455\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.4049 - acc: 0.8500 - val_loss: 0.9454 - val_acc: 0.7091\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.4154 - acc: 0.8458 - val_loss: 0.8886 - val_acc: 0.7818\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.3117 - acc: 0.9125 - val_loss: 0.9895 - val_acc: 0.7636\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.2672 - acc: 0.9042 - val_loss: 0.8591 - val_acc: 0.7909\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.2730 - acc: 0.9125 - val_loss: 0.7918 - val_acc: 0.7818\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.2432 - acc: 0.9208 - val_loss: 0.7347 - val_acc: 0.7909\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.2879 - acc: 0.9083 - val_loss: 0.8149 - val_acc: 0.7636\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.3361 - acc: 0.8958 - val_loss: 0.8461 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.3334 - acc: 0.8750 - val_loss: 0.7741 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.3134 - acc: 0.8792 - val_loss: 0.8244 - val_acc: 0.7818\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.2531 - acc: 0.9208 - val_loss: 0.7908 - val_acc: 0.7909\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.2553 - acc: 0.9125 - val_loss: 0.7965 - val_acc: 0.7818\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 5s 23ms/step - loss: 0.2966 - acc: 0.8792 - val_loss: 0.8744 - val_acc: 0.7364\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.3270 - acc: 0.8667 - val_loss: 0.9406 - val_acc: 0.7636\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.3103 - acc: 0.8833 - val_loss: 0.9657 - val_acc: 0.7364\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.3195 - acc: 0.8792 - val_loss: 0.8489 - val_acc: 0.7727\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.2781 - acc: 0.9000 - val_loss: 0.8000 - val_acc: 0.7636\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.2421 - acc: 0.9208 - val_loss: 0.8093 - val_acc: 0.8091\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.2289 - acc: 0.9292 - val_loss: 0.8455 - val_acc: 0.8091\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.1967 - acc: 0.9417 - val_loss: 0.7605 - val_acc: 0.8091\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.2475 - acc: 0.9208 - val_loss: 0.8377 - val_acc: 0.7818\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.1977 - acc: 0.9417 - val_loss: 0.8443 - val_acc: 0.8182\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.2839 - acc: 0.9208 - val_loss: 0.9893 - val_acc: 0.7455\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.3127 - acc: 0.8917 - val_loss: 1.0140 - val_acc: 0.7091\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.4182 - acc: 0.8500 - val_loss: 0.9288 - val_acc: 0.7545\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 10s 43ms/step - loss: 0.3347 - acc: 0.8917 - val_loss: 0.8435 - val_acc: 0.7727\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 10s 42ms/step - loss: 0.3020 - acc: 0.8958 - val_loss: 0.9041 - val_acc: 0.7818\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 10s 42ms/step - loss: 0.3190 - acc: 0.9083 - val_loss: 1.0412 - val_acc: 0.7364\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 10s 42ms/step - loss: 0.2586 - acc: 0.9250 - val_loss: 0.9436 - val_acc: 0.7818\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 0.2305 - acc: 0.9417 - val_loss: 0.8266 - val_acc: 0.8091\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 10s 42ms/step - loss: 0.1768 - acc: 0.9500 - val_loss: 0.7908 - val_acc: 0.8273\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 10s 42ms/step - loss: 0.2356 - acc: 0.9333 - val_loss: 0.9449 - val_acc: 0.7727\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.4397 - acc: 0.8625 - val_loss: 0.8687 - val_acc: 0.7909\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.2681 - acc: 0.9083 - val_loss: 0.8006 - val_acc: 0.8091\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.2637 - acc: 0.9292 - val_loss: 0.9007 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.2003 - acc: 0.9333 - val_loss: 0.7865 - val_acc: 0.7727\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1958 - acc: 0.9333 - val_loss: 0.7791 - val_acc: 0.8000\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1384 - acc: 0.9625 - val_loss: 0.7779 - val_acc: 0.8273\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1316 - acc: 0.9542 - val_loss: 0.8034 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1211 - acc: 0.9583 - val_loss: 0.7797 - val_acc: 0.8091\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0977 - acc: 0.9750 - val_loss: 0.7176 - val_acc: 0.8364\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1435 - acc: 0.9667 - val_loss: 0.7928 - val_acc: 0.8273\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.2184 - acc: 0.9500 - val_loss: 0.9849 - val_acc: 0.7818\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1150 - acc: 0.9750 - val_loss: 0.9418 - val_acc: 0.7818\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.1176 - acc: 0.9708 - val_loss: 0.8965 - val_acc: 0.8273\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.1399 - acc: 0.9667 - val_loss: 0.9929 - val_acc: 0.7636\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.1412 - acc: 0.9583 - val_loss: 1.0429 - val_acc: 0.7455\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1271 - acc: 0.9667 - val_loss: 0.9915 - val_acc: 0.7818\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1336 - acc: 0.9625 - val_loss: 0.9498 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.2220 - acc: 0.9208 - val_loss: 0.8724 - val_acc: 0.7818\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.2242 - acc: 0.9417 - val_loss: 0.9410 - val_acc: 0.7273\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1648 - acc: 0.9542 - val_loss: 0.8080 - val_acc: 0.7727\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1505 - acc: 0.9542 - val_loss: 0.7473 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1689 - acc: 0.9542 - val_loss: 0.8797 - val_acc: 0.8091\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1291 - acc: 0.9667 - val_loss: 0.8012 - val_acc: 0.8091\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1655 - acc: 0.9375 - val_loss: 0.7556 - val_acc: 0.8273\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0973 - acc: 0.9750 - val_loss: 0.7602 - val_acc: 0.7818\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1039 - acc: 0.9708 - val_loss: 0.8581 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1377 - acc: 0.9625 - val_loss: 0.7957 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1293 - acc: 0.9542 - val_loss: 0.7752 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1028 - acc: 0.9792 - val_loss: 0.8331 - val_acc: 0.7909\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0996 - acc: 0.9750 - val_loss: 0.8222 - val_acc: 0.8182\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0701 - acc: 0.9833 - val_loss: 0.8849 - val_acc: 0.7909\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0799 - acc: 0.9875 - val_loss: 0.8693 - val_acc: 0.8091\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1042 - acc: 0.9708 - val_loss: 0.9130 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0459 - acc: 0.9917 - val_loss: 0.9094 - val_acc: 0.8091\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0521 - acc: 0.9917 - val_loss: 0.9587 - val_acc: 0.8182\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0721 - acc: 0.9750 - val_loss: 0.9066 - val_acc: 0.7727\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0642 - acc: 0.9833 - val_loss: 0.8812 - val_acc: 0.7909\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0609 - acc: 0.9792 - val_loss: 0.7726 - val_acc: 0.8273\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0579 - acc: 0.9750 - val_loss: 0.8096 - val_acc: 0.8091\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0438 - acc: 0.9875 - val_loss: 0.8242 - val_acc: 0.8182\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0529 - acc: 0.9875 - val_loss: 0.8049 - val_acc: 0.8273\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0789 - acc: 0.9792 - val_loss: 0.8283 - val_acc: 0.8455\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0744 - acc: 0.9833 - val_loss: 0.8725 - val_acc: 0.8273\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0584 - acc: 0.9833 - val_loss: 0.8570 - val_acc: 0.8182\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0732 - acc: 0.9833 - val_loss: 0.9241 - val_acc: 0.8182\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.1099 - acc: 0.9667 - val_loss: 0.8774 - val_acc: 0.8182\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0955 - acc: 0.9792 - val_loss: 0.8475 - val_acc: 0.8182\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0841 - acc: 0.9833 - val_loss: 0.9544 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.1180 - acc: 0.9625 - val_loss: 0.9223 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.1322 - acc: 0.9667 - val_loss: 0.8974 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0880 - acc: 0.9708 - val_loss: 0.8210 - val_acc: 0.8273\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0645 - acc: 0.9833 - val_loss: 0.8380 - val_acc: 0.8273\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0524 - acc: 0.9833 - val_loss: 0.8889 - val_acc: 0.8273\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0532 - acc: 0.9833 - val_loss: 0.8799 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0468 - acc: 0.9917 - val_loss: 0.8069 - val_acc: 0.8182\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0666 - acc: 0.9833 - val_loss: 0.8658 - val_acc: 0.8273\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0577 - acc: 0.9833 - val_loss: 0.9017 - val_acc: 0.8273\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0867 - acc: 0.9708 - val_loss: 0.7607 - val_acc: 0.8455\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0525 - acc: 0.9875 - val_loss: 0.7085 - val_acc: 0.8636\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.3390 - acc: 0.9375 - val_loss: 1.2576 - val_acc: 0.7455\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.3997 - acc: 0.8833 - val_loss: 0.7855 - val_acc: 0.8364\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.2074 - acc: 0.9333 - val_loss: 0.7394 - val_acc: 0.8273\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1780 - acc: 0.9500 - val_loss: 0.8586 - val_acc: 0.8091\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.3301 - acc: 0.9042 - val_loss: 0.9064 - val_acc: 0.7636\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.2928 - acc: 0.9333 - val_loss: 0.7904 - val_acc: 0.8364\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.3147 - acc: 0.9083 - val_loss: 0.8041 - val_acc: 0.8182\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.2238 - acc: 0.9417 - val_loss: 1.1274 - val_acc: 0.7636\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.2292 - acc: 0.9333 - val_loss: 0.9448 - val_acc: 0.7727\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.2533 - acc: 0.9250 - val_loss: 0.9018 - val_acc: 0.7818\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1825 - acc: 0.9375 - val_loss: 0.8573 - val_acc: 0.7727\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1672 - acc: 0.9500 - val_loss: 0.8256 - val_acc: 0.7818\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.2728 - acc: 0.9125 - val_loss: 1.1467 - val_acc: 0.6909\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.6276 - acc: 0.8292 - val_loss: 1.3972 - val_acc: 0.6636\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 1.1553 - acc: 0.7125 - val_loss: 0.9672 - val_acc: 0.6727\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.6563 - acc: 0.7750 - val_loss: 0.8839 - val_acc: 0.7364\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.4420 - acc: 0.8583 - val_loss: 0.7042 - val_acc: 0.7818\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.3710 - acc: 0.8917 - val_loss: 0.8011 - val_acc: 0.7909\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.2530 - acc: 0.9250 - val_loss: 0.8083 - val_acc: 0.7727\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1864 - acc: 0.9625 - val_loss: 0.7481 - val_acc: 0.8091\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.2401 - acc: 0.9333 - val_loss: 0.7910 - val_acc: 0.7636\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1896 - acc: 0.9500 - val_loss: 0.6205 - val_acc: 0.8273\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1985 - acc: 0.9458 - val_loss: 1.0086 - val_acc: 0.7364\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.2070 - acc: 0.9375 - val_loss: 1.0110 - val_acc: 0.7727\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1640 - acc: 0.9417 - val_loss: 0.9000 - val_acc: 0.7909\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1490 - acc: 0.9625 - val_loss: 0.8906 - val_acc: 0.7909\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1592 - acc: 0.9625 - val_loss: 0.8031 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1077 - acc: 0.9708 - val_loss: 0.7939 - val_acc: 0.7909\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1082 - acc: 0.9667 - val_loss: 0.7960 - val_acc: 0.8091\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0722 - acc: 0.9833 - val_loss: 0.9167 - val_acc: 0.7818\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0871 - acc: 0.9708 - val_loss: 0.8668 - val_acc: 0.7636\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1158 - acc: 0.9625 - val_loss: 0.8444 - val_acc: 0.8182\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0766 - acc: 0.9750 - val_loss: 0.8617 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0655 - acc: 0.9792 - val_loss: 0.9044 - val_acc: 0.8273\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0635 - acc: 0.9833 - val_loss: 0.8393 - val_acc: 0.8091\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0583 - acc: 0.9792 - val_loss: 0.7119 - val_acc: 0.8182\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0560 - acc: 0.9792 - val_loss: 0.6920 - val_acc: 0.8182\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0563 - acc: 0.9792 - val_loss: 0.7200 - val_acc: 0.8273\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0613 - acc: 0.9833 - val_loss: 0.6983 - val_acc: 0.8273\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0414 - acc: 0.9875 - val_loss: 0.6877 - val_acc: 0.8364\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0387 - acc: 0.9875 - val_loss: 0.6780 - val_acc: 0.8455\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0386 - acc: 0.9875 - val_loss: 0.7158 - val_acc: 0.8364\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0508 - acc: 0.9792 - val_loss: 0.7358 - val_acc: 0.8273\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0346 - acc: 0.9917 - val_loss: 0.7757 - val_acc: 0.8273\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0486 - acc: 0.9833 - val_loss: 0.7978 - val_acc: 0.8182\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0342 - acc: 0.9917 - val_loss: 0.8054 - val_acc: 0.8273\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0330 - acc: 0.9917 - val_loss: 0.8008 - val_acc: 0.8273\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0283 - acc: 0.9958 - val_loss: 0.7952 - val_acc: 0.8182\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0311 - acc: 0.9917 - val_loss: 0.7836 - val_acc: 0.8273\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0518 - acc: 0.9875 - val_loss: 0.7897 - val_acc: 0.8273\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0265 - acc: 0.9958 - val_loss: 0.7415 - val_acc: 0.8545\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0292 - acc: 0.9917 - val_loss: 0.7495 - val_acc: 0.8545\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0300 - acc: 0.9875 - val_loss: 0.7339 - val_acc: 0.8545\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0538 - acc: 0.9875 - val_loss: 0.7262 - val_acc: 0.8455\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0341 - acc: 0.9875 - val_loss: 0.8166 - val_acc: 0.8273\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0429 - acc: 0.9792 - val_loss: 0.9082 - val_acc: 0.8091\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.0573 - acc: 0.9708 - val_loss: 0.8324 - val_acc: 0.8273\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0789 - acc: 0.9875 - val_loss: 0.8446 - val_acc: 0.8182\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0664 - acc: 0.9875 - val_loss: 0.8362 - val_acc: 0.8273\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0870 - acc: 0.9792 - val_loss: 0.8829 - val_acc: 0.8182\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0604 - acc: 0.9792 - val_loss: 0.8759 - val_acc: 0.8091\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0551 - acc: 0.9833 - val_loss: 0.8694 - val_acc: 0.8182\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0474 - acc: 0.9875 - val_loss: 0.8151 - val_acc: 0.8273\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0311 - acc: 0.9917 - val_loss: 0.8433 - val_acc: 0.8182\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0356 - acc: 0.9875 - val_loss: 0.8215 - val_acc: 0.8364\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0274 - acc: 0.9917 - val_loss: 0.8622 - val_acc: 0.8364\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0249 - acc: 0.9875 - val_loss: 0.8504 - val_acc: 0.8273\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0358 - acc: 0.9917 - val_loss: 0.7947 - val_acc: 0.8455\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0340 - acc: 0.9875 - val_loss: 0.8322 - val_acc: 0.8364\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0361 - acc: 0.9875 - val_loss: 0.8933 - val_acc: 0.8364\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.1133 - acc: 0.9750 - val_loss: 0.7642 - val_acc: 0.8455\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0417 - acc: 0.9875 - val_loss: 0.8317 - val_acc: 0.8455\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0381 - acc: 0.9875 - val_loss: 0.8401 - val_acc: 0.8273\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0308 - acc: 0.9875 - val_loss: 0.8879 - val_acc: 0.8364\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 0.0664 - acc: 0.9792 - val_loss: 0.8636 - val_acc: 0.8455\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0448 - acc: 0.9875 - val_loss: 0.7891 - val_acc: 0.8273\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 9s 35ms/step - loss: 0.1413 - acc: 0.9500 - val_loss: 0.9054 - val_acc: 0.8182\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.2059 - acc: 0.9375 - val_loss: 0.7024 - val_acc: 0.8545\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.2016 - acc: 0.9500 - val_loss: 0.7668 - val_acc: 0.8273\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1643 - acc: 0.9625 - val_loss: 0.7461 - val_acc: 0.8364\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1732 - acc: 0.9500 - val_loss: 0.7278 - val_acc: 0.8182\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0793 - acc: 0.9792 - val_loss: 0.8423 - val_acc: 0.8091\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0786 - acc: 0.9833 - val_loss: 0.8406 - val_acc: 0.8182\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1373 - acc: 0.9542 - val_loss: 0.8896 - val_acc: 0.8091\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.2412 - acc: 0.9292 - val_loss: 0.7408 - val_acc: 0.8364\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.2057 - acc: 0.9417 - val_loss: 0.8344 - val_acc: 0.8000\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.1258 - acc: 0.9500 - val_loss: 0.7339 - val_acc: 0.8364\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1016 - acc: 0.9667 - val_loss: 0.9690 - val_acc: 0.8091\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.3724 - acc: 0.9125 - val_loss: 0.9426 - val_acc: 0.7909\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.2883 - acc: 0.9250 - val_loss: 0.7536 - val_acc: 0.8273\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.3421 - acc: 0.9208 - val_loss: 0.7308 - val_acc: 0.8091\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1874 - acc: 0.9500 - val_loss: 0.5756 - val_acc: 0.8545\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1135 - acc: 0.9708 - val_loss: 0.5995 - val_acc: 0.8636\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1108 - acc: 0.9625 - val_loss: 0.6654 - val_acc: 0.8091\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0766 - acc: 0.9833 - val_loss: 0.5968 - val_acc: 0.8455\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0614 - acc: 0.9792 - val_loss: 0.5890 - val_acc: 0.8545\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0744 - acc: 0.9792 - val_loss: 0.6167 - val_acc: 0.8455\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0510 - acc: 0.9875 - val_loss: 0.6413 - val_acc: 0.8636\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0508 - acc: 0.9875 - val_loss: 0.6388 - val_acc: 0.8636\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0522 - acc: 0.9833 - val_loss: 0.6660 - val_acc: 0.8455\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0492 - acc: 0.9833 - val_loss: 0.6520 - val_acc: 0.8636\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0654 - acc: 0.9792 - val_loss: 0.6584 - val_acc: 0.8545\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0784 - acc: 0.9750 - val_loss: 0.6675 - val_acc: 0.8455\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0564 - acc: 0.9750 - val_loss: 0.6575 - val_acc: 0.8636\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0808 - acc: 0.9667 - val_loss: 0.6675 - val_acc: 0.8455\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0864 - acc: 0.9750 - val_loss: 0.6771 - val_acc: 0.8455\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.1309 - acc: 0.9750 - val_loss: 0.7866 - val_acc: 0.8364\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.1331 - acc: 0.9708 - val_loss: 0.8023 - val_acc: 0.8273\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0691 - acc: 0.9792 - val_loss: 0.7981 - val_acc: 0.8273\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0484 - acc: 0.9917 - val_loss: 0.8264 - val_acc: 0.8273\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 0.1467 - acc: 0.9542 - val_loss: 0.7332 - val_acc: 0.8364\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0965 - acc: 0.9708 - val_loss: 0.6677 - val_acc: 0.8455\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0822 - acc: 0.9750 - val_loss: 0.6766 - val_acc: 0.8455\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0672 - acc: 0.9875 - val_loss: 0.7229 - val_acc: 0.8545\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0555 - acc: 0.9833 - val_loss: 0.7357 - val_acc: 0.8364\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0712 - acc: 0.9792 - val_loss: 0.6696 - val_acc: 0.8545\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0501 - acc: 0.9833 - val_loss: 0.6297 - val_acc: 0.8727\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0469 - acc: 0.9917 - val_loss: 0.6723 - val_acc: 0.8636\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0548 - acc: 0.9833 - val_loss: 0.7035 - val_acc: 0.8545\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0475 - acc: 0.9875 - val_loss: 0.7086 - val_acc: 0.8545\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 9s 35ms/step - loss: 0.0628 - acc: 0.9833 - val_loss: 0.6933 - val_acc: 0.8545\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0395 - acc: 0.9833 - val_loss: 0.7362 - val_acc: 0.8455\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0645 - acc: 0.9833 - val_loss: 0.7601 - val_acc: 0.8455\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.1250 - acc: 0.9500 - val_loss: 1.1156 - val_acc: 0.7636\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.2878 - acc: 0.9333 - val_loss: 0.8090 - val_acc: 0.8182\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.1869 - acc: 0.9625 - val_loss: 0.8849 - val_acc: 0.8091\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.1139 - acc: 0.9750 - val_loss: 0.7971 - val_acc: 0.8182\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0996 - acc: 0.9750 - val_loss: 0.8004 - val_acc: 0.8091\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0799 - acc: 0.9792 - val_loss: 0.8172 - val_acc: 0.8091\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0701 - acc: 0.9833 - val_loss: 0.8018 - val_acc: 0.8545\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0733 - acc: 0.9792 - val_loss: 0.7577 - val_acc: 0.8455\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0607 - acc: 0.9792 - val_loss: 0.7961 - val_acc: 0.8364\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0508 - acc: 0.9833 - val_loss: 0.8132 - val_acc: 0.8091\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0538 - acc: 0.9833 - val_loss: 0.8154 - val_acc: 0.8364\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0581 - acc: 0.9833 - val_loss: 0.7879 - val_acc: 0.8455\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0381 - acc: 0.9875 - val_loss: 0.7998 - val_acc: 0.8545\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0422 - acc: 0.9875 - val_loss: 0.7779 - val_acc: 0.8455\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0385 - acc: 0.9833 - val_loss: 0.8457 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0658 - acc: 0.9792 - val_loss: 0.8234 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0694 - acc: 0.9750 - val_loss: 0.9295 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.1167 - acc: 0.9625 - val_loss: 0.8714 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0642 - acc: 0.9792 - val_loss: 0.8198 - val_acc: 0.8091\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0690 - acc: 0.9708 - val_loss: 0.7844 - val_acc: 0.8273\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0522 - acc: 0.9792 - val_loss: 0.7481 - val_acc: 0.8182\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0363 - acc: 0.9875 - val_loss: 0.7636 - val_acc: 0.8273\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0394 - acc: 0.9917 - val_loss: 0.7848 - val_acc: 0.8182\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0313 - acc: 0.9875 - val_loss: 0.7923 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 0.0340 - acc: 0.9875 - val_loss: 0.8088 - val_acc: 0.8273\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0333 - acc: 0.9875 - val_loss: 0.8196 - val_acc: 0.8364\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0796 - acc: 0.9708 - val_loss: 0.7932 - val_acc: 0.8182\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0530 - acc: 0.9833 - val_loss: 0.7096 - val_acc: 0.8364\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0353 - acc: 0.9833 - val_loss: 0.7079 - val_acc: 0.8364\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0351 - acc: 0.9792 - val_loss: 0.7219 - val_acc: 0.8364\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0318 - acc: 0.9875 - val_loss: 0.7041 - val_acc: 0.8455\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0405 - acc: 0.9833 - val_loss: 0.6926 - val_acc: 0.8636\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0487 - acc: 0.9833 - val_loss: 0.6504 - val_acc: 0.8636\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.0355 - acc: 0.9833 - val_loss: 0.6702 - val_acc: 0.8455\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0346 - acc: 0.9875 - val_loss: 0.7051 - val_acc: 0.8364\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0228 - acc: 0.9917 - val_loss: 0.6955 - val_acc: 0.8364\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0246 - acc: 0.9917 - val_loss: 0.7141 - val_acc: 0.8545\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0249 - acc: 0.9875 - val_loss: 0.7235 - val_acc: 0.8455\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0183 - acc: 0.9958 - val_loss: 0.7279 - val_acc: 0.8545\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 10s 42ms/step - loss: 0.0175 - acc: 0.9875 - val_loss: 0.7253 - val_acc: 0.8545\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0247 - acc: 0.9875 - val_loss: 0.7027 - val_acc: 0.8455\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0319 - acc: 0.9875 - val_loss: 0.7243 - val_acc: 0.8455\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0189 - acc: 0.9875 - val_loss: 0.7249 - val_acc: 0.8455\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0742 - acc: 0.9750 - val_loss: 0.7056 - val_acc: 0.8182\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0610 - acc: 0.9667 - val_loss: 0.8150 - val_acc: 0.8455\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0745 - acc: 0.9833 - val_loss: 0.8786 - val_acc: 0.8182\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0847 - acc: 0.9750 - val_loss: 0.7217 - val_acc: 0.8727\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0709 - acc: 0.9708 - val_loss: 0.8263 - val_acc: 0.8545\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0651 - acc: 0.9750 - val_loss: 0.9208 - val_acc: 0.8364\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.2026 - acc: 0.9167 - val_loss: 0.9584 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.1939 - acc: 0.9500 - val_loss: 0.9928 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.2273 - acc: 0.9250 - val_loss: 0.9308 - val_acc: 0.8182\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.1560 - acc: 0.9542 - val_loss: 0.8107 - val_acc: 0.8364\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.1336 - acc: 0.9500 - val_loss: 0.7950 - val_acc: 0.8273\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.1557 - acc: 0.9542 - val_loss: 0.8707 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.1412 - acc: 0.9542 - val_loss: 0.9562 - val_acc: 0.8091\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.1542 - acc: 0.9417 - val_loss: 0.9705 - val_acc: 0.8364\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0837 - acc: 0.9750 - val_loss: 0.9335 - val_acc: 0.8182\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.1337 - acc: 0.9667 - val_loss: 0.9030 - val_acc: 0.8182\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0789 - acc: 0.9750 - val_loss: 0.9340 - val_acc: 0.8273\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0563 - acc: 0.9833 - val_loss: 1.0473 - val_acc: 0.8182\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0550 - acc: 0.9833 - val_loss: 1.0426 - val_acc: 0.8182\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0892 - acc: 0.9792 - val_loss: 0.9849 - val_acc: 0.8182\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0731 - acc: 0.9792 - val_loss: 0.6925 - val_acc: 0.8727\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0427 - acc: 0.9833 - val_loss: 0.7102 - val_acc: 0.8636\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0363 - acc: 0.9875 - val_loss: 0.7769 - val_acc: 0.8727\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0219 - acc: 0.9958 - val_loss: 0.7977 - val_acc: 0.8727\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0230 - acc: 0.9917 - val_loss: 0.7863 - val_acc: 0.8636\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0248 - acc: 0.9958 - val_loss: 0.8013 - val_acc: 0.8545\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0187 - acc: 0.9958 - val_loss: 0.7910 - val_acc: 0.8545\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0149 - acc: 0.9958 - val_loss: 0.7735 - val_acc: 0.8545\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0320 - acc: 0.9917 - val_loss: 0.7626 - val_acc: 0.8545\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0156 - acc: 0.9958 - val_loss: 0.7679 - val_acc: 0.8636\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0151 - acc: 0.9958 - val_loss: 0.7768 - val_acc: 0.8545\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0118 - acc: 0.9958 - val_loss: 0.7813 - val_acc: 0.8545\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0111 - acc: 0.9958 - val_loss: 0.7863 - val_acc: 0.8545\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.7847 - val_acc: 0.8636\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.7852 - val_acc: 0.8636\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0152 - acc: 0.9958 - val_loss: 0.7991 - val_acc: 0.8545\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.0129 - acc: 0.9958 - val_loss: 0.7933 - val_acc: 0.8545\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.0395 - acc: 0.9833 - val_loss: 0.7116 - val_acc: 0.8727\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 0.0249 - acc: 0.9917 - val_loss: 0.7228 - val_acc: 0.8636\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0120 - acc: 0.9958 - val_loss: 0.7867 - val_acc: 0.8545\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0117 - acc: 0.9958 - val_loss: 0.8206 - val_acc: 0.8545\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0669 - acc: 0.9750 - val_loss: 0.8654 - val_acc: 0.8545\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0454 - acc: 0.9833 - val_loss: 0.8833 - val_acc: 0.8455\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0380 - acc: 0.9875 - val_loss: 0.9041 - val_acc: 0.8545\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.1545 - acc: 0.9583 - val_loss: 0.8911 - val_acc: 0.8182\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.3255 - acc: 0.8792 - val_loss: 0.9179 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.4129 - acc: 0.8792 - val_loss: 0.9126 - val_acc: 0.8182\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.3554 - acc: 0.8875 - val_loss: 0.8109 - val_acc: 0.8273\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.2306 - acc: 0.9250 - val_loss: 0.7682 - val_acc: 0.8182\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.1376 - acc: 0.9625 - val_loss: 0.7874 - val_acc: 0.8273\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 8s 31ms/step - loss: 0.1310 - acc: 0.9625 - val_loss: 0.6746 - val_acc: 0.8545\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.1100 - acc: 0.9792 - val_loss: 0.6520 - val_acc: 0.8636\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0644 - acc: 0.9875 - val_loss: 0.6859 - val_acc: 0.8545\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0547 - acc: 0.9875 - val_loss: 0.7650 - val_acc: 0.8273\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0570 - acc: 0.9875 - val_loss: 0.7513 - val_acc: 0.8364\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0283 - acc: 0.9917 - val_loss: 0.7104 - val_acc: 0.8545\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0464 - acc: 0.9875 - val_loss: 0.7134 - val_acc: 0.8455\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0232 - acc: 0.9917 - val_loss: 0.8293 - val_acc: 0.8364\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0473 - acc: 0.9917 - val_loss: 0.7642 - val_acc: 0.8545\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0262 - acc: 0.9917 - val_loss: 0.7529 - val_acc: 0.8545\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.0387 - acc: 0.9875 - val_loss: 0.8910 - val_acc: 0.8364\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0571 - acc: 0.9875 - val_loss: 0.7774 - val_acc: 0.8455\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0302 - acc: 0.9875 - val_loss: 0.7452 - val_acc: 0.8455\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0191 - acc: 0.9958 - val_loss: 0.7376 - val_acc: 0.8545\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0481 - acc: 0.9792 - val_loss: 0.6903 - val_acc: 0.8545\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0658 - acc: 0.9833 - val_loss: 0.7945 - val_acc: 0.8273\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0350 - acc: 0.9875 - val_loss: 0.7354 - val_acc: 0.8455\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.0263 - acc: 0.9917 - val_loss: 0.8242 - val_acc: 0.8364\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.1522 - acc: 0.9542 - val_loss: 0.8239 - val_acc: 0.8091\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0915 - acc: 0.9625 - val_loss: 0.8806 - val_acc: 0.8091\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0598 - acc: 0.9833 - val_loss: 0.8473 - val_acc: 0.8182\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0442 - acc: 0.9875 - val_loss: 0.7438 - val_acc: 0.8455\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0420 - acc: 0.9875 - val_loss: 0.7606 - val_acc: 0.8273\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0244 - acc: 0.9875 - val_loss: 0.6672 - val_acc: 0.8455\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0240 - acc: 0.9958 - val_loss: 0.7410 - val_acc: 0.8455\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0431 - acc: 0.9875 - val_loss: 0.7632 - val_acc: 0.8364\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0309 - acc: 0.9875 - val_loss: 0.9118 - val_acc: 0.8273\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0147 - acc: 0.9958 - val_loss: 0.9004 - val_acc: 0.8364\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0386 - acc: 0.9917 - val_loss: 0.9079 - val_acc: 0.8364\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.0172 - acc: 0.9917 - val_loss: 0.8933 - val_acc: 0.8364\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0191 - acc: 0.9875 - val_loss: 0.8735 - val_acc: 0.8364\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0138 - acc: 0.9958 - val_loss: 0.8825 - val_acc: 0.8273\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0127 - acc: 0.9958 - val_loss: 0.8023 - val_acc: 0.8545\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.0119 - acc: 0.9917 - val_loss: 0.7852 - val_acc: 0.8636\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.0277 - acc: 0.9875 - val_loss: 0.7562 - val_acc: 0.8727\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0388 - acc: 0.9833 - val_loss: 0.8449 - val_acc: 0.8545\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0706 - acc: 0.9833 - val_loss: 0.8423 - val_acc: 0.8545\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0155 - acc: 0.9958 - val_loss: 0.8224 - val_acc: 0.8273\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0231 - acc: 0.9875 - val_loss: 0.8111 - val_acc: 0.8545\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0227 - acc: 0.9833 - val_loss: 0.8876 - val_acc: 0.8455\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0423 - acc: 0.9833 - val_loss: 1.0432 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0177 - acc: 0.9958 - val_loss: 1.0283 - val_acc: 0.7909\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0120 - acc: 0.9958 - val_loss: 1.0066 - val_acc: 0.8091\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0171 - acc: 0.9875 - val_loss: 0.8279 - val_acc: 0.8545\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0175 - acc: 0.9917 - val_loss: 0.8831 - val_acc: 0.8364\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0180 - acc: 0.9875 - val_loss: 0.9609 - val_acc: 0.8091\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0152 - acc: 0.9875 - val_loss: 0.8539 - val_acc: 0.8455\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0097 - acc: 0.9917 - val_loss: 0.8330 - val_acc: 0.8636\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0123 - acc: 0.9917 - val_loss: 0.8197 - val_acc: 0.8636\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0099 - acc: 0.9917 - val_loss: 0.8186 - val_acc: 0.8636\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0362 - acc: 0.9917 - val_loss: 0.8280 - val_acc: 0.8545\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0138 - acc: 0.9917 - val_loss: 0.7834 - val_acc: 0.8545\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0103 - acc: 0.9958 - val_loss: 0.7993 - val_acc: 0.8636\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0111 - acc: 0.9958 - val_loss: 0.8091 - val_acc: 0.8636\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0109 - acc: 0.9917 - val_loss: 0.8127 - val_acc: 0.8727\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0170 - acc: 0.9917 - val_loss: 0.8496 - val_acc: 0.8636\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.8475 - val_acc: 0.8545\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0264 - acc: 0.9958 - val_loss: 0.8315 - val_acc: 0.8636\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0102 - acc: 0.9958 - val_loss: 0.8423 - val_acc: 0.8636\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0077 - acc: 0.9958 - val_loss: 0.8471 - val_acc: 0.8636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0085 - acc: 0.9958 - val_loss: 0.8465 - val_acc: 0.8727\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0085 - acc: 0.9958 - val_loss: 0.8533 - val_acc: 0.8727\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.8535 - val_acc: 0.8727\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0089 - acc: 0.9958 - val_loss: 0.8521 - val_acc: 0.8727\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0326 - acc: 0.9917 - val_loss: 0.8546 - val_acc: 0.8636\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0071 - acc: 0.9958 - val_loss: 0.8530 - val_acc: 0.8727\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0148 - acc: 0.9917 - val_loss: 0.7963 - val_acc: 0.8727\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0288 - acc: 0.9917 - val_loss: 0.8010 - val_acc: 0.8727\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0079 - acc: 0.9958 - val_loss: 0.8366 - val_acc: 0.8818\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0084 - acc: 0.9958 - val_loss: 0.8415 - val_acc: 0.8818\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0088 - acc: 0.9917 - val_loss: 0.8431 - val_acc: 0.8818\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0073 - acc: 0.9958 - val_loss: 0.8409 - val_acc: 0.8818\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0093 - acc: 0.9917 - val_loss: 0.8437 - val_acc: 0.8818\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0084 - acc: 0.9958 - val_loss: 0.8467 - val_acc: 0.8818\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.8497 - val_acc: 0.8818\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0077 - acc: 0.9917 - val_loss: 0.8524 - val_acc: 0.8818\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0092 - acc: 0.9917 - val_loss: 0.8559 - val_acc: 0.8818\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.8578 - val_acc: 0.8818\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0082 - acc: 0.9958 - val_loss: 0.8588 - val_acc: 0.8636\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0085 - acc: 0.9917 - val_loss: 0.9193 - val_acc: 0.8545\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.9336 - val_acc: 0.8545\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0080 - acc: 0.9958 - val_loss: 0.9371 - val_acc: 0.8455\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0072 - acc: 0.9958 - val_loss: 0.9379 - val_acc: 0.8455\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0088 - acc: 0.9917 - val_loss: 0.9378 - val_acc: 0.8455\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0072 - acc: 0.9958 - val_loss: 0.9329 - val_acc: 0.8455\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0086 - acc: 0.9958 - val_loss: 0.8448 - val_acc: 0.8636\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0097 - acc: 0.9958 - val_loss: 0.8004 - val_acc: 0.8727\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0082 - acc: 0.9958 - val_loss: 0.8231 - val_acc: 0.8727\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0080 - acc: 0.9958 - val_loss: 0.8631 - val_acc: 0.8727\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0086 - acc: 0.9917 - val_loss: 0.8646 - val_acc: 0.8727\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0077 - acc: 0.9958 - val_loss: 0.8673 - val_acc: 0.8727\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.8533 - val_acc: 0.8727\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0068 - acc: 0.9958 - val_loss: 0.8476 - val_acc: 0.8636\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0087 - acc: 0.9917 - val_loss: 0.8492 - val_acc: 0.8727\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0086 - acc: 0.9958 - val_loss: 0.8514 - val_acc: 0.8727\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0079 - acc: 0.9958 - val_loss: 0.8546 - val_acc: 0.8727\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0066 - acc: 0.9958 - val_loss: 0.8565 - val_acc: 0.8727\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0324 - acc: 0.9917 - val_loss: 0.7865 - val_acc: 0.8909\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.0356 - acc: 0.9875 - val_loss: 0.8932 - val_acc: 0.8636\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.1057 - acc: 0.9708 - val_loss: 0.9336 - val_acc: 0.8364\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0535 - acc: 0.9833 - val_loss: 0.8630 - val_acc: 0.8636\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0406 - acc: 0.9917 - val_loss: 0.9292 - val_acc: 0.8636\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0345 - acc: 0.9875 - val_loss: 0.8171 - val_acc: 0.8818\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0175 - acc: 0.9917 - val_loss: 0.8900 - val_acc: 0.8455\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0261 - acc: 0.9917 - val_loss: 0.8937 - val_acc: 0.8273\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0129 - acc: 0.9958 - val_loss: 0.8649 - val_acc: 0.8455\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0108 - acc: 0.9958 - val_loss: 0.8900 - val_acc: 0.8455\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0092 - acc: 0.9958 - val_loss: 0.9746 - val_acc: 0.8364\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0152 - acc: 0.9917 - val_loss: 0.8945 - val_acc: 0.8545\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0109 - acc: 0.9958 - val_loss: 0.7964 - val_acc: 0.8636\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0087 - acc: 0.9917 - val_loss: 0.8038 - val_acc: 0.8545\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0094 - acc: 0.9958 - val_loss: 0.8161 - val_acc: 0.8545\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.0080 - acc: 0.9958 - val_loss: 0.8229 - val_acc: 0.8636\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0089 - acc: 0.9917 - val_loss: 0.8198 - val_acc: 0.8636\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0088 - acc: 0.9958 - val_loss: 0.7332 - val_acc: 0.9000\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0081 - acc: 0.9958 - val_loss: 0.7456 - val_acc: 0.9000\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0926 - acc: 0.9833 - val_loss: 1.0515 - val_acc: 0.8273\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.4489 - acc: 0.8875 - val_loss: 0.7400 - val_acc: 0.8364\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.2596 - acc: 0.8333 - val_loss: 0.6416 - val_acc: 0.8545\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 7s 27ms/step - loss: 0.1714 - acc: 0.9583 - val_loss: 0.5733 - val_acc: 0.8727\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.1541 - acc: 0.9583 - val_loss: 0.5631 - val_acc: 0.8727\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 10s 40ms/step - loss: 0.1927 - acc: 0.9458 - val_loss: 0.7239 - val_acc: 0.8273\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.2729 - acc: 0.9417 - val_loss: 0.8046 - val_acc: 0.8182\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.2061 - acc: 0.9458 - val_loss: 0.6212 - val_acc: 0.8545\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.1328 - acc: 0.9625 - val_loss: 0.5221 - val_acc: 0.8909\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.0634 - acc: 0.9792 - val_loss: 0.4730 - val_acc: 0.8636\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0854 - acc: 0.9792 - val_loss: 0.5676 - val_acc: 0.8636\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0487 - acc: 0.9833 - val_loss: 0.7356 - val_acc: 0.8273\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0846 - acc: 0.9708 - val_loss: 0.7140 - val_acc: 0.8273\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.1089 - acc: 0.9667 - val_loss: 0.5076 - val_acc: 0.8636\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 0.0514 - acc: 0.9792 - val_loss: 0.5592 - val_acc: 0.8636\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 10s 43ms/step - loss: 0.0745 - acc: 0.9750 - val_loss: 0.6122 - val_acc: 0.8545\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.0512 - acc: 0.9792 - val_loss: 0.7420 - val_acc: 0.8364\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0840 - acc: 0.9750 - val_loss: 0.8192 - val_acc: 0.8091\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 0.1701 - acc: 0.9542 - val_loss: 0.8008 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.1019 - acc: 0.9750 - val_loss: 0.7826 - val_acc: 0.8091\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.1436 - acc: 0.9625 - val_loss: 0.7558 - val_acc: 0.8182\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.1185 - acc: 0.9583 - val_loss: 0.9008 - val_acc: 0.8364\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0701 - acc: 0.9833 - val_loss: 0.7564 - val_acc: 0.8545\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0489 - acc: 0.9833 - val_loss: 0.7729 - val_acc: 0.8455\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0564 - acc: 0.9875 - val_loss: 0.7847 - val_acc: 0.8455\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0734 - acc: 0.9750 - val_loss: 0.7251 - val_acc: 0.8455\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 9s 39ms/step - loss: 0.0707 - acc: 0.9792 - val_loss: 0.7251 - val_acc: 0.8455\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 0.0471 - acc: 0.9833 - val_loss: 0.7712 - val_acc: 0.8455\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0354 - acc: 0.9833 - val_loss: 0.7953 - val_acc: 0.8273\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0196 - acc: 0.9958 - val_loss: 0.7785 - val_acc: 0.8273\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0182 - acc: 0.9958 - val_loss: 0.7601 - val_acc: 0.8545\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0309 - acc: 0.9875 - val_loss: 0.7781 - val_acc: 0.8455\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0175 - acc: 0.9917 - val_loss: 0.7359 - val_acc: 0.8455\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0288 - acc: 0.9917 - val_loss: 0.7797 - val_acc: 0.8636\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0254 - acc: 0.9833 - val_loss: 0.7696 - val_acc: 0.8545\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0141 - acc: 0.9917 - val_loss: 0.7427 - val_acc: 0.8636\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 0.0170 - acc: 0.9917 - val_loss: 0.7592 - val_acc: 0.8545\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0387 - acc: 0.9833 - val_loss: 0.7675 - val_acc: 0.8545\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0124 - acc: 0.9958 - val_loss: 0.6676 - val_acc: 0.8727\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.0147 - acc: 0.9917 - val_loss: 0.6934 - val_acc: 0.8727\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.0165 - acc: 0.9917 - val_loss: 0.7087 - val_acc: 0.8727\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0106 - acc: 0.9917 - val_loss: 0.7060 - val_acc: 0.8727\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0117 - acc: 0.9958 - val_loss: 0.7071 - val_acc: 0.8727\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0112 - acc: 0.9958 - val_loss: 0.7074 - val_acc: 0.8727\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0118 - acc: 0.9958 - val_loss: 0.7032 - val_acc: 0.8727\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0114 - acc: 0.9958 - val_loss: 0.6927 - val_acc: 0.8818\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0114 - acc: 0.9958 - val_loss: 0.6922 - val_acc: 0.8818\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0109 - acc: 0.9958 - val_loss: 0.6872 - val_acc: 0.8818\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0094 - acc: 0.9958 - val_loss: 0.6873 - val_acc: 0.8818\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0103 - acc: 0.9917 - val_loss: 0.6872 - val_acc: 0.8818\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0170 - acc: 0.9917 - val_loss: 0.9248 - val_acc: 0.8182\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0425 - acc: 0.9875 - val_loss: 0.7461 - val_acc: 0.8545\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0115 - acc: 0.9958 - val_loss: 0.6981 - val_acc: 0.8727\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0097 - acc: 0.9958 - val_loss: 0.6695 - val_acc: 0.8818\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0097 - acc: 0.9958 - val_loss: 0.6731 - val_acc: 0.8818\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0221 - acc: 0.9875 - val_loss: 0.6810 - val_acc: 0.8727\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0088 - acc: 0.9958 - val_loss: 0.6980 - val_acc: 0.8636\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.7351 - val_acc: 0.8455\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0238 - acc: 0.9917 - val_loss: 0.7643 - val_acc: 0.8636\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0198 - acc: 0.9875 - val_loss: 0.6279 - val_acc: 0.8818\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0546 - acc: 0.9750 - val_loss: 0.6954 - val_acc: 0.8909\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0374 - acc: 0.9875 - val_loss: 0.6695 - val_acc: 0.8909\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 7s 27ms/step - loss: 0.0883 - acc: 0.9708 - val_loss: 0.6724 - val_acc: 0.8818\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0799 - acc: 0.9792 - val_loss: 0.6069 - val_acc: 0.9000\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0129 - acc: 0.9917 - val_loss: 0.6194 - val_acc: 0.8727\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0326 - acc: 0.9792 - val_loss: 0.7105 - val_acc: 0.8727\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0337 - acc: 0.9875 - val_loss: 0.7255 - val_acc: 0.8636\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0781 - acc: 0.9708 - val_loss: 0.7725 - val_acc: 0.8455\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0805 - acc: 0.9833 - val_loss: 0.8701 - val_acc: 0.8273\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0750 - acc: 0.9708 - val_loss: 0.7574 - val_acc: 0.8727\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.0363 - acc: 0.9917 - val_loss: 0.6888 - val_acc: 0.8818\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0754 - acc: 0.9792 - val_loss: 0.7195 - val_acc: 0.8727\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.1150 - acc: 0.9667 - val_loss: 0.6896 - val_acc: 0.8545\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.2221 - acc: 0.9333 - val_loss: 0.7566 - val_acc: 0.8273\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.1502 - acc: 0.9583 - val_loss: 0.6308 - val_acc: 0.8909\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0961 - acc: 0.9750 - val_loss: 0.5873 - val_acc: 0.8818\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.1245 - acc: 0.9542 - val_loss: 0.7340 - val_acc: 0.8545\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0680 - acc: 0.9750 - val_loss: 0.7371 - val_acc: 0.8364\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.1010 - acc: 0.9708 - val_loss: 0.7803 - val_acc: 0.8364\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0541 - acc: 0.9792 - val_loss: 0.7983 - val_acc: 0.8455\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.1991 - acc: 0.9375 - val_loss: 0.8962 - val_acc: 0.8182\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.1576 - acc: 0.9667 - val_loss: 0.7731 - val_acc: 0.8455\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.1073 - acc: 0.9708 - val_loss: 0.7705 - val_acc: 0.8727\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.0609 - acc: 0.9875 - val_loss: 0.7458 - val_acc: 0.8636\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0575 - acc: 0.9792 - val_loss: 0.7580 - val_acc: 0.8545\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0716 - acc: 0.9708 - val_loss: 0.7407 - val_acc: 0.8727\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0522 - acc: 0.9833 - val_loss: 0.7584 - val_acc: 0.8727\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0968 - acc: 0.9667 - val_loss: 0.8013 - val_acc: 0.8545\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0549 - acc: 0.9750 - val_loss: 0.9048 - val_acc: 0.8545\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0786 - acc: 0.9833 - val_loss: 0.9206 - val_acc: 0.8455\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0448 - acc: 0.9833 - val_loss: 0.8941 - val_acc: 0.8545\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0486 - acc: 0.9833 - val_loss: 0.9040 - val_acc: 0.8182\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0302 - acc: 0.9875 - val_loss: 0.9163 - val_acc: 0.8364\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0249 - acc: 0.9917 - val_loss: 0.8890 - val_acc: 0.8455\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0216 - acc: 0.9917 - val_loss: 0.8860 - val_acc: 0.8364\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0206 - acc: 0.9917 - val_loss: 0.8817 - val_acc: 0.8364\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0231 - acc: 0.9917 - val_loss: 0.8827 - val_acc: 0.8455\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0265 - acc: 0.9917 - val_loss: 0.8614 - val_acc: 0.8364\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0218 - acc: 0.9917 - val_loss: 0.8627 - val_acc: 0.8364\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0207 - acc: 0.9917 - val_loss: 0.8570 - val_acc: 0.8455\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0194 - acc: 0.9917 - val_loss: 0.8711 - val_acc: 0.8545\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0157 - acc: 0.9958 - val_loss: 0.8695 - val_acc: 0.8636\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0170 - acc: 0.9917 - val_loss: 0.8920 - val_acc: 0.8636\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0222 - acc: 0.9917 - val_loss: 1.1682 - val_acc: 0.8091\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.1017 - acc: 0.9792 - val_loss: 1.0791 - val_acc: 0.8273\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0514 - acc: 0.9833 - val_loss: 1.0109 - val_acc: 0.8455\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 8s 35ms/step - loss: 0.0343 - acc: 0.9917 - val_loss: 0.8807 - val_acc: 0.8636\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 11s 44ms/step - loss: 0.0553 - acc: 0.9833 - val_loss: 0.7845 - val_acc: 0.8727\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 11s 46ms/step - loss: 0.0773 - acc: 0.9708 - val_loss: 1.0712 - val_acc: 0.8273\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 7s 31ms/step - loss: 0.1420 - acc: 0.9542 - val_loss: 0.9423 - val_acc: 0.8182\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 0.1872 - acc: 0.9542 - val_loss: 0.9650 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.1442 - acc: 0.9667 - val_loss: 1.0481 - val_acc: 0.7909\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.1037 - acc: 0.9667 - val_loss: 0.9270 - val_acc: 0.8182\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0545 - acc: 0.9833 - val_loss: 0.9952 - val_acc: 0.8182\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1056 - acc: 0.9667 - val_loss: 0.9582 - val_acc: 0.8273\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0719 - acc: 0.9833 - val_loss: 0.9573 - val_acc: 0.8182\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0343 - acc: 0.9917 - val_loss: 1.0472 - val_acc: 0.7909\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0284 - acc: 0.9917 - val_loss: 1.0656 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.1079 - acc: 0.9708 - val_loss: 1.0148 - val_acc: 0.7909\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0529 - acc: 0.9667 - val_loss: 1.0610 - val_acc: 0.7909\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0559 - acc: 0.9833 - val_loss: 1.0705 - val_acc: 0.8000\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0436 - acc: 0.9875 - val_loss: 1.0962 - val_acc: 0.8091\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0385 - acc: 0.9833 - val_loss: 1.0092 - val_acc: 0.8182\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0241 - acc: 0.9917 - val_loss: 0.8916 - val_acc: 0.8273\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0185 - acc: 0.9958 - val_loss: 0.8052 - val_acc: 0.8273\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0249 - acc: 0.9917 - val_loss: 0.7154 - val_acc: 0.8545\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0183 - acc: 0.9875 - val_loss: 0.8092 - val_acc: 0.8545\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0362 - acc: 0.9875 - val_loss: 0.8882 - val_acc: 0.8364\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0121 - acc: 0.9958 - val_loss: 0.7552 - val_acc: 0.8455\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0256 - acc: 0.9875 - val_loss: 0.8179 - val_acc: 0.8364\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0126 - acc: 0.9917 - val_loss: 0.8278 - val_acc: 0.8364\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0113 - acc: 0.9958 - val_loss: 0.8376 - val_acc: 0.8455\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0095 - acc: 0.9958 - val_loss: 0.8448 - val_acc: 0.8455\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0099 - acc: 0.9917 - val_loss: 0.8504 - val_acc: 0.8455\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0099 - acc: 0.9958 - val_loss: 0.8550 - val_acc: 0.8455\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.8598 - val_acc: 0.8455\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0091 - acc: 0.9958 - val_loss: 0.8615 - val_acc: 0.8455\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0090 - acc: 0.9958 - val_loss: 0.8638 - val_acc: 0.8455\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0109 - acc: 0.9917 - val_loss: 0.8652 - val_acc: 0.8455\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0097 - acc: 0.9958 - val_loss: 0.8622 - val_acc: 0.8364\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0100 - acc: 0.9958 - val_loss: 0.8602 - val_acc: 0.8364\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0094 - acc: 0.9958 - val_loss: 0.8636 - val_acc: 0.8364\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0099 - acc: 0.9958 - val_loss: 0.8699 - val_acc: 0.8364\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.0098 - acc: 0.9917 - val_loss: 0.8682 - val_acc: 0.8364\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0084 - acc: 0.9958 - val_loss: 0.8746 - val_acc: 0.8364\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0087 - acc: 0.9958 - val_loss: 0.8817 - val_acc: 0.8364\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0090 - acc: 0.9917 - val_loss: 0.8825 - val_acc: 0.8364\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0080 - acc: 0.9958 - val_loss: 0.8822 - val_acc: 0.8364\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0077 - acc: 0.9958 - val_loss: 0.8839 - val_acc: 0.8364\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0086 - acc: 0.9917 - val_loss: 0.8843 - val_acc: 0.8364\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0077 - acc: 0.9958 - val_loss: 0.8822 - val_acc: 0.8364\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0091 - acc: 0.9917 - val_loss: 0.8837 - val_acc: 0.8364\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0073 - acc: 0.9958 - val_loss: 0.8859 - val_acc: 0.8364\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0078 - acc: 0.9958 - val_loss: 0.8844 - val_acc: 0.8364\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0073 - acc: 0.9958 - val_loss: 0.8900 - val_acc: 0.8364\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.8970 - val_acc: 0.8364\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0092 - acc: 0.9917 - val_loss: 0.8972 - val_acc: 0.8364\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0083 - acc: 0.9917 - val_loss: 0.9010 - val_acc: 0.8364\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0077 - acc: 0.9958 - val_loss: 0.9025 - val_acc: 0.8364\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0078 - acc: 0.9917 - val_loss: 0.9010 - val_acc: 0.8364\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0080 - acc: 0.9958 - val_loss: 0.8991 - val_acc: 0.8364\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0081 - acc: 0.9917 - val_loss: 0.9022 - val_acc: 0.8364\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0086 - acc: 0.9917 - val_loss: 0.9057 - val_acc: 0.8364\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0245 - acc: 0.9875 - val_loss: 0.8837 - val_acc: 0.8545\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.8788 - val_acc: 0.8545\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0071 - acc: 0.9958 - val_loss: 0.8843 - val_acc: 0.8545\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0087 - acc: 0.9917 - val_loss: 0.8906 - val_acc: 0.8545\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0074 - acc: 0.9958 - val_loss: 0.8943 - val_acc: 0.8545\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0093 - acc: 0.9958 - val_loss: 0.9008 - val_acc: 0.8545\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0088 - acc: 0.9917 - val_loss: 0.9046 - val_acc: 0.8545\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0078 - acc: 0.9917 - val_loss: 0.9079 - val_acc: 0.8545\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0070 - acc: 0.9958 - val_loss: 0.9101 - val_acc: 0.8545\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0066 - acc: 0.9958 - val_loss: 0.9121 - val_acc: 0.8545\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0078 - acc: 0.9958 - val_loss: 0.9130 - val_acc: 0.8545\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0077 - acc: 0.9917 - val_loss: 0.9146 - val_acc: 0.8545\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0074 - acc: 0.9958 - val_loss: 0.9162 - val_acc: 0.8545\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0094 - acc: 0.9917 - val_loss: 0.9162 - val_acc: 0.8545\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0084 - acc: 0.9917 - val_loss: 0.9187 - val_acc: 0.8545\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0069 - acc: 0.9958 - val_loss: 0.9184 - val_acc: 0.8545\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0077 - acc: 0.9958 - val_loss: 0.9188 - val_acc: 0.8545\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0089 - acc: 0.9917 - val_loss: 0.9180 - val_acc: 0.8545\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0077 - acc: 0.9958 - val_loss: 0.9363 - val_acc: 0.8455\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0165 - acc: 0.9875 - val_loss: 0.9937 - val_acc: 0.8364\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0252 - acc: 0.9917 - val_loss: 0.9768 - val_acc: 0.8545\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0114 - acc: 0.9958 - val_loss: 0.9942 - val_acc: 0.8545\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0079 - acc: 0.9958 - val_loss: 1.0015 - val_acc: 0.8545\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0085 - acc: 0.9958 - val_loss: 0.9993 - val_acc: 0.8545\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.9891 - val_acc: 0.8545\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0092 - acc: 0.9917 - val_loss: 0.9918 - val_acc: 0.8545\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0070 - acc: 0.9958 - val_loss: 0.9920 - val_acc: 0.8545\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0079 - acc: 0.9958 - val_loss: 0.9932 - val_acc: 0.8545\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0088 - acc: 0.9917 - val_loss: 0.9980 - val_acc: 0.8545\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0073 - acc: 0.9958 - val_loss: 0.9989 - val_acc: 0.8545\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0342 - acc: 0.9917 - val_loss: 0.9466 - val_acc: 0.8636\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0079 - acc: 0.9917 - val_loss: 0.9362 - val_acc: 0.8636\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.0259 - acc: 0.9875 - val_loss: 1.1771 - val_acc: 0.8182\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 10s 42ms/step - loss: 0.0371 - acc: 0.9917 - val_loss: 0.8702 - val_acc: 0.8818\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0107 - acc: 0.9917 - val_loss: 0.8750 - val_acc: 0.8727\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.0080 - acc: 0.9958 - val_loss: 0.8810 - val_acc: 0.8727\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0076 - acc: 0.9958 - val_loss: 0.8801 - val_acc: 0.8727\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 0.0075 - acc: 0.9958 - val_loss: 0.8851 - val_acc: 0.8727\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.8872 - val_acc: 0.8727\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.8885 - val_acc: 0.8727\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0075 - acc: 0.9917 - val_loss: 0.8901 - val_acc: 0.8545\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 30ms/step - loss: 0.0084 - acc: 0.9958 - val_loss: 0.8891 - val_acc: 0.8636\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 8s 34ms/step - loss: 0.0069 - acc: 0.9958 - val_loss: 0.8901 - val_acc: 0.8545\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0074 - acc: 0.9958 - val_loss: 0.8913 - val_acc: 0.8545\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.8941 - val_acc: 0.8545\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0067 - acc: 0.9958 - val_loss: 0.8931 - val_acc: 0.8636\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0071 - acc: 0.9958 - val_loss: 0.8963 - val_acc: 0.8545\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0100 - acc: 0.9917 - val_loss: 0.8995 - val_acc: 0.8545\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0068 - acc: 0.9958 - val_loss: 0.8939 - val_acc: 0.8545\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0069 - acc: 0.9958 - val_loss: 0.8900 - val_acc: 0.8545\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0076 - acc: 0.9917 - val_loss: 0.8856 - val_acc: 0.8636\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0069 - acc: 0.9958 - val_loss: 0.8827 - val_acc: 0.8727\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0076 - acc: 0.9958 - val_loss: 0.8822 - val_acc: 0.8727\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0079 - acc: 0.9958 - val_loss: 0.8847 - val_acc: 0.8727\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0080 - acc: 0.9917 - val_loss: 0.8853 - val_acc: 0.8727\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0075 - acc: 0.9917 - val_loss: 0.8880 - val_acc: 0.8636\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0077 - acc: 0.9958 - val_loss: 0.8899 - val_acc: 0.8727\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.8935 - val_acc: 0.8545\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0063 - acc: 0.9958 - val_loss: 0.8947 - val_acc: 0.8545\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0071 - acc: 0.9958 - val_loss: 0.8969 - val_acc: 0.8545\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0074 - acc: 0.9958 - val_loss: 0.8979 - val_acc: 0.8636\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.8969 - val_acc: 0.8636\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.8972 - val_acc: 0.8727\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 8s 32ms/step - loss: 0.0070 - acc: 0.9958 - val_loss: 0.8977 - val_acc: 0.8727\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.0073 - acc: 0.9958 - val_loss: 0.8990 - val_acc: 0.8727\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0072 - acc: 0.9917 - val_loss: 0.8990 - val_acc: 0.8727\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0059 - acc: 0.9958 - val_loss: 0.9015 - val_acc: 0.8636\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0063 - acc: 0.9958 - val_loss: 0.9029 - val_acc: 0.8636\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0076 - acc: 0.9958 - val_loss: 0.9046 - val_acc: 0.8636\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0077 - acc: 0.9917 - val_loss: 0.9047 - val_acc: 0.8636\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.9011 - val_acc: 0.8636\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0063 - acc: 0.9958 - val_loss: 0.8946 - val_acc: 0.8636\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0076 - acc: 0.9958 - val_loss: 0.8958 - val_acc: 0.8636\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0076 - acc: 0.9958 - val_loss: 0.8957 - val_acc: 0.8636\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0067 - acc: 0.9958 - val_loss: 0.8955 - val_acc: 0.8727\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 0.0082 - acc: 0.9958 - val_loss: 0.9298 - val_acc: 0.8545\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0078 - acc: 0.9958 - val_loss: 0.9263 - val_acc: 0.8545\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0071 - acc: 0.9958 - val_loss: 0.9152 - val_acc: 0.8636\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.9066 - val_acc: 0.8636\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0073 - acc: 0.9917 - val_loss: 0.9039 - val_acc: 0.8636\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0094 - acc: 0.9917 - val_loss: 0.8245 - val_acc: 0.8727\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0069 - acc: 0.9958 - val_loss: 0.8223 - val_acc: 0.8727\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0393 - acc: 0.9917 - val_loss: 0.8498 - val_acc: 0.8909\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0370 - acc: 0.9917 - val_loss: 0.8958 - val_acc: 0.8818\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0739 - acc: 0.9833 - val_loss: 1.1293 - val_acc: 0.8455\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 5s 22ms/step - loss: 0.0810 - acc: 0.9708 - val_loss: 1.0079 - val_acc: 0.8364\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1674 - acc: 0.9667 - val_loss: 1.0480 - val_acc: 0.8273\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0661 - acc: 0.9875 - val_loss: 1.0191 - val_acc: 0.8455\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0728 - acc: 0.9792 - val_loss: 1.0228 - val_acc: 0.8182\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.1587 - acc: 0.9542 - val_loss: 1.1895 - val_acc: 0.7818\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0903 - acc: 0.9833 - val_loss: 1.1593 - val_acc: 0.7909\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0962 - acc: 0.9542 - val_loss: 0.9672 - val_acc: 0.8273\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.1004 - acc: 0.9750 - val_loss: 0.7561 - val_acc: 0.8636\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0875 - acc: 0.9708 - val_loss: 0.7860 - val_acc: 0.8545\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.1489 - acc: 0.9458 - val_loss: 0.9784 - val_acc: 0.7818\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.3791 - acc: 0.9042 - val_loss: 0.9785 - val_acc: 0.7636\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.1415 - acc: 0.9542 - val_loss: 0.8341 - val_acc: 0.7818\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.1502 - acc: 0.9292 - val_loss: 0.8000 - val_acc: 0.8091\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.1160 - acc: 0.9625 - val_loss: 0.8752 - val_acc: 0.8364\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.0711 - acc: 0.9833 - val_loss: 0.7310 - val_acc: 0.8545\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.1123 - acc: 0.9750 - val_loss: 0.6475 - val_acc: 0.8727\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.3848 - acc: 0.8958 - val_loss: 0.7534 - val_acc: 0.7636\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 0.1901 - acc: 0.9333 - val_loss: 0.6622 - val_acc: 0.8273\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.2214 - acc: 0.9417 - val_loss: 0.6760 - val_acc: 0.8727\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0686 - acc: 0.9833 - val_loss: 0.6863 - val_acc: 0.8818\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0633 - acc: 0.9750 - val_loss: 0.6536 - val_acc: 0.8818\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0333 - acc: 0.9917 - val_loss: 0.6689 - val_acc: 0.8909\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0380 - acc: 0.9875 - val_loss: 0.7318 - val_acc: 0.8909\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0441 - acc: 0.9833 - val_loss: 0.7588 - val_acc: 0.8909\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.0292 - acc: 0.9833 - val_loss: 0.7589 - val_acc: 0.8727\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 0.0370 - acc: 0.9833 - val_loss: 0.7839 - val_acc: 0.8818\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 8s 31ms/step - loss: 0.0322 - acc: 0.9917 - val_loss: 0.7233 - val_acc: 0.8818\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0214 - acc: 0.9917 - val_loss: 0.7228 - val_acc: 0.8818\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0212 - acc: 0.9917 - val_loss: 0.7253 - val_acc: 0.8818\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 6s 23ms/step - loss: 0.0341 - acc: 0.9917 - val_loss: 0.6968 - val_acc: 0.8818\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 7s 28ms/step - loss: 0.0164 - acc: 0.9917 - val_loss: 0.7078 - val_acc: 0.9000\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0137 - acc: 0.9958 - val_loss: 0.7176 - val_acc: 0.9000\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0385 - acc: 0.9833 - val_loss: 0.6696 - val_acc: 0.8909\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 7s 27ms/step - loss: 0.0183 - acc: 1.0000 - val_loss: 0.6996 - val_acc: 0.8909\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0228 - acc: 0.9875 - val_loss: 0.7251 - val_acc: 0.8818\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.0108 - acc: 0.9958 - val_loss: 0.8152 - val_acc: 0.8636\n",
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.0284 - acc: 0.9875 - val_loss: 0.7356 - val_acc: 0.8636\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 6s 24ms/step - loss: 0.0317 - acc: 0.9917 - val_loss: 0.7841 - val_acc: 0.8545\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.0149 - acc: 0.9917 - val_loss: 0.7991 - val_acc: 0.8727\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 5s 23ms/step - loss: 0.1698 - acc: 0.9458 - val_loss: 0.8109 - val_acc: 0.8273\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.1207 - acc: 0.9542 - val_loss: 0.8679 - val_acc: 0.8364\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 6s 25ms/step - loss: 0.0995 - acc: 0.9667 - val_loss: 0.8832 - val_acc: 0.8182\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 6s 26ms/step - loss: 0.1050 - acc: 0.9625 - val_loss: 0.8722 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 0.0785 - acc: 0.9625 - val_loss: 0.8820 - val_acc: 0.8182\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 7s 29ms/step - loss: 0.1377 - acc: 0.9625 - val_loss: 0.8214 - val_acc: 0.8182\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 6s 27ms/step - loss: 0.1437 - acc: 0.9583 - val_loss: 0.7907 - val_acc: 0.8182\n"
     ]
    }
   ],
   "source": [
    "ti=time.time()\n",
    "history=[]\n",
    "for i in range(100):\n",
    "    result=model.fit(trainX,trainY,batch_size=batch_size,epochs=n_epochs,validation_data=[testX,testY])\n",
    "    model.save('Models/keras_2LSTM_Dropout')\n",
    "    history.append(result)\n",
    "tiempofinal=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.39026056130727\n"
     ]
    }
   ],
   "source": [
    "print((tiempofinal-ti)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.callbacks.History"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Get the dictionary containing each metric and the loss for each epoch\n",
    "r = result.history\n",
    "# Save it under the form of a json file\n",
    "json.dump(r, open('Models/Results/LSTM_simple', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(result.history['acc'])\n",
    "plt.plot(result.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(result.history['loss'])\n",
    "plt.plot(result.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.91332112, -1.20854392, -0.19381587, ...,  0.09185654,\n",
       "         0.4319833 ,  0.45809148],\n",
       "       [-0.88884379, -1.11266398, -0.04986061, ..., -0.4501449 ,\n",
       "         0.08398442, -0.00812885],\n",
       "       [-0.81044921, -0.81749539,  0.34608203, ..., -0.66089419,\n",
       "        -0.02356124, -0.03912434],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=model.predict([[trainX[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09945323, 0.0985247 , 0.09981292, 0.09982746, 0.10115309,\n",
       "        0.09877511, 0.09959589, 0.10086489, 0.10064428, 0.10134849]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[trainX[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cero'], dtype='<U6')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.inverse_transform([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cero'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_text(model,[[trainX[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.5458267e-01, 1.3367206e-05, 1.1010848e-04, 1.2222943e-06,\n",
       "        1.5461472e-05, 3.2351786e-04, 6.4432106e-06, 1.4490633e-01,\n",
       "        3.8986556e-05, 1.9558286e-06]], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_result=y[0]>=y[0][np.argmax(y,axis=-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8600664"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cero'], dtype='<U6')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode([class_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_result=class_result.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict_proba() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-236-45b0ea53bfaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: predict_proba() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "wave, sr = librosa.load('data/test/6_seg_v1.wav', mono=True)\n",
    "features= librosa.feature.mfcc(wave, sr,n_mfcc=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.0500123e-08,  1.5895614e-08, -2.1860259e-08, ...,\n",
       "        8.4779126e-04,  6.8931724e-04,  7.1130751e-04], dtype=float32)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sklearn.preprocessing.scale(features, axis=1)\n",
    "features=np.pad(features,((0,0),(0,160-len(features[0]))),mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=np.matrix.transpose(np.array([features]),[0,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=m.predict_classes(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['dos']], dtype='<U6')"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(np.eye(10)[predict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['three'], dtype='<U5')"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.inverse_transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'three'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_text(m,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "m=tf.keras.models.load_model('Models/keras_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(m, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict_classes([[trainX[0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recording audios and predict them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37058879aefd401cba529cc3b7b5bd71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Record', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "button = widgets.Button(description=\"Record\")\n",
    "display(button)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    print(\"Button clicked.\")\n",
    "\n",
    "button.on_click(on_button_clicked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 10000  # seconds\n",
    "fs=16000\n",
    "myrecording = sd.rec(int(duration * fs), samplerate=fs, channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.3615484e-07],\n",
       "       [ 8.7624744e-07],\n",
       "       [-9.1520860e-07],\n",
       "       ...,\n",
       "       [ 0.0000000e+00],\n",
       "       [ 0.0000000e+00],\n",
       "       [ 0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrecording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording...\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    " \n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 48000#44100\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 2\n",
    "WAVE_OUTPUT_FILENAME = \"file.wav\"\n",
    " \n",
    "audio = pyaudio.PyAudio()\n",
    " \n",
    "# start Recording\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                rate=RATE, input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "print (\"recording...\")\n",
    "frames = []\n",
    " \n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "print (\"finished recording\")\n",
    " \n",
    " \n",
    "# stop Recording\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    " \n",
    "waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "waveFile.setnchannels(CHANNELS)\n",
    "waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "waveFile.setframerate(RATE)\n",
    "waveFile.writeframes(b''.join(frames))\n",
    "waveFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'wave' from '/home/visoc/anaconda3/envs/tf/lib/python3.6/wave.py'>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "wave, sr = librosa.load('file.wav', mono=True)\n",
    "features= librosa.feature.mfcc(wave, sr,n_mfcc=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00155109, -0.00390198, -0.00120344, ...,  0.00196864,\n",
       "        0.00147835,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = sklearn.preprocessing.scale(features, axis=1)\n",
    "features=np.pad(features,((0,0),(0,160-len(features[0]))),mode='constant', constant_values=0)\n",
    "f=np.matrix.transpose(np.array([features]),[0,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=model.predict_classes(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Sequential.get_config of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f4076c35128>>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['cuatro']], dtype='<U6')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(np.eye(10)[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=class_to_integer_encoded(label[0]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['seis'], dtype='<U6')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.inverse_transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential()\n",
    "#model.add(tf.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.RNN(_units, input_shape=(time_steps,n_inputs)))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.layers.Dense(n_class, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
