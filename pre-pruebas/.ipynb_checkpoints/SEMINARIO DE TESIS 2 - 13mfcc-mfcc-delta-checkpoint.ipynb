{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importanción de librerías "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de ficheros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función se encarga de generar un archivo txt de manera que este contenga 2 elementos por fila ('name_file','etiqueta') de esta manera permitirá poder entrenar la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "def generate_file_data(dir,name):\n",
    "    directory=dir\n",
    "    #el nombre de los archivos posee el primer dígito en el nombre de esta forma permitirá etiquetarlos.\n",
    "    a={'0':'cero','1':'uno','2':'dos','3':'tres','4':'cuatro','5':'cinco','6':'seis','7':'siete','8':'ocho','9':'nueve'}\n",
    "    da=os.listdir(directory)\n",
    "    # ordena los archivos\n",
    "    da.sort()\n",
    "    file = open(dir+name+'.txt',\"w\")\n",
    "    for filename in da:\n",
    "        if '.wav' in filename:\n",
    "            file.write(filename+','+a[filename[0]]+'\\n')\n",
    "    file.close() \n",
    "    # genera el fichero\n",
    "    with open(directory+'/'+name+'.txt') as f:\n",
    "        read_data = f.read()\n",
    "        f.closed\n",
    "    read_data=read_data.split('\\n')\n",
    "    read_data=read_data[0:len(read_data)-1]\n",
    "    return read_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding words with One Hot Encoding\n",
    "En esta sección se usará one hot encoding para representar las palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "vocabulary_words=np.array(['cero','uno','dos','tres','cuatro','cinco','seis','siete','ocho','nueve'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore',categories='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories='auto',\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "       n_values=None, sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder.fit(X=vocabulary_words.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['cero', 'cinco', 'cuatro', 'dos', 'nueve', 'ocho', 'seis', 'siete',\n",
       "        'tres', 'uno'], dtype='<U6')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=onehot_encoder.transform(vocabulary_words.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['cero'],\n",
       "       ['uno'],\n",
       "       ['dos'],\n",
       "       ['tres'],\n",
       "       ['cuatro'],\n",
       "       ['cinco'],\n",
       "       ['seis'],\n",
       "       ['siete'],\n",
       "       ['ocho'],\n",
       "       ['nueve']], dtype='<U6')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder.inverse_transform(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se muestran las funciones para codificar y decodificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x):# tomará un array de string y lo transformada a encode\n",
    "    return onehot_encoder.transform(x.reshape(-1,1)).toarray()\n",
    "def decode(x):\n",
    "    return onehot_encoder.inverse_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=encode(np.array(['uno','dos']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['uno'],\n",
       "       ['dos']], dtype='<U6')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_features(DIR,list_dir,mean,delta):\n",
    "    mfccd_audios=[]\n",
    "    for dir in list_dir:\n",
    "        wave, sr = librosa.load(DIR+dir, mono=True,sr=16000)\n",
    "        features= librosa.feature.mfcc(wave, sr,n_mfcc=13)\n",
    "        try:\n",
    "            features=np.pad(features,((0,0),(0,110-len(features[0]))),mode='constant', constant_values=0)\n",
    "        except OSError as err:\n",
    "            print(dir)\n",
    "        if delta == True:\n",
    "            featuresdelta=librosa.feature.delta(features)\n",
    "        if mean == True:\n",
    "            features=sklearn.preprocessing.scale(features)\n",
    "        mfccd_audios.append(np.concatenate((features, featuresdelta), axis=0))\n",
    "        \n",
    "    mfccd_audios=np.array(mfccd_audios)\n",
    "    return mfccd_audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(dir,name,mean,delta):\n",
    "    file = open(dir+name)\n",
    "    f=file.read()\n",
    "    file.close()\n",
    "    f=f.split('\\n')\n",
    "    f=f[0:len(f)-1]\n",
    "    labels=[]\n",
    "    names_audios=[]\n",
    "    for i in f:\n",
    "        j=i.split(',')\n",
    "        names_audios.append(j[0])\n",
    "        labels.append(j[1])\n",
    "    labels=np.array(labels)\n",
    "    onehot= encode(labels)\n",
    "    mfcc=mfcc_features(dir,names_audios,mean,delta)\n",
    "    print(name+' OK')\n",
    "    return mfcc,onehot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    def __init__(self,data):\n",
    "        self.i=0#para el shuffle\n",
    "        self.data_dir=data\n",
    "        self.shuffle=None\n",
    "        self.dir_training=data+'/training/'\n",
    "        self.dir_test=data+'/test/'\n",
    "        self.training_set=None\n",
    "        self.test_set=None\n",
    "    def split_dataset(self):\n",
    "        if os.path.exists(self.dir_training+'training.txt')==False:\n",
    "            generate_file_data(self.dir_training,name='training')\n",
    "        if os.path.exists(self.dir_training+'test.txt')==False:\n",
    "            generate_file_data(self.dir_test,name='test')\n",
    "        print('loadfiles')\n",
    "    def prepare(self,mean,delta):\n",
    "        self.training_set=prepare_data(self.dir_training,'training.txt',mean,delta)\n",
    "        self.test_set=prepare_data(self.dir_test,'test.txt',mean,delta)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loadfiles\n"
     ]
    }
   ],
   "source": [
    "d=dataset('data')\n",
    "d.split_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training.txt OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.txt OK\n"
     ]
    }
   ],
   "source": [
    "d.prepare(mean=False,delta=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red neuronal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se definen los distintos modelos a aplicar en este seminario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se dividen los conjuntos\n",
    "trainX, trainY = d.training_set[0],d.training_set[1]\n",
    "testX, testY = d.test_set[0],d.test_set[1]\n",
    "trainX=np.matrix.transpose(trainX,[0,2,1])\n",
    "testX=np.matrix.transpose(testX,[0,2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A continuación mostramos un elemento del training y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 110)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 26, 110)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.47886929e+02, -5.12919733e+02, -4.99292312e+02, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 2.10888556e+01,  5.03670836e+01,  6.13104118e+01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 1.00847706e+01,  1.38455019e+01,  1.39460105e+01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       ...,\n",
       "       [ 1.03480394e+00,  1.03480394e+00,  1.03480394e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-6.07707637e-01, -6.07707637e-01, -6.07707637e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 3.06914671e-01,  3.06914671e-01,  3.06914671e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.15955778e+02, -5.06970959e+02, -4.96018059e+02, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 4.53158084e-01,  1.27755327e+01,  2.62601550e+01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 4.40423351e-01,  1.17358671e+01,  2.04444784e+01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       ...,\n",
       "       [ 4.62477042e-01,  4.62477042e-01,  4.62477042e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 9.55215444e-01,  9.55215444e-01,  9.55215444e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 4.75798914e-01,  4.75798914e-01,  4.75798914e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de prueba\n",
    "A continuación presentamos 4 modelos que serán entrenados para el reconocimiento de voz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_simple(name,n_units=128,time_steps=110,n_inputs=26,batch_size=10,n_epochs=400):\n",
    "    n_class=10\n",
    "    dir='Models/Model_'\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.SimpleRNN(128, input_shape=(time_steps,n_inputs)))\n",
    "    model.add(tf.layers.Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    timei=time.time()\n",
    "    history=model.fit(trainX,trainY,batch_size=batch_size,epochs=n_epochs,validation_data=[testX,testY])\n",
    "    timef=time.time()\n",
    "    if os.path.exists(dir+name) == False:\n",
    "        os.mkdir(dir+name)\n",
    "    model.save(dir+name+'/'+name)\n",
    "    t=timef-timei\n",
    "    file = open(dir+name+'/'+name+'_time.txt',\"w\")\n",
    "    file.write(str(t))\n",
    "    file.close()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_simple(name,n_units=128,time_steps=110,n_inputs=26,batch_size=10,n_epochs=400):\n",
    "    n_class=10\n",
    "    dir='Models/Model_'\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(n_units, input_shape=(time_steps,n_inputs)))\n",
    "    model.add(tf.layers.Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    timei=time.time()\n",
    "    history=model.fit(trainX,trainY,batch_size=batch_size,epochs=n_epochs,validation_data=[testX,testY])\n",
    "    timef=time.time()\n",
    "    if os.path.exists(dir+name) == False:\n",
    "        os.mkdir(dir+name)\n",
    "    model.save(dir+name+'/'+name)\n",
    "    t=timef-timei\n",
    "    file = open(dir+name+'/'+name+'_time.txt',\"w\")\n",
    "    file.write(str(t))\n",
    "    file.close()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_with_Dropout(name,n_units=128,time_steps=110,n_inputs=26,batch_size=10,n_epochs=400,dropout=0.5):\n",
    "    n_class=10\n",
    "    dir='Models/Model_'\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(n_units, input_shape=(time_steps,n_inputs)))\n",
    "    model.add(tf.layers.Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    timei=time.time()\n",
    "    history=model.fit(trainX,trainY,batch_size=batch_size,epochs=n_epochs,validation_data=[testX,testY])\n",
    "    timef=time.time()\n",
    "    if os.path.exists(dir+name) == False:\n",
    "        os.mkdir(dir+name)\n",
    "    model.save(dir+name+'/'+name)\n",
    "    t=timef-timei\n",
    "    file = open(dir+name+'/'+name+'_time.txt',\"w\")\n",
    "    file.write(str(t))\n",
    "    file.close()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_with_2layers_1D(name,dropout,n_units=13,time_steps=110,n_inputs=26,batch_size=10,n_epochs=400):\n",
    "    n_class=10\n",
    "    dir='Models/Model_'\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(n_units, input_shape=(time_steps,n_inputs),return_sequences=True))\n",
    "    #model.add(tf.keras.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
    "    model.add(tf.keras.layers.LSTM(n_units, input_shape=(time_steps,n_inputs)))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.layers.Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    timei=time.time()\n",
    "    history=model.fit(trainX,trainY,batch_size=batch_size,epochs=n_epochs,validation_data=[testX,testY])\n",
    "    timef=time.time()\n",
    "    if os.path.exists(dir+name) == False:\n",
    "        os.mkdir(dir+name)\n",
    "    model.save(dir+name+'/'+name)\n",
    "    t=timef-timei\n",
    "    file = open(dir+name+'/'+name+'_time.txt',\"w\")\n",
    "    file.write(str(t))\n",
    "    file.close()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting and saving modelo\n",
    "Se presentará una función que graficará los resultados y guardará el modelo y sus datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_saving(history,name):\n",
    "    dir='Models/Model_'\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Precision del Modelo')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Test'], loc='upper left')\n",
    "    plt.savefig(dir+name+'/prec')\n",
    "    plt.show()\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Perdida del modelo')\n",
    "    plt.ylabel('Perdida')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Test'], loc='upper left')\n",
    "    plt.savefig(dir+name+'/cost')\n",
    "    plt.show()\n",
    "    json.dump(history.history, open('Models/Model_'+name+'/'+name+'_history', 'w'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento \n",
    "Entrenaremos distintas con los modelos definidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/400\n",
      "240/240 [==============================] - 3s 12ms/step - loss: 2.3765 - acc: 0.0750 - val_loss: 2.3898 - val_acc: 0.0727\n",
      "Epoch 2/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3288 - acc: 0.1125 - val_loss: 2.3784 - val_acc: 0.1091\n",
      "Epoch 3/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2957 - acc: 0.1167 - val_loss: 2.3595 - val_acc: 0.0909\n",
      "Epoch 4/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.3173 - acc: 0.1542 - val_loss: 2.3558 - val_acc: 0.1000\n",
      "Epoch 5/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3212 - acc: 0.1083 - val_loss: 2.3335 - val_acc: 0.1000\n",
      "Epoch 6/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.3099 - acc: 0.1083 - val_loss: 2.3148 - val_acc: 0.1273\n",
      "Epoch 7/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2982 - acc: 0.1375 - val_loss: 2.3018 - val_acc: 0.1182\n",
      "Epoch 8/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2925 - acc: 0.1000 - val_loss: 2.3187 - val_acc: 0.1000\n",
      "Epoch 9/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2700 - acc: 0.1667 - val_loss: 2.3481 - val_acc: 0.0727\n",
      "Epoch 10/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2841 - acc: 0.1542 - val_loss: 2.3280 - val_acc: 0.1182\n",
      "Epoch 11/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2994 - acc: 0.1333 - val_loss: 2.3034 - val_acc: 0.1182\n",
      "Epoch 12/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2658 - acc: 0.1625 - val_loss: 2.3824 - val_acc: 0.1000\n",
      "Epoch 13/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.3140 - acc: 0.1083 - val_loss: 2.3121 - val_acc: 0.1091\n",
      "Epoch 14/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2780 - acc: 0.1167 - val_loss: 2.3006 - val_acc: 0.1000\n",
      "Epoch 15/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2810 - acc: 0.1167 - val_loss: 2.2887 - val_acc: 0.1182\n",
      "Epoch 16/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2734 - acc: 0.1542 - val_loss: 2.3221 - val_acc: 0.0909\n",
      "Epoch 17/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2989 - acc: 0.1500 - val_loss: 2.3283 - val_acc: 0.0818\n",
      "Epoch 18/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.3024 - acc: 0.1292 - val_loss: 2.3398 - val_acc: 0.1182\n",
      "Epoch 19/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2826 - acc: 0.1333 - val_loss: 2.3294 - val_acc: 0.1000\n",
      "Epoch 20/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2986 - acc: 0.1417 - val_loss: 2.3387 - val_acc: 0.1091\n",
      "Epoch 21/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2954 - acc: 0.1167 - val_loss: 2.3149 - val_acc: 0.0909\n",
      "Epoch 22/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2703 - acc: 0.1417 - val_loss: 2.3052 - val_acc: 0.1273\n",
      "Epoch 23/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2536 - acc: 0.1792 - val_loss: 2.4239 - val_acc: 0.1000\n",
      "Epoch 24/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.3682 - acc: 0.1083 - val_loss: 2.3499 - val_acc: 0.0818\n",
      "Epoch 25/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3295 - acc: 0.1083 - val_loss: 2.3947 - val_acc: 0.0909\n",
      "Epoch 26/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.3617 - acc: 0.0917 - val_loss: 2.3736 - val_acc: 0.1000\n",
      "Epoch 27/400\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.3834 - acc: 0.0875 - val_loss: 2.3291 - val_acc: 0.1273\n",
      "Epoch 28/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3785 - acc: 0.1208 - val_loss: 2.3559 - val_acc: 0.1182\n",
      "Epoch 29/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3899 - acc: 0.0917 - val_loss: 2.3901 - val_acc: 0.0727\n",
      "Epoch 30/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3485 - acc: 0.1208 - val_loss: 2.3811 - val_acc: 0.1091\n",
      "Epoch 31/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.4207 - acc: 0.1042 - val_loss: 2.3687 - val_acc: 0.0909\n",
      "Epoch 32/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.3609 - acc: 0.1000 - val_loss: 2.3645 - val_acc: 0.0545\n",
      "Epoch 33/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.3385 - acc: 0.1208 - val_loss: 2.3504 - val_acc: 0.1000\n",
      "Epoch 34/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.3328 - acc: 0.1417 - val_loss: 2.3617 - val_acc: 0.0909\n",
      "Epoch 35/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.3794 - acc: 0.0958 - val_loss: 2.3438 - val_acc: 0.1364\n",
      "Epoch 36/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.3637 - acc: 0.0750 - val_loss: 2.3497 - val_acc: 0.0545\n",
      "Epoch 37/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.3422 - acc: 0.1125 - val_loss: 2.3443 - val_acc: 0.0727\n",
      "Epoch 38/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.3727 - acc: 0.0833 - val_loss: 2.4146 - val_acc: 0.0636\n",
      "Epoch 39/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.3877 - acc: 0.0875 - val_loss: 2.3511 - val_acc: 0.0636\n",
      "Epoch 40/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.3648 - acc: 0.0958 - val_loss: 2.3585 - val_acc: 0.1091\n",
      "Epoch 41/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.3588 - acc: 0.1000 - val_loss: 2.4135 - val_acc: 0.0727\n",
      "Epoch 42/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.3834 - acc: 0.0958 - val_loss: 2.3487 - val_acc: 0.1364\n",
      "Epoch 43/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.3795 - acc: 0.0958 - val_loss: 2.3629 - val_acc: 0.1000\n",
      "Epoch 44/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.3387 - acc: 0.1417 - val_loss: 2.3893 - val_acc: 0.0909\n",
      "Epoch 45/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.3494 - acc: 0.1042 - val_loss: 2.3160 - val_acc: 0.0818\n",
      "Epoch 46/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.3103 - acc: 0.1208 - val_loss: 2.3082 - val_acc: 0.1545\n",
      "Epoch 47/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.3118 - acc: 0.0958 - val_loss: 2.3436 - val_acc: 0.0818\n",
      "Epoch 48/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.3062 - acc: 0.1000 - val_loss: 2.3024 - val_acc: 0.1273\n",
      "Epoch 49/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.3204 - acc: 0.1125 - val_loss: 2.3350 - val_acc: 0.1182\n",
      "Epoch 50/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.3102 - acc: 0.1208 - val_loss: 2.2921 - val_acc: 0.1545\n",
      "Epoch 51/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3039 - acc: 0.1375 - val_loss: 2.3420 - val_acc: 0.0818\n",
      "Epoch 52/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3179 - acc: 0.1125 - val_loss: 2.2945 - val_acc: 0.1182\n",
      "Epoch 53/400\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.3099 - acc: 0.1167 - val_loss: 2.3221 - val_acc: 0.1182\n",
      "Epoch 54/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3060 - acc: 0.0792 - val_loss: 2.3316 - val_acc: 0.1000\n",
      "Epoch 55/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3051 - acc: 0.1333 - val_loss: 2.3059 - val_acc: 0.0818\n",
      "Epoch 56/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3056 - acc: 0.1125 - val_loss: 2.3340 - val_acc: 0.1182\n",
      "Epoch 57/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2950 - acc: 0.0917 - val_loss: 2.3136 - val_acc: 0.1182\n",
      "Epoch 58/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.3014 - acc: 0.1292 - val_loss: 2.3213 - val_acc: 0.1000\n",
      "Epoch 59/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.3104 - acc: 0.1208 - val_loss: 2.2980 - val_acc: 0.1182\n",
      "Epoch 60/400\n",
      "180/240 [=====================>........] - ETA: 0s - loss: 2.2953 - acc: 0.1278"
     ]
    }
   ],
   "source": [
    "RNN=RNN_simple('RNNsimple13mfcc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_saving(RNN,'RNNsimple13mfcc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_SIMPLE=LSTM_simple(name='LSTM_13mfcc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_saving(LSTM_SIMPLE,name='LSTM_13mfcc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMD5=LSTM_with_Dropout('LSTM_Dropout5_mfcc13',dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_saving(LSTMD5,name='LSTM_Dropout5_mfcc13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMD8=LSTM_with_Dropout('LSTM_Dropout8_mfcc13',dropout=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_saving(LSTMD8,name='LSTM_Dropout8_mfcc13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM2_1=LSTM_with_2layers_1D('LSTM_2Layer1DDelta8',dropout=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_saving(LSTM2_1,name='LSTM_2Layer1D_13mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM2_1iter9005=LSTM_with_2layers_1D('LSTM_2Layer1D_13mfcc_Delta5iter900',dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_saving(LSTM2_1iter9005,name='LSTM_2Layer1D_13mfcc_Delta5iter900')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM2_1iter9008=LSTM_with_2layers_1D('LSTM_2Layer1D_13mfcc_Delta8iter900',dropout=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_saving(LSTM2_1iter9008,name='LSTM_2Layer1D_13mfcc_Delta8iter900')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(dir):\n",
    "    m=tf.keras.models.load_model(dir)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recording audios and predict them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8e68eb1c774a59a8b114ebe183cd9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Record', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "button1 = widgets.Button(description=\"Record\",)\n",
    "button2 = widgets.Button(description='Test')\n",
    "display(button)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    print(\"Button clicked.\")\n",
    "\n",
    "button1.on_click(on_button_clicked)\n",
    "button2.on_click(on_button_clicked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording...\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    " \n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 48000#44100\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 2\n",
    "WAVE_OUTPUT_FILENAME = \"file.wav\"\n",
    " \n",
    "audio = pyaudio.PyAudio()\n",
    " \n",
    "# start Recording\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                rate=RATE, input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "print (\"recording...\")\n",
    "frames = []\n",
    " \n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "print (\"finished recording\")\n",
    " \n",
    " \n",
    "# stop Recording\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    " \n",
    "waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "waveFile.setnchannels(CHANNELS)\n",
    "waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "waveFile.setframerate(RATE)\n",
    "waveFile.writeframes(b''.join(frames))\n",
    "waveFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'wave' from '/home/visoc/anaconda3/envs/tf/lib/python3.6/wave.py'>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "wave, sr = librosa.load('file.wav', mono=True)\n",
    "features= librosa.feature.mfcc(wave, sr,n_mfcc=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00155109, -0.00390198, -0.00120344, ...,  0.00196864,\n",
       "        0.00147835,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = sklearn.preprocessing.scale(features, axis=1)\n",
    "features=np.pad(features,((0,0),(0,160-len(features[0]))),mode='constant', constant_values=0)\n",
    "f=np.matrix.transpose(np.array([features]),[0,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=model.predict_classes(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Sequential.get_config of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f4076c35128>>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['cuatro']], dtype='<U6')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(np.eye(10)[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=class_to_integer_encoded(label[0]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['seis'], dtype='<U6')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.inverse_transform(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
