{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importanción de librerías "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de ficheros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función se encarga de generar un archivo txt de manera que este contenga 2 elementos por fila ('name_file','etiqueta') de esta manera permitirá poder entrenar la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "def generate_file_data(dir,name):\n",
    "    directory=dir\n",
    "    #el nombre de los archivos posee el primer dígito en el nombre de esta forma permitirá etiquetarlos.\n",
    "    a={'0':'cero','1':'uno','2':'dos','3':'tres','4':'cuatro','5':'cinco','6':'seis','7':'siete','8':'ocho','9':'nueve'}\n",
    "    da=os.listdir(directory)\n",
    "    # ordena los archivos\n",
    "    da.sort()\n",
    "    file = open(dir+name+'.txt',\"w\")\n",
    "    for filename in da:\n",
    "        if '.wav' in filename:\n",
    "            file.write(filename+','+a[filename[0]]+'\\n')\n",
    "    file.close() \n",
    "    # genera el fichero\n",
    "    with open(directory+'/'+name+'.txt') as f:\n",
    "        read_data = f.read()\n",
    "        f.closed\n",
    "    read_data=read_data.split('\\n')\n",
    "    read_data=read_data[0:len(read_data)-1]\n",
    "    return read_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding words with One Hot Encoding\n",
    "En esta sección se usará one hot encoding para representar las palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "vocabulary_words=np.array(['cero','uno','dos','tres','cuatro','cinco','seis','siete','ocho','nueve'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore',categories='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories='auto',\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "       n_values=None, sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder.fit(X=vocabulary_words.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['cero', 'cinco', 'cuatro', 'dos', 'nueve', 'ocho', 'seis', 'siete',\n",
       "        'tres', 'uno'], dtype='<U6')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=onehot_encoder.transform(vocabulary_words.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['cero'],\n",
       "       ['uno'],\n",
       "       ['dos'],\n",
       "       ['tres'],\n",
       "       ['cuatro'],\n",
       "       ['cinco'],\n",
       "       ['seis'],\n",
       "       ['siete'],\n",
       "       ['ocho'],\n",
       "       ['nueve']], dtype='<U6')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder.inverse_transform(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se muestran las funciones para codificar y decodificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x):# tomará un array de string y lo transformada a encode\n",
    "    return onehot_encoder.transform(x.reshape(-1,1)).toarray()\n",
    "def decode(x):\n",
    "    return onehot_encoder.inverse_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=encode(np.array(['uno','dos']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['uno'],\n",
       "       ['dos']], dtype='<U6')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_features(DIR,list_dir,mean,delta):\n",
    "    mfccd_audios=[]\n",
    "    for dir in list_dir:\n",
    "        wave, sr = librosa.load(DIR+dir, mono=True,sr=16000)\n",
    "        features= librosa.feature.mfcc(wave, sr,n_mfcc=13)\n",
    "        if delta == True:\n",
    "            features=librosa.feature.delta(features)\n",
    "        if mean == True:\n",
    "            features=sklearn.preprocessing.scale(features)\n",
    "        try:\n",
    "            features=np.pad(features,((0,0),(0,110-len(features[0]))),mode='constant', constant_values=0)\n",
    "        except OSError as err:\n",
    "            print(dir)\n",
    "        mfccd_audios.append(features)\n",
    "        #mfccd_audios.append(np.array([features[0],featuresdelta[0]]))\n",
    "    mfccd_audios=np.array(mfccd_audios)\n",
    "    return mfccd_audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(dir,name,mean,delta):\n",
    "    file = open(dir+name)\n",
    "    f=file.read()\n",
    "    file.close()\n",
    "    f=f.split('\\n')\n",
    "    f=f[0:len(f)-1]\n",
    "    labels=[]\n",
    "    names_audios=[]\n",
    "    for i in f:\n",
    "        j=i.split(',')\n",
    "        names_audios.append(j[0])\n",
    "        labels.append(j[1])\n",
    "    labels=np.array(labels)\n",
    "    onehot= encode(labels)\n",
    "    mfcc=mfcc_features(dir,names_audios,mean,delta)\n",
    "    print(name+' OK')\n",
    "    return mfcc,onehot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    def __init__(self,data):\n",
    "        self.i=0#para el shuffle\n",
    "        self.data_dir=data\n",
    "        self.shuffle=None\n",
    "        self.dir_training=data+'/training/'\n",
    "        self.dir_test=data+'/test/'\n",
    "        self.training_set=None\n",
    "        self.test_set=None\n",
    "    def split_dataset(self):\n",
    "        if os.path.exists(self.dir_training+'training.txt')==False:\n",
    "            generate_file_data(self.dir_training,name='training')\n",
    "        if os.path.exists(self.dir_training+'test.txt')==False:\n",
    "            generate_file_data(self.dir_test,name='test')\n",
    "        print('loadfiles')\n",
    "    def prepare(self,mean,delta):\n",
    "        self.training_set=prepare_data(self.dir_training,'training.txt',mean,delta)\n",
    "        self.test_set=prepare_data(self.dir_test,'test.txt',mean,delta)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loadfiles\n"
     ]
    }
   ],
   "source": [
    "d=dataset('data')\n",
    "d.split_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training.txt OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.txt OK\n"
     ]
    }
   ],
   "source": [
    "d.prepare(mean=False,delta=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red neuronal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se definen los distintos modelos a aplicar en este seminario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se dividen los conjuntos\n",
    "trainX, trainY = d.training_set[0],d.training_set[1]\n",
    "testX, testY = d.test_set[0],d.test_set[1]\n",
    "trainX=np.matrix.transpose(trainX,[0,2,1])\n",
    "testX=np.matrix.transpose(testX,[0,2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A continuación mostramos un elemento del training y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.62005689, -6.46370755,  5.88644224, ...,  1.03480394,\n",
       "        -0.60770764,  0.30691467],\n",
       "       [ 8.62005689, -6.46370755,  5.88644224, ...,  1.03480394,\n",
       "        -0.60770764,  0.30691467],\n",
       "       [ 8.62005689, -6.46370755,  5.88644224, ...,  1.03480394,\n",
       "        -0.60770764,  0.30691467],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 110, 13)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.62005689, -6.46370755,  5.88644224, ...,  1.03480394,\n",
       "        -0.60770764,  0.30691467],\n",
       "       [ 8.62005689, -6.46370755,  5.88644224, ...,  1.03480394,\n",
       "        -0.60770764,  0.30691467],\n",
       "       [ 8.62005689, -6.46370755,  5.88644224, ...,  1.03480394,\n",
       "        -0.60770764,  0.30691467],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.61172524,  3.15274442, -0.62109424, ...,  0.46247704,\n",
       "         0.95521544,  0.47579891],\n",
       "       [ 7.61172524,  3.15274442, -0.62109424, ...,  0.46247704,\n",
       "         0.95521544,  0.47579891],\n",
       "       [ 7.61172524,  3.15274442, -0.62109424, ...,  0.46247704,\n",
       "         0.95521544,  0.47579891],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de prueba\n",
    "A continuación presentamos 4 modelos que serán entrenados para el reconocimiento de voz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_simple(name,n_units=128,time_steps=110,n_inputs=13,batch_size=10,n_epochs=400):\n",
    "    n_class=10\n",
    "    dir='Models/Model_'\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.SimpleRNN(128, input_shape=(time_steps,n_inputs)))\n",
    "    model.add(tf.layers.Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    timei=time.time()\n",
    "    history=model.fit(trainX,trainY,batch_size=batch_size,epochs=n_epochs,validation_data=[testX,testY])\n",
    "    timef=time.time()\n",
    "    if os.path.exists(dir+name) == False:\n",
    "        os.mkdir(dir+name)\n",
    "    model.save(dir+name+'/'+name)\n",
    "    t=timef-timei\n",
    "    file = open(dir+name+'/'+name+'_time.txt',\"w\")\n",
    "    file.write(str(t))\n",
    "    file.close()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_simple(name,n_units=128,time_steps=110,n_inputs=13,batch_size=10,n_epochs=400):\n",
    "    n_class=10\n",
    "    dir='Models/Model_'\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(n_units, input_shape=(time_steps,n_inputs)))\n",
    "    model.add(tf.layers.Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    timei=time.time()\n",
    "    history=model.fit(trainX,trainY,batch_size=batch_size,epochs=n_epochs,validation_data=[testX,testY])\n",
    "    timef=time.time()\n",
    "    if os.path.exists(dir+name) == False:\n",
    "        os.mkdir(dir+name)\n",
    "    model.save(dir+name+'/'+name)\n",
    "    t=timef-timei\n",
    "    file = open(dir+name+'/'+name+'_time.txt',\"w\")\n",
    "    file.write(str(t))\n",
    "    file.close()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_with_Dropout(name,n_units=128,time_steps=110,n_inputs=13,batch_size=10,n_epochs=400,dropout=0.5):\n",
    "    n_class=10\n",
    "    dir='Models/Model_'\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(n_units, input_shape=(time_steps,n_inputs)))\n",
    "    model.add(tf.layers.Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    timei=time.time()\n",
    "    history=model.fit(trainX,trainY,batch_size=batch_size,epochs=n_epochs,validation_data=[testX,testY])\n",
    "    timef=time.time()\n",
    "    if os.path.exists(dir+name) == False:\n",
    "        os.mkdir(dir+name)\n",
    "    model.save(dir+name+'/'+name)\n",
    "    t=timef-timei\n",
    "    file = open(dir+name+'/'+name+'_time.txt',\"w\")\n",
    "    file.write(str(t))\n",
    "    file.close()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_with_2layers_1D(name,dropout,n_units=13,time_steps=110,n_inputs=20,batch_size=10,n_epochs=400):\n",
    "    n_class=10\n",
    "    dir='Models/Model_'\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(n_units, input_shape=(time_steps,n_inputs),return_sequences=True))\n",
    "    #model.add(tf.keras.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
    "    model.add(tf.keras.layers.LSTM(n_units, input_shape=(time_steps,n_inputs)))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.layers.Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    timei=time.time()\n",
    "    history=model.fit(trainX,trainY,batch_size=batch_size,epochs=n_epochs,validation_data=[testX,testY])\n",
    "    timef=time.time()\n",
    "    if os.path.exists(dir+name) == False:\n",
    "        os.mkdir(dir+name)\n",
    "    model.save(dir+name+'/'+name)\n",
    "    t=timef-timei\n",
    "    file = open(dir+name+'/'+name+'_time.txt',\"w\")\n",
    "    file.write(str(t))\n",
    "    file.close()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting and saving modelo\n",
    "Se presentará una función que graficará los resultados y guardará el modelo y sus datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_saving(history,name):\n",
    "    dir='Models/Model_'\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Precision del Modelo')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Test'], loc='upper left')\n",
    "    plt.savefig(dir+name+'/prec')\n",
    "    plt.show()\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Perdida del modelo')\n",
    "    plt.ylabel('Perdida')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Test'], loc='upper left')\n",
    "    plt.savefig(dir+name+'/cost')\n",
    "    plt.show()\n",
    "    json.dump(history.history, open('Models/Model_'+name+'/'+name+'_history', 'w'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento \n",
    "Entrenaremos distintas con los modelos definidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/400\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.3527 - acc: 0.1042 - val_loss: 2.2825 - val_acc: 0.1273\n",
      "Epoch 2/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3536 - acc: 0.1208 - val_loss: 2.4042 - val_acc: 0.1000\n",
      "Epoch 3/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.3973 - acc: 0.0833 - val_loss: 2.3855 - val_acc: 0.0455\n",
      "Epoch 4/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.3632 - acc: 0.1292 - val_loss: 2.3634 - val_acc: 0.1364\n",
      "Epoch 5/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.3862 - acc: 0.1000 - val_loss: 2.3028 - val_acc: 0.1455\n",
      "Epoch 6/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3487 - acc: 0.0958 - val_loss: 2.3192 - val_acc: 0.1364\n",
      "Epoch 7/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.3397 - acc: 0.1083 - val_loss: 2.3377 - val_acc: 0.1182\n",
      "Epoch 8/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3522 - acc: 0.0958 - val_loss: 2.3067 - val_acc: 0.1273\n",
      "Epoch 9/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3362 - acc: 0.1167 - val_loss: 2.3450 - val_acc: 0.1091\n",
      "Epoch 10/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.3407 - acc: 0.1000 - val_loss: 2.3215 - val_acc: 0.1091\n",
      "Epoch 11/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.3360 - acc: 0.0708 - val_loss: 2.3495 - val_acc: 0.0818\n",
      "Epoch 12/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.3020 - acc: 0.1042 - val_loss: 2.3670 - val_acc: 0.1000\n",
      "Epoch 13/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.3697 - acc: 0.0833 - val_loss: 2.3287 - val_acc: 0.0818\n",
      "Epoch 14/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.3323 - acc: 0.1167 - val_loss: 2.3669 - val_acc: 0.1364\n",
      "Epoch 15/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3870 - acc: 0.0792 - val_loss: 2.3557 - val_acc: 0.0818\n",
      "Epoch 16/400\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.3486 - acc: 0.0750 - val_loss: 2.3480 - val_acc: 0.0818\n",
      "Epoch 17/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3390 - acc: 0.1000 - val_loss: 2.3654 - val_acc: 0.1273\n",
      "Epoch 18/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3619 - acc: 0.0958 - val_loss: 2.3901 - val_acc: 0.1000\n",
      "Epoch 19/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3673 - acc: 0.1125 - val_loss: 2.4493 - val_acc: 0.0636\n",
      "Epoch 20/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3415 - acc: 0.1125 - val_loss: 2.3226 - val_acc: 0.1273\n",
      "Epoch 21/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3546 - acc: 0.1000 - val_loss: 2.3979 - val_acc: 0.0727\n",
      "Epoch 22/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3581 - acc: 0.1167 - val_loss: 2.3783 - val_acc: 0.0727\n",
      "Epoch 23/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3241 - acc: 0.0958 - val_loss: 2.3601 - val_acc: 0.1545\n",
      "Epoch 24/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3419 - acc: 0.0917 - val_loss: 2.3970 - val_acc: 0.0727\n",
      "Epoch 25/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3696 - acc: 0.1083 - val_loss: 2.3199 - val_acc: 0.1545\n",
      "Epoch 26/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.3507 - acc: 0.0875 - val_loss: 2.3454 - val_acc: 0.0818\n",
      "Epoch 27/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3638 - acc: 0.0667 - val_loss: 2.4156 - val_acc: 0.0545\n",
      "Epoch 28/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3625 - acc: 0.0833 - val_loss: 2.3569 - val_acc: 0.0909\n",
      "Epoch 29/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3911 - acc: 0.0542 - val_loss: 2.3319 - val_acc: 0.1182\n",
      "Epoch 30/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3127 - acc: 0.1292 - val_loss: 2.3351 - val_acc: 0.1273\n",
      "Epoch 31/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3774 - acc: 0.1042 - val_loss: 2.4389 - val_acc: 0.0909\n",
      "Epoch 32/400\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.3432 - acc: 0.0875 - val_loss: 2.3591 - val_acc: 0.0818\n",
      "Epoch 33/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3031 - acc: 0.1125 - val_loss: 2.4350 - val_acc: 0.1000\n",
      "Epoch 34/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2907 - acc: 0.1250 - val_loss: 2.3989 - val_acc: 0.0818\n",
      "Epoch 35/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2885 - acc: 0.1375 - val_loss: 2.4190 - val_acc: 0.0818\n",
      "Epoch 36/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2748 - acc: 0.1250 - val_loss: 2.4138 - val_acc: 0.0909\n",
      "Epoch 37/400\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.2759 - acc: 0.1417 - val_loss: 2.4252 - val_acc: 0.0727\n",
      "Epoch 38/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2661 - acc: 0.1583 - val_loss: 2.4367 - val_acc: 0.0818\n",
      "Epoch 39/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.2752 - acc: 0.1375 - val_loss: 2.4138 - val_acc: 0.0909\n",
      "Epoch 40/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2777 - acc: 0.1375 - val_loss: 2.4181 - val_acc: 0.0818\n",
      "Epoch 41/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2686 - acc: 0.1458 - val_loss: 2.4347 - val_acc: 0.0727\n",
      "Epoch 42/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2948 - acc: 0.1250 - val_loss: 2.4065 - val_acc: 0.0909\n",
      "Epoch 43/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2906 - acc: 0.1500 - val_loss: 2.4176 - val_acc: 0.0636\n",
      "Epoch 44/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2822 - acc: 0.1208 - val_loss: 2.4333 - val_acc: 0.0636\n",
      "Epoch 45/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.2690 - acc: 0.1417 - val_loss: 2.4137 - val_acc: 0.0636\n",
      "Epoch 46/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2703 - acc: 0.1417 - val_loss: 2.3993 - val_acc: 0.0636\n",
      "Epoch 47/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2770 - acc: 0.1208 - val_loss: 2.4310 - val_acc: 0.0636\n",
      "Epoch 48/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2881 - acc: 0.1250 - val_loss: 2.4135 - val_acc: 0.0727\n",
      "Epoch 49/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2910 - acc: 0.1458 - val_loss: 2.4461 - val_acc: 0.0818\n",
      "Epoch 50/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2851 - acc: 0.1333 - val_loss: 2.4209 - val_acc: 0.0636\n",
      "Epoch 51/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.2681 - acc: 0.1542 - val_loss: 2.4218 - val_acc: 0.0545\n",
      "Epoch 52/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2711 - acc: 0.1542 - val_loss: 2.4269 - val_acc: 0.0636\n",
      "Epoch 53/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2822 - acc: 0.1292 - val_loss: 2.4181 - val_acc: 0.0636\n",
      "Epoch 54/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2741 - acc: 0.1458 - val_loss: 2.4172 - val_acc: 0.0727\n",
      "Epoch 55/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2663 - acc: 0.1167 - val_loss: 2.4228 - val_acc: 0.0818\n",
      "Epoch 56/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2678 - acc: 0.1375 - val_loss: 2.4259 - val_acc: 0.0545\n",
      "Epoch 57/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2656 - acc: 0.1417 - val_loss: 2.4338 - val_acc: 0.0818\n",
      "Epoch 58/400\n",
      " 60/240 [======>.......................] - ETA: 1s - loss: 2.2039 - acc: 0.1833"
     ]
    }
   ],
   "source": [
    "RNN=RNN_simple('RNNsimple13mfcc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_saving(RNN,'RNNsimple13mfcc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_SIMPLE=LSTM_simple(name='LSTM_13mfcc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_saving(LSTM_SIMPLE,name='LSTM_13mfcc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMD5=LSTM_with_Dropout('LSTM_Dropout5_mfcc13',dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_saving(LSTMD5,name='LSTM_Dropout5_mfcc13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMD8=LSTM_with_Dropout('LSTM_Dropout8_mfcc13',dropout=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_saving(LSTMD8,name='LSTM_Dropout8_mfcc13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM2_1=LSTM_with_2layers_1D('LSTM_2Layer1DDelta8',dropout=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_saving(LSTM2_1,name='LSTM_2Layer1D_13mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM2_1iter900=LSTM_with_2layers_1D('LSTM_2Layer1D_13mfcc_Delta8',dropout=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM2_1iter900=LSTM_with_2layers_1D('LSTM_2Layer1D_13mfcc_Delta8',dropout=0.8)\n",
    "plot_and_saving(LSTM2_1,name='LSTM_2Layer1D_13mfcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(dir):\n",
    "    m=tf.keras.models.load_model(dir)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recording audios and predict them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8e68eb1c774a59a8b114ebe183cd9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Record', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "button1 = widgets.Button(description=\"Record\",)\n",
    "button2 = widgets.Button(description='Test')\n",
    "display(button)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    print(\"Button clicked.\")\n",
    "\n",
    "button1.on_click(on_button_clicked)\n",
    "button2.on_click(on_button_clicked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording...\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    " \n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 48000#44100\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 2\n",
    "WAVE_OUTPUT_FILENAME = \"file.wav\"\n",
    " \n",
    "audio = pyaudio.PyAudio()\n",
    " \n",
    "# start Recording\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                rate=RATE, input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "print (\"recording...\")\n",
    "frames = []\n",
    " \n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "print (\"finished recording\")\n",
    " \n",
    " \n",
    "# stop Recording\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    " \n",
    "waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "waveFile.setnchannels(CHANNELS)\n",
    "waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "waveFile.setframerate(RATE)\n",
    "waveFile.writeframes(b''.join(frames))\n",
    "waveFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'wave' from '/home/visoc/anaconda3/envs/tf/lib/python3.6/wave.py'>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "wave, sr = librosa.load('file.wav', mono=True)\n",
    "features= librosa.feature.mfcc(wave, sr,n_mfcc=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00155109, -0.00390198, -0.00120344, ...,  0.00196864,\n",
       "        0.00147835,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = sklearn.preprocessing.scale(features, axis=1)\n",
    "features=np.pad(features,((0,0),(0,160-len(features[0]))),mode='constant', constant_values=0)\n",
    "f=np.matrix.transpose(np.array([features]),[0,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=model.predict_classes(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Sequential.get_config of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f4076c35128>>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['cuatro']], dtype='<U6')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(np.eye(10)[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=class_to_integer_encoded(label[0]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['seis'], dtype='<U6')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.inverse_transform(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
