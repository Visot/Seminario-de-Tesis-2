{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUDIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "from python_speech_features import mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wavfile(wavfile):\n",
    "    rate, data = wav.read(wavfile)\n",
    "    name = os.path.splitext(os.path.basename(wavfile))[0]#obtenemos el nombre del archivo\n",
    "    return rate, data, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class audio:# esta clase tendrá los principales metodos para tratar el audio\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=load_wavfile('data/1.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, array([201, 225, 118, ..., 224, 173,  94], dtype=int16), '1')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audiofile_to_input_vector(audio_filename, numcep, numcontext):\n",
    "    #cargado de la data\n",
    "    fs, audio = wav.read(audio_filename)\n",
    "    # función mfcc para obtener los coeficientes mfcc\n",
    "    features = mfcc(audio, samplerate=fs, numcep=numcep)\n",
    "    # mantenemos las características cada 2 segundos\n",
    "    features = features[::2]\n",
    "\n",
    "    # For each time slice of the training set, we need to copy the context this makes\n",
    "    # the numcep dimensions vector into a numcep + 2*numcep*numcontext dimensions\n",
    "    # because of:\n",
    "    #  - numcep dimensions for the current mfcc feature set\n",
    "    #  - numcontext*numcep dimensions for each of the past and future (x2) mfcc feature set\n",
    "    # => so numcep + 2*numcontext*numcep\n",
    "    train_inputs = np.array([], np.float32)\n",
    "    train_inputs.resize((features.shape[0], numcep + 2 * numcep * numcontext))\n",
    "\n",
    "    # Prepare pre-fix post fix context\n",
    "    empty_mfcc = np.array([])\n",
    "    empty_mfcc.resize((numcep))\n",
    "\n",
    "    # Prepare train_inputs with past and future contexts\n",
    "    time_slices = range(train_inputs.shape[0])\n",
    "    context_past_min = time_slices[0] + numcontext\n",
    "    context_future_max = time_slices[-1] - numcontext\n",
    "    for time_slice in time_slices:\n",
    "        # Reminder: array[start:stop:step]\n",
    "        # slices from indice |start| up to |stop| (not included), every |step|\n",
    "\n",
    "        # Add empty context data of the correct size to the start and end\n",
    "        # of the MFCC feature matrix\n",
    "\n",
    "        # Pick up to numcontext time slices in the past, and complete with empty\n",
    "        # mfcc features\n",
    "        need_empty_past = max(0, (context_past_min - time_slice))\n",
    "        empty_source_past = list(empty_mfcc for empty_slots in range(need_empty_past))\n",
    "        data_source_past = features[max(0, time_slice - numcontext):time_slice]\n",
    "        assert(len(empty_source_past) + len(data_source_past) == numcontext)\n",
    "\n",
    "        # Pick up to numcontext time slices in the future, and complete with empty\n",
    "        # mfcc features\n",
    "        need_empty_future = max(0, (time_slice - context_future_max))\n",
    "        empty_source_future = list(empty_mfcc for empty_slots in range(need_empty_future))\n",
    "        data_source_future = features[time_slice + 1:time_slice + numcontext + 1]\n",
    "        assert(len(empty_source_future) + len(data_source_future) == numcontext)\n",
    "\n",
    "        if need_empty_past:\n",
    "            past = np.concatenate((empty_source_past, data_source_past))\n",
    "        else:\n",
    "            past = data_source_past\n",
    "\n",
    "        if need_empty_future:\n",
    "            future = np.concatenate((data_source_future, empty_source_future))\n",
    "        else:\n",
    "            future = data_source_future\n",
    "\n",
    "        past = np.reshape(past, numcontext * numcep)\n",
    "        now = features[time_slice]\n",
    "        future = np.reshape(future, numcontext * numcep)\n",
    "\n",
    "        train_inputs[time_slice] = np.concatenate((past, now, future))\n",
    "        assert(len(train_inputs[time_slice]) == numcep + 2 * numcep * numcontext)\n",
    "\n",
    "    # Scale/standardize the inputs\n",
    "    # This can be done more efficiently in the TensorFlow graph\n",
    "    train_inputs = (train_inputs - np.mean(train_inputs)) / np.std(train_inputs)\n",
    "return train_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data(txt_files, wav_files, n_input, n_context):\n",
    "    #convertirá la data audio a MFCC arrray y text a un array númerico\n",
    "    audio = []\n",
    "    audio_len = []\n",
    "    transcript = []\n",
    "    transcript_len = []\n",
    "\n",
    "    for txt_file, wav_file in zip(txt_files, wav_files):\n",
    "        # load audio and convert to features\n",
    "        audio_data = audiofile_to_input_vector(wav_file, n_input, n_context)\n",
    "        audio_data = audio_data.astype('float32')\n",
    "\n",
    "        audio.append(audio_data)\n",
    "        audio_len.append(np.int32(len(audio_data)))\n",
    "\n",
    "        # load text transcription and convert to numerical array\n",
    "        target = normalize_txt_file(txt_file)\n",
    "        target = text_to_char_array(target)\n",
    "        transcript.append(target)\n",
    "        transcript_len.append(len(target))\n",
    "\n",
    "    audio = np.asarray(audio)\n",
    "    audio_len = np.asarray(audio_len)\n",
    "    transcript = np.asarray(transcript)\n",
    "    transcript_len = np.asarray(transcript_len)\n",
    "return audio, audio_len, transcript, transcript_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import unicodedata\n",
    "import codecs\n",
    "import re\n",
    "import tensorflow as tf\n",
    "\n",
    "# Constants\n",
    "SPACE_TOKEN = '<space>'\n",
    "SPACE_INDEX = 0\n",
    "FIRST_INDEX = ord('a') - 1  # 0 is reserved to space\n",
    "\n",
    "def normalize_txt_file(txt_file, remove_apostrophe=True):\n",
    "    #Dado una dirección se normalizará el texto\n",
    "    with codecs.open(txt_file, encoding=\"utf-8\") as open_txt_file:# abre el archivo codificado en un encoding.\n",
    "        return normalize_text(open_txt_file.read(), remove_apostrophe=remove_apostrophe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_text(original, remove_apostrophe=True):\n",
    "    \"\"\"\n",
    "    Given a Python string ``original``, remove unsupported characters.\n",
    "    The only supported characters are letters and apostrophes.\n",
    "    \"\"\"\n",
    "    # convert any unicode characters to ASCII equivalent\n",
    "    # then ignore anything else and decode to a string\n",
    "    result = unicodedata.normalize(\"NFKD\", original).encode(\"ascii\", \"ignore\").decode()\n",
    "    if remove_apostrophe:\n",
    "        # remove apostrophes to keep contractions together\n",
    "        result = result.replace(\"'\", \"\")\n",
    "    # return lowercase alphabetic characters and apostrophes (if still present)\n",
    "    return re.sub(\"[^a-zA-Z']+\", ' ', result).strip().lower()\n",
    "\n",
    "\n",
    "def text_to_char_array(original):\n",
    "    \"\"\"\n",
    "    Given a Python string ``original``, map characters\n",
    "    to integers and return a numpy array representing the processed string.\n",
    "    This function has been modified from Mozilla DeepSpeech:\n",
    "    https://github.com/mozilla/DeepSpeech/blob/master/util/text.py\n",
    "    # This Source Code Form is subject to the terms of the Mozilla Public\n",
    "    # License, v. 2.0. If a copy of the MPL was not distributed with this\n",
    "    # file, You can obtain one at http://mozilla.org/MPL/2.0/.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create list of sentence's words w/spaces replaced by ''\n",
    "    result = original.replace(' ', '  ')\n",
    "    result = result.split(' ')\n",
    "\n",
    "    # Tokenize words into letters adding in SPACE_TOKEN where required\n",
    "    result = np.hstack([SPACE_TOKEN if xt == '' else list(xt) for xt in result])\n",
    "\n",
    "    # Return characters mapped into indicies\n",
    "    return np.asarray([SPACE_INDEX if xt == SPACE_TOKEN else ord(xt) - FIRST_INDEX for xt in result])\n",
    "\n",
    "\n",
    "def sparse_tuple_from(sequences, dtype=np.int32):\n",
    "    \"\"\"\n",
    "    Create a sparse representention of ``sequences``.\n",
    "    Args:\n",
    "        sequences: a list of lists of type dtype where each element is a sequence\n",
    "    Returns:\n",
    "        A tuple with (indices, values, shape)\n",
    "    This function has been modified from Mozilla DeepSpeech:\n",
    "    https://github.com/mozilla/DeepSpeech/blob/master/util/text.py\n",
    "    # This Source Code Form is subject to the terms of the Mozilla Public\n",
    "    # License, v. 2.0. If a copy of the MPL was not distributed with this\n",
    "    # file, You can obtain one at http://mozilla.org/MPL/2.0/.\n",
    "    \"\"\"\n",
    "\n",
    "    indices = []\n",
    "    values = []\n",
    "\n",
    "    for n, seq in enumerate(sequences):\n",
    "        indices.extend(zip([n] * len(seq), range(len(seq))))\n",
    "        values.extend(seq)\n",
    "\n",
    "    indices = np.asarray(indices, dtype=np.int64)\n",
    "    values = np.asarray(values, dtype=dtype)\n",
    "    shape = np.asarray([len(sequences), indices.max(0)[1] + 1], dtype=np.int64)\n",
    "\n",
    "    # return tf.SparseTensor(indices=indices, values=values, shape=shape)\n",
    "    return indices, values, shape\n",
    "\n",
    "\n",
    "def sparse_tensor_value_to_texts(value):\n",
    "    \"\"\"\n",
    "    Given a :class:`tf.SparseTensor` ``value``, return an array of Python strings\n",
    "    representing its values.\n",
    "    This function has been modified from Mozilla DeepSpeech:\n",
    "    https://github.com/mozilla/DeepSpeech/blob/master/util/text.py\n",
    "    # This Source Code Form is subject to the terms of the Mozilla Public\n",
    "    # License, v. 2.0. If a copy of the MPL was not distributed with this\n",
    "    # file, You can obtain one at http://mozilla.org/MPL/2.0/.\n",
    "    \"\"\"\n",
    "    return sparse_tuple_to_texts((value.indices, value.values, value.dense_shape))\n",
    "\n",
    "\n",
    "def sparse_tuple_to_texts(tuple):\n",
    "    '''\n",
    "    This function has been modified from Mozilla DeepSpeech:\n",
    "    https://github.com/mozilla/DeepSpeech/blob/master/util/text.py\n",
    "    # This Source Code Form is subject to the terms of the Mozilla Public\n",
    "    # License, v. 2.0. If a copy of the MPL was not distributed with this\n",
    "    # file, You can obtain one at http://mozilla.org/MPL/2.0/.\n",
    "    '''\n",
    "    indices = tuple[0]\n",
    "    values = tuple[1]\n",
    "    results = [''] * tuple[2][0]\n",
    "    for i in range(len(indices)):\n",
    "        index = indices[i][0]\n",
    "        c = values[i]\n",
    "        c = ' ' if c == SPACE_INDEX else chr(c + FIRST_INDEX)\n",
    "        results[index] = results[index] + c\n",
    "    # List of strings\n",
    "    return results\n",
    "\n",
    "\n",
    "def ndarray_to_text(value):\n",
    "    '''\n",
    "    This function has been modified from Mozilla DeepSpeech:\n",
    "    https://github.com/mozilla/DeepSpeech/blob/master/util/text.py\n",
    "    # This Source Code Form is subject to the terms of the Mozilla Public\n",
    "    # License, v. 2.0. If a copy of the MPL was not distributed with this\n",
    "    # file, You can obtain one at http://mozilla.org/MPL/2.0/.\n",
    "    '''\n",
    "    results = ''\n",
    "    for i in range(len(value)):\n",
    "        results += chr(value[i] + FIRST_INDEX)\n",
    "    return results.replace('`', ' ')\n",
    "\n",
    "\n",
    "def gather_nd(params, indices, shape):\n",
    "    '''\n",
    "    # Function aken from https://github.com/tensorflow/tensorflow/issues/206#issuecomment-229678962\n",
    "    '''\n",
    "    rank = len(shape)\n",
    "    flat_params = tf.reshape(params, [-1])\n",
    "    multipliers = [reduce(lambda x, y: x * y, shape[i + 1:], 1) for i in range(0, rank)]\n",
    "    indices_unpacked = tf.unstack(tf.transpose(indices, [rank - 1] + range(0, rank - 1)))\n",
    "    flat_indices = sum([a * b for a, b in zip(multipliers, indices_unpacked)])\n",
    "    return tf.gather(flat_params, flat_indices)\n",
    "\n",
    "\n",
    "def ctc_label_dense_to_sparse(labels, label_lengths, batch_size):\n",
    "    '''\n",
    "    The CTC implementation in TensorFlow needs labels in a sparse representation,\n",
    "    but sparse data and queues don't mix well, so we store padded tensors in the\n",
    "    queue and convert to a sparse representation after dequeuing a batch.\n",
    "    Taken from https://github.com/tensorflow/tensorflow/issues/1742#issuecomment-205291527\n",
    "    '''\n",
    "\n",
    "    # The second dimension of labels must be equal to the longest label length in the batch\n",
    "    correct_shape_assert = tf.assert_equal(tf.shape(labels)[1], tf.reduce_max(label_lengths))\n",
    "    with tf.control_dependencies([correct_shape_assert]):\n",
    "        labels = tf.identity(labels)\n",
    "\n",
    "    label_shape = tf.shape(labels)\n",
    "    num_batches_tns = tf.stack([label_shape[0]])\n",
    "    max_num_labels_tns = tf.stack([label_shape[1]])\n",
    "\n",
    "    def range_less_than(previous_state, current_input):\n",
    "        return tf.expand_dims(tf.range(label_shape[1]), 0) < current_input\n",
    "\n",
    "    init = tf.cast(tf.fill(max_num_labels_tns, 0), tf.bool)\n",
    "    init = tf.expand_dims(init, 0)\n",
    "    dense_mask = tf.scan(range_less_than, label_lengths, initializer=init, parallel_iterations=1)\n",
    "    dense_mask = dense_mask[:, 0, :]\n",
    "\n",
    "    label_array = tf.reshape(tf.tile(tf.range(0, label_shape[1]), num_batches_tns), label_shape)\n",
    "\n",
    "    label_ind = tf.boolean_mask(label_array, dense_mask)\n",
    "\n",
    "    batch_array = tf.transpose(tf.reshape(tf.tile(tf.range(0, label_shape[0]), max_num_labels_tns),\n",
    "                                          tf.reverse(label_shape, [0]))\n",
    "                               )\n",
    "    batch_ind = tf.boolean_mask(batch_array, dense_mask)\n",
    "    batch_label = tf.concat([batch_ind, label_ind], 0)\n",
    "    indices = tf.transpose(tf.reshape(batch_label, [2, -1]))\n",
    "    shape = [batch_size, tf.reduce_max(label_lengths)]\n",
    "    vals_sparse = gather_nd(labels, indices, shape)\n",
    "\n",
    "    return tf.SparseTensor(tf.to_int64(indices), vals_sparse, tf.to_int64(label_shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
