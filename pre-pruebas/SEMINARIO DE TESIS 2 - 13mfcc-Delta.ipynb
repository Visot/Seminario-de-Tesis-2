{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importanción de librerías "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de ficheros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función se encarga de generar un archivo txt de manera que este contenga 2 elementos por fila ('name_file','etiqueta') de esta manera permitirá poder entrenar la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "def generate_file_data(dir,name):\n",
    "    directory=dir\n",
    "    #el nombre de los archivos posee el primer dígito en el nombre de esta forma permitirá etiquetarlos.\n",
    "    a={'0':'cero','1':'uno','2':'dos','3':'tres','4':'cuatro','5':'cinco','6':'seis','7':'siete','8':'ocho','9':'nueve'}\n",
    "    da=os.listdir(directory)\n",
    "    # ordena los archivos\n",
    "    da.sort()\n",
    "    file = open(dir+name+'.txt',\"w\")\n",
    "    for filename in da:\n",
    "        if '.wav' in filename:\n",
    "            file.write(filename+','+a[filename[0]]+'\\n')\n",
    "    file.close() \n",
    "    # genera el fichero\n",
    "    with open(directory+'/'+name+'.txt') as f:\n",
    "        read_data = f.read()\n",
    "        f.closed\n",
    "    read_data=read_data.split('\\n')\n",
    "    read_data=read_data[0:len(read_data)-1]\n",
    "    return read_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding words with One Hot Encoding\n",
    "En esta sección se usará one hot encoding para representar las palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "vocabulary_words=np.array(['cero','uno','dos','tres','cuatro','cinco','seis','siete','ocho','nueve'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore',categories='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories='auto',\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "       n_values=None, sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder.fit(X=vocabulary_words.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['cero', 'cinco', 'cuatro', 'dos', 'nueve', 'ocho', 'seis', 'siete',\n",
       "        'tres', 'uno'], dtype='<U6')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=onehot_encoder.transform(vocabulary_words.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['cero'],\n",
       "       ['uno'],\n",
       "       ['dos'],\n",
       "       ['tres'],\n",
       "       ['cuatro'],\n",
       "       ['cinco'],\n",
       "       ['seis'],\n",
       "       ['siete'],\n",
       "       ['ocho'],\n",
       "       ['nueve']], dtype='<U6')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder.inverse_transform(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se muestran las funciones para codificar y decodificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x):# tomará un array de string y lo transformada a encode\n",
    "    return onehot_encoder.transform(x.reshape(-1,1)).toarray()\n",
    "def decode(x):\n",
    "    return onehot_encoder.inverse_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=encode(np.array(['uno','dos']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['uno'],\n",
       "       ['dos']], dtype='<U6')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_features(DIR,list_dir,mean,delta):\n",
    "    mfccd_audios=[]\n",
    "    for dir in list_dir:\n",
    "        wave, sr = librosa.load(DIR+dir, mono=True,sr=16000)\n",
    "        features= librosa.feature.mfcc(wave, sr,n_mfcc=13)\n",
    "        if delta == True:\n",
    "            features=librosa.feature.delta(features)\n",
    "        if mean == True:\n",
    "            features=sklearn.preprocessing.scale(features)\n",
    "        try:\n",
    "            features=np.pad(features,((0,0),(0,110-len(features[0]))),mode='constant', constant_values=0)\n",
    "        except OSError as err:\n",
    "            print(dir)\n",
    "        mfccd_audios.append(features)\n",
    "        #mfccd_audios.append(np.array([features[0],featuresdelta[0]]))\n",
    "    mfccd_audios=np.array(mfccd_audios)\n",
    "    return mfccd_audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(dir,name,mean,delta):\n",
    "    file = open(dir+name)\n",
    "    f=file.read()\n",
    "    file.close()\n",
    "    f=f.split('\\n')\n",
    "    f=f[0:len(f)-1]\n",
    "    labels=[]\n",
    "    names_audios=[]\n",
    "    for i in f:\n",
    "        j=i.split(',')\n",
    "        names_audios.append(j[0])\n",
    "        labels.append(j[1])\n",
    "    labels=np.array(labels)\n",
    "    onehot= encode(labels)\n",
    "    mfcc=mfcc_features(dir,names_audios,mean,delta)\n",
    "    print(name+' OK')\n",
    "    return mfcc,onehot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    def __init__(self,data):\n",
    "        self.i=0#para el shuffle\n",
    "        self.data_dir=data\n",
    "        self.shuffle=None\n",
    "        self.dir_training=data+'/training/'\n",
    "        self.dir_test=data+'/test/'\n",
    "        self.training_set=None\n",
    "        self.test_set=None\n",
    "    def split_dataset(self):\n",
    "        if os.path.exists(self.dir_training+'training.txt')==False:\n",
    "            generate_file_data(self.dir_training,name='training')\n",
    "        if os.path.exists(self.dir_training+'test.txt')==False:\n",
    "            generate_file_data(self.dir_test,name='test')\n",
    "        print('loadfiles')\n",
    "    def prepare(self,mean,delta):\n",
    "        self.training_set=prepare_data(self.dir_training,'training.txt',mean,delta)\n",
    "        self.test_set=prepare_data(self.dir_test,'test.txt',mean,delta)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loadfiles\n"
     ]
    }
   ],
   "source": [
    "d=dataset('data')\n",
    "d.split_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training.txt OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visoc/anaconda3/envs/tf/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.txt OK\n"
     ]
    }
   ],
   "source": [
    "d.prepare(mean=False,delta=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red neuronal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se definen los distintos modelos a aplicar en este seminario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se dividen los conjuntos\n",
    "trainX, trainY = d.training_set[0],d.training_set[1]\n",
    "testX, testY = d.test_set[0],d.test_set[1]\n",
    "trainX=np.matrix.transpose(trainX,[0,2,1])\n",
    "testX=np.matrix.transpose(testX,[0,2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A continuación mostramos un elemento del training y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.62005689, -6.46370755,  5.88644224, ...,  1.03480394,\n",
       "        -0.60770764,  0.30691467],\n",
       "       [ 8.62005689, -6.46370755,  5.88644224, ...,  1.03480394,\n",
       "        -0.60770764,  0.30691467],\n",
       "       [ 8.62005689, -6.46370755,  5.88644224, ...,  1.03480394,\n",
       "        -0.60770764,  0.30691467],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 110, 13)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.62005689, -6.46370755,  5.88644224, ...,  1.03480394,\n",
       "        -0.60770764,  0.30691467],\n",
       "       [ 8.62005689, -6.46370755,  5.88644224, ...,  1.03480394,\n",
       "        -0.60770764,  0.30691467],\n",
       "       [ 8.62005689, -6.46370755,  5.88644224, ...,  1.03480394,\n",
       "        -0.60770764,  0.30691467],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.61172524,  3.15274442, -0.62109424, ...,  0.46247704,\n",
       "         0.95521544,  0.47579891],\n",
       "       [ 7.61172524,  3.15274442, -0.62109424, ...,  0.46247704,\n",
       "         0.95521544,  0.47579891],\n",
       "       [ 7.61172524,  3.15274442, -0.62109424, ...,  0.46247704,\n",
       "         0.95521544,  0.47579891],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de prueba\n",
    "A continuación presentamos 4 modelos que serán entrenados para el reconocimiento de voz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_simple(name,n_units=128,time_steps=110,n_inputs=13,batch_size=10,n_epochs=400):\n",
    "    n_class=10\n",
    "    dir='Models/Model_'\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.SimpleRNN(128, input_shape=(time_steps,n_inputs)))\n",
    "    model.add(tf.layers.Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    timei=time.time()\n",
    "    history=model.fit(trainX,trainY,batch_size=batch_size,epochs=n_epochs,validation_data=[testX,testY])\n",
    "    timef=time.time()\n",
    "    if os.path.exists(dir+name) == False:\n",
    "        os.mkdir(dir+name)\n",
    "    model.save(dir+name+'/'+name)\n",
    "    t=timef-timei\n",
    "    file = open(dir+name+'/'+name+'_time.txt',\"w\")\n",
    "    file.write(str(t))\n",
    "    file.close()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_simple(name,n_units=128,time_steps=110,n_inputs=13,batch_size=10,n_epochs=400):\n",
    "    n_class=10\n",
    "    dir='Models/Model_'\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(n_units, input_shape=(time_steps,n_inputs)))\n",
    "    model.add(tf.layers.Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    timei=time.time()\n",
    "    history=model.fit(trainX,trainY,batch_size=batch_size,epochs=n_epochs,validation_data=[testX,testY])\n",
    "    timef=time.time()\n",
    "    if os.path.exists(dir+name) == False:\n",
    "        os.mkdir(dir+name)\n",
    "    model.save(dir+name+'/'+name)\n",
    "    t=timef-timei\n",
    "    file = open(dir+name+'/'+name+'_time.txt',\"w\")\n",
    "    file.write(str(t))\n",
    "    file.close()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_with_Dropout(name,n_units=128,time_steps=110,n_inputs=13,batch_size=10,n_epochs=400,dropout=0.5):\n",
    "    n_class=10\n",
    "    dir='Models/Model_'\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(n_units, input_shape=(time_steps,n_inputs)))\n",
    "    model.add(tf.layers.Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    timei=time.time()\n",
    "    history=model.fit(trainX,trainY,batch_size=batch_size,epochs=n_epochs,validation_data=[testX,testY])\n",
    "    timef=time.time()\n",
    "    if os.path.exists(dir+name) == False:\n",
    "        os.mkdir(dir+name)\n",
    "    model.save(dir+name+'/'+name)\n",
    "    t=timef-timei\n",
    "    file = open(dir+name+'/'+name+'_time.txt',\"w\")\n",
    "    file.write(str(t))\n",
    "    file.close()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_with_2layers_1D(name,dropout,n_units=13,time_steps=110,n_inputs=20,batch_size=10,n_epochs=400):\n",
    "    n_class=10\n",
    "    dir='Models/Model_'\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(n_units, input_shape=(time_steps,n_inputs),return_sequences=True))\n",
    "    #model.add(tf.keras.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
    "    model.add(tf.keras.layers.LSTM(n_units, input_shape=(time_steps,n_inputs)))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.layers.Dense(n_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    timei=time.time()\n",
    "    history=model.fit(trainX,trainY,batch_size=batch_size,epochs=n_epochs,validation_data=[testX,testY])\n",
    "    timef=time.time()\n",
    "    if os.path.exists(dir+name) == False:\n",
    "        os.mkdir(dir+name)\n",
    "    model.save(dir+name+'/'+name)\n",
    "    t=timef-timei\n",
    "    file = open(dir+name+'/'+name+'_time.txt',\"w\")\n",
    "    file.write(str(t))\n",
    "    file.close()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting and saving modelo\n",
    "Se presentará una función que graficará los resultados y guardará el modelo y sus datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_saving(history,name):\n",
    "    dir='Models/Model_'\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Precision del Modelo')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Test'], loc='upper left')\n",
    "    plt.savefig(dir+name+'/prec')\n",
    "    plt.show()\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Perdida del modelo')\n",
    "    plt.ylabel('Perdida')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Test'], loc='upper left')\n",
    "    plt.savefig(dir+name+'/cost')\n",
    "    plt.show()\n",
    "    json.dump(history.history, open('Models/Model_'+name+'/'+name+'_history', 'w'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento \n",
    "Entrenaremos distintas con los modelos definidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 110 samples\n",
      "Epoch 1/400\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.3527 - acc: 0.1042 - val_loss: 2.2825 - val_acc: 0.1273\n",
      "Epoch 2/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3536 - acc: 0.1208 - val_loss: 2.4042 - val_acc: 0.1000\n",
      "Epoch 3/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.3973 - acc: 0.0833 - val_loss: 2.3855 - val_acc: 0.0455\n",
      "Epoch 4/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.3632 - acc: 0.1292 - val_loss: 2.3634 - val_acc: 0.1364\n",
      "Epoch 5/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.3862 - acc: 0.1000 - val_loss: 2.3028 - val_acc: 0.1455\n",
      "Epoch 6/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3487 - acc: 0.0958 - val_loss: 2.3192 - val_acc: 0.1364\n",
      "Epoch 7/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.3397 - acc: 0.1083 - val_loss: 2.3377 - val_acc: 0.1182\n",
      "Epoch 8/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3522 - acc: 0.0958 - val_loss: 2.3067 - val_acc: 0.1273\n",
      "Epoch 9/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3362 - acc: 0.1167 - val_loss: 2.3450 - val_acc: 0.1091\n",
      "Epoch 10/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.3407 - acc: 0.1000 - val_loss: 2.3215 - val_acc: 0.1091\n",
      "Epoch 11/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.3360 - acc: 0.0708 - val_loss: 2.3495 - val_acc: 0.0818\n",
      "Epoch 12/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.3020 - acc: 0.1042 - val_loss: 2.3670 - val_acc: 0.1000\n",
      "Epoch 13/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.3697 - acc: 0.0833 - val_loss: 2.3287 - val_acc: 0.0818\n",
      "Epoch 14/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.3323 - acc: 0.1167 - val_loss: 2.3669 - val_acc: 0.1364\n",
      "Epoch 15/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3870 - acc: 0.0792 - val_loss: 2.3557 - val_acc: 0.0818\n",
      "Epoch 16/400\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.3486 - acc: 0.0750 - val_loss: 2.3480 - val_acc: 0.0818\n",
      "Epoch 17/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3390 - acc: 0.1000 - val_loss: 2.3654 - val_acc: 0.1273\n",
      "Epoch 18/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3619 - acc: 0.0958 - val_loss: 2.3901 - val_acc: 0.1000\n",
      "Epoch 19/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3673 - acc: 0.1125 - val_loss: 2.4493 - val_acc: 0.0636\n",
      "Epoch 20/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3415 - acc: 0.1125 - val_loss: 2.3226 - val_acc: 0.1273\n",
      "Epoch 21/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3546 - acc: 0.1000 - val_loss: 2.3979 - val_acc: 0.0727\n",
      "Epoch 22/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3581 - acc: 0.1167 - val_loss: 2.3783 - val_acc: 0.0727\n",
      "Epoch 23/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3241 - acc: 0.0958 - val_loss: 2.3601 - val_acc: 0.1545\n",
      "Epoch 24/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3419 - acc: 0.0917 - val_loss: 2.3970 - val_acc: 0.0727\n",
      "Epoch 25/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3696 - acc: 0.1083 - val_loss: 2.3199 - val_acc: 0.1545\n",
      "Epoch 26/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.3507 - acc: 0.0875 - val_loss: 2.3454 - val_acc: 0.0818\n",
      "Epoch 27/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3638 - acc: 0.0667 - val_loss: 2.4156 - val_acc: 0.0545\n",
      "Epoch 28/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3625 - acc: 0.0833 - val_loss: 2.3569 - val_acc: 0.0909\n",
      "Epoch 29/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.3911 - acc: 0.0542 - val_loss: 2.3319 - val_acc: 0.1182\n",
      "Epoch 30/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3127 - acc: 0.1292 - val_loss: 2.3351 - val_acc: 0.1273\n",
      "Epoch 31/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3774 - acc: 0.1042 - val_loss: 2.4389 - val_acc: 0.0909\n",
      "Epoch 32/400\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.3432 - acc: 0.0875 - val_loss: 2.3591 - val_acc: 0.0818\n",
      "Epoch 33/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.3031 - acc: 0.1125 - val_loss: 2.4350 - val_acc: 0.1000\n",
      "Epoch 34/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2907 - acc: 0.1250 - val_loss: 2.3989 - val_acc: 0.0818\n",
      "Epoch 35/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2885 - acc: 0.1375 - val_loss: 2.4190 - val_acc: 0.0818\n",
      "Epoch 36/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2748 - acc: 0.1250 - val_loss: 2.4138 - val_acc: 0.0909\n",
      "Epoch 37/400\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.2759 - acc: 0.1417 - val_loss: 2.4252 - val_acc: 0.0727\n",
      "Epoch 38/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2661 - acc: 0.1583 - val_loss: 2.4367 - val_acc: 0.0818\n",
      "Epoch 39/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.2752 - acc: 0.1375 - val_loss: 2.4138 - val_acc: 0.0909\n",
      "Epoch 40/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2777 - acc: 0.1375 - val_loss: 2.4181 - val_acc: 0.0818\n",
      "Epoch 41/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2686 - acc: 0.1458 - val_loss: 2.4347 - val_acc: 0.0727\n",
      "Epoch 42/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2948 - acc: 0.1250 - val_loss: 2.4065 - val_acc: 0.0909\n",
      "Epoch 43/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2906 - acc: 0.1500 - val_loss: 2.4176 - val_acc: 0.0636\n",
      "Epoch 44/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2822 - acc: 0.1208 - val_loss: 2.4333 - val_acc: 0.0636\n",
      "Epoch 45/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.2690 - acc: 0.1417 - val_loss: 2.4137 - val_acc: 0.0636\n",
      "Epoch 46/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2703 - acc: 0.1417 - val_loss: 2.3993 - val_acc: 0.0636\n",
      "Epoch 47/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2770 - acc: 0.1208 - val_loss: 2.4310 - val_acc: 0.0636\n",
      "Epoch 48/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2881 - acc: 0.1250 - val_loss: 2.4135 - val_acc: 0.0727\n",
      "Epoch 49/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2910 - acc: 0.1458 - val_loss: 2.4461 - val_acc: 0.0818\n",
      "Epoch 50/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2851 - acc: 0.1333 - val_loss: 2.4209 - val_acc: 0.0636\n",
      "Epoch 51/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.2681 - acc: 0.1542 - val_loss: 2.4218 - val_acc: 0.0545\n",
      "Epoch 52/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2711 - acc: 0.1542 - val_loss: 2.4269 - val_acc: 0.0636\n",
      "Epoch 53/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2822 - acc: 0.1292 - val_loss: 2.4181 - val_acc: 0.0636\n",
      "Epoch 54/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2741 - acc: 0.1458 - val_loss: 2.4172 - val_acc: 0.0727\n",
      "Epoch 55/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2663 - acc: 0.1167 - val_loss: 2.4228 - val_acc: 0.0818\n",
      "Epoch 56/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2678 - acc: 0.1375 - val_loss: 2.4259 - val_acc: 0.0545\n",
      "Epoch 57/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2656 - acc: 0.1417 - val_loss: 2.4338 - val_acc: 0.0818\n",
      "Epoch 58/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2768 - acc: 0.1625 - val_loss: 2.4229 - val_acc: 0.0545\n",
      "Epoch 59/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2713 - acc: 0.1083 - val_loss: 2.4302 - val_acc: 0.1091\n",
      "Epoch 60/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2723 - acc: 0.1333 - val_loss: 2.4188 - val_acc: 0.0727\n",
      "Epoch 61/400\n",
      "240/240 [==============================] - 3s 13ms/step - loss: 2.2726 - acc: 0.1125 - val_loss: 2.4175 - val_acc: 0.0818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/400\n",
      "240/240 [==============================] - 3s 12ms/step - loss: 2.2634 - acc: 0.1208 - val_loss: 2.4467 - val_acc: 0.0818\n",
      "Epoch 63/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2627 - acc: 0.1542 - val_loss: 2.4406 - val_acc: 0.0818\n",
      "Epoch 64/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2588 - acc: 0.1458 - val_loss: 2.4495 - val_acc: 0.0818\n",
      "Epoch 65/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2650 - acc: 0.1333 - val_loss: 2.4445 - val_acc: 0.0545\n",
      "Epoch 66/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.2685 - acc: 0.1583 - val_loss: 2.4419 - val_acc: 0.0727\n",
      "Epoch 67/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2735 - acc: 0.1458 - val_loss: 2.4658 - val_acc: 0.1000\n",
      "Epoch 68/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2695 - acc: 0.1333 - val_loss: 2.4404 - val_acc: 0.0545\n",
      "Epoch 69/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.2573 - acc: 0.1625 - val_loss: 2.4649 - val_acc: 0.0636\n",
      "Epoch 70/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2542 - acc: 0.1625 - val_loss: 2.4431 - val_acc: 0.0727\n",
      "Epoch 71/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.2626 - acc: 0.1417 - val_loss: 2.4507 - val_acc: 0.0727\n",
      "Epoch 72/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2677 - acc: 0.1250 - val_loss: 2.4513 - val_acc: 0.0909\n",
      "Epoch 73/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2519 - acc: 0.1625 - val_loss: 2.4651 - val_acc: 0.0636\n",
      "Epoch 74/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2498 - acc: 0.1542 - val_loss: 2.4782 - val_acc: 0.0545\n",
      "Epoch 75/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2481 - acc: 0.1625 - val_loss: 2.4962 - val_acc: 0.0818\n",
      "Epoch 76/400\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.2455 - acc: 0.1667 - val_loss: 2.4357 - val_acc: 0.1000\n",
      "Epoch 77/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2717 - acc: 0.1458 - val_loss: 2.4689 - val_acc: 0.0909\n",
      "Epoch 78/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2557 - acc: 0.1167 - val_loss: 2.4578 - val_acc: 0.0727\n",
      "Epoch 79/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2754 - acc: 0.1250 - val_loss: 2.4587 - val_acc: 0.0818\n",
      "Epoch 80/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2916 - acc: 0.1208 - val_loss: 2.3969 - val_acc: 0.0636\n",
      "Epoch 81/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2949 - acc: 0.1208 - val_loss: 2.4335 - val_acc: 0.1091\n",
      "Epoch 82/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.3117 - acc: 0.1000 - val_loss: 2.4642 - val_acc: 0.1091\n",
      "Epoch 83/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2784 - acc: 0.1333 - val_loss: 2.5053 - val_acc: 0.0818\n",
      "Epoch 84/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.2700 - acc: 0.0833 - val_loss: 2.5083 - val_acc: 0.0818\n",
      "Epoch 85/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2566 - acc: 0.1667 - val_loss: 2.5168 - val_acc: 0.0818\n",
      "Epoch 86/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2644 - acc: 0.1625 - val_loss: 2.5006 - val_acc: 0.0636\n",
      "Epoch 87/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2617 - acc: 0.1458 - val_loss: 2.5042 - val_acc: 0.0545\n",
      "Epoch 88/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.2548 - acc: 0.1875 - val_loss: 2.5109 - val_acc: 0.0727\n",
      "Epoch 89/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2399 - acc: 0.1625 - val_loss: 2.4963 - val_acc: 0.0727\n",
      "Epoch 90/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2538 - acc: 0.1333 - val_loss: 2.5110 - val_acc: 0.0727\n",
      "Epoch 91/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2637 - acc: 0.1250 - val_loss: 2.5299 - val_acc: 0.0727\n",
      "Epoch 92/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2343 - acc: 0.1750 - val_loss: 2.5235 - val_acc: 0.0727\n",
      "Epoch 93/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.2394 - acc: 0.1333 - val_loss: 2.5056 - val_acc: 0.1182\n",
      "Epoch 94/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2523 - acc: 0.1458 - val_loss: 2.5046 - val_acc: 0.0727\n",
      "Epoch 95/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2653 - acc: 0.1583 - val_loss: 2.5153 - val_acc: 0.0818\n",
      "Epoch 96/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2514 - acc: 0.1292 - val_loss: 2.5167 - val_acc: 0.0545\n",
      "Epoch 97/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2455 - acc: 0.1667 - val_loss: 2.5287 - val_acc: 0.0818\n",
      "Epoch 98/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2333 - acc: 0.1458 - val_loss: 2.5705 - val_acc: 0.1000\n",
      "Epoch 99/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2228 - acc: 0.1292 - val_loss: 2.5299 - val_acc: 0.1182\n",
      "Epoch 100/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2441 - acc: 0.1458 - val_loss: 2.5454 - val_acc: 0.1000\n",
      "Epoch 101/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2414 - acc: 0.1125 - val_loss: 2.5834 - val_acc: 0.0818\n",
      "Epoch 102/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2425 - acc: 0.1458 - val_loss: 2.5736 - val_acc: 0.1000\n",
      "Epoch 103/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2424 - acc: 0.1500 - val_loss: 2.5467 - val_acc: 0.0818\n",
      "Epoch 104/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2466 - acc: 0.1542 - val_loss: 2.6112 - val_acc: 0.0818\n",
      "Epoch 105/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2387 - acc: 0.1625 - val_loss: 2.5734 - val_acc: 0.0909\n",
      "Epoch 106/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2390 - acc: 0.1500 - val_loss: 2.6142 - val_acc: 0.0727\n",
      "Epoch 107/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2452 - acc: 0.1083 - val_loss: 2.5856 - val_acc: 0.0545\n",
      "Epoch 108/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2494 - acc: 0.1583 - val_loss: 2.5986 - val_acc: 0.1182\n",
      "Epoch 109/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2428 - acc: 0.1458 - val_loss: 2.5760 - val_acc: 0.0818\n",
      "Epoch 110/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2302 - acc: 0.1292 - val_loss: 2.6106 - val_acc: 0.0636\n",
      "Epoch 111/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2360 - acc: 0.1292 - val_loss: 2.6006 - val_acc: 0.0727\n",
      "Epoch 112/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2526 - acc: 0.1333 - val_loss: 2.5898 - val_acc: 0.0727\n",
      "Epoch 113/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2229 - acc: 0.1292 - val_loss: 2.5995 - val_acc: 0.0909\n",
      "Epoch 114/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2243 - acc: 0.1375 - val_loss: 2.6062 - val_acc: 0.0727\n",
      "Epoch 115/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2265 - acc: 0.1542 - val_loss: 2.6370 - val_acc: 0.0636\n",
      "Epoch 116/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2257 - acc: 0.1667 - val_loss: 2.6070 - val_acc: 0.1000\n",
      "Epoch 117/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2227 - acc: 0.1500 - val_loss: 2.5866 - val_acc: 0.1182\n",
      "Epoch 118/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2482 - acc: 0.1250 - val_loss: 2.6021 - val_acc: 0.0727\n",
      "Epoch 119/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2301 - acc: 0.1750 - val_loss: 2.5721 - val_acc: 0.0818\n",
      "Epoch 120/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2377 - acc: 0.1125 - val_loss: 2.5916 - val_acc: 0.0545\n",
      "Epoch 121/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2229 - acc: 0.1292 - val_loss: 2.6377 - val_acc: 0.0727\n",
      "Epoch 122/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2198 - acc: 0.1542 - val_loss: 2.5836 - val_acc: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2383 - acc: 0.1458 - val_loss: 2.6214 - val_acc: 0.0818\n",
      "Epoch 124/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2321 - acc: 0.1292 - val_loss: 2.5919 - val_acc: 0.0636\n",
      "Epoch 125/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.2435 - acc: 0.1625 - val_loss: 2.6372 - val_acc: 0.0636\n",
      "Epoch 126/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2223 - acc: 0.1542 - val_loss: 2.5842 - val_acc: 0.1000\n",
      "Epoch 127/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2189 - acc: 0.1500 - val_loss: 2.6011 - val_acc: 0.0818\n",
      "Epoch 128/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2146 - acc: 0.1417 - val_loss: 2.6520 - val_acc: 0.0545\n",
      "Epoch 129/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2199 - acc: 0.1292 - val_loss: 2.6364 - val_acc: 0.0727\n",
      "Epoch 130/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2178 - acc: 0.1417 - val_loss: 2.6306 - val_acc: 0.0727\n",
      "Epoch 131/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2401 - acc: 0.1500 - val_loss: 2.5980 - val_acc: 0.1000\n",
      "Epoch 132/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2041 - acc: 0.1417 - val_loss: 2.6357 - val_acc: 0.0818\n",
      "Epoch 133/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2081 - acc: 0.1292 - val_loss: 2.6401 - val_acc: 0.0636\n",
      "Epoch 134/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2328 - acc: 0.1333 - val_loss: 2.6926 - val_acc: 0.0636\n",
      "Epoch 135/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2222 - acc: 0.1167 - val_loss: 2.6658 - val_acc: 0.0727\n",
      "Epoch 136/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2339 - acc: 0.1125 - val_loss: 2.6436 - val_acc: 0.0545\n",
      "Epoch 137/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2131 - acc: 0.1625 - val_loss: 2.6709 - val_acc: 0.0818\n",
      "Epoch 138/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2372 - acc: 0.1208 - val_loss: 2.6534 - val_acc: 0.0909\n",
      "Epoch 139/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2208 - acc: 0.1417 - val_loss: 2.6671 - val_acc: 0.0636\n",
      "Epoch 140/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2140 - acc: 0.1375 - val_loss: 2.6293 - val_acc: 0.0909\n",
      "Epoch 141/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2048 - acc: 0.1250 - val_loss: 2.6628 - val_acc: 0.0455\n",
      "Epoch 142/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2153 - acc: 0.1375 - val_loss: 2.6474 - val_acc: 0.0636\n",
      "Epoch 143/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2201 - acc: 0.1417 - val_loss: 2.6470 - val_acc: 0.0545\n",
      "Epoch 144/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2245 - acc: 0.1208 - val_loss: 2.6544 - val_acc: 0.0545\n",
      "Epoch 145/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2101 - acc: 0.1208 - val_loss: 2.6914 - val_acc: 0.0636\n",
      "Epoch 146/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2262 - acc: 0.1542 - val_loss: 2.6817 - val_acc: 0.0727\n",
      "Epoch 147/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2236 - acc: 0.1333 - val_loss: 2.6628 - val_acc: 0.0545\n",
      "Epoch 148/400\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.2551 - acc: 0.1500 - val_loss: 2.6672 - val_acc: 0.0727\n",
      "Epoch 149/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2543 - acc: 0.1417 - val_loss: 2.5991 - val_acc: 0.1091\n",
      "Epoch 150/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2219 - acc: 0.1375 - val_loss: 2.6393 - val_acc: 0.0727\n",
      "Epoch 151/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2147 - acc: 0.1542 - val_loss: 2.6439 - val_acc: 0.0364\n",
      "Epoch 152/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2309 - acc: 0.1333 - val_loss: 2.6338 - val_acc: 0.0818\n",
      "Epoch 153/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2173 - acc: 0.1500 - val_loss: 2.6557 - val_acc: 0.0727\n",
      "Epoch 154/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2264 - acc: 0.1375 - val_loss: 2.6149 - val_acc: 0.0727\n",
      "Epoch 155/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.2141 - acc: 0.1292 - val_loss: 2.6462 - val_acc: 0.1000\n",
      "Epoch 156/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2287 - acc: 0.1125 - val_loss: 2.6280 - val_acc: 0.0727\n",
      "Epoch 157/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.2271 - acc: 0.1083 - val_loss: 2.6557 - val_acc: 0.0545\n",
      "Epoch 158/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.2297 - acc: 0.1167 - val_loss: 2.6679 - val_acc: 0.0818\n",
      "Epoch 159/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2084 - acc: 0.1208 - val_loss: 2.6677 - val_acc: 0.0636\n",
      "Epoch 160/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2194 - acc: 0.1125 - val_loss: 2.6456 - val_acc: 0.0909\n",
      "Epoch 161/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2051 - acc: 0.1083 - val_loss: 2.6702 - val_acc: 0.0545\n",
      "Epoch 162/400\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.2160 - acc: 0.1500 - val_loss: 2.6520 - val_acc: 0.0727\n",
      "Epoch 163/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2143 - acc: 0.1250 - val_loss: 2.6581 - val_acc: 0.0455\n",
      "Epoch 164/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2140 - acc: 0.1167 - val_loss: 2.6843 - val_acc: 0.0818\n",
      "Epoch 165/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2168 - acc: 0.1250 - val_loss: 2.6694 - val_acc: 0.0727\n",
      "Epoch 166/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2263 - acc: 0.0917 - val_loss: 2.6481 - val_acc: 0.0727\n",
      "Epoch 167/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2106 - acc: 0.1458 - val_loss: 2.6561 - val_acc: 0.0818\n",
      "Epoch 168/400\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1995 - acc: 0.1375 - val_loss: 2.6670 - val_acc: 0.0818\n",
      "Epoch 169/400\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.1986 - acc: 0.1208 - val_loss: 2.6846 - val_acc: 0.0545\n",
      "Epoch 170/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2191 - acc: 0.1458 - val_loss: 2.7060 - val_acc: 0.0545\n",
      "Epoch 171/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2020 - acc: 0.1333 - val_loss: 2.7050 - val_acc: 0.0636\n",
      "Epoch 172/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.2118 - acc: 0.1583 - val_loss: 2.7130 - val_acc: 0.0636\n",
      "Epoch 173/400\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.2377 - acc: 0.1042 - val_loss: 2.6742 - val_acc: 0.0818\n",
      "Epoch 174/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2539 - acc: 0.1083 - val_loss: 2.6994 - val_acc: 0.0545\n",
      "Epoch 175/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2141 - acc: 0.0958 - val_loss: 2.6873 - val_acc: 0.0818\n",
      "Epoch 176/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2240 - acc: 0.1292 - val_loss: 2.6606 - val_acc: 0.0818\n",
      "Epoch 177/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2104 - acc: 0.1333 - val_loss: 2.6880 - val_acc: 0.0909\n",
      "Epoch 178/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2327 - acc: 0.1333 - val_loss: 2.6726 - val_acc: 0.0636\n",
      "Epoch 179/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2107 - acc: 0.1083 - val_loss: 2.6918 - val_acc: 0.0727\n",
      "Epoch 180/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2101 - acc: 0.1458 - val_loss: 2.6889 - val_acc: 0.0545\n",
      "Epoch 181/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2095 - acc: 0.1250 - val_loss: 2.6891 - val_acc: 0.0545\n",
      "Epoch 182/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2046 - acc: 0.1125 - val_loss: 2.7014 - val_acc: 0.0636\n",
      "Epoch 183/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2133 - acc: 0.0792 - val_loss: 2.7147 - val_acc: 0.0545\n",
      "Epoch 184/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2224 - acc: 0.1333 - val_loss: 2.6709 - val_acc: 0.0455\n",
      "Epoch 185/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2053 - acc: 0.1292 - val_loss: 2.7057 - val_acc: 0.0636\n",
      "Epoch 186/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2110 - acc: 0.1500 - val_loss: 2.6493 - val_acc: 0.0636\n",
      "Epoch 187/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.2071 - acc: 0.1417 - val_loss: 2.6640 - val_acc: 0.0727\n",
      "Epoch 188/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2121 - acc: 0.1292 - val_loss: 2.6424 - val_acc: 0.0818\n",
      "Epoch 189/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.1990 - acc: 0.1292 - val_loss: 2.6379 - val_acc: 0.0273\n",
      "Epoch 190/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2019 - acc: 0.1333 - val_loss: 2.6740 - val_acc: 0.0455\n",
      "Epoch 191/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2022 - acc: 0.1333 - val_loss: 2.6543 - val_acc: 0.0545\n",
      "Epoch 192/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2214 - acc: 0.1125 - val_loss: 2.6779 - val_acc: 0.0455\n",
      "Epoch 193/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2198 - acc: 0.1500 - val_loss: 2.6395 - val_acc: 0.0636\n",
      "Epoch 194/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2067 - acc: 0.1458 - val_loss: 2.6381 - val_acc: 0.0727\n",
      "Epoch 195/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2122 - acc: 0.1417 - val_loss: 2.6550 - val_acc: 0.0545\n",
      "Epoch 196/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2084 - acc: 0.1458 - val_loss: 2.6706 - val_acc: 0.0545\n",
      "Epoch 197/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2176 - acc: 0.1000 - val_loss: 2.6313 - val_acc: 0.0364\n",
      "Epoch 198/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.2106 - acc: 0.1333 - val_loss: 2.6483 - val_acc: 0.0455\n",
      "Epoch 199/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2015 - acc: 0.1375 - val_loss: 2.6433 - val_acc: 0.0545\n",
      "Epoch 200/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2021 - acc: 0.1292 - val_loss: 2.6255 - val_acc: 0.0636\n",
      "Epoch 201/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.1908 - acc: 0.1542 - val_loss: 2.6489 - val_acc: 0.0545\n",
      "Epoch 202/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.1969 - acc: 0.1583 - val_loss: 2.6379 - val_acc: 0.0455\n",
      "Epoch 203/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.1905 - acc: 0.1542 - val_loss: 2.6633 - val_acc: 0.0545\n",
      "Epoch 204/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.1989 - acc: 0.1333 - val_loss: 2.6688 - val_acc: 0.0545\n",
      "Epoch 205/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.1945 - acc: 0.1500 - val_loss: 2.6703 - val_acc: 0.0636\n",
      "Epoch 206/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2019 - acc: 0.1458 - val_loss: 2.6677 - val_acc: 0.0636\n",
      "Epoch 207/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2032 - acc: 0.1500 - val_loss: 2.6551 - val_acc: 0.0545\n",
      "Epoch 208/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.1926 - acc: 0.1375 - val_loss: 2.6620 - val_acc: 0.0818\n",
      "Epoch 209/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2064 - acc: 0.1583 - val_loss: 2.6744 - val_acc: 0.0636\n",
      "Epoch 210/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.1918 - acc: 0.1542 - val_loss: 2.6635 - val_acc: 0.1000\n",
      "Epoch 211/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.2024 - acc: 0.1208 - val_loss: 2.7017 - val_acc: 0.0909\n",
      "Epoch 212/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2079 - acc: 0.1583 - val_loss: 2.6918 - val_acc: 0.0636\n",
      "Epoch 213/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.1928 - acc: 0.1417 - val_loss: 2.6603 - val_acc: 0.1182\n",
      "Epoch 214/400\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.1949 - acc: 0.1292 - val_loss: 2.6655 - val_acc: 0.0545\n",
      "Epoch 215/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.1988 - acc: 0.1417 - val_loss: 2.6982 - val_acc: 0.0636\n",
      "Epoch 216/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2069 - acc: 0.1417 - val_loss: 2.6655 - val_acc: 0.0636\n",
      "Epoch 217/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2166 - acc: 0.1583 - val_loss: 2.6951 - val_acc: 0.0545\n",
      "Epoch 218/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2219 - acc: 0.1500 - val_loss: 2.6796 - val_acc: 0.0636\n",
      "Epoch 219/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2291 - acc: 0.1333 - val_loss: 2.6574 - val_acc: 0.0727\n",
      "Epoch 220/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2006 - acc: 0.1375 - val_loss: 2.6977 - val_acc: 0.0545\n",
      "Epoch 221/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2408 - acc: 0.1125 - val_loss: 2.7132 - val_acc: 0.0636\n",
      "Epoch 222/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.3124 - acc: 0.1125 - val_loss: 2.6708 - val_acc: 0.0545\n",
      "Epoch 223/400\n",
      "240/240 [==============================] - 3s 13ms/step - loss: 2.2464 - acc: 0.1458 - val_loss: 2.5994 - val_acc: 0.0455\n",
      "Epoch 224/400\n",
      "240/240 [==============================] - 3s 12ms/step - loss: 2.2314 - acc: 0.1750 - val_loss: 2.5845 - val_acc: 0.0545\n",
      "Epoch 225/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2301 - acc: 0.1583 - val_loss: 2.5458 - val_acc: 0.0636\n",
      "Epoch 226/400\n",
      "240/240 [==============================] - 3s 12ms/step - loss: 2.2412 - acc: 0.1750 - val_loss: 2.5365 - val_acc: 0.0545\n",
      "Epoch 227/400\n",
      "240/240 [==============================] - 3s 13ms/step - loss: 2.2420 - acc: 0.1542 - val_loss: 2.5410 - val_acc: 0.0545\n",
      "Epoch 228/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2301 - acc: 0.1625 - val_loss: 2.5279 - val_acc: 0.0545\n",
      "Epoch 229/400\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.2376 - acc: 0.1833 - val_loss: 2.5785 - val_acc: 0.0455\n",
      "Epoch 230/400\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.2240 - acc: 0.1500 - val_loss: 2.5121 - val_acc: 0.0727\n",
      "Epoch 231/400\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.2358 - acc: 0.1292 - val_loss: 2.5510 - val_acc: 0.0545\n",
      "Epoch 232/400\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.2182 - acc: 0.1542 - val_loss: 2.5442 - val_acc: 0.0455\n",
      "Epoch 233/400\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.2400 - acc: 0.1708 - val_loss: 2.5302 - val_acc: 0.0727\n",
      "Epoch 234/400\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.2226 - acc: 0.1708 - val_loss: 2.5577 - val_acc: 0.0545\n",
      "Epoch 235/400\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.2276 - acc: 0.1375 - val_loss: 2.5392 - val_acc: 0.0636\n",
      "Epoch 236/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2405 - acc: 0.1375 - val_loss: 2.5445 - val_acc: 0.0818\n",
      "Epoch 237/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2230 - acc: 0.1708 - val_loss: 2.5523 - val_acc: 0.0636\n",
      "Epoch 238/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2261 - acc: 0.1583 - val_loss: 2.5581 - val_acc: 0.0636\n",
      "Epoch 239/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2247 - acc: 0.1750 - val_loss: 2.5594 - val_acc: 0.0727\n",
      "Epoch 240/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2251 - acc: 0.1667 - val_loss: 2.5616 - val_acc: 0.0636\n",
      "Epoch 241/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2197 - acc: 0.1625 - val_loss: 2.5794 - val_acc: 0.0727\n",
      "Epoch 242/400\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.2256 - acc: 0.1542 - val_loss: 2.5477 - val_acc: 0.0818\n",
      "Epoch 243/400\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.2267 - acc: 0.1625 - val_loss: 2.5851 - val_acc: 0.0545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2191 - acc: 0.1583 - val_loss: 2.5620 - val_acc: 0.0636\n",
      "Epoch 245/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2168 - acc: 0.1542 - val_loss: 2.5832 - val_acc: 0.0636\n",
      "Epoch 246/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2160 - acc: 0.1792 - val_loss: 2.5692 - val_acc: 0.0727\n",
      "Epoch 247/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2184 - acc: 0.1250 - val_loss: 2.5942 - val_acc: 0.0727\n",
      "Epoch 248/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2185 - acc: 0.1458 - val_loss: 2.5561 - val_acc: 0.0727\n",
      "Epoch 249/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2010 - acc: 0.1542 - val_loss: 2.5708 - val_acc: 0.0727\n",
      "Epoch 250/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2219 - acc: 0.1542 - val_loss: 2.6088 - val_acc: 0.0818\n",
      "Epoch 251/400\n",
      "240/240 [==============================] - 3s 10ms/step - loss: 2.2136 - acc: 0.1542 - val_loss: 2.5904 - val_acc: 0.0909\n",
      "Epoch 252/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2186 - acc: 0.1583 - val_loss: 2.5771 - val_acc: 0.0727\n",
      "Epoch 253/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2107 - acc: 0.1625 - val_loss: 2.5869 - val_acc: 0.0727\n",
      "Epoch 254/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2197 - acc: 0.1458 - val_loss: 2.5625 - val_acc: 0.0909\n",
      "Epoch 255/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2165 - acc: 0.1583 - val_loss: 2.5690 - val_acc: 0.0909\n",
      "Epoch 256/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2139 - acc: 0.1542 - val_loss: 2.6071 - val_acc: 0.0636\n",
      "Epoch 257/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2091 - acc: 0.1750 - val_loss: 2.6074 - val_acc: 0.0727\n",
      "Epoch 258/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2117 - acc: 0.1500 - val_loss: 2.5758 - val_acc: 0.0818\n",
      "Epoch 259/400\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.2099 - acc: 0.1625 - val_loss: 2.5887 - val_acc: 0.0727\n",
      "Epoch 260/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2052 - acc: 0.1708 - val_loss: 2.5800 - val_acc: 0.0818\n",
      "Epoch 261/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2063 - acc: 0.1583 - val_loss: 2.5908 - val_acc: 0.0727\n",
      "Epoch 262/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.1945 - acc: 0.1833 - val_loss: 2.6033 - val_acc: 0.0636\n",
      "Epoch 263/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2061 - acc: 0.1667 - val_loss: 2.5580 - val_acc: 0.0818\n",
      "Epoch 264/400\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.2079 - acc: 0.1500 - val_loss: 2.5517 - val_acc: 0.0909\n",
      "Epoch 265/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2068 - acc: 0.1458 - val_loss: 2.6166 - val_acc: 0.0727\n",
      "Epoch 266/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.2067 - acc: 0.1167 - val_loss: 2.5260 - val_acc: 0.0909\n",
      "Epoch 267/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2098 - acc: 0.1667 - val_loss: 2.5956 - val_acc: 0.0818\n",
      "Epoch 268/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2066 - acc: 0.1375 - val_loss: 2.5573 - val_acc: 0.0818\n",
      "Epoch 269/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2153 - acc: 0.1333 - val_loss: 2.5613 - val_acc: 0.1091\n",
      "Epoch 270/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.1947 - acc: 0.1458 - val_loss: 2.5661 - val_acc: 0.0727\n",
      "Epoch 271/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.1906 - acc: 0.1375 - val_loss: 2.5709 - val_acc: 0.0818\n",
      "Epoch 272/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.1948 - acc: 0.1500 - val_loss: 2.5702 - val_acc: 0.1091\n",
      "Epoch 273/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2081 - acc: 0.1667 - val_loss: 2.5632 - val_acc: 0.1182\n",
      "Epoch 274/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2041 - acc: 0.1125 - val_loss: 2.5744 - val_acc: 0.1091\n",
      "Epoch 275/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.1969 - acc: 0.1708 - val_loss: 2.5510 - val_acc: 0.0909\n",
      "Epoch 276/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.1963 - acc: 0.1458 - val_loss: 2.5748 - val_acc: 0.0818\n",
      "Epoch 277/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2119 - acc: 0.1375 - val_loss: 2.5625 - val_acc: 0.0909\n",
      "Epoch 278/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2052 - acc: 0.1708 - val_loss: 2.5890 - val_acc: 0.0909\n",
      "Epoch 279/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.1929 - acc: 0.1750 - val_loss: 2.5817 - val_acc: 0.0727\n",
      "Epoch 280/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.1985 - acc: 0.1583 - val_loss: 2.5983 - val_acc: 0.0818\n",
      "Epoch 281/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2029 - acc: 0.1583 - val_loss: 2.5778 - val_acc: 0.0909\n",
      "Epoch 282/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.2062 - acc: 0.1417 - val_loss: 2.5949 - val_acc: 0.0818\n",
      "Epoch 283/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2229 - acc: 0.1458 - val_loss: 2.5727 - val_acc: 0.1091\n",
      "Epoch 284/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2028 - acc: 0.1625 - val_loss: 2.5886 - val_acc: 0.0727\n",
      "Epoch 285/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2044 - acc: 0.1667 - val_loss: 2.5860 - val_acc: 0.0909\n",
      "Epoch 286/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2005 - acc: 0.1458 - val_loss: 2.5973 - val_acc: 0.0636\n",
      "Epoch 287/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2114 - acc: 0.1458 - val_loss: 2.5785 - val_acc: 0.0818\n",
      "Epoch 288/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2209 - acc: 0.1583 - val_loss: 2.5616 - val_acc: 0.1091\n",
      "Epoch 289/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2081 - acc: 0.1458 - val_loss: 2.5984 - val_acc: 0.0727\n",
      "Epoch 290/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2079 - acc: 0.1625 - val_loss: 2.5501 - val_acc: 0.0818\n",
      "Epoch 291/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2032 - acc: 0.1375 - val_loss: 2.5730 - val_acc: 0.1000\n",
      "Epoch 292/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2171 - acc: 0.1417 - val_loss: 2.5715 - val_acc: 0.0909\n",
      "Epoch 293/400\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.2105 - acc: 0.1333 - val_loss: 2.5496 - val_acc: 0.0818\n",
      "Epoch 294/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2063 - acc: 0.1708 - val_loss: 2.5643 - val_acc: 0.0727\n",
      "Epoch 295/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2202 - acc: 0.1500 - val_loss: 2.5558 - val_acc: 0.0636\n",
      "Epoch 296/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2202 - acc: 0.1458 - val_loss: 2.5717 - val_acc: 0.0727\n",
      "Epoch 297/400\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.2024 - acc: 0.1542 - val_loss: 2.5404 - val_acc: 0.1000\n",
      "Epoch 298/400\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 2.2172 - acc: 0.1458 - val_loss: 2.5585 - val_acc: 0.0909\n",
      "Epoch 299/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2192 - acc: 0.1542 - val_loss: 2.5559 - val_acc: 0.0909\n",
      "Epoch 300/400\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.2108 - acc: 0.1583 - val_loss: 2.5864 - val_acc: 0.0636\n",
      "Epoch 301/400\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 2.2099 - acc: 0.1625 - val_loss: 2.5706 - val_acc: 0.0636\n",
      "Epoch 302/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2091 - acc: 0.1542 - val_loss: 2.5519 - val_acc: 0.1091\n",
      "Epoch 303/400\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2096 - acc: 0.1708 - val_loss: 2.5817 - val_acc: 0.0727\n",
      "Epoch 304/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/240 [======================>.......] - ETA: 0s - loss: 2.2094 - acc: 0.1789"
     ]
    }
   ],
   "source": [
    "RNN=RNN_simple('RNNsimple13mfcc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_saving(RNN,'RNNsimple13mfcc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_SIMPLE=LSTM_simple(name='LSTM_13mfcc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_saving(LSTM_SIMPLE,name='LSTM_13mfcc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMD5=LSTM_with_Dropout('LSTM_Dropout5_mfcc13',dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_saving(LSTMD5,name='LSTM_Dropout5_mfcc13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMD8=LSTM_with_Dropout('LSTM_Dropout8_mfcc13',dropout=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_saving(LSTMD8,name='LSTM_Dropout8_mfcc13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM2_1=LSTM_with_2layers_1D('LSTM_2Layer1DDelta8',dropout=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_saving(LSTM2_1,name='LSTM_2Layer1D_13mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM2_1iter900=LSTM_with_2layers_1D('LSTM_2Layer1D_13mfcc_Delta8',dropout=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM2_1iter900=LSTM_with_2layers_1D('LSTM_2Layer1D_13mfcc_Delta8',dropout=0.8)\n",
    "plot_and_saving(LSTM2_1,name='LSTM_2Layer1D_13mfcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(dir):\n",
    "    m=tf.keras.models.load_model(dir)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recording audios and predict them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8e68eb1c774a59a8b114ebe183cd9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Record', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "button1 = widgets.Button(description=\"Record\",)\n",
    "button2 = widgets.Button(description='Test')\n",
    "display(button)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    print(\"Button clicked.\")\n",
    "\n",
    "button1.on_click(on_button_clicked)\n",
    "button2.on_click(on_button_clicked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording...\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    " \n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 48000#44100\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 2\n",
    "WAVE_OUTPUT_FILENAME = \"file.wav\"\n",
    " \n",
    "audio = pyaudio.PyAudio()\n",
    " \n",
    "# start Recording\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                rate=RATE, input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "print (\"recording...\")\n",
    "frames = []\n",
    " \n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "print (\"finished recording\")\n",
    " \n",
    " \n",
    "# stop Recording\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    " \n",
    "waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "waveFile.setnchannels(CHANNELS)\n",
    "waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "waveFile.setframerate(RATE)\n",
    "waveFile.writeframes(b''.join(frames))\n",
    "waveFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'wave' from '/home/visoc/anaconda3/envs/tf/lib/python3.6/wave.py'>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "wave, sr = librosa.load('file.wav', mono=True)\n",
    "features= librosa.feature.mfcc(wave, sr,n_mfcc=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00155109, -0.00390198, -0.00120344, ...,  0.00196864,\n",
       "        0.00147835,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = sklearn.preprocessing.scale(features, axis=1)\n",
    "features=np.pad(features,((0,0),(0,160-len(features[0]))),mode='constant', constant_values=0)\n",
    "f=np.matrix.transpose(np.array([features]),[0,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=model.predict_classes(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Sequential.get_config of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f4076c35128>>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['cuatro']], dtype='<U6')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(np.eye(10)[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=class_to_integer_encoded(label[0]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['seis'], dtype='<U6')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.inverse_transform(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
